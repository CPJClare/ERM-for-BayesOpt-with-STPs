{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Import modules:\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.latex.preamble']=[r'\\usepackage{amsmath}']\n",
    "plt.rcParams['text.latex.preamble'] = [r'\\boldmath']\n",
    "from matplotlib.pyplot import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=False)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from numpy.linalg import slogdet\n",
    "from scipy.linalg import inv\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gamma\n",
    "from scipy.stats import norm, t\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from pyGPGO.logger import EventLogger\n",
    "from pyGPGO.GPGO import GPGO\n",
    "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
    "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
    "from pyGPGO.surrogates.tStudentProcess import logpdf\n",
    "from pyGPGO.acquisition import Acquisition\n",
    "from pyGPGO.covfunc import squaredExponential, matern32, matern52\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. User-defined - inputs:\n",
    "\n",
    "### Objective Function:\n",
    "obj_func = 'Rosenbrock' # 2-D;\n",
    "\n",
    "### Data inputs:\n",
    "n_test = 50\n",
    "\n",
    "### Student-t parameter input:\n",
    "df1 = 5 # Degree(s)-of-freedom (DF)\n",
    "\n",
    "### Acquisition / Utility function - MLE/Type II:\n",
    "util_gp = 'RegretMinimized' # Gaussian MLE\n",
    "util_stp = 'tRegretMinimized' # Student-t MLE\n",
    "\n",
    "#util_gp = 'ExpectedImprovement' # Gaussian MLE\n",
    "#util_stp = 'tExpectedImprovement' # Student-t MLE\n",
    "\n",
    "### Probabilistic / Surrogate / Stochastic model - MLE/Type II: \n",
    "#surrogate_model_gp = 'Gaussian Process'\n",
    "surrogate_model_stp = 'Student-t Process'\n",
    "\n",
    "### Covariance Function:\n",
    "cov_func = squaredExponential()\n",
    "#cov_func = matern32()\n",
    "#cov_func = matern52()\n",
    "\n",
    "n_init = 5  # Number of iterations used to initialise Bayesian optimisation; minimum 2\n",
    "\n",
    "### MLE / Type II Empirical Bayes:\n",
    "optimize = False # MLE Boolean\n",
    "usegrads = False # MLE Boolean (pyGPGO not programmed for Student-t MLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. Objective Function - Rosenbrock(x) 2-D:\n",
    "\n",
    "if obj_func == 'Rosenbrock':\n",
    "            \n",
    "    # True y bounds:\n",
    "    y_lb = 0\n",
    "    operator = -1 # targets global minimum \n",
    "    y_global_orig = y_lb * operator # targets global minimum\n",
    "            \n",
    "# Constraints:\n",
    "    lb = -2.048 \n",
    "    ub = +2.048 \n",
    "    \n",
    "# Input array dimension(s):\n",
    "    dim = 2\n",
    "\n",
    "# 2-D inputs' parameter bounds:\n",
    "    param = {'x1_training': ('cont', [lb, ub]),\n",
    "             'x2_training': ('cont', [lb, ub])}\n",
    "    \n",
    "    max_iter = (10 * dim)*0 + 100  # iterations of Bayesian optimisation\n",
    "    \n",
    "# Test data:\n",
    "    x1_test = np.linspace(lb, ub, n_test)\n",
    "    x2_test = np.linspace(lb, ub, n_test)\n",
    "    Xstar_d = np.column_stack((x1_test, x2_test))\n",
    "    \n",
    "    def f_syn_polarity(x1_training, x2_training):\n",
    "        return operator * (100 * (x2_training - x1_training ** 2) ** 2 + (x1_training - 1) ** 2)\n",
    "      \n",
    "    def f_syn_transform_polarity(x1_training, x2_training):\n",
    "            return operator * (np.sqrt(2 * (y_global_orig - f_syn_polarity(x1_training, x2_training))))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4a. Add new acquisition functions: add CBM & ERM (Nyugen and Osborne, 2019) method .\n",
    "\n",
    "### Inherits from class Acquisition()\n",
    "\n",
    "class Acquisition_new(Acquisition):    \n",
    "    def __init__(self, mode, eps=1e-06, **params):\n",
    "        \"\"\"\n",
    "        Acquisition function class.\n",
    "        Parameters\n",
    "        ----------\n",
    "        mode: str\n",
    "            Defines the behaviour of the acquisition strategy.\n",
    "        eps: float\n",
    "            Small floating value to avoid `np.sqrt` or zero-division warnings.\n",
    "        params: float\n",
    "            Extra parameters needed for certain acquisition functions, e.g. UCB needs\n",
    "            to be supplied with `beta`.\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.eps = eps\n",
    "\n",
    "        mode_dict = {\n",
    "            'ExpectedImprovement': self.ExpectedImprovement,\n",
    "            'tExpectedImprovement': self.tExpectedImprovement,\n",
    "            'RegretMinimized': self.RegretMinimized,\n",
    "            'tRegretMinimized': self.tRegretMinimized\n",
    "        }\n",
    "\n",
    "        self.f = mode_dict[mode]\n",
    "   \n",
    "    def ExpectedImprovement(self, tau, mean, std):\n",
    "        \"\"\"\n",
    "        Expected Improvement acquisition function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tau: float\n",
    "            Best observed function evaluation.\n",
    "        mean: float\n",
    "            Point mean of the posterior process.\n",
    "        std: float\n",
    "            Point std of the posterior process.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Expected improvement.\n",
    "        \"\"\"\n",
    "        z = (mean - tau - self.eps) / (std + self.eps)\n",
    "        return (mean - tau) * norm.cdf(z) + std * norm.pdf(z)[0]\n",
    "\n",
    "\n",
    "    def RegretMinimized(self, tau, mean, std):\n",
    "        \"\"\"\n",
    "        Regret Minimized acquisition function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tau: float\n",
    "            Best observed function evaluation.\n",
    "        mean: float\n",
    "            Point mean of the posterior process.\n",
    "        std: float\n",
    "            Point std of the posterior process.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Expected improvement.\n",
    "        \"\"\"\n",
    "        \n",
    "        z = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
    "        return z * (std + self.eps) * norm.cdf(z) + std * norm.pdf(z)[0]\n",
    "    \n",
    "    \n",
    "    def tExpectedImprovement(self, tau, mean, std, nu=3.0):\n",
    "        \"\"\"\n",
    "        Expected Improvement acquisition function. Only to be used with `tStudentProcess` surrogate.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tau: float\n",
    "            Best observed function evaluation.\n",
    "        mean: float\n",
    "            Point mean of the posterior process.\n",
    "        std: float\n",
    "            Point std of the posterior process.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Expected improvement.\n",
    "        \"\"\"\n",
    "        gamma = (mean - tau - self.eps) / (std + self.eps)\n",
    "        return gamma * std * t.cdf(gamma, df=nu) + std * (1 + (gamma ** 2 - 1)/(nu - 1)) * t.pdf(gamma, df=nu)\n",
    "    \n",
    "    \n",
    "    def tRegretMinimized(self, tau, mean, std, nu=3.0):\n",
    "        \"\"\"\n",
    "        Regret Minimized acquisition function. Only to be used with `tStudentProcess` surrogate.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tau: float\n",
    "            Best observed function evaluation.\n",
    "        mean: float\n",
    "            Point mean of the posterior process.\n",
    "        std: float\n",
    "            Point std of the posterior process.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Expected improvement.\n",
    "        \"\"\"\n",
    "        \n",
    "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
    "        return gamma * (std + self.eps) * t.cdf(gamma, df=nu) + std * (nu + gamma ** 2)/(nu - 1) * t.pdf(gamma, df=nu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4b. Re-define tStudentProcess class with non-zero prior mean function:\n",
    "\n",
    "### [Nyugen and Osborne, 2019] \"Knowing The What But Not The Where in Bayesian Optimization\"\n",
    "\n",
    "### Inherits from class tStudentProcess()\n",
    "\n",
    "class tStudentProcess_prior(tStudentProcess):\n",
    "    def __init__(self, covfunc, nu, optimize=False, mprior=0):\n",
    "        \"\"\"\n",
    "        t-Student Process regressor class.\n",
    "        This class DOES NOT support gradients in ML estimation yet.\n",
    "        Parameters\n",
    "        ----------\n",
    "        covfunc: instance from a class of covfunc module\n",
    "            An instance from a class from the `covfunc` module.\n",
    "        nu: float\n",
    "            (>2.0) Degrees of freedom\n",
    "        Attributes\n",
    "        ----------\n",
    "        covfunc: object\n",
    "            Internal covariance function.\n",
    "        nu: float\n",
    "            Degrees of freedom.\n",
    "        optimize: bool\n",
    "            Whether to optimize covariance function hyperparameters.\n",
    "        \"\"\"\n",
    "        self.covfunc = covfunc\n",
    "        self.nu = nu\n",
    "        self.optimize = optimize\n",
    "        self.mprior = mprior\n",
    "        \n",
    "    def logpdf(x, nu, Sigma):\n",
    "        \"\"\"\n",
    "        Marginal log-likelihood of a Student-t Process\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: array-like\n",
    "            Point to be evaluated\n",
    "        df: float\n",
    "            Degrees of freedom (>2.0)\n",
    "        mu: array-like\n",
    "            Mean of the process.\n",
    "        Sigma: array-like\n",
    "            Covariance matrix of the process.\n",
    "        Returns\n",
    "        -------\n",
    "        logp: float\n",
    "            log-likelihood \n",
    "        \"\"\"\n",
    "        d = len(x)\n",
    "        x = np.atleast_2d(x)\n",
    "        xm = x - self.mprior\n",
    "        V = nu * Sigma\n",
    "        V_inv = np.linalg.inv(V)\n",
    "        _, logdet = slogdet(np.pi * V)\n",
    "\n",
    "        logz = -gamma(nu / 2.0 + d / 2.0) + gamma(nu / 2.0) + 0.5 * logdet\n",
    "        logp = -0.5 * (nu + d) * np.log(1 + np.sum(np.dot(xm, V_inv) * xm, axis=1))\n",
    "\n",
    "        logp = logp - logz\n",
    "\n",
    "        return logp[0]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits a t-Student Process regressor\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray, shape=(nsamples, nfeatures)\n",
    "            Training instances to fit the GP.\n",
    "        y: np.ndarray, shape=(nsamples,)\n",
    "            Corresponding continuous target values to `X`.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n1 = X.shape[0]\n",
    "\n",
    "        if self.optimize:\n",
    "            self.optHyp(param_key=self.covfunc.parameters, param_bounds=self.covfunc.bounds)\n",
    "\n",
    "        self.K11 = self.covfunc.K(self.X, self.X)\n",
    "        self.beta1 = np.dot(np.dot(self.y.T, inv(self.K11)), self.y)\n",
    "        self.logp = logpdf(self.y, self.nu, mu=self.mprior, Sigma=self.K11)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5a. Cumulative Regret Calculator:\n",
    "\n",
    "def min_max_array(x):\n",
    "    new_list = []\n",
    "    for i, num in enumerate(x):\n",
    "            new_list.append(np.min(x[0:i+1]))\n",
    "    return new_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5b. Set-seeds:\n",
    "\n",
    "run_num_1 = 111\n",
    "run_num_2 = 222\n",
    "run_num_3 = 333\n",
    "run_num_4 = 444\n",
    "run_num_5 = 555\n",
    "run_num_6 = 666\n",
    "run_num_7 = 777\n",
    "run_num_8 = 888\n",
    "run_num_9 = 999\n",
    "run_num_10 = 1000\n",
    "run_num_11 = 1111\n",
    "run_num_12 = 1222\n",
    "run_num_13 = 1333\n",
    "run_num_14 = 1444\n",
    "run_num_15 = 1555\n",
    "run_num_16 = 1666\n",
    "run_num_17 = 1777\n",
    "run_num_18 = 1888\n",
    "run_num_19 = 1999\n",
    "run_num_20 = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.45944904 -1.35549029]. \t  -245.71064611316496 \t -108.5713485785257\n",
      "init   \t [-0.26190226  1.10289909]. \t  -108.5713485785257 \t -108.5713485785257\n",
      "init   \t [-0.83834755 -1.43702853]. \t  -461.2775269355244 \t -108.5713485785257\n",
      "init   \t [-1.95592878 -0.32676048]. \t  -1732.9949421003257 \t -108.5713485785257\n",
      "init   \t [-1.07035795 -0.66496024]. \t  -332.12317010404104 \t -108.5713485785257\n",
      "1      \t [-0.22246619 -0.23774559]. \t  \u001b[92m-9.744921046208802\u001b[0m \t -9.744921046208802\n",
      "2      \t [-0.44259375 -0.41212289]. \t  -39.0489503873149 \t -9.744921046208802\n",
      "3      \t [ 1.38387453 -0.09997218]. \t  -406.2024592983455 \t -9.744921046208802\n",
      "4      \t [-0.16665495  0.08681731]. \t  \u001b[92m-1.7096965758921434\u001b[0m \t -1.7096965758921434\n",
      "5      \t [ 1.53746043 -2.048     ]. \t  -1946.6731855791215 \t -1.7096965758921434\n",
      "6      \t [0.04198276 0.29493309]. \t  -9.512693379708264 \t -1.7096965758921434\n",
      "7      \t [ 1.78803192 -0.60648493]. \t  -1447.3149830671293 \t -1.7096965758921434\n",
      "8      \t [1.53108397 1.0603866 ]. \t  -165.10439098121483 \t -1.7096965758921434\n",
      "9      \t [0.58686362 0.11291338]. \t  -5.529699506533904 \t -1.7096965758921434\n",
      "10     \t [-1.46718824  0.91875406]. \t  -158.33479736047443 \t -1.7096965758921434\n",
      "11     \t [-1.74048852  1.90210593]. \t  -134.5669896122083 \t -1.7096965758921434\n",
      "12     \t [-0.94792857  1.03619938]. \t  -5.688649619839159 \t -1.7096965758921434\n",
      "13     \t [ 0.24301262 -0.13160409]. \t  -4.208123832979571 \t -1.7096965758921434\n",
      "14     \t [0.9684561 1.7270646]. \t  -62.27793206271763 \t -1.7096965758921434\n",
      "15     \t [-0.13798151  1.2120092 ]. \t  -143.61281532895606 \t -1.7096965758921434\n",
      "16     \t [-0.43805569  0.3064678 ]. \t  -3.380747551456502 \t -1.7096965758921434\n",
      "17     \t [1.02381855 2.048     ]. \t  -99.95968733819728 \t -1.7096965758921434\n",
      "18     \t [ 0.74775298 -0.63960254]. \t  -143.7606812354837 \t -1.7096965758921434\n",
      "19     \t [-1.27748718  1.27771382]. \t  -17.736939660519692 \t -1.7096965758921434\n",
      "20     \t [1.58184171 1.11098514]. \t  -193.89287342355146 \t -1.7096965758921434\n",
      "21     \t [0.84228287 0.70428779]. \t  \u001b[92m-0.027529658614248012\u001b[0m \t -0.027529658614248012\n",
      "22     \t [0.8053464  0.54015317]. \t  -1.2135892189172595 \t -0.027529658614248012\n",
      "23     \t [1.06089113 1.82174536]. \t  -48.480860367576014 \t -0.027529658614248012\n",
      "24     \t [-1.92372447 -0.91331464]. \t  -2137.475875853538 \t -0.027529658614248012\n",
      "25     \t [-0.53301038  0.06339445]. \t  -7.221217698408557 \t -0.027529658614248012\n",
      "26     \t [-0.08235995  0.39477545]. \t  -16.22530470798019 \t -0.027529658614248012\n",
      "27     \t [-1.13241307  1.71344778]. \t  -23.130907183586356 \t -0.027529658614248012\n",
      "28     \t [-1.02080879 -0.13940014]. \t  -143.66625118755718 \t -0.027529658614248012\n",
      "29     \t [1.0372993 1.0937724]. \t  -0.03301318607314278 \t -0.027529658614248012\n",
      "30     \t [0.95964351 0.90722491]. \t  \u001b[92m-0.020372347530900253\u001b[0m \t -0.020372347530900253\n",
      "31     \t [0.96924208 0.93445639]. \t  \u001b[92m-0.0034199452627614335\u001b[0m \t -0.0034199452627614335\n",
      "32     \t [0.53386496 0.02594546]. \t  -6.928818537696993 \t -0.0034199452627614335\n",
      "33     \t [-1.39253331 -0.59085225]. \t  -645.8148494698042 \t -0.0034199452627614335\n",
      "34     \t [-0.85840066  1.22147162]. \t  -26.939300528904813 \t -0.0034199452627614335\n",
      "35     \t [ 0.81411133 -0.95859836]. \t  -262.92044163522456 \t -0.0034199452627614335\n",
      "36     \t [-1.23462122  0.38938055]. \t  -133.79537733532314 \t -0.0034199452627614335\n",
      "37     \t [0.68281647 0.45551651]. \t  -0.11210114314710315 \t -0.0034199452627614335\n",
      "38     \t [-0.26683513 -0.66227277]. \t  -55.40324609566223 \t -0.0034199452627614335\n",
      "39     \t [0.96809271 1.0329298 ]. \t  -0.9173704463288109 \t -0.0034199452627614335\n",
      "40     \t [-1.53740048  1.2231408 ]. \t  -136.50317180697115 \t -0.0034199452627614335\n",
      "41     \t [1.9426309 1.9633803]. \t  -328.65586656807943 \t -0.0034199452627614335\n",
      "42     \t [0.08183052 1.23046565]. \t  -150.60419279831945 \t -0.0034199452627614335\n",
      "43     \t [-1.16223016 -1.42849377]. \t  -777.1109183233424 \t -0.0034199452627614335\n",
      "44     \t [-1.04316404  1.15873988]. \t  -4.672230813198803 \t -0.0034199452627614335\n",
      "45     \t [0.74327672 1.96714473]. \t  -200.19911334585981 \t -0.0034199452627614335\n",
      "46     \t [-2.01047749 -0.74297611]. \t  -2298.681505002316 \t -0.0034199452627614335\n",
      "47     \t [-1.21082569  1.68390588]. \t  -9.631740102570523 \t -0.0034199452627614335\n",
      "48     \t [-1.33437787  0.68815167]. \t  -124.78585917988336 \t -0.0034199452627614335\n",
      "49     \t [-0.23094754 -1.61276938]. \t  -279.10620252253784 \t -0.0034199452627614335\n",
      "50     \t [0.66014216 1.64749383]. \t  -146.93868689891644 \t -0.0034199452627614335\n",
      "51     \t [-0.43226986  1.33958364]. \t  -134.92921491596502 \t -0.0034199452627614335\n",
      "52     \t [1.22158747 1.08415614]. \t  -16.70527922550893 \t -0.0034199452627614335\n",
      "53     \t [ 0.16555488 -0.53612718]. \t  -32.4535352858786 \t -0.0034199452627614335\n",
      "54     \t [ 0.42173736 -1.26611057]. \t  -208.84018173094518 \t -0.0034199452627614335\n",
      "55     \t [-0.5189422  -1.68782909]. \t  -385.34301020541506 \t -0.0034199452627614335\n",
      "56     \t [-0.95070309  1.48236624]. \t  -37.27492459488175 \t -0.0034199452627614335\n",
      "57     \t [ 0.54384183 -0.89280069]. \t  -141.4766651669655 \t -0.0034199452627614335\n",
      "58     \t [0.8051323  0.49947153]. \t  -2.2511201711580875 \t -0.0034199452627614335\n",
      "59     \t [0.40937437 1.18707475]. \t  -104.28428965658428 \t -0.0034199452627614335\n",
      "60     \t [1.02250523 1.72285278]. \t  -45.878888676329034 \t -0.0034199452627614335\n",
      "61     \t [-0.54492688 -0.24007982]. \t  -31.226397664342578 \t -0.0034199452627614335\n",
      "62     \t [0.25962153 1.26514291]. \t  -144.0061684773042 \t -0.0034199452627614335\n",
      "63     \t [-1.12854391  1.29562523]. \t  -4.57916022324821 \t -0.0034199452627614335\n",
      "64     \t [-1.00705448  1.16548517]. \t  -6.318237027567069 \t -0.0034199452627614335\n",
      "65     \t [-0.21515472  1.99157176]. \t  -379.8881065908075 \t -0.0034199452627614335\n",
      "66     \t [0.97254944 0.91457515]. \t  -0.0985801857821006 \t -0.0034199452627614335\n",
      "67     \t [ 1.46348283 -1.48988797]. \t  -1319.1174901038878 \t -0.0034199452627614335\n",
      "68     \t [-1.95064235 -0.88388403]. \t  -2207.274882433743 \t -0.0034199452627614335\n",
      "69     \t [0.16198391 0.10840563]. \t  -1.3774100518971923 \t -0.0034199452627614335\n",
      "70     \t [-1.55333206 -1.38547729]. \t  -1449.24130480916 \t -0.0034199452627614335\n",
      "71     \t [1.27468998 0.27710306]. \t  -181.71346766613016 \t -0.0034199452627614335\n",
      "72     \t [-0.28009762  1.23351318]. \t  -135.0546635396757 \t -0.0034199452627614335\n",
      "73     \t [0.58992994 0.36899586]. \t  -0.21216727382353945 \t -0.0034199452627614335\n",
      "74     \t [0.44485672 0.22472667]. \t  -0.38016447122718194 \t -0.0034199452627614335\n",
      "75     \t [-0.24921281  0.39865629]. \t  -12.887073322359871 \t -0.0034199452627614335\n",
      "76     \t [-0.52180996 -0.0714736 ]. \t  -14.132946809213406 \t -0.0034199452627614335\n",
      "77     \t [ 0.215878   -0.57694162]. \t  -39.495675767076335 \t -0.0034199452627614335\n",
      "78     \t [1.02999374 2.00653251]. \t  -89.42542473466041 \t -0.0034199452627614335\n",
      "79     \t [-0.4332399 -0.1926707]. \t  -16.522120495331716 \t -0.0034199452627614335\n",
      "80     \t [1.0443921  1.09219307]. \t  \u001b[92m-0.002177505215474416\u001b[0m \t -0.002177505215474416\n",
      "81     \t [ 0.66521893 -0.23347934]. \t  -45.80907842624932 \t -0.002177505215474416\n",
      "82     \t [1.03839203 1.07938241]. \t  \u001b[92m-0.0016003741043034985\u001b[0m \t -0.0016003741043034985\n",
      "83     \t [0.80777678 0.66365278]. \t  -0.049380795879166925 \t -0.0016003741043034985\n",
      "84     \t [1.18993284 1.65277456]. \t  -5.6451275735506075 \t -0.0016003741043034985\n",
      "85     \t [-1.82086888  0.66929264]. \t  -708.232246310807 \t -0.0016003741043034985\n",
      "86     \t [ 0.74271154 -1.83825245]. \t  -571.2154314512803 \t -0.0016003741043034985\n",
      "87     \t [-0.39927098  1.30131624]. \t  -132.3512741366938 \t -0.0016003741043034985\n",
      "88     \t [0.60696291 0.37760409]. \t  -0.16294235908038157 \t -0.0016003741043034985\n",
      "89     \t [0.88647147 0.72135748]. \t  -0.42858072349503895 \t -0.0016003741043034985\n",
      "90     \t [ 1.21960029 -0.11987661]. \t  -258.3900302193461 \t -0.0016003741043034985\n",
      "91     \t [1.10224874 1.21526272]. \t  -0.010464442113477274 \t -0.0016003741043034985\n",
      "92     \t [ 1.46806628 -0.6833924 ]. \t  -805.9903261107626 \t -0.0016003741043034985\n",
      "93     \t [1.10093847 1.23767273]. \t  -0.07576147281820803 \t -0.0016003741043034985\n",
      "94     \t [-1.17118342  0.76949043]. \t  -40.976133562082566 \t -0.0016003741043034985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95     \t [ 1.65361628 -1.69356049]. \t  -1961.1520765663745 \t -0.0016003741043034985\n",
      "96     \t [-1.65372101 -1.45526157]. \t  -1762.698113551249 \t -0.0016003741043034985\n",
      "97     \t [1.00035869 0.99881315]. \t  \u001b[92m-0.0003627891011106931\u001b[0m \t -0.0003627891011106931\n",
      "98     \t [ 1.72114382 -0.85529876]. \t  -1457.9536047382583 \t -0.0003627891011106931\n",
      "99     \t [0.34268958 0.38226986]. \t  -7.445746616971624 \t -0.0003627891011106931\n",
      "100    \t [-1.0954881   0.33887054]. \t  -78.56168510444935 \t -0.0003627891011106931\n"
     ]
    }
   ],
   "source": [
    "### 6(a). Bayesian optimization runs (x20): GP run number = 1\n",
    "\n",
    "np.random.seed(run_num_1)\n",
    "surrogate_gp_1 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_1 = GPGO(surrogate_gp_1, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_1.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.45944904 -1.35549029]. \t  -245.71064611316496 \t -108.5713485785257\n",
      "init   \t [-0.26190226  1.10289909]. \t  -108.5713485785257 \t -108.5713485785257\n",
      "init   \t [-0.83834755 -1.43702853]. \t  -461.2775269355244 \t -108.5713485785257\n",
      "init   \t [-1.95592878 -0.32676048]. \t  -1732.9949421003257 \t -108.5713485785257\n",
      "init   \t [-1.07035795 -0.66496024]. \t  -332.12317010404104 \t -108.5713485785257\n",
      "1      \t [-0.04757384 -0.15629853]. \t  \u001b[92m-3.611595436434821\u001b[0m \t -3.611595436434821\n",
      "2      \t [2.048 2.048]. \t  -461.7603900415999 \t -3.611595436434821\n",
      "3      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -3.611595436434821\n",
      "4      \t [-1.82647855  2.048     ]. \t  -173.88953548190548 \t -3.611595436434821\n",
      "5      \t [0.32457068 2.048     ]. \t  -377.84661210889266 \t -3.611595436434821\n",
      "6      \t [2.048      0.44714658]. \t  -1405.2171761267687 \t -3.611595436434821\n",
      "7      \t [-0.81571825  2.048     ]. \t  -194.45614394166262 \t -3.611595436434821\n",
      "8      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -3.611595436434821\n",
      "9      \t [-0.25388743 -0.99587221]. \t  -114.002423340225 \t -3.611595436434821\n",
      "10     \t [-0.00783991 -2.048     ]. \t  -420.4713173668341 \t -3.611595436434821\n",
      "11     \t [-1.13833338  0.75726034]. \t  -33.57527690761273 \t -3.611595436434821\n",
      "12     \t [ 0.89746026 -0.29412596]. \t  -120.91392832611469 \t -3.611595436434821\n",
      "13     \t [0.78590159 0.83702972]. \t  -4.858965675921405 \t -3.611595436434821\n",
      "14     \t [-2.048       1.24784829]. \t  -877.4504282182344 \t -3.611595436434821\n",
      "15     \t [-0.65264528  0.32988937]. \t  -3.653921368716344 \t -3.611595436434821\n",
      "16     \t [0.45036843 0.32772487]. \t  \u001b[92m-1.861924868473305\u001b[0m \t -1.861924868473305\n",
      "17     \t [1.21403932 2.048     ]. \t  -33.00587349739072 \t -1.861924868473305\n",
      "18     \t [-1.10355443  1.42974203]. \t  -8.915511543134244 \t -1.861924868473305\n",
      "19     \t [1.02428062 1.52050711]. \t  -22.218268520838812 \t -1.861924868473305\n",
      "20     \t [ 0.4361207  -0.55224395]. \t  -55.44044917558038 \t -1.861924868473305\n",
      "21     \t [ 2.048      -0.66616116]. \t  -2363.510461570233 \t -1.861924868473305\n",
      "22     \t [-0.8554625   0.98982013]. \t  -10.099350063797171 \t -1.861924868473305\n",
      "23     \t [-1.36241223  2.048     ]. \t  -9.26097828511137 \t -1.861924868473305\n",
      "24     \t [0.60055584 1.24145292]. \t  -77.73788401162741 \t -1.861924868473305\n",
      "25     \t [-0.58713834 -0.25652967]. \t  -38.670500085438285 \t -1.861924868473305\n",
      "26     \t [ 0.72523546 -2.048     ]. \t  -662.6058373402145 \t -1.861924868473305\n",
      "27     \t [0.85704292 0.29429068]. \t  -19.400848153603583 \t -1.861924868473305\n",
      "28     \t [1.48522338 1.4584947 ]. \t  -56.09519145407957 \t -1.861924868473305\n",
      "29     \t [1.12523659 1.15062651]. \t  \u001b[92m-1.3504221830356737\u001b[0m \t -1.3504221830356737\n",
      "30     \t [-0.25472163  0.27508484]. \t  -5.992803162982313 \t -1.3504221830356737\n",
      "31     \t [1.48803855 2.048     ]. \t  -3.0023775588648896 \t -1.3504221830356737\n",
      "32     \t [1.34603525 1.75845203]. \t  \u001b[92m-0.40445712853791516\u001b[0m \t -0.40445712853791516\n",
      "33     \t [0.51198065 0.02924762]. \t  -5.661312422321559 \t -0.40445712853791516\n",
      "34     \t [-1.35908048  1.79598113]. \t  -5.826571961316794 \t -0.40445712853791516\n",
      "35     \t [-0.7835894 -2.048    ]. \t  -711.8121630311471 \t -0.40445712853791516\n",
      "36     \t [1.18208937 1.39459567]. \t  \u001b[92m-0.033907090789757684\u001b[0m \t -0.033907090789757684\n",
      "37     \t [ 1.13534505 -1.27308851]. \t  -656.4523612037175 \t -0.033907090789757684\n",
      "38     \t [-1.20645996  1.79542203]. \t  -16.420061380984723 \t -0.033907090789757684\n",
      "39     \t [0.76913589 0.55195129]. \t  -0.21026257889998975 \t -0.033907090789757684\n",
      "40     \t [0.14956387 0.05034421]. \t  -0.8015008532246627 \t -0.033907090789757684\n",
      "41     \t [-2.048      -1.14719315]. \t  -2862.44948342464 \t -0.033907090789757684\n",
      "42     \t [-0.82841294  0.6586853 ]. \t  -3.419174375944698 \t -0.033907090789757684\n",
      "43     \t [-0.14086763  0.03826365]. \t  -1.3355084474150354 \t -0.033907090789757684\n",
      "44     \t [1.36970078 1.89913116]. \t  -0.18981324929106116 \t -0.033907090789757684\n",
      "45     \t [1.41033592 2.03002813]. \t  -0.3363175378435924 \t -0.033907090789757684\n",
      "46     \t [-1.17551367  1.24320008]. \t  -6.654751017322241 \t -0.033907090789757684\n",
      "47     \t [0.61362986 0.36128282]. \t  -0.17256493344084986 \t -0.033907090789757684\n",
      "48     \t [1.22800217 1.46061518]. \t  -0.27641597606568863 \t -0.033907090789757684\n",
      "49     \t [1.0967049  1.22407101]. \t  -0.05476076448377039 \t -0.033907090789757684\n",
      "50     \t [0.81749406 0.65431894]. \t  -0.0528457292951675 \t -0.033907090789757684\n",
      "51     \t [0.70376927 0.4640604 ]. \t  -0.18528879395150433 \t -0.033907090789757684\n",
      "52     \t [1.24448276 1.55837998]. \t  -0.06906985481908197 \t -0.033907090789757684\n",
      "53     \t [1.08907214 1.21165894]. \t  -0.07337161926166125 \t -0.033907090789757684\n",
      "54     \t [0.94901477 0.90129757]. \t  \u001b[92m-0.0026441877294442998\u001b[0m \t -0.0026441877294442998\n",
      "55     \t [0.84540659 0.66655037]. \t  -0.2558562598387005 \t -0.0026441877294442998\n",
      "56     \t [1.39319171 2.03782759]. \t  -1.0924843620084872 \t -0.0026441877294442998\n",
      "57     \t [1.25241785 1.54276073]. \t  -0.13022587051772616 \t -0.0026441877294442998\n",
      "58     \t [0.73715846 0.53636412]. \t  -0.07403968459756638 \t -0.0026441877294442998\n",
      "59     \t [0.75855203 0.55903979]. \t  -0.08506661374449971 \t -0.0026441877294442998\n",
      "60     \t [1.1768558  1.41838114]. \t  -0.14277768349791176 \t -0.0026441877294442998\n",
      "61     \t [0.03730709 0.04399182]. \t  -1.1082536640930511 \t -0.0026441877294442998\n",
      "62     \t [1.10941924 1.23588378]. \t  -0.014545837129786554 \t -0.0026441877294442998\n",
      "63     \t [0.78542249 0.5603454 ]. \t  -0.3657554886242552 \t -0.0026441877294442998\n",
      "64     \t [0.77374147 0.6090553 ]. \t  -0.06196618742145213 \t -0.0026441877294442998\n",
      "65     \t [0.7685892  0.57930285]. \t  -0.06660745363665733 \t -0.0026441877294442998\n",
      "66     \t [0.89170146 0.77752272]. \t  -0.042735456453106044 \t -0.0026441877294442998\n",
      "67     \t [1.08048965 1.17891086]. \t  -0.019595634447948172 \t -0.0026441877294442998\n",
      "68     \t [0.58030806 0.31242197]. \t  -0.2353628420447037 \t -0.0026441877294442998\n",
      "69     \t [0.97362802 0.96326054]. \t  -0.024132085179728414 \t -0.0026441877294442998\n",
      "70     \t [1.20428147 1.43618353]. \t  -0.06164106850780179 \t -0.0026441877294442998\n",
      "71     \t [0.79694529 0.65416029]. \t  -0.07747763434602004 \t -0.0026441877294442998\n",
      "72     \t [0.67540194 0.43882621]. \t  -0.13543688139067972 \t -0.0026441877294442998\n",
      "73     \t [1.4307772 2.048    ]. \t  -0.18564583925717734 \t -0.0026441877294442998\n",
      "74     \t [0.74379707 0.54855463]. \t  -0.0678296612912663 \t -0.0026441877294442998\n",
      "75     \t [0.70917163 0.47919496]. \t  -0.14088975309544174 \t -0.0026441877294442998\n",
      "76     \t [1.04382177 1.10856731]. \t  -0.0380333342747488 \t -0.0026441877294442998\n",
      "77     \t [1.4227359 2.048    ]. \t  -0.23545706157959556 \t -0.0026441877294442998\n",
      "78     \t [0.7082059  0.46952458]. \t  -0.18774243135207963 \t -0.0026441877294442998\n",
      "79     \t [0.64020338 0.35119648]. \t  -0.4735988931260716 \t -0.0026441877294442998\n",
      "80     \t [1.05733503 1.06879499]. \t  -0.24498128884251294 \t -0.0026441877294442998\n",
      "81     \t [1.18976186 1.41793025]. \t  -0.03658410536247918 \t -0.0026441877294442998\n",
      "82     \t [1.08882841 1.18168732]. \t  -0.009380436610223718 \t -0.0026441877294442998\n",
      "83     \t [0.88229639 0.77452824]. \t  -0.015389738287154557 \t -0.0026441877294442998\n",
      "84     \t [0.77162236 0.59211649]. \t  -0.0532351882095599 \t -0.0026441877294442998\n",
      "85     \t [1.34477223 1.76879558]. \t  -0.2758167528317227 \t -0.0026441877294442998\n",
      "86     \t [1.12494542 1.25953358]. \t  -0.01917379923614791 \t -0.0026441877294442998\n",
      "87     \t [1.31052883 1.69832971]. \t  -0.1331238219008743 \t -0.0026441877294442998\n",
      "88     \t [0.69581555 0.44122189]. \t  -0.2768901066690016 \t -0.0026441877294442998\n",
      "89     \t [0.80706148 0.66803317]. \t  -0.06506400381222 \t -0.0026441877294442998\n",
      "90     \t [0.88130633 0.79718308]. \t  -0.056040424920185454 \t -0.0026441877294442998\n",
      "91     \t [1.18322613 1.41624665]. \t  -0.05988898543129686 \t -0.0026441877294442998\n",
      "92     \t [1.37139022 1.91070382]. \t  -0.2278868805907748 \t -0.0026441877294442998\n",
      "93     \t [1.42619604 2.048     ]. \t  -0.20114478050635823 \t -0.0026441877294442998\n",
      "94     \t [1.25834216 1.58472841]. \t  -0.06691056168559409 \t -0.0026441877294442998\n",
      "95     \t [-0.31531509 -1.6738613 ]. \t  -316.1839906603448 \t -0.0026441877294442998\n",
      "96     \t [1.36639993 1.87793325]. \t  -0.146096092077071 \t -0.0026441877294442998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [1.05498413 1.12829332]. \t  -0.026437768641870946 \t -0.0026441877294442998\n",
      "98     \t [-2.048       0.50690122]. \t  -1368.9842308447046 \t -0.0026441877294442998\n",
      "99     \t [0.79652656 0.63594732]. \t  -0.04162427912642141 \t -0.0026441877294442998\n",
      "100    \t [0.23945969 0.03533717]. \t  -0.6268381854126626 \t -0.0026441877294442998\n"
     ]
    }
   ],
   "source": [
    "### 6(a). Bayesian optimization runs (x20): STP DF1 run number = 1\n",
    "\n",
    "np.random.seed(run_num_1)\n",
    "surrogate_stp_df1_1 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_1 = GPGO(surrogate_stp_df1_1, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_1.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.92168888121452, -5.935391357454109)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(a). Training Regret Minimisation: run number = 1\n",
    "\n",
    "gp_output_1 = np.append(np.max(gpgo_gp_1.GP.y[0:n_init]),gpgo_gp_1.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_1 = np.append(np.max(gpgo_stp_df1_1.GP.y[0:n_init]),gpgo_stp_df1_1.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_1 = np.log(y_global_orig - gp_output_1)\n",
    "regret_stp_df1_1 = np.log(y_global_orig - stp_df1_output_1)\n",
    "\n",
    "train_regret_gp_1 = min_max_array(regret_gp_1)\n",
    "train_regret_stp_df1_1 = min_max_array(regret_stp_df1_1)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 1\n",
    "min_train_regret_gp_1 = min(train_regret_gp_1)\n",
    "min_train_regret_stp_df1_1 = min(train_regret_stp_df1_1)\n",
    "\n",
    "min_train_regret_gp_1, min_train_regret_stp_df1_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.10661243 0.75905919]. \t  -56.702620456131505 \t -56.702620456131505\n",
      "init   \t [1.37492148 0.6298225 ]. \t  -159.04841388329066 \t -56.702620456131505\n",
      "init   \t [-1.89635807 -1.3100824 ]. \t  -2415.524020089492 \t -56.702620456131505\n",
      "init   \t [ 1.06729234 -1.12924829]. \t  -514.5507928619267 \t -56.702620456131505\n",
      "init   \t [ 0.96311326 -0.87043907]. \t  -323.2911877214845 \t -56.702620456131505\n",
      "1      \t [ 0.49506782 -0.01340997]. \t  \u001b[92m-6.937290997452454\u001b[0m \t -6.937290997452454\n",
      "2      \t [-0.69800286  2.04422543]. \t  -245.31354538913362 \t -6.937290997452454\n",
      "3      \t [-1.96227849  2.02994006]. \t  -340.23237122094275 \t -6.937290997452454\n",
      "4      \t [ 1.06056397 -1.70340679]. \t  -799.8767332263327 \t -6.937290997452454\n",
      "5      \t [1.82460814 1.83801802]. \t  -223.04081357989017 \t -6.937290997452454\n",
      "6      \t [-1.74627654 -0.39596112]. \t  -1194.6497024706387 \t -6.937290997452454\n",
      "7      \t [0.43579625 0.06994297]. \t  \u001b[92m-1.7577355286428062\u001b[0m \t -1.7577355286428062\n",
      "8      \t [-0.08697099  0.2494343 ]. \t  -7.0316323905510165 \t -1.7577355286428062\n",
      "9      \t [0.20764166 0.17392609]. \t  -2.338984429832546 \t -1.7577355286428062\n",
      "10     \t [-0.23928387  0.51527856]. \t  -22.51422026288923 \t -1.7577355286428062\n",
      "11     \t [0.2510654 0.2408425]. \t  -3.7224951378377416 \t -1.7577355286428062\n",
      "12     \t [-0.89909867  0.57608708]. \t  -9.00250257279332 \t -1.7577355286428062\n",
      "13     \t [-0.94703609  0.31089017]. \t  -38.12904794975383 \t -1.7577355286428062\n",
      "14     \t [0.94583131 0.89328423]. \t  \u001b[92m-0.0031065475553809004\u001b[0m \t -0.0031065475553809004\n",
      "15     \t [0.87966329 1.25727152]. \t  -23.388226270309108 \t -0.0031065475553809004\n",
      "16     \t [0.77585952 0.79724114]. \t  -3.8637894542628013 \t -0.0031065475553809004\n",
      "17     \t [0.98637429 1.03237966]. \t  -0.35356162652648443 \t -0.0031065475553809004\n",
      "18     \t [ 0.4073052  -1.14435127]. \t  -172.0264782217725 \t -0.0031065475553809004\n",
      "19     \t [ 1.98324911 -1.61764297]. \t  -3082.238073268025 \t -0.0031065475553809004\n",
      "20     \t [ 0.20275419 -0.80472038]. \t  -72.17837867229753 \t -0.0031065475553809004\n",
      "21     \t [ 0.13916456 -0.12219312]. \t  -2.7449578970194906 \t -0.0031065475553809004\n",
      "22     \t [0.29235928 0.05284153]. \t  -0.6072428591826868 \t -0.0031065475553809004\n",
      "23     \t [ 0.27540152 -1.34526876]. \t  -202.48175756912792 \t -0.0031065475553809004\n",
      "24     \t [-1.87714358 -0.20404532]. \t  -1397.8626317139503 \t -0.0031065475553809004\n",
      "25     \t [-0.60292574 -0.56972614]. \t  -89.66410358831632 \t -0.0031065475553809004\n",
      "26     \t [-0.60293556  0.28662976]. \t  -3.1607869899369043 \t -0.0031065475553809004\n",
      "27     \t [-1.78527401  1.26051056]. \t  -378.9722411264166 \t -0.0031065475553809004\n",
      "28     \t [ 0.60495182 -0.67827519]. \t  -109.20017647659726 \t -0.0031065475553809004\n",
      "29     \t [0.46353375 0.59347833]. \t  -14.622712013019521 \t -0.0031065475553809004\n",
      "30     \t [-0.90496109  1.8530625 ]. \t  -110.56679731152373 \t -0.0031065475553809004\n",
      "31     \t [0.95744714 0.94889126]. \t  -0.1054061290115317 \t -0.0031065475553809004\n",
      "32     \t [-1.14694449  1.34991991]. \t  -4.7279699544125275 \t -0.0031065475553809004\n",
      "33     \t [1.97894272 1.23298629]. \t  -720.9295762793761 \t -0.0031065475553809004\n",
      "34     \t [ 1.76365541 -0.89139434]. \t  -1602.083312921408 \t -0.0031065475553809004\n",
      "35     \t [0.34141639 1.71186717]. \t  -254.93258586140834 \t -0.0031065475553809004\n",
      "36     \t [1.38148255 2.048     ]. \t  -2.09172069975315 \t -0.0031065475553809004\n",
      "37     \t [ 1.02196339 -1.06260125]. \t  -443.9497773067598 \t -0.0031065475553809004\n",
      "38     \t [ 0.88717868 -0.01510376]. \t  -64.36357298063604 \t -0.0031065475553809004\n",
      "39     \t [ 1.49797575 -1.72634631]. \t  -1576.5584495547532 \t -0.0031065475553809004\n",
      "40     \t [-0.9881953   1.03359792]. \t  -4.278595822252034 \t -0.0031065475553809004\n",
      "41     \t [-1.31504078 -1.38627306]. \t  -976.0590573594378 \t -0.0031065475553809004\n",
      "42     \t [-1.73937811  1.50553684]. \t  -238.5136015567562 \t -0.0031065475553809004\n",
      "43     \t [ 1.7971075  -0.28697846]. \t  -1237.2645281224368 \t -0.0031065475553809004\n",
      "44     \t [0.85252453 0.66729532]. \t  -0.37580670588958975 \t -0.0031065475553809004\n",
      "45     \t [-1.50335245  0.68240286]. \t  -255.1696928991652 \t -0.0031065475553809004\n",
      "46     \t [-1.38840189  2.048     ]. \t  -7.152639958877707 \t -0.0031065475553809004\n",
      "47     \t [-0.00647174 -1.74670757]. \t  -306.1263502055893 \t -0.0031065475553809004\n",
      "48     \t [-1.33589156  1.81609606]. \t  -5.555550149687946 \t -0.0031065475553809004\n",
      "49     \t [ 1.59814083 -1.76621878]. \t  -1866.8335507256538 \t -0.0031065475553809004\n",
      "50     \t [-0.36277037 -0.89113163]. \t  -106.45562090993928 \t -0.0031065475553809004\n",
      "51     \t [-1.99714215 -0.72589485]. \t  -2231.6071150604716 \t -0.0031065475553809004\n",
      "52     \t [1.17568671 1.26321144]. \t  -1.4476273091977312 \t -0.0031065475553809004\n",
      "53     \t [0.89007069 0.77164552]. \t  -0.05443937498899498 \t -0.0031065475553809004\n",
      "54     \t [-2.00593401 -0.99920331]. \t  -2532.062980168114 \t -0.0031065475553809004\n",
      "55     \t [-1.33181025  1.07223603]. \t  -54.64511105319513 \t -0.0031065475553809004\n",
      "56     \t [-0.30567352 -1.02656318]. \t  -127.1446683255367 \t -0.0031065475553809004\n",
      "57     \t [0.38789162 1.63252876]. \t  -220.02748664764226 \t -0.0031065475553809004\n",
      "58     \t [-1.19904158 -0.65138152]. \t  -441.2622414496609 \t -0.0031065475553809004\n",
      "59     \t [1.28266027 1.71919969]. \t  -0.6272350301148854 \t -0.0031065475553809004\n",
      "60     \t [0.63012858 0.38245008]. \t  -0.15815575368691756 \t -0.0031065475553809004\n",
      "61     \t [-0.21133981  0.02670116]. \t  -1.4996123586289407 \t -0.0031065475553809004\n",
      "62     \t [ 1.95597783 -0.71293251]. \t  -2060.9679045961693 \t -0.0031065475553809004\n",
      "63     \t [ 1.97299601 -0.54409178]. \t  -1969.4706044984232 \t -0.0031065475553809004\n",
      "64     \t [1.04076151 1.35671492]. \t  -7.483549214921184 \t -0.0031065475553809004\n",
      "65     \t [0.07213341 1.72030139]. \t  -295.01710596592426 \t -0.0031065475553809004\n",
      "66     \t [1.13467856 1.30015147]. \t  -0.03415584410186111 \t -0.0031065475553809004\n",
      "67     \t [ 1.19484446 -0.18668364]. \t  -260.6463329595147 \t -0.0031065475553809004\n",
      "68     \t [-0.70572097  0.10346812]. \t  -18.478345261598392 \t -0.0031065475553809004\n",
      "69     \t [1.1503203  1.33942071]. \t  -0.04878806919393464 \t -0.0031065475553809004\n",
      "70     \t [ 1.15882338 -1.73646469]. \t  -948.2564383318849 \t -0.0031065475553809004\n",
      "71     \t [ 1.99174224 -0.32235845]. \t  -1840.8750179751987 \t -0.0031065475553809004\n",
      "72     \t [1.92854593 1.48517236]. \t  -499.9900940063513 \t -0.0031065475553809004\n",
      "73     \t [-0.39713205 -1.91137637]. \t  -430.0654176248116 \t -0.0031065475553809004\n",
      "74     \t [1.08882404 1.19330241]. \t  -0.013918631256092646 \t -0.0031065475553809004\n",
      "75     \t [0.9795546  0.98447608]. \t  -0.06266265653781093 \t -0.0031065475553809004\n",
      "76     \t [ 1.11414403 -0.85468847]. \t  -439.3368852377307 \t -0.0031065475553809004\n",
      "77     \t [0.61102975 0.36741858]. \t  -0.1548247553319469 \t -0.0031065475553809004\n",
      "78     \t [1.24267322 1.8964984 ]. \t  -12.467717444624244 \t -0.0031065475553809004\n",
      "79     \t [0.7023131  0.51672518]. \t  -0.14375549083111405 \t -0.0031065475553809004\n",
      "80     \t [0.76084671 1.97794177]. \t  -195.79242037531458 \t -0.0031065475553809004\n",
      "81     \t [1.45225166 1.47285399]. \t  -40.67714289158654 \t -0.0031065475553809004\n",
      "82     \t [0.55946458 0.24887137]. \t  -0.6053274973737636 \t -0.0031065475553809004\n",
      "83     \t [0.59947114 0.35324674]. \t  -0.1641674668062552 \t -0.0031065475553809004\n",
      "84     \t [ 1.59144387 -1.8585282 ]. \t  -1928.6326833007556 \t -0.0031065475553809004\n",
      "85     \t [ 1.65019572 -0.4592428 ]. \t  -1013.1825433179065 \t -0.0031065475553809004\n",
      "86     \t [-0.04885738 -0.96086447]. \t  -93.88544949461347 \t -0.0031065475553809004\n",
      "87     \t [-0.94803192 -0.09832123]. \t  -103.21283000649417 \t -0.0031065475553809004\n",
      "88     \t [ 1.03367022 -0.07079455]. \t  -129.7944439685133 \t -0.0031065475553809004\n",
      "89     \t [-1.2730849  -0.95832773]. \t  -670.3286115243 \t -0.0031065475553809004\n",
      "90     \t [1.32470909 1.73793491]. \t  -0.13406215227691926 \t -0.0031065475553809004\n",
      "91     \t [-1.25259766 -1.497755  ]. \t  -945.5733748840523 \t -0.0031065475553809004\n",
      "92     \t [-0.97499849 -1.617978  ]. \t  -663.6712441353293 \t -0.0031065475553809004\n",
      "93     \t [1.80048075 1.01648557]. \t  -495.81246842023796 \t -0.0031065475553809004\n",
      "94     \t [-0.02464621  0.06277581]. \t  -1.4363905487422592 \t -0.0031065475553809004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95     \t [0.02344799 0.84588291]. \t  -72.41245897837452 \t -0.0031065475553809004\n",
      "96     \t [0.55717288 0.30999826]. \t  -0.19611551169872077 \t -0.0031065475553809004\n",
      "97     \t [-0.71434245  0.82781638]. \t  -13.021579666895601 \t -0.0031065475553809004\n",
      "98     \t [-1.16410722  0.17073232]. \t  -144.96684617326616 \t -0.0031065475553809004\n",
      "99     \t [-1.14450898 -1.73933682]. \t  -934.3839238116695 \t -0.0031065475553809004\n",
      "100    \t [-1.77801292  0.10744283]. \t  -940.3400170288595 \t -0.0031065475553809004\n"
     ]
    }
   ],
   "source": [
    "### 6(b). Bayesian optimization runs (x20): GP run number = 2\n",
    "\n",
    "np.random.seed(run_num_2)\n",
    "surrogate_gp_2 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_2 = GPGO(surrogate_gp_2, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_2.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.10661243 0.75905919]. \t  -56.702620456131505 \t -56.702620456131505\n",
      "init   \t [1.37492148 0.6298225 ]. \t  -159.04841388329066 \t -56.702620456131505\n",
      "init   \t [-1.89635807 -1.3100824 ]. \t  -2415.524020089492 \t -56.702620456131505\n",
      "init   \t [ 1.06729234 -1.12924829]. \t  -514.5507928619267 \t -56.702620456131505\n",
      "init   \t [ 0.96311326 -0.87043907]. \t  -323.2911877214845 \t -56.702620456131505\n",
      "1      \t [-2.048  2.048]. \t  -469.9523900415999 \t -56.702620456131505\n",
      "2      \t [2.048 2.048]. \t  -461.7603900415999 \t -56.702620456131505\n",
      "3      \t [-0.07866976  2.048     ]. \t  -418.0627724060575 \t -56.702620456131505\n",
      "4      \t [ 2.048      -0.25883864]. \t  -1984.1462430784259 \t -56.702620456131505\n",
      "5      \t [ 0.13470663 -0.47220248]. \t  \u001b[92m-24.792883440356857\u001b[0m \t -24.792883440356857\n",
      "6      \t [0.63948687 0.29992064]. \t  \u001b[92m-1.3185672025321913\u001b[0m \t -1.3185672025321913\n",
      "7      \t [0.97454613 1.36310756]. \t  -17.08790909430167 \t -1.3185672025321913\n",
      "8      \t [ 0.05161541 -2.048     ]. \t  -421.421779288898 \t -1.3185672025321913\n",
      "9      \t [-1.46721148  0.812672  ]. \t  -185.65719256145746 \t -1.3185672025321913\n",
      "10     \t [-0.95021448  1.42929699]. \t  -31.51191908167009 \t -1.3185672025321913\n",
      "11     \t [ 0.36009088 -1.01078027]. \t  -130.4711264724407 \t -1.3185672025321913\n",
      "12     \t [-0.72480203  0.68519116]. \t  -5.530245844868258 \t -1.3185672025321913\n",
      "13     \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -1.3185672025321913\n",
      "14     \t [2.048     1.2412199]. \t  -873.1688749177457 \t -1.3185672025321913\n",
      "15     \t [-1.11118692  2.048     ]. \t  -70.59688455237712 \t -1.3185672025321913\n",
      "16     \t [-0.71290354 -0.18212739]. \t  -50.59357161416335 \t -1.3185672025321913\n",
      "17     \t [0.92699858 0.872774  ]. \t  \u001b[92m-0.02341310429872985\u001b[0m \t -0.02341310429872985\n",
      "18     \t [1.19821114 2.048     ]. \t  -37.52919945033611 \t -0.02341310429872985\n",
      "19     \t [-0.27700665  0.1146348 ]. \t  -1.7744030252984904 \t -0.02341310429872985\n",
      "20     \t [-2.048       0.11384543]. \t  -1674.3045220487847 \t -0.02341310429872985\n",
      "21     \t [-0.91695732 -2.048     ]. \t  -838.1974707157109 \t -0.02341310429872985\n",
      "22     \t [-0.4640533  -0.96847765]. \t  -142.28716972618645 \t -0.02341310429872985\n",
      "23     \t [-1.4272204   1.51776281]. \t  -32.847769505539596 \t -0.02341310429872985\n",
      "24     \t [-2.048      1.2508981]. \t  -875.6541322484994 \t -0.02341310429872985\n",
      "25     \t [-1.11228202  1.09474177]. \t  -6.490352031511336 \t -0.02341310429872985\n",
      "26     \t [0.55384577 1.5457058 ]. \t  -153.7014062210999 \t -0.02341310429872985\n",
      "27     \t [ 0.75569792 -2.048     ]. \t  -686.0173495820447 \t -0.02341310429872985\n",
      "28     \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -0.02341310429872985\n",
      "29     \t [ 0.29878616 -0.00761476]. \t  -1.4304279005767473 \t -0.02341310429872985\n",
      "30     \t [1.39125655 1.79003037]. \t  -2.2719814141338412 \t -0.02341310429872985\n",
      "31     \t [-1.47268525  2.048     ]. \t  -7.5734809433863495 \t -0.02341310429872985\n",
      "32     \t [1.23565478 1.63892794]. \t  -1.3118427463376825 \t -0.02341310429872985\n",
      "33     \t [1.44053075 2.048     ]. \t  -0.26766480102394663 \t -0.02341310429872985\n",
      "34     \t [-0.88051872  0.44800838]. \t  -14.24919656431589 \t -0.02341310429872985\n",
      "35     \t [-1.32139053  1.81021138]. \t  -5.800228064562151 \t -0.02341310429872985\n",
      "36     \t [ 0.65745021 -0.00433467]. \t  -19.17715206369199 \t -0.02341310429872985\n",
      "37     \t [1.28510941 1.79870967]. \t  -2.248173943906804 \t -0.02341310429872985\n",
      "38     \t [-0.22866166 -0.16646832]. \t  -6.29496154110104 \t -0.02341310429872985\n",
      "39     \t [-1.05668196 -1.20906522]. \t  -545.0910077234003 \t -0.02341310429872985\n",
      "40     \t [0.89581755 0.60707075]. \t  -3.8296862809949217 \t -0.02341310429872985\n",
      "41     \t [-0.57430339  0.29307277]. \t  -2.6134992551821914 \t -0.02341310429872985\n",
      "42     \t [1.13911047 1.25108099]. \t  -0.23549929568290542 \t -0.02341310429872985\n",
      "43     \t [ 2.048     -1.1627084]. \t  -2870.856488807324 \t -0.02341310429872985\n",
      "44     \t [-0.4142622  -1.65495528]. \t  -335.63536833057765 \t -0.02341310429872985\n",
      "45     \t [1.09324376 1.20310497]. \t  \u001b[92m-0.01497187526858883\u001b[0m \t -0.01497187526858883\n",
      "46     \t [-1.48723993 -0.52468984]. \t  -755.0692310168213 \t -0.01497187526858883\n",
      "47     \t [1.2661738  1.56203874]. \t  -0.24024137974606574 \t -0.01497187526858883\n",
      "48     \t [0.95359713 0.8421514 ]. \t  -0.4536846065831973 \t -0.01497187526858883\n",
      "49     \t [1.40406468 2.02508732]. \t  -0.4515264465384119 \t -0.01497187526858883\n",
      "50     \t [1.18818552 1.40658422]. \t  -0.03811841026215843 \t -0.01497187526858883\n",
      "51     \t [1.10019327 1.19340381]. \t  -0.03901157039153624 \t -0.01497187526858883\n",
      "52     \t [0.85942364 0.71214524]. \t  -0.08979472484708201 \t -0.01497187526858883\n",
      "53     \t [1.40827843 2.04523284]. \t  -0.5509016379679261 \t -0.01497187526858883\n",
      "54     \t [1.17796543 1.39269063]. \t  -0.0342605471966395 \t -0.01497187526858883\n",
      "55     \t [1.26810065 1.65115597]. \t  -0.25743831229625147 \t -0.01497187526858883\n",
      "56     \t [1.2585284  1.60411144]. \t  -0.10771254001041865 \t -0.01497187526858883\n",
      "57     \t [1.4060053 1.9795527]. \t  -0.1655702747127066 \t -0.01497187526858883\n",
      "58     \t [ 0.06027436 -0.04132364]. \t  -1.0851942126019989 \t -0.01497187526858883\n",
      "59     \t [1.33963736 1.80675245]. \t  -0.13005315836642348 \t -0.01497187526858883\n",
      "60     \t [1.0128129  1.03745346]. \t  \u001b[92m-0.013767857168650742\u001b[0m \t -0.013767857168650742\n",
      "61     \t [-1.23938278  1.43287201]. \t  -6.079810777768328 \t -0.013767857168650742\n",
      "62     \t [0.35148776 0.09626281]. \t  -0.49499252426734075 \t -0.013767857168650742\n",
      "63     \t [0.62676803 0.32429678]. \t  -0.6090942604666887 \t -0.013767857168650742\n",
      "64     \t [0.97117747 0.93709482]. \t  \u001b[92m-0.004540608342923597\u001b[0m \t -0.004540608342923597\n",
      "65     \t [0.75645786 0.55781542]. \t  -0.08008645126486023 \t -0.004540608342923597\n",
      "66     \t [1.12211399 1.27066172]. \t  -0.02818728981196349 \t -0.004540608342923597\n",
      "67     \t [1.02297801 1.0458584 ]. \t  \u001b[92m-0.0005671260467056312\u001b[0m \t -0.0005671260467056312\n",
      "68     \t [1.34093646 1.79586456]. \t  -0.11674214014606571 \t -0.0005671260467056312\n",
      "69     \t [1.00413436 1.02379187]. \t  -0.024060901097877355 \t -0.0005671260467056312\n",
      "70     \t [1.28845248 1.67248241]. \t  -0.09851297584497765 \t -0.0005671260467056312\n",
      "71     \t [1.22545247 1.52583059]. \t  -0.10889460083663996 \t -0.0005671260467056312\n",
      "72     \t [1.25679239 1.60816224]. \t  -0.14793931848878306 \t -0.0005671260467056312\n",
      "73     \t [1.19710029 1.47221086]. \t  -0.19221272537402775 \t -0.0005671260467056312\n",
      "74     \t [1.05209461 1.10516034]. \t  -0.0030175617080765472 \t -0.0005671260467056312\n",
      "75     \t [0.9795546  0.98447608]. \t  -0.06266265653781093 \t -0.0005671260467056312\n",
      "76     \t [0.7182298  0.52540916]. \t  -0.0885244808510194 \t -0.0005671260467056312\n",
      "77     \t [1.34695426 1.82311739]. \t  -0.1281770056948796 \t -0.0005671260467056312\n",
      "78     \t [1.29225461 1.65364573]. \t  -0.11190439125260282 \t -0.0005671260467056312\n",
      "79     \t [1.29088686 1.64351211]. \t  -0.13694981147812574 \t -0.0005671260467056312\n",
      "80     \t [1.21835935 1.50349652]. \t  -0.08415038098729374 \t -0.0005671260467056312\n",
      "81     \t [1.21480893 1.44791178]. \t  -0.1236992759075131 \t -0.0005671260467056312\n",
      "82     \t [1.37986143 1.96473101]. \t  -0.5129071268420571 \t -0.0005671260467056312\n",
      "83     \t [1.35508177 1.84517431]. \t  -0.1340534669337234 \t -0.0005671260467056312\n",
      "84     \t [1.10898574 1.26201454]. \t  -0.11533770968788518 \t -0.0005671260467056312\n",
      "85     \t [1.18926115 1.43103626]. \t  -0.0636893749179466 \t -0.0005671260467056312\n",
      "86     \t [1.0799848  1.12848422]. \t  -0.14990933770880016 \t -0.0005671260467056312\n",
      "87     \t [0.32915678 0.04334776]. \t  -0.8724841768024205 \t -0.0005671260467056312\n",
      "88     \t [1.11292396 1.27157161]. \t  -0.1214662077850002 \t -0.0005671260467056312\n",
      "89     \t [1.41655051 2.048     ]. \t  -0.3447831559479895 \t -0.0005671260467056312\n",
      "90     \t [1.11703609 1.24383654]. \t  -0.015244369820912484 \t -0.0005671260467056312\n",
      "91     \t [1.22380961 1.49532545]. \t  -0.05065932866666765 \t -0.0005671260467056312\n",
      "92     \t [1.14562657 1.34121836]. \t  -0.10391004477115864 \t -0.0005671260467056312\n",
      "93     \t [0.468011   0.19367415]. \t  -0.34732599718363566 \t -0.0005671260467056312\n",
      "94     \t [0.88969323 0.78366734]. \t  -0.01838759248730853 \t -0.0005671260467056312\n",
      "95     \t [1.2518819  1.62008616]. \t  -0.3430514940833607 \t -0.0005671260467056312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [1.21929929 1.48853746]. \t  -0.048433209353267156 \t -0.0005671260467056312\n",
      "97     \t [1.03600595 1.06683832]. \t  -0.005482522357898088 \t -0.0005671260467056312\n",
      "98     \t [1.30207232 1.69481497]. \t  -0.09128102275505501 \t -0.0005671260467056312\n",
      "99     \t [0.96929187 0.93185612]. \t  -0.006826800433194677 \t -0.0005671260467056312\n",
      "100    \t [0.95421098 0.92459759]. \t  -0.021918451234412762 \t -0.0005671260467056312\n"
     ]
    }
   ],
   "source": [
    "### 6(b). Bayesian optimization runs (x20): STP DF1 run number = 2\n",
    "\n",
    "np.random.seed(run_num_2)\n",
    "surrogate_stp_df1_2 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_2 = GPGO(surrogate_stp_df1_2, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_2.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.774243280230393, -7.4749289743470575)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(b). Training Regret Minimisation: run number = 2\n",
    "\n",
    "gp_output_2 = np.append(np.max(gpgo_gp_2.GP.y[0:n_init]),gpgo_gp_2.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_2 = np.append(np.max(gpgo_stp_df1_2.GP.y[0:n_init]),gpgo_stp_df1_2.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_2 = np.log(y_global_orig - gp_output_2)\n",
    "regret_stp_df1_2 = np.log(y_global_orig - stp_df1_output_2)\n",
    "\n",
    "train_regret_gp_2 = min_max_array(regret_gp_2)\n",
    "train_regret_stp_df1_2 = min_max_array(regret_stp_df1_2)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 2\n",
    "min_train_regret_gp_2 = min(train_regret_gp_2)\n",
    "min_train_regret_stp_df1_2 = min(train_regret_stp_df1_2)\n",
    "\n",
    "min_train_regret_gp_2, min_train_regret_stp_df1_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.17732029 0.93778218]. \t  -82.82196623934672 \t -23.738031122629355\n",
      "init   \t [-1.9788536  -0.69493226]. \t  -2134.815535382776 \t -23.738031122629355\n",
      "init   \t [-0.53771541 -1.85014819]. \t  -460.0190456847185 \t -23.738031122629355\n",
      "init   \t [-1.61984435 -1.64889594]. \t  -1832.5384343989504 \t -23.738031122629355\n",
      "init   \t [-1.04282802  1.5298124 ]. \t  -23.738031122629355 \t -23.738031122629355\n",
      "1      \t [ 0.58445164 -2.048     ]. \t  -571.1837151153449 \t -23.738031122629355\n",
      "2      \t [-1.0895813  2.048    ]. \t  -78.46618140959139 \t -23.738031122629355\n",
      "3      \t [1.15416417 0.62820161]. \t  -49.57034920504751 \t -23.738031122629355\n",
      "4      \t [2.048      0.90411956]. \t  -1083.6296674998525 \t -23.738031122629355\n",
      "5      \t [0.79724371 0.03939012]. \t  -35.587438528682576 \t -23.738031122629355\n",
      "6      \t [0.78011286 0.63834367]. \t  \u001b[92m-0.13696136970049763\u001b[0m \t -0.13696136970049763\n",
      "7      \t [1.09201113 0.14141433]. \t  -110.48411928658983 \t -0.13696136970049763\n",
      "8      \t [0.75686123 1.72289284]. \t  -132.3215159144186 \t -0.13696136970049763\n",
      "9      \t [ 0.1953193 -0.4942369]. \t  -28.991052558538744 \t -0.13696136970049763\n",
      "10     \t [-0.88294306  1.27948197]. \t  -28.53482866085368 \t -0.13696136970049763\n",
      "11     \t [0.89943928 0.79505899]. \t  \u001b[92m-0.029522581131758235\u001b[0m \t -0.029522581131758235\n",
      "12     \t [-0.79870547  0.18627068]. \t  -23.634993842631655 \t -0.029522581131758235\n",
      "13     \t [-2.048       1.80894846]. \t  -578.2824087172794 \t -0.029522581131758235\n",
      "14     \t [-0.22815345  0.05588672]. \t  -1.509829884497165 \t -0.029522581131758235\n",
      "15     \t [-0.44671113  1.84459819]. \t  -272.7110531365009 \t -0.029522581131758235\n",
      "16     \t [-0.69790646  0.51040165]. \t  -2.9373069638900735 \t -0.029522581131758235\n",
      "17     \t [-0.54067089  0.21737679]. \t  -2.935390445587016 \t -0.029522581131758235\n",
      "18     \t [ 0.16255786 -0.14226387]. \t  -3.546904695443189 \t -0.029522581131758235\n",
      "19     \t [-1.1163213   0.91256006]. \t  -15.608591507326631 \t -0.029522581131758235\n",
      "20     \t [0.93320538 1.44791193]. \t  -33.30193595101149 \t -0.029522581131758235\n",
      "21     \t [-1.66822866 -0.74039724]. \t  -1248.5430028661146 \t -0.029522581131758235\n",
      "22     \t [-0.66778053 -0.76753675]. \t  -150.03184972149444 \t -0.029522581131758235\n",
      "23     \t [0.02198113 0.32914204]. \t  -11.758185883592812 \t -0.029522581131758235\n",
      "24     \t [-0.9638623   0.00284967]. \t  -89.63785272822487 \t -0.029522581131758235\n",
      "25     \t [-1.88808024  0.39791807]. \t  -1011.2848773638565 \t -0.029522581131758235\n",
      "26     \t [-0.19554692 -1.21491657]. \t  -158.4691201866766 \t -0.029522581131758235\n",
      "27     \t [-1.44517741  0.15970977]. \t  -378.0166263266245 \t -0.029522581131758235\n",
      "28     \t [ 0.56954848 -1.40522082]. \t  -299.33907928438043 \t -0.029522581131758235\n",
      "29     \t [0.85278957 0.61255428]. \t  -1.3371828653260658 \t -0.029522581131758235\n",
      "30     \t [-1.11063519  0.60326957]. \t  -44.175145846814246 \t -0.029522581131758235\n",
      "31     \t [0.77726219 0.15318158]. \t  -20.385647825762565 \t -0.029522581131758235\n",
      "32     \t [-0.22047821  0.26199081]. \t  -6.0426766547905295 \t -0.029522581131758235\n",
      "33     \t [-1.29226344  0.03181099]. \t  -273.602708106066 \t -0.029522581131758235\n",
      "34     \t [1.8020222  1.28442774]. \t  -385.9237113680105 \t -0.029522581131758235\n",
      "35     \t [1.51306089 2.048     ]. \t  -6.088370537256891 \t -0.029522581131758235\n",
      "36     \t [1.33003972 1.65546217]. \t  -1.398138459073704 \t -0.029522581131758235\n",
      "37     \t [1.14500798 1.29673835]. \t  -0.04149040632941295 \t -0.029522581131758235\n",
      "38     \t [-0.23205739  0.54654357]. \t  -25.792598213413843 \t -0.029522581131758235\n",
      "39     \t [0.26176954 1.77831324]. \t  -292.8831494084489 \t -0.029522581131758235\n",
      "40     \t [-1.3628386   0.27523885]. \t  -255.88394961432024 \t -0.029522581131758235\n",
      "41     \t [ 1.23410476 -0.92682893]. \t  -600.2281220373786 \t -0.029522581131758235\n",
      "42     \t [-1.61560964  2.04546902]. \t  -38.73290128808209 \t -0.029522581131758235\n",
      "43     \t [-1.9229364  -1.74931046]. \t  -2975.5188670552625 \t -0.029522581131758235\n",
      "44     \t [1.39946867 0.7120353 ]. \t  -155.53013280959598 \t -0.029522581131758235\n",
      "45     \t [-0.43677182  1.00770946]. \t  -68.80338327488188 \t -0.029522581131758235\n",
      "46     \t [0.42754221 0.16273814]. \t  -0.36792502440971836 \t -0.029522581131758235\n",
      "47     \t [ 1.21641862 -0.11869403]. \t  -255.52496078250252 \t -0.029522581131758235\n",
      "48     \t [ 0.29724987 -0.11879015]. \t  -4.784872198457507 \t -0.029522581131758235\n",
      "49     \t [ 1.68220094 -1.90345899]. \t  -2240.8394607524356 \t -0.029522581131758235\n",
      "50     \t [ 1.82462729 -0.72615758]. \t  -1645.3250306732855 \t -0.029522581131758235\n",
      "51     \t [-1.47319531 -1.84955067]. \t  -1622.0401985521091 \t -0.029522581131758235\n",
      "52     \t [ 0.47183025 -1.95186422]. \t  -473.11876806415796 \t -0.029522581131758235\n",
      "53     \t [-0.36969638 -1.02368193]. \t  -136.51898461731705 \t -0.029522581131758235\n",
      "54     \t [1.19038166 1.41738053]. \t  -0.036259017741945586 \t -0.029522581131758235\n",
      "55     \t [-1.62701645 -1.80286851]. \t  -1987.196647069028 \t -0.029522581131758235\n",
      "56     \t [-0.674215    0.82706147]. \t  -16.67829334945903 \t -0.029522581131758235\n",
      "57     \t [-0.38699117 -1.8311593 ]. \t  -394.32873126320226 \t -0.029522581131758235\n",
      "58     \t [-0.72667473  0.08984342]. \t  -22.184446851846207 \t -0.029522581131758235\n",
      "59     \t [-1.54662294 -0.97685631]. \t  -1141.4332237296726 \t -0.029522581131758235\n",
      "60     \t [0.57876166 0.35812952]. \t  -0.23110097651231748 \t -0.029522581131758235\n",
      "61     \t [0.85761016 0.18916347]. \t  -29.868109176516743 \t -0.029522581131758235\n",
      "62     \t [1.11312843 1.26248103]. \t  -0.0676763632163919 \t -0.029522581131758235\n",
      "63     \t [0.58375908 0.35909799]. \t  -0.20683093763018634 \t -0.029522581131758235\n",
      "64     \t [-0.92534688 -1.72989852]. \t  -672.5320899053452 \t -0.029522581131758235\n",
      "65     \t [0.92967817 0.84260899]. \t  -0.05200163405952532 \t -0.029522581131758235\n",
      "66     \t [ 0.56982084 -1.95506523]. \t  -519.9160825292462 \t -0.029522581131758235\n",
      "67     \t [ 1.56844099 -1.40365839]. \t  -1493.11425164041 \t -0.029522581131758235\n",
      "68     \t [ 1.59898032 -0.88432696]. \t  -1184.4516295432666 \t -0.029522581131758235\n",
      "69     \t [-0.51459116 -0.93282113]. \t  -145.72459563610107 \t -0.029522581131758235\n",
      "70     \t [-0.81795081  0.51499748]. \t  -5.677963532413255 \t -0.029522581131758235\n",
      "71     \t [-0.43726735  2.00486764]. \t  -331.0037766553119 \t -0.029522581131758235\n",
      "72     \t [1.02989037 1.05292592]. \t  \u001b[92m-0.006896978199597085\u001b[0m \t -0.006896978199597085\n",
      "73     \t [ 0.02532436 -1.02636083]. \t  -106.4233346514738 \t -0.006896978199597085\n",
      "74     \t [1.69639001 0.30382662]. \t  -662.9874870643357 \t -0.006896978199597085\n",
      "75     \t [-0.56094427 -0.87633082]. \t  -144.2820949080133 \t -0.006896978199597085\n",
      "76     \t [1.26448196 1.38237329]. \t  -4.758965848711953 \t -0.006896978199597085\n",
      "77     \t [1.02731097 1.06301834]. \t  \u001b[92m-0.006598919352373833\u001b[0m \t -0.006598919352373833\n",
      "78     \t [0.53346195 0.29277877]. \t  -0.2243770389677004 \t -0.006598919352373833\n",
      "79     \t [1.7003654  1.62126896]. \t  -161.7737938632234 \t -0.006598919352373833\n",
      "80     \t [-1.70261797 -0.32501536]. \t  -1046.6722965276417 \t -0.006598919352373833\n",
      "81     \t [-0.0440407  -0.27164665]. \t  -8.574963823588702 \t -0.006598919352373833\n",
      "82     \t [1.38035143 2.048     ]. \t  -2.1789971681381117 \t -0.006598919352373833\n",
      "83     \t [1.04809826 1.13715193]. \t  -0.15163363120764334 \t -0.006598919352373833\n",
      "84     \t [ 2.03979698 -1.66999113]. \t  -3400.860746568202 \t -0.006598919352373833\n",
      "85     \t [ 0.76721678 -0.37859805]. \t  -93.60557134603403 \t -0.006598919352373833\n",
      "86     \t [1.21870831 1.48891971]. \t  -0.04918004468477846 \t -0.006598919352373833\n",
      "87     \t [0.99882859 1.02142418]. \t  -0.05648189009226167 \t -0.006598919352373833\n",
      "88     \t [1.06502895 1.73164033]. \t  -35.68736940618109 \t -0.006598919352373833\n",
      "89     \t [-1.51113597 -1.7273826 ]. \t  -1615.0493251166633 \t -0.006598919352373833\n",
      "90     \t [ 1.16342211 -1.31996643]. \t  -714.7962491560417 \t -0.006598919352373833\n",
      "91     \t [-0.95215287  0.5214103 ]. \t  -18.647633719994325 \t -0.006598919352373833\n",
      "92     \t [0.09652919 1.48062145]. \t  -217.28967653082105 \t -0.006598919352373833\n",
      "93     \t [ 1.35853704 -0.43699258]. \t  -521.1618850203678 \t -0.006598919352373833\n",
      "94     \t [1.78630412 1.39450049]. \t  -323.31706911096023 \t -0.006598919352373833\n",
      "95     \t [ 0.16211304 -1.21080227]. \t  -153.73946667201275 \t -0.006598919352373833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [-1.41173576 -0.02253594]. \t  -412.0541195808984 \t -0.006598919352373833\n",
      "97     \t [1.20401683 1.79247992]. \t  -11.794411224854302 \t -0.006598919352373833\n",
      "98     \t [ 1.95473746 -0.83443929]. \t  -2168.22166309131 \t -0.006598919352373833\n",
      "99     \t [0.77789355 1.44429221]. \t  -70.47060346483623 \t -0.006598919352373833\n",
      "100    \t [-1.92117275 -2.01137339]. \t  -3260.130853929836 \t -0.006598919352373833\n"
     ]
    }
   ],
   "source": [
    "### 6(c). Bayesian optimization runs (x20): GP run number = 3\n",
    "\n",
    "np.random.seed(run_num_3)\n",
    "surrogate_gp_3 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_3 = GPGO(surrogate_gp_3, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_3.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.17732029 0.93778218]. \t  -82.82196623934672 \t -23.738031122629355\n",
      "init   \t [-1.9788536  -0.69493226]. \t  -2134.815535382776 \t -23.738031122629355\n",
      "init   \t [-0.53771541 -1.85014819]. \t  -460.0190456847185 \t -23.738031122629355\n",
      "init   \t [-1.61984435 -1.64889594]. \t  -1832.5384343989504 \t -23.738031122629355\n",
      "init   \t [-1.04282802  1.5298124 ]. \t  -23.738031122629355 \t -23.738031122629355\n",
      "1      \t [ 1.15356154 -2.048     ]. \t  -1141.5878026183627 \t -23.738031122629355\n",
      "2      \t [2.048 2.048]. \t  -461.7603900415999 \t -23.738031122629355\n",
      "3      \t [-2.048  2.048]. \t  -469.9523900415999 \t -23.738031122629355\n",
      "4      \t [2.048      0.08181575]. \t  -1692.35426503317 \t -23.738031122629355\n",
      "5      \t [0.02407235 2.048     ]. \t  -420.14551425518385 \t -23.738031122629355\n",
      "6      \t [-0.10324995 -0.17884901]. \t  \u001b[92m-4.808547691458011\u001b[0m \t -4.808547691458011\n",
      "7      \t [-0.60728234  0.68214664]. \t  -12.402479541196106 \t -4.808547691458011\n",
      "8      \t [-2.048       0.99834989]. \t  -1030.702572691683 \t -4.808547691458011\n",
      "9      \t [ 0.20537523 -1.01226721]. \t  -111.81710670110303 \t -4.808547691458011\n",
      "10     \t [-0.46300898  1.18640424]. \t  -96.62402862728801 \t -4.808547691458011\n",
      "11     \t [-1.08081677  2.048     ]. \t  -81.7407813349536 \t -4.808547691458011\n",
      "12     \t [0.34259292 0.1165635 ]. \t  \u001b[92m-0.43224909714731474\u001b[0m \t -0.43224909714731474\n",
      "13     \t [1.12402448 2.048     ]. \t  -61.570227488742034 \t -0.43224909714731474\n",
      "14     \t [1.14770998 1.30403136]. \t  \u001b[92m-0.039260312904297136\u001b[0m \t -0.039260312904297136\n",
      "15     \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -0.039260312904297136\n",
      "16     \t [ 0.2608017 -2.048    ]. \t  -448.2994315774573 \t -0.039260312904297136\n",
      "17     \t [ 0.9049339  -0.78982213]. \t  -258.8094534397787 \t -0.039260312904297136\n",
      "18     \t [0.88832521 1.5369004 ]. \t  -55.92977443104272 \t -0.039260312904297136\n",
      "19     \t [0.85606857 0.71847572]. \t  -0.04138802476152565 \t -0.039260312904297136\n",
      "20     \t [-0.67267285 -0.80734532]. \t  -161.51602781744333 \t -0.039260312904297136\n",
      "21     \t [-0.83425123  0.00572356]. \t  -51.00919880296044 \t -0.039260312904297136\n",
      "22     \t [-0.42679963  0.13646092]. \t  -2.244578772684571 \t -0.039260312904297136\n",
      "23     \t [2.048      1.22385347]. \t  -883.4559365919393 \t -0.039260312904297136\n",
      "24     \t [0.72482265 0.86834376]. \t  -11.83896902105019 \t -0.039260312904297136\n",
      "25     \t [ 0.63256435 -0.21281259]. \t  -37.705808514389275 \t -0.039260312904297136\n",
      "26     \t [1.33301755 1.73660361]. \t  -0.2735691660637476 \t -0.039260312904297136\n",
      "27     \t [-1.46592905  2.048     ]. \t  -7.099855619976725 \t -0.039260312904297136\n",
      "28     \t [-1.07085671  0.98589065]. \t  -6.875508552803311 \t -0.039260312904297136\n",
      "29     \t [0.61893041 0.38713076]. \t  -0.14685906197909865 \t -0.039260312904297136\n",
      "30     \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -0.039260312904297136\n",
      "31     \t [-1.4003868  1.6429682]. \t  -15.88157149245227 \t -0.039260312904297136\n",
      "32     \t [ 0.63269809 -1.46992083]. \t  -349.9100739563838 \t -0.039260312904297136\n",
      "33     \t [-0.88117579  0.50956827]. \t  -10.662516853907684 \t -0.039260312904297136\n",
      "34     \t [ 0.34293218 -0.50679645]. \t  -39.419140456433006 \t -0.039260312904297136\n",
      "35     \t [1.45916707 2.048     ]. \t  -0.869667394014788 \t -0.039260312904297136\n",
      "36     \t [ 2.048      -0.94558211]. \t  -2642.9412287614273 \t -0.039260312904297136\n",
      "37     \t [-1.08447687 -2.048     ]. \t  -1043.8207335000532 \t -0.039260312904297136\n",
      "38     \t [-1.67463923  0.24039545]. \t  -664.57410951028 \t -0.039260312904297136\n",
      "39     \t [-1.34336674  1.86369605]. \t  -5.8401979978414085 \t -0.039260312904297136\n",
      "40     \t [-0.05917714  0.11434946]. \t  -2.3505736739925087 \t -0.039260312904297136\n",
      "41     \t [1.29617807 1.79835916]. \t  -1.4867745642970902 \t -0.039260312904297136\n",
      "42     \t [-1.15371162  1.354344  ]. \t  -4.69273242357509 \t -0.039260312904297136\n",
      "43     \t [1.12468018 1.34599025]. \t  -0.6730185871104547 \t -0.039260312904297136\n",
      "44     \t [1.38308202 2.048     ]. \t  -1.9715240903636424 \t -0.039260312904297136\n",
      "45     \t [-1.00505105  1.0614754 ]. \t  -4.283889292465847 \t -0.039260312904297136\n",
      "46     \t [1.03570224 1.0883916 ]. \t  \u001b[92m-0.02596282731152252\u001b[0m \t -0.02596282731152252\n",
      "47     \t [0.69047097 0.50158807]. \t  -0.15750040090268674 \t -0.02596282731152252\n",
      "48     \t [1.38465571 1.92605034]. \t  -0.15566691673837943 \t -0.02596282731152252\n",
      "49     \t [1.01223231 1.06890663]. \t  -0.1963311683397748 \t -0.02596282731152252\n",
      "50     \t [0.58604722 0.34818306]. \t  -0.17359580927132753 \t -0.02596282731152252\n",
      "51     \t [0.8801009  0.79845737]. \t  -0.07140016868538267 \t -0.02596282731152252\n",
      "52     \t [1.24565125 1.55936892]. \t  -0.06630727741369151 \t -0.02596282731152252\n",
      "53     \t [-0.80129116 -1.46288951]. \t  -446.3290606661825 \t -0.02596282731152252\n",
      "54     \t [0.57602157 0.3633823 ]. \t  -0.27949649994109044 \t -0.02596282731152252\n",
      "55     \t [1.37588348 1.90848286]. \t  -0.16508917658319103 \t -0.02596282731152252\n",
      "56     \t [0.48168098 0.19850446]. \t  -0.38096073026101357 \t -0.02596282731152252\n",
      "57     \t [1.03067412 1.09905942]. \t  -0.13614621100070856 \t -0.02596282731152252\n",
      "58     \t [1.07554679 1.19576597]. \t  -0.1575350819353958 \t -0.02596282731152252\n",
      "59     \t [1.36273514 1.8833451 ]. \t  -0.2007354486267866 \t -0.02596282731152252\n",
      "60     \t [0.65450191 0.45858879]. \t  -0.2106698728233541 \t -0.02596282731152252\n",
      "61     \t [0.67457346 0.43526847]. \t  -0.14503078779436304 \t -0.02596282731152252\n",
      "62     \t [1.11312843 1.26248103]. \t  -0.0676763632163919 \t -0.02596282731152252\n",
      "63     \t [0.60202211 0.37126646]. \t  -0.1661936094283351 \t -0.02596282731152252\n",
      "64     \t [1.00298948 1.07694901]. \t  -0.5035567765115433 \t -0.02596282731152252\n",
      "65     \t [1.4305942  2.04782343]. \t  -0.18556110068692863 \t -0.02596282731152252\n",
      "66     \t [1.09237521 1.27114967]. \t  -0.6148457588317798 \t -0.02596282731152252\n",
      "67     \t [1.02682442 1.09457382]. \t  -0.1623672196725118 \t -0.02596282731152252\n",
      "68     \t [0.66031249 0.42577714]. \t  -0.12586402519699028 \t -0.02596282731152252\n",
      "69     \t [0.6407022  0.43142657]. \t  -0.17288991027890277 \t -0.02596282731152252\n",
      "70     \t [1.39176393 1.98283542]. \t  -0.3635048521044613 \t -0.02596282731152252\n",
      "71     \t [-1.27405218 -0.80209712]. \t  -593.382270607468 \t -0.02596282731152252\n",
      "72     \t [1.13666003 1.29322825]. \t  \u001b[92m-0.018827801535832706\u001b[0m \t -0.018827801535832706\n",
      "73     \t [0.65130334 0.43744742]. \t  -0.13914924052673763 \t -0.018827801535832706\n",
      "74     \t [1.07819844 1.22529819]. \t  -0.4003270636777426 \t -0.018827801535832706\n",
      "75     \t [0.60685329 0.37084894]. \t  -0.15522896118610985 \t -0.018827801535832706\n",
      "76     \t [1.24016818 1.58309951]. \t  -0.2609230361345074 \t -0.018827801535832706\n",
      "77     \t [1.37708348 1.89855339]. \t  -0.14267352503944222 \t -0.018827801535832706\n",
      "78     \t [0.56996514 0.33831015]. \t  -0.2030199183721528 \t -0.018827801535832706\n",
      "79     \t [1.41733146 2.04799954]. \t  -0.32760292688823184 \t -0.018827801535832706\n",
      "80     \t [0.98707473 1.00338096]. \t  -0.08464117461937594 \t -0.018827801535832706\n",
      "81     \t [1.42224165 2.01701692]. \t  -0.1815993293534998 \t -0.018827801535832706\n",
      "82     \t [1.1922336  1.43263782]. \t  -0.04953557957072434 \t -0.018827801535832706\n",
      "83     \t [0.99183081 1.02517582]. \t  -0.17185590683738552 \t -0.018827801535832706\n",
      "84     \t [1.24013344 1.53392632]. \t  -0.05926776623204501 \t -0.018827801535832706\n",
      "85     \t [0.62643841 0.34602184]. \t  -0.3548743678385611 \t -0.018827801535832706\n",
      "86     \t [1.31378327 1.72846788]. \t  -0.09905598205183384 \t -0.018827801535832706\n",
      "87     \t [0.99882859 1.02142418]. \t  -0.05648189009226167 \t -0.018827801535832706\n",
      "88     \t [0.55050483 0.31883701]. \t  -0.2269513036395288 \t -0.018827801535832706\n",
      "89     \t [1.2652696  1.59816089]. \t  -0.07112216727942744 \t -0.018827801535832706\n",
      "90     \t [0.9214237  0.86926704]. \t  -0.04716185953563236 \t -0.018827801535832706\n",
      "91     \t [1.01092898 1.05959368]. \t  -0.14161791930439094 \t -0.018827801535832706\n",
      "92     \t [1.25398277 1.57614831]. \t  -0.06585819839967708 \t -0.018827801535832706\n",
      "93     \t [0.70648821 0.52923997]. \t  -0.17683678667680625 \t -0.018827801535832706\n",
      "94     \t [0.90201973 0.81023373]. \t  \u001b[92m-0.010760124726760441\u001b[0m \t -0.010760124726760441\n",
      "95     \t [1.22899963 1.55896206]. \t  -0.28787887564348497 \t -0.010760124726760441\n",
      "96     \t [0.6733967  0.47452479]. \t  -0.15102912650583156 \t -0.010760124726760441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [1.26907164 1.61644907]. \t  -0.07588791303273028 \t -0.010760124726760441\n",
      "98     \t [1.0734875  1.18785103]. \t  -0.13125224866114468 \t -0.010760124726760441\n",
      "99     \t [1.17590148 1.41927145]. \t  -0.16436465332893782 \t -0.010760124726760441\n",
      "100    \t [1.40557371 2.03902934]. \t  -0.5663432894675537 \t -0.010760124726760441\n"
     ]
    }
   ],
   "source": [
    "### 6(c). Bayesian optimization runs (x20): STP DF1 run number = 3\n",
    "\n",
    "np.random.seed(run_num_3)\n",
    "surrogate_stp_df1_3 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_3 = GPGO(surrogate_stp_df1_3, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_3.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.020849377844526, -4.531908132609321)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(c). Training Regret Minimisation: run number = 3\n",
    "\n",
    "gp_output_3 = np.append(np.max(gpgo_gp_3.GP.y[0:n_init]),gpgo_gp_3.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_3 = np.append(np.max(gpgo_stp_df1_3.GP.y[0:n_init]),gpgo_stp_df1_3.GP.y[n_init:(n_init+max_iter)]) \n",
    "\n",
    "regret_gp_3 = np.log(y_global_orig - gp_output_3)\n",
    "regret_stp_df1_3 = np.log(y_global_orig - stp_df1_output_3)\n",
    "\n",
    "train_regret_gp_3 = min_max_array(regret_gp_3)\n",
    "train_regret_stp_df1_3 = min_max_array(regret_stp_df1_3)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 3\n",
    "min_train_regret_gp_3 = min(train_regret_gp_3)\n",
    "min_train_regret_stp_df1_3 = min(train_regret_stp_df1_3)\n",
    "\n",
    "min_train_regret_gp_3, min_train_regret_stp_df1_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.39002285 1.31602418]. \t  -38.11488737154776 \t -12.122423820878506\n",
      "init   \t [0.58248055 0.68494384]. \t  -12.122423820878506 \t -12.122423820878506\n",
      "init   \t [-1.88768295 -1.7790059 ]. \t  -2862.4120613667637 \t -12.122423820878506\n",
      "init   \t [-0.91545338 -0.75218738]. \t  -256.5560079635026 \t -12.122423820878506\n",
      "init   \t [-1.25504548 -1.24070756]. \t  -797.98450090518 \t -12.122423820878506\n",
      "1      \t [-0.00933519 -1.72218378]. \t  -297.64047024942215 \t -12.122423820878506\n",
      "2      \t [0.55438246 1.26879645]. \t  -92.63844192618087 \t -12.122423820878506\n",
      "3      \t [1.4102362 0.3572151]. \t  -266.3641717959405 \t -12.122423820878506\n",
      "4      \t [2.048 2.048]. \t  -461.7603900415999 \t -12.122423820878506\n",
      "5      \t [0.9509412  0.96688936]. \t  \u001b[92m-0.3942852631873592\u001b[0m \t -0.3942852631873592\n",
      "6      \t [0.74756226 0.81859824]. \t  -6.810674116298312 \t -0.3942852631873592\n",
      "7      \t [ 1.73111495 -0.26146777]. \t  -1062.138680699351 \t -0.3942852631873592\n",
      "8      \t [-1.25608718  2.048     ]. \t  -27.20296449843555 \t -0.3942852631873592\n",
      "9      \t [ 1.56120513 -1.00487715]. \t  -1185.2156248763604 \t -0.3942852631873592\n",
      "10     \t [1.35128464 0.97742284]. \t  -72.1266585070784 \t -0.3942852631873592\n",
      "11     \t [0.92697923 2.048     ]. \t  -141.30836244744683 \t -0.3942852631873592\n",
      "12     \t [0.64998785 0.1785837 ]. \t  -6.071254454769831 \t -0.3942852631873592\n",
      "13     \t [-2.03015262  2.048     ]. \t  -439.13019743941044 \t -0.3942852631873592\n",
      "14     \t [-0.90259306  1.80221397]. \t  -101.14333432247408 \t -0.3942852631873592\n",
      "15     \t [0.72474662 0.44655116]. \t  -0.6952356914691592 \t -0.3942852631873592\n",
      "16     \t [1.13234759 1.44036937]. \t  -2.5189207362198966 \t -0.3942852631873592\n",
      "17     \t [ 1.73164586 -0.32150232]. \t  -1102.8415029977223 \t -0.3942852631873592\n",
      "18     \t [1.11463544 1.25424319]. \t  \u001b[92m-0.027138606722327728\u001b[0m \t -0.027138606722327728\n",
      "19     \t [ 1.12210002 -1.56110415]. \t  -795.3748184470774 \t -0.027138606722327728\n",
      "20     \t [-0.61916606 -0.43957734]. \t  -70.34537379874358 \t -0.027138606722327728\n",
      "21     \t [-0.31507715  0.3438056 ]. \t  -7.709017501530861 \t -0.027138606722327728\n",
      "22     \t [-0.11945482 -0.38998665]. \t  -17.595478726285823 \t -0.027138606722327728\n",
      "23     \t [-0.17126697  0.00821645]. \t  -1.4164545256032628 \t -0.027138606722327728\n",
      "24     \t [1.83420092 1.92805264]. \t  -206.97453394502486 \t -0.027138606722327728\n",
      "25     \t [1.41537703 2.048     ]. \t  -0.3724173994062161 \t -0.027138606722327728\n",
      "26     \t [-1.47557584  0.22933391]. \t  -385.5950403975736 \t -0.027138606722327728\n",
      "27     \t [1.35807386 1.8167148 ]. \t  -0.20466807643511364 \t -0.027138606722327728\n",
      "28     \t [-0.55290055  1.30781461]. \t  -102.83506472840799 \t -0.027138606722327728\n",
      "29     \t [-1.07206331  1.34781616]. \t  -8.233529643120526 \t -0.027138606722327728\n",
      "30     \t [-0.97183737  1.01587431]. \t  -4.398030415261907 \t -0.027138606722327728\n",
      "31     \t [ 1.48633283 -0.77964418]. \t  -893.5466803786309 \t -0.027138606722327728\n",
      "32     \t [-0.55885019 -1.36792651]. \t  -284.7506778298577 \t -0.027138606722327728\n",
      "33     \t [0.24363327 1.74337258]. \t  -284.16287928828496 \t -0.027138606722327728\n",
      "34     \t [-0.01587209 -0.58220972]. \t  -34.958152717907716 \t -0.027138606722327728\n",
      "35     \t [-1.70714828 -1.19774021]. \t  -1698.2615538946 \t -0.027138606722327728\n",
      "36     \t [0.85396525 0.70586942]. \t  -0.0760224272470041 \t -0.027138606722327728\n",
      "37     \t [1.34122372 1.78401813]. \t  -0.13852429536418476 \t -0.027138606722327728\n",
      "38     \t [0.84723796 0.70420699]. \t  -0.041846290657416324 \t -0.027138606722327728\n",
      "39     \t [-1.12292196  1.80136345]. \t  -33.71106413908456 \t -0.027138606722327728\n",
      "40     \t [ 0.82992569 -0.41506505]. \t  -121.87557525235378 \t -0.027138606722327728\n",
      "41     \t [-0.25533525 -0.95263609]. \t  -105.17410174748937 \t -0.027138606722327728\n",
      "42     \t [1.19079437 0.37061068]. \t  -109.7370036372121 \t -0.027138606722327728\n",
      "43     \t [0.67366559 0.44652367]. \t  -0.11182556337420382 \t -0.027138606722327728\n",
      "44     \t [0.68814987 0.46456601]. \t  -0.10532214306050768 \t -0.027138606722327728\n",
      "45     \t [-1.37429839  1.73310574]. \t  -8.058127826750235 \t -0.027138606722327728\n",
      "46     \t [-0.23860944 -1.69672867]. \t  -309.06759363010303 \t -0.027138606722327728\n",
      "47     \t [0.1361602  0.91973458]. \t  -81.9614576900326 \t -0.027138606722327728\n",
      "48     \t [0.26502029 1.06660612]. \t  -99.81558628550876 \t -0.027138606722327728\n",
      "49     \t [-0.85724841 -1.36641014]. \t  -444.9892310789567 \t -0.027138606722327728\n",
      "50     \t [-1.91655642 -0.80527284]. \t  -2014.1679084374393 \t -0.027138606722327728\n",
      "51     \t [-0.69945308  0.39398562]. \t  -3.7953777387036833 \t -0.027138606722327728\n",
      "52     \t [1.96827608 0.51385253]. \t  -1130.0710754655745 \t -0.027138606722327728\n",
      "53     \t [1.88164587 0.89465385]. \t  -700.875734542644 \t -0.027138606722327728\n",
      "54     \t [-1.2761054   1.32626477]. \t  -14.311943750743499 \t -0.027138606722327728\n",
      "55     \t [0.30263909 0.11405759]. \t  -0.5367896228146735 \t -0.027138606722327728\n",
      "56     \t [0.52310086 0.28987593]. \t  -0.25381118969960237 \t -0.027138606722327728\n",
      "57     \t [0.52180079 0.33005145]. \t  -0.5624739375058474 \t -0.027138606722327728\n",
      "58     \t [-1.13628881 -0.58089985]. \t  -355.02164384040896 \t -0.027138606722327728\n",
      "59     \t [-1.90671123  0.45571025]. \t  -1019.5855922763678 \t -0.027138606722327728\n",
      "60     \t [ 1.69350482 -0.70147587]. \t  -1274.5671653469997 \t -0.027138606722327728\n",
      "61     \t [1.38830453 1.92222225]. \t  -0.15345042744001428 \t -0.027138606722327728\n",
      "62     \t [ 1.0450378  -1.71499994]. \t  -787.9852810986221 \t -0.027138606722327728\n",
      "63     \t [-0.68900583 -0.93015724]. \t  -200.2232850113495 \t -0.027138606722327728\n",
      "64     \t [-1.9511115   1.59976625]. \t  -495.82478171662814 \t -0.027138606722327728\n",
      "65     \t [0.1433744  0.57671401]. \t  -31.66495620399632 \t -0.027138606722327728\n",
      "66     \t [-0.75099975 -0.36212237]. \t  -88.83637904884068 \t -0.027138606722327728\n",
      "67     \t [1.04057566 1.08647885]. \t  \u001b[92m-0.0030014583968002388\u001b[0m \t -0.0030014583968002388\n",
      "68     \t [0.1155818 0.9244811]. \t  -83.79651624949977 \t -0.0030014583968002388\n",
      "69     \t [0.9302396  0.89922877]. \t  -0.11967264793471892 \t -0.0030014583968002388\n",
      "70     \t [-1.47252835  0.50797933]. \t  -281.7930650445806 \t -0.0030014583968002388\n",
      "71     \t [-0.60496585  0.88407464]. \t  -29.41773966484951 \t -0.0030014583968002388\n",
      "72     \t [0.13545758 1.00238521]. \t  -97.58020718432583 \t -0.0030014583968002388\n",
      "73     \t [-0.29352304 -0.09093165]. \t  -4.8091973629883595 \t -0.0030014583968002388\n",
      "74     \t [-0.84245666 -1.64991733]. \t  -560.1897177737782 \t -0.0030014583968002388\n",
      "75     \t [ 1.60969256 -1.00479884]. \t  -1293.4278517665257 \t -0.0030014583968002388\n",
      "76     \t [0.33941695 0.41635123]. \t  -9.50534310900239 \t -0.0030014583968002388\n",
      "77     \t [1.43984719 1.69352848]. \t  -14.605468984402297 \t -0.0030014583968002388\n",
      "78     \t [1.74876814 1.68137527]. \t  -190.12253463601016 \t -0.0030014583968002388\n",
      "79     \t [0.59607989 0.36541864]. \t  -0.17336742519789472 \t -0.0030014583968002388\n",
      "80     \t [-1.6419876  -1.70374082]. \t  -1942.8604978327307 \t -0.0030014583968002388\n",
      "81     \t [0.77102632 0.77151141]. \t  -3.1863844894260773 \t -0.0030014583968002388\n",
      "82     \t [1.08616483 1.14274229]. \t  -0.14441133113668123 \t -0.0030014583968002388\n",
      "83     \t [0.15961369 0.02980052]. \t  -0.7081188313880217 \t -0.0030014583968002388\n",
      "84     \t [1.01586111 1.01434984]. \t  -0.03131192845511335 \t -0.0030014583968002388\n",
      "85     \t [1.78889777 0.96399803]. \t  -500.6622668173832 \t -0.0030014583968002388\n",
      "86     \t [ 0.62086675 -1.99945441]. \t  -568.9328188065471 \t -0.0030014583968002388\n",
      "87     \t [-1.99508571  1.16711341]. \t  -800.410112024754 \t -0.0030014583968002388\n",
      "88     \t [ 2.00197735 -0.98261503]. \t  -2491.5412798331467 \t -0.0030014583968002388\n",
      "89     \t [-0.75829718 -1.78029594]. \t  -557.8403897443384 \t -0.0030014583968002388\n",
      "90     \t [ 1.26053213 -0.50401093]. \t  -438.1127623760935 \t -0.0030014583968002388\n",
      "91     \t [2.04206484 1.39503674]. \t  -771.1439943589678 \t -0.0030014583968002388\n",
      "92     \t [ 1.1015313  -0.52844185]. \t  -303.40158362456754 \t -0.0030014583968002388\n",
      "93     \t [1.11703424 1.1815487 ]. \t  -0.4521633044595778 \t -0.0030014583968002388\n",
      "94     \t [0.97817863 0.96346351]. \t  -0.0048719716429606475 \t -0.0030014583968002388\n",
      "95     \t [-0.26471549 -0.51119417]. \t  -35.38680766315234 \t -0.0030014583968002388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [ 1.35705638 -0.0890798 ]. \t  -372.880721250297 \t -0.0030014583968002388\n",
      "97     \t [0.79248782 0.00551502]. \t  -38.79641589678887 \t -0.0030014583968002388\n",
      "98     \t [-1.22520577  1.49539825]. \t  -4.954825042362605 \t -0.0030014583968002388\n",
      "99     \t [-0.26276442  1.13854958]. \t  -115.97854910800217 \t -0.0030014583968002388\n",
      "100    \t [ 1.28981407 -0.97803313]. \t  -697.9172874987738 \t -0.0030014583968002388\n"
     ]
    }
   ],
   "source": [
    "### 6(d). Bayesian optimization runs (x20): GP run number = 4\n",
    "\n",
    "np.random.seed(run_num_4)\n",
    "surrogate_gp_4 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_4 = GPGO(surrogate_gp_4, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_4.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.39002285 1.31602418]. \t  -38.11488737154776 \t -12.122423820878506\n",
      "init   \t [0.58248055 0.68494384]. \t  -12.122423820878506 \t -12.122423820878506\n",
      "init   \t [-1.88768295 -1.7790059 ]. \t  -2862.4120613667637 \t -12.122423820878506\n",
      "init   \t [-0.91545338 -0.75218738]. \t  -256.5560079635026 \t -12.122423820878506\n",
      "init   \t [-1.25504548 -1.24070756]. \t  -797.98450090518 \t -12.122423820878506\n",
      "1      \t [ 0.30487227 -2.02003899]. \t  -446.95422591890787 \t -12.122423820878506\n",
      "2      \t [-2.048  2.048]. \t  -469.9523900415999 \t -12.122423820878506\n",
      "3      \t [ 2.048      -0.44896696]. \t  -2157.0948211603877 \t -12.122423820878506\n",
      "4      \t [0.15979551 2.048     ]. \t  -409.7425705842364 \t -12.122423820878506\n",
      "5      \t [2.048 2.048]. \t  -461.7603900415999 \t -12.122423820878506\n",
      "6      \t [-2.048       0.42457872]. \t  -1430.3731704385827 \t -12.122423820878506\n",
      "7      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -12.122423820878506\n",
      "8      \t [-0.3283321  -1.37897876]. \t  -222.81615952398352 \t -12.122423820878506\n",
      "9      \t [-0.60565178  1.13763679]. \t  -61.994883058810466 \t -12.122423820878506\n",
      "10     \t [-0.97201383  2.048     ]. \t  -125.59146048183501 \t -12.122423820878506\n",
      "11     \t [2.048      0.94746742]. \t  -1055.2930846094212 \t -12.122423820878506\n",
      "12     \t [0.64674469 1.27110881]. \t  -72.85671069423556 \t -12.122423820878506\n",
      "13     \t [1.20946712 2.048     ]. \t  -34.288527809485025 \t -12.122423820878506\n",
      "14     \t [-0.424132 -2.048   ]. \t  -498.3766252835747 \t -12.122423820878506\n",
      "15     \t [ 0.47003048 -0.43609667]. \t  -43.449095622485416 \t -12.122423820878506\n",
      "16     \t [-0.07561111  0.16632962]. \t  \u001b[92m-3.7365794251145914\u001b[0m \t -3.7365794251145914\n",
      "17     \t [-1.30732016  1.43779165]. \t  -12.683789133863836 \t -3.7365794251145914\n",
      "18     \t [0.3349788  0.00604267]. \t  \u001b[92m-1.569420456543643\u001b[0m \t -1.569420456543643\n",
      "19     \t [-0.89806206  0.58340108]. \t  -8.580642589277408 \t -1.569420456543643\n",
      "20     \t [1.07141209 1.30911606]. \t  -2.603391933464119 \t -1.569420456543643\n",
      "21     \t [1.34665679 1.68207557]. \t  -1.8470016329198717 \t -1.569420456543643\n",
      "22     \t [-1.43444716  2.048     ]. \t  -5.935823295766151 \t -1.569420456543643\n",
      "23     \t [-0.42621099  0.59929422]. \t  -19.47626171888515 \t -1.569420456543643\n",
      "24     \t [ 0.08747931 -0.60447038]. \t  -38.30215183275364 \t -1.569420456543643\n",
      "25     \t [-2.048      -0.62787287]. \t  -2334.6292758392638 \t -1.569420456543643\n",
      "26     \t [-1.03797196  1.02623527]. \t  -4.414967196566918 \t -1.569420456543643\n",
      "27     \t [-1.21195869  1.69781337]. \t  -10.13546431870829 \t -1.569420456543643\n",
      "28     \t [1.10985893 0.32266887]. \t  -82.66161823698042 \t -1.569420456543643\n",
      "29     \t [-0.45321098 -0.01330921]. \t  -6.8952021973688655 \t -1.569420456543643\n",
      "30     \t [0.97985138 0.79683732]. \t  -2.6661613470139143 \t -1.569420456543643\n",
      "31     \t [ 0.42434898 -1.29056279]. \t  -216.6080580313885 \t -1.569420456543643\n",
      "32     \t [ 1.0050354 -2.048    ]. \t  -935.195237777104 \t -1.569420456543643\n",
      "33     \t [1.47783042 2.048     ]. \t  -2.0774525804567827 \t -1.569420456543643\n",
      "34     \t [ 1.2462076  -1.10390933]. \t  -705.9950712693154 \t -1.569420456543643\n",
      "35     \t [0.6967976  0.33818372]. \t  -2.262932532206917 \t -1.569420456543643\n",
      "36     \t [-0.13936036 -0.1921534 ]. \t  -5.774527955612352 \t -1.569420456543643\n",
      "37     \t [-1.1324064 -2.048    ]. \t  -1113.6664447719543 \t -1.569420456543643\n",
      "38     \t [-2.048       1.35622373]. \t  -814.760268466023 \t -1.569420456543643\n",
      "39     \t [1.21012816 1.43944882]. \t  \u001b[92m-0.10646069163447587\u001b[0m \t -0.10646069163447587\n",
      "40     \t [-0.54953073  0.29645505]. \t  -2.404102451815549 \t -0.10646069163447587\n",
      "41     \t [1.13043823 1.23855498]. \t  -0.17174317058242472 \t -0.10646069163447587\n",
      "42     \t [-1.22841136 -0.11930527]. \t  -270.1018179427514 \t -0.10646069163447587\n",
      "43     \t [1.40005279 2.03518219]. \t  -0.7230578033461756 \t -0.10646069163447587\n",
      "44     \t [-1.13177747  1.34954507]. \t  -5.015411879506103 \t -0.10646069163447587\n",
      "45     \t [ 0.06847926 -0.03912867]. \t  -1.0597333349121043 \t -0.10646069163447587\n",
      "46     \t [-1.36613273  1.71925998]. \t  -7.761209141329875 \t -0.10646069163447587\n",
      "47     \t [0.8949039 0.7824118]. \t  \u001b[92m-0.0450529293818494\u001b[0m \t -0.0450529293818494\n",
      "48     \t [1.14228453 1.22757883]. \t  -0.6167710893140331 \t -0.0450529293818494\n",
      "49     \t [1.15911288 1.31154364]. \t  -0.1277106050072375 \t -0.0450529293818494\n",
      "50     \t [0.7847283  0.57426937]. \t  -0.21880875283235388 \t -0.0450529293818494\n",
      "51     \t [1.22016468 1.43611271]. \t  -0.32608695841897833 \t -0.0450529293818494\n",
      "52     \t [1.09264673 1.18951201]. \t  \u001b[92m-0.010488620540081465\u001b[0m \t -0.010488620540081465\n",
      "53     \t [1.00061422 1.01825892]. \t  -0.029002798103150526 \t -0.010488620540081465\n",
      "54     \t [1.10111535 1.2068037 ]. \t  -0.01341804454157038 \t -0.010488620540081465\n",
      "55     \t [1.10287652 1.2064783 ]. \t  -0.020302231552822545 \t -0.010488620540081465\n",
      "56     \t [1.16652218 1.36622054]. \t  -0.030696119130089333 \t -0.010488620540081465\n",
      "57     \t [ 2.048      -1.29204695]. \t  -3011.1029839452813 \t -0.010488620540081465\n",
      "58     \t [0.97903473 0.93846347]. \t  -0.040621879464538546 \t -0.010488620540081465\n",
      "59     \t [1.41454758 2.04794238]. \t  -0.39272638553152606 \t -0.010488620540081465\n",
      "60     \t [1.15234493 1.35002759]. \t  -0.07217708855027169 \t -0.010488620540081465\n",
      "61     \t [1.36726494 1.85433147]. \t  -0.1576300129510156 \t -0.010488620540081465\n",
      "62     \t [1.08194112 1.12373249]. \t  -0.2263387426115763 \t -0.010488620540081465\n",
      "63     \t [0.78041766 0.58493438]. \t  -0.10638100123073929 \t -0.010488620540081465\n",
      "64     \t [1.23118927 1.49215057]. \t  -0.10950592373378493 \t -0.010488620540081465\n",
      "65     \t [1.21884568 1.44847949]. \t  -0.18557384020331724 \t -0.010488620540081465\n",
      "66     \t [1.11242365 1.2142264 ]. \t  -0.06674172614832308 \t -0.010488620540081465\n",
      "67     \t [1.43545352 2.04799791]. \t  -0.2053171269099678 \t -0.010488620540081465\n",
      "68     \t [1.44235539 2.048     ]. \t  -0.30058345188949825 \t -0.010488620540081465\n",
      "69     \t [1.41400328 2.04799974]. \t  -0.40754076785846094 \t -0.010488620540081465\n",
      "70     \t [1.18611796 1.39362668]. \t  -0.05219388124725305 \t -0.010488620540081465\n",
      "71     \t [0.97545559 0.93902808]. \t  -0.016191287389794785 \t -0.010488620540081465\n",
      "72     \t [0.96300977 0.92620701]. \t  \u001b[92m-0.001507708129716722\u001b[0m \t -0.001507708129716722\n",
      "73     \t [0.81733247 0.66727205]. \t  -0.03342523476460667 \t -0.001507708129716722\n",
      "74     \t [ 0.07614406 -0.01561587]. \t  -0.8993648223499882 \t -0.001507708129716722\n",
      "75     \t [1.42849644 2.048     ]. \t  -0.18908213213593086 \t -0.001507708129716722\n",
      "76     \t [0.82760319 0.64834053]. \t  -0.16357792813442404 \t -0.001507708129716722\n",
      "77     \t [0.97840825 0.9151572 ]. \t  -0.17792201281030096 \t -0.001507708129716722\n",
      "78     \t [1.13377467 1.22640208]. \t  -0.3665022789121209 \t -0.001507708129716722\n",
      "79     \t [0.8633951  0.71015224]. \t  -0.14326179542938275 \t -0.001507708129716722\n",
      "80     \t [1.41157446 2.048     ]. \t  -0.4769474088408302 \t -0.001507708129716722\n",
      "81     \t [0.74258754 0.57385495]. \t  -0.11652095993265027 \t -0.001507708129716722\n",
      "82     \t [1.08616483 1.14274229]. \t  -0.14441133113668123 \t -0.001507708129716722\n",
      "83     \t [0.99994476 1.0087903 ]. \t  -0.007922379973825451 \t -0.001507708129716722\n",
      "84     \t [1.01586111 1.01434984]. \t  -0.03131192845511335 \t -0.001507708129716722\n",
      "85     \t [1.04658225 1.09252104]. \t  -0.0029614127638609637 \t -0.001507708129716722\n",
      "86     \t [0.83573851 0.66254748]. \t  -0.15594456368702336 \t -0.001507708129716722\n",
      "87     \t [0.86799181 0.74902941]. \t  -0.01934491879741459 \t -0.001507708129716722\n",
      "88     \t [0.76475067 0.57561666]. \t  -0.06385585994138843 \t -0.001507708129716722\n",
      "89     \t [1.38904956 1.9345991 ]. \t  -0.1540019586280528 \t -0.001507708129716722\n",
      "90     \t [0.89953556 0.76389013]. \t  -0.21506746831589166 \t -0.001507708129716722\n",
      "91     \t [1.43198537 2.048     ]. \t  -0.18727808830973497 \t -0.001507708129716722\n",
      "92     \t [1.37564718 1.88773508]. \t  -0.14329178274314763 \t -0.001507708129716722\n",
      "93     \t [1.12075249 1.20925233]. \t  -0.23392164283694192 \t -0.001507708129716722\n",
      "94     \t [0.97817863 0.96346351]. \t  -0.0048719716429606475 \t -0.001507708129716722\n",
      "95     \t [0.69992026 0.43364855]. \t  -0.4063395968922541 \t -0.001507708129716722\n",
      "96     \t [1.08730716 1.09809216]. \t  -0.7156555730767681 \t -0.001507708129716722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [ 0.01091283 -0.03700933]. \t  -1.1161453862155808 \t -0.001507708129716722\n",
      "98     \t [0.77039917 0.59171003]. \t  -0.05304228979834189 \t -0.001507708129716722\n",
      "99     \t [0.74158565 0.50762974]. \t  -0.2458723760620021 \t -0.001507708129716722\n",
      "100    \t [1.11270162 1.23252635]. \t  -0.015813678542386984 \t -0.001507708129716722\n"
     ]
    }
   ],
   "source": [
    "### 6(d). Bayesian optimization runs (x20): STP DF1 run number = 4\n",
    "\n",
    "np.random.seed(run_num_4)\n",
    "surrogate_stp_df1_4 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_4 = GPGO(surrogate_stp_df1_4, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_4.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.8086569761712905, -6.497164576062399)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(d). Training Regret Minimisation: run number = 4\n",
    "\n",
    "gp_output_4 = np.append(np.max(gpgo_gp_4.GP.y[0:n_init]),gpgo_gp_4.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_4 = np.append(np.max(gpgo_stp_df1_4.GP.y[0:n_init]),gpgo_stp_df1_4.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_4 = np.log(y_global_orig - gp_output_4)\n",
    "regret_stp_df1_4 = np.log(y_global_orig - stp_df1_output_4)\n",
    "\n",
    "train_regret_gp_4 = min_max_array(regret_gp_4)\n",
    "train_regret_stp_df1_4 = min_max_array(regret_stp_df1_4)\n",
    "\n",
    "# GP, STP df1, STP df2 - training regret minimization: run number = 4\n",
    "min_train_regret_gp_4 = min(train_regret_gp_4)\n",
    "min_train_regret_stp_df1_4 = min(train_regret_stp_df1_4)\n",
    "\n",
    "min_train_regret_gp_4, min_train_regret_stp_df1_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.89224842 -1.85198538]. \t  -701.2510650265426 \t -19.26858879438613\n",
      "init   \t [1.82055722 0.76341264]. \t  -651.4415516282996 \t -19.26858879438613\n",
      "init   \t [ 0.33262524 -1.46358839]. \t  -248.26474965119897 \t -19.26858879438613\n",
      "init   \t [ 1.82648497 -0.65539856]. \t  -1593.8471029071798 \t -19.26858879438613\n",
      "init   \t [ 0.49330364 -0.1926773 ]. \t  -19.26858879438613 \t -19.26858879438613\n",
      "1      \t [-0.28843095 -0.12921037]. \t  \u001b[92m-6.1715485561395855\u001b[0m \t -6.1715485561395855\n",
      "2      \t [0.19747079 0.11273098]. \t  \u001b[92m-1.1877569000264503\u001b[0m \t -1.1877569000264503\n",
      "3      \t [-0.01757139 -0.57307891]. \t  -33.91279240710749 \t -1.1877569000264503\n",
      "4      \t [-1.57211147  0.29041168]. \t  -482.34542541867296 \t -1.1877569000264503\n",
      "5      \t [ 0.14433783 -0.15588651]. \t  -3.855150679497099 \t -1.1877569000264503\n",
      "6      \t [-0.94204176 -1.86255396]. \t  -760.0196775121007 \t -1.1877569000264503\n",
      "7      \t [0.37488994 0.11610766]. \t  \u001b[92m-0.4504685712363787\u001b[0m \t -0.4504685712363787\n",
      "8      \t [-0.38656839  0.15727624]. \t  -1.928720216604107 \t -0.4504685712363787\n",
      "9      \t [ 0.66536335 -0.68574436]. \t  -127.4525440493784 \t -0.4504685712363787\n",
      "10     \t [0.46832141 0.75699845]. \t  -29.191962531159998 \t -0.4504685712363787\n",
      "11     \t [ 0.30818766 -0.95779961]. \t  -111.31301897774816 \t -0.4504685712363787\n",
      "12     \t [-0.79199657  1.24030259]. \t  -40.7935497215405 \t -0.4504685712363787\n",
      "13     \t [ 0.1617288  -1.70981743]. \t  -302.06314378204524 \t -0.4504685712363787\n",
      "14     \t [-0.52447741  0.67309235]. \t  -18.16568887566376 \t -0.4504685712363787\n",
      "15     \t [-1.39118819  2.048     ]. \t  -6.985553944537488 \t -0.4504685712363787\n",
      "16     \t [0.18631966 0.22642973]. \t  -4.337528730555026 \t -0.4504685712363787\n",
      "17     \t [-0.20620385  0.07384068]. \t  -1.5530260357742134 \t -0.4504685712363787\n",
      "18     \t [-1.86644484 -0.81095363]. \t  -1852.5496309990187 \t -0.4504685712363787\n",
      "19     \t [-1.40201475  1.34983871]. \t  -43.6914566252332 \t -0.4504685712363787\n",
      "20     \t [0.30382441 0.07864089]. \t  -0.5033429139397431 \t -0.4504685712363787\n",
      "21     \t [ 1.95309727 -0.85304942]. \t  -2179.5931706828223 \t -0.4504685712363787\n",
      "22     \t [-0.95727494  0.78014798]. \t  -5.686713775669741 \t -0.4504685712363787\n",
      "23     \t [ 0.67124135 -1.79132645]. \t  -502.7157858003789 \t -0.4504685712363787\n",
      "24     \t [-0.7517983  0.5739709]. \t  -3.0764889475728885 \t -0.4504685712363787\n",
      "25     \t [-0.87114217 -1.35563903]. \t  -450.6239178166734 \t -0.4504685712363787\n",
      "26     \t [ 1.90213146 -0.1753872 ]. \t  -1439.8714465437474 \t -0.4504685712363787\n",
      "27     \t [2.048 2.048]. \t  -461.7603900415999 \t -0.4504685712363787\n",
      "28     \t [-1.59710966  1.6712795 ]. \t  -84.0934413571611 \t -0.4504685712363787\n",
      "29     \t [ 0.524736   -0.52823335]. \t  -64.80015296484173 \t -0.4504685712363787\n",
      "30     \t [-1.85968107 -0.42642886]. \t  -1517.377938264438 \t -0.4504685712363787\n",
      "31     \t [1.16701927 1.0303953 ]. \t  -11.019684425350619 \t -0.4504685712363787\n",
      "32     \t [1.78533202 0.18581936]. \t  -901.5716411353206 \t -0.4504685712363787\n",
      "33     \t [ 1.09677473 -1.1605802 ]. \t  -558.6202333727973 \t -0.4504685712363787\n",
      "34     \t [0.910323   0.72154278]. \t  -1.1560508545995172 \t -0.4504685712363787\n",
      "35     \t [1.06175496 1.84426495]. \t  -51.40430386415457 \t -0.4504685712363787\n",
      "36     \t [-1.84753725 -0.90425291]. \t  -1872.3158393168924 \t -0.4504685712363787\n",
      "37     \t [1.04842931 1.24928174]. \t  -2.2546775766478433 \t -0.4504685712363787\n",
      "38     \t [ 1.85155885 -0.06032526]. \t  -1217.7549658121766 \t -0.4504685712363787\n",
      "39     \t [-0.47409794 -1.07288929]. \t  -170.5646308735413 \t -0.4504685712363787\n",
      "40     \t [-1.46171993 -0.84438835]. \t  -894.7042201361589 \t -0.4504685712363787\n",
      "41     \t [ 0.70288772 -1.40412133]. \t  -360.39415131500715 \t -0.4504685712363787\n",
      "42     \t [-0.34408017  1.33298505]. \t  -149.33038225758912 \t -0.4504685712363787\n",
      "43     \t [0.9703395  1.86355054]. \t  -85.00776489243397 \t -0.4504685712363787\n",
      "44     \t [ 2.03889143 -0.13842641]. \t  -1846.2153330174212 \t -0.4504685712363787\n",
      "45     \t [1.19417494 1.45905984]. \t  \u001b[92m-0.1466439078501095\u001b[0m \t -0.1466439078501095\n",
      "46     \t [ 0.88480869 -0.11548773]. \t  -80.72087973774273 \t -0.1466439078501095\n",
      "47     \t [ 1.80510749 -0.5414978 ]. \t  -1444.5804302979589 \t -0.1466439078501095\n",
      "48     \t [ 1.47770263 -0.7042792 ]. \t  -834.2157619854326 \t -0.1466439078501095\n",
      "49     \t [-1.21804523  2.048     ]. \t  -36.770601086361296 \t -0.1466439078501095\n",
      "50     \t [ 1.82896166 -0.79628617]. \t  -1715.7957488310178 \t -0.1466439078501095\n",
      "51     \t [1.16167114 1.37758906]. \t  \u001b[92m-0.10515044765901199\u001b[0m \t -0.10515044765901199\n",
      "52     \t [-1.13727757 -0.48391893]. \t  -320.4543105300327 \t -0.10515044765901199\n",
      "53     \t [0.54470964 0.05868839]. \t  -5.872650844990371 \t -0.10515044765901199\n",
      "54     \t [-1.77083668 -0.78496102]. \t  -1544.9632796953172 \t -0.10515044765901199\n",
      "55     \t [-1.61596707  1.87406092]. \t  -61.202736722330066 \t -0.10515044765901199\n",
      "56     \t [-0.18210678  0.5449946 ]. \t  -27.594547290197674 \t -0.10515044765901199\n",
      "57     \t [ 0.91341547 -0.19158267]. \t  -105.2567296404248 \t -0.10515044765901199\n",
      "58     \t [0.67357667 0.42801373]. \t  -0.17255906735178672 \t -0.10515044765901199\n",
      "59     \t [-0.46293544  0.98191754]. \t  -61.062432456908915 \t -0.10515044765901199\n",
      "60     \t [1.15223633 1.34219026]. \t  \u001b[92m-0.04432198505913773\u001b[0m \t -0.04432198505913773\n",
      "61     \t [1.79181136 1.96545684]. \t  -155.66211400260087 \t -0.04432198505913773\n",
      "62     \t [-1.84243827  1.12569931]. \t  -522.860866063789 \t -0.04432198505913773\n",
      "63     \t [1.42279806 2.048     ]. \t  -0.23467000435030594 \t -0.04432198505913773\n",
      "64     \t [1.36793178 1.82899607]. \t  -0.313806341929654 \t -0.04432198505913773\n",
      "65     \t [-1.2600135   1.61055724]. \t  -5.160208411772265 \t -0.04432198505913773\n",
      "66     \t [-1.24753263  1.31923265]. \t  -10.6732816744281 \t -0.04432198505913773\n",
      "67     \t [1.13636014 1.0797459 ]. \t  -4.494715722148892 \t -0.04432198505913773\n",
      "68     \t [ 0.59571034 -1.75689577]. \t  -446.11925720159877 \t -0.04432198505913773\n",
      "69     \t [-0.45001186  1.34030459]. \t  -131.5600350527523 \t -0.04432198505913773\n",
      "70     \t [0.26606461 0.93872914]. \t  -75.8704309781511 \t -0.04432198505913773\n",
      "71     \t [-0.4594266   0.79774648]. \t  -36.54852667761673 \t -0.04432198505913773\n",
      "72     \t [1.06902703 1.80610294]. \t  -43.99935146922012 \t -0.04432198505913773\n",
      "73     \t [0.31023289 0.2037111 ]. \t  -1.6306869020685317 \t -0.04432198505913773\n",
      "74     \t [-1.17935756 -1.10289653]. \t  -626.6438563804901 \t -0.04432198505913773\n",
      "75     \t [-1.60787827  1.80847178]. \t  -67.14297118451498 \t -0.04432198505913773\n",
      "76     \t [1.36550569 1.84391407]. \t  -0.1764091622083999 \t -0.04432198505913773\n",
      "77     \t [ 1.26056756 -1.68744052]. \t  -1073.5941760425349 \t -0.04432198505913773\n",
      "78     \t [-0.08296231 -0.19072486]. \t  -5.077684008941686 \t -0.04432198505913773\n",
      "79     \t [0.52006441 1.14213243]. \t  -76.2104012157738 \t -0.04432198505913773\n",
      "80     \t [1.16983775 1.01121605]. \t  -12.795482119271753 \t -0.04432198505913773\n",
      "81     \t [-0.26678744  0.45927273]. \t  -16.66669350295007 \t -0.04432198505913773\n",
      "82     \t [0.61793428 0.36623989]. \t  -0.17031922043218656 \t -0.04432198505913773\n",
      "83     \t [0.62086162 0.66630343]. \t  -8.030535161003021 \t -0.04432198505913773\n",
      "84     \t [-0.52481659  0.96661821]. \t  -50.09884108648903 \t -0.04432198505913773\n",
      "85     \t [-1.45311614  0.17828721]. \t  -379.7669316665363 \t -0.04432198505913773\n",
      "86     \t [-1.08490153  0.33776414]. \t  -74.78039998886929 \t -0.04432198505913773\n",
      "87     \t [0.32562902 0.79325948]. \t  -47.68262687498201 \t -0.04432198505913773\n",
      "88     \t [1.78718165 0.57046909]. \t  -688.920672118577 \t -0.04432198505913773\n",
      "89     \t [-0.10473139 -0.70101213]. \t  -51.91209662785994 \t -0.04432198505913773\n",
      "90     \t [1.34613474 0.31623092]. \t  -223.87587811827424 \t -0.04432198505913773\n",
      "91     \t [-0.01138777  0.76012614]. \t  -58.78236632474647 \t -0.04432198505913773\n",
      "92     \t [-0.8584134 -0.3534916]. \t  -122.34331911774673 \t -0.04432198505913773\n",
      "93     \t [1.04828353 1.10529352]. \t  \u001b[92m-0.006421105149141345\u001b[0m \t -0.006421105149141345\n",
      "94     \t [1.41016946 1.95914456]. \t  -0.2548711441052899 \t -0.006421105149141345\n",
      "95     \t [-1.18216667e-01  4.67764674e-05]. \t  -1.2698085577142209 \t -0.006421105149141345\n",
      "96     \t [1.05692107 1.12200744]. \t  \u001b[92m-0.005665851664246987\u001b[0m \t -0.005665851664246987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [ 1.39882708 -0.35325143]. \t  -533.7545625527544 \t -0.005665851664246987\n",
      "98     \t [1.06121167 1.13086634]. \t  -0.0059522375344331305 \t -0.005665851664246987\n",
      "99     \t [ 0.73772642 -0.24340781]. \t  -62.107737024432794 \t -0.005665851664246987\n",
      "100    \t [0.94613686 1.71182443]. \t  -66.69453842429482 \t -0.005665851664246987\n"
     ]
    }
   ],
   "source": [
    "### 6(e). Bayesian optimization runs (x20): GP run number = 5\n",
    "\n",
    "np.random.seed(run_num_5)\n",
    "surrogate_gp_5 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_5 = GPGO(surrogate_gp_5, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_5.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.89224842 -1.85198538]. \t  -701.2510650265426 \t -19.26858879438613\n",
      "init   \t [1.82055722 0.76341264]. \t  -651.4415516282996 \t -19.26858879438613\n",
      "init   \t [ 0.33262524 -1.46358839]. \t  -248.26474965119897 \t -19.26858879438613\n",
      "init   \t [ 1.82648497 -0.65539856]. \t  -1593.8471029071798 \t -19.26858879438613\n",
      "init   \t [ 0.49330364 -0.1926773 ]. \t  -19.26858879438613 \t -19.26858879438613\n",
      "1      \t [-0.58199593 -0.13579202]. \t  -25.01880700766411 \t -19.26858879438613\n",
      "2      \t [-0.03235765  2.048     ]. \t  -420.0674135012082 \t -19.26858879438613\n",
      "3      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -19.26858879438613\n",
      "4      \t [-2.048  2.048]. \t  -469.9523900415999 \t -19.26858879438613\n",
      "5      \t [2.048 2.048]. \t  -461.7603900415999 \t -19.26858879438613\n",
      "6      \t [-2.048       0.53370091]. \t  -1349.2918008544018 \t -19.26858879438613\n",
      "7      \t [0.06170756 0.70685223]. \t  -50.307536356559424 \t -19.26858879438613\n",
      "8      \t [-0.06269852 -0.42787723]. \t  -19.77517171510459 \t -19.26858879438613\n",
      "9      \t [-1.025822  2.048   ]. \t  -103.2436583555939 \t -19.26858879438613\n",
      "10     \t [-0.07818715 -2.048     ]. \t  -423.1006040166043 \t -19.26858879438613\n",
      "11     \t [-0.77248128  0.88822019]. \t  \u001b[92m-11.638499456693737\u001b[0m \t -11.638499456693737\n",
      "12     \t [-0.3220936   0.28728879]. \t  \u001b[92m-5.116790103112903\u001b[0m \t -5.116790103112903\n",
      "13     \t [1.05540595 1.50103263]. \t  -14.991652035379806 \t -5.116790103112903\n",
      "14     \t [0.85388803 0.71447319]. \t  \u001b[92m-0.04281557956714523\u001b[0m \t -0.04281557956714523\n",
      "15     \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -0.04281557956714523\n",
      "16     \t [1.11308886 2.048     ]. \t  -65.4662586972646 \t -0.04281557956714523\n",
      "17     \t [-1.2020297   1.51093418]. \t  -5.285311094832666 \t -0.04281557956714523\n",
      "18     \t [-0.75083829  1.45556491]. \t  -82.5973667373204 \t -0.04281557956714523\n",
      "19     \t [0.66011386 1.29398703]. \t  -73.77254904048438 \t -0.04281557956714523\n",
      "20     \t [-2.048      -0.62708224]. \t  -2333.8668288062013 \t -0.04281557956714523\n",
      "21     \t [0.42577709 0.29544141]. \t  -1.6328748515804667 \t -0.04281557956714523\n",
      "22     \t [ 0.40837918 -2.048     ]. \t  -490.87220452801574 \t -0.04281557956714523\n",
      "23     \t [-0.62130939 -1.11996273]. \t  -229.4286581613444 \t -0.04281557956714523\n",
      "24     \t [ 0.74564568 -0.88227558]. \t  -206.92475667211104 \t -0.04281557956714523\n",
      "25     \t [0.95293051 0.11048534]. \t  -63.617390016398396 \t -0.04281557956714523\n",
      "26     \t [-1.45161749  2.048     ]. \t  -6.3608134587228955 \t -0.04281557956714523\n",
      "27     \t [-1.31702949  1.82411839]. \t  -6.170576773112823 \t -0.04281557956714523\n",
      "28     \t [-0.92452314 -2.048     ]. \t  -846.2955007949215 \t -0.04281557956714523\n",
      "29     \t [1.48836597 2.048     ]. \t  -3.035197379429622 \t -0.04281557956714523\n",
      "30     \t [1.37619255 1.7886378 ]. \t  -1.249658973552329 \t -0.04281557956714523\n",
      "31     \t [-0.29561445 -0.15090773]. \t  -7.357097613725183 \t -0.04281557956714523\n",
      "32     \t [0.677289   0.42805871]. \t  -0.1981562669074528 \t -0.04281557956714523\n",
      "33     \t [-0.99116028  0.52835275]. \t  -24.58049170100946 \t -0.04281557956714523\n",
      "34     \t [1.20253732 1.31106748]. \t  -1.8642914478972517 \t -0.04281557956714523\n",
      "35     \t [-0.68011806  0.3871073 ]. \t  -3.392116347750346 \t -0.04281557956714523\n",
      "36     \t [-1.84195959  1.40085847]. \t  -404.8658621501827 \t -0.04281557956714523\n",
      "37     \t [0.15151905 0.00193477]. \t  -0.7641176571845689 \t -0.04281557956714523\n",
      "38     \t [1.36983805 1.94622956]. \t  -0.6236112120417172 \t -0.04281557956714523\n",
      "39     \t [-1.05246842  1.02107359]. \t  -4.962862845673275 \t -0.04281557956714523\n",
      "40     \t [1.01570168 1.15133626]. \t  -1.432729291847667 \t -0.04281557956714523\n",
      "41     \t [ 2.048      -0.01833121]. \t  -1775.7278444387455 \t -0.04281557956714523\n",
      "42     \t [-1.38672565 -1.19273616]. \t  -976.4826387297252 \t -0.04281557956714523\n",
      "43     \t [1.4094343 2.048    ]. \t  -0.5457994151294445 \t -0.04281557956714523\n",
      "44     \t [2.048      1.39462949]. \t  -784.9160383826797 \t -0.04281557956714523\n",
      "45     \t [1.08226208 1.02668492]. \t  -2.0978648234611796 \t -0.04281557956714523\n",
      "46     \t [0.57290799 0.24986877]. \t  -0.7963549679293094 \t -0.04281557956714523\n",
      "47     \t [1.18175993 1.38837349]. \t  \u001b[92m-0.03973287450252386\u001b[0m \t -0.03973287450252386\n",
      "48     \t [1.25881738 1.59553032]. \t  -0.07888733534425782 \t -0.03973287450252386\n",
      "49     \t [ 0.05783649 -0.04548359]. \t  -1.1260957880772295 \t -0.03973287450252386\n",
      "50     \t [1.10758073 1.21776503]. \t  \u001b[92m-0.019619760805083056\u001b[0m \t -0.019619760805083056\n",
      "51     \t [1.35838012 1.81950921]. \t  -0.19442023963649355 \t -0.019619760805083056\n",
      "52     \t [1.32640543 1.73966829]. \t  -0.14528288678756163 \t -0.019619760805083056\n",
      "53     \t [1.29053787 1.6803889 ]. \t  -0.10661596953738899 \t -0.019619760805083056\n",
      "54     \t [0.60953816 0.30082794]. \t  -0.6524343062964518 \t -0.019619760805083056\n",
      "55     \t [-0.86656449  0.72506719]. \t  -3.550972223222633 \t -0.019619760805083056\n",
      "56     \t [-1.38376274  2.048     ]. \t  -7.456567200269828 \t -0.019619760805083056\n",
      "57     \t [1.4081807 2.048    ]. \t  -0.5894640274098554 \t -0.019619760805083056\n",
      "58     \t [0.87989077 0.77597071]. \t  \u001b[92m-0.014737020185731925\u001b[0m \t -0.014737020185731925\n",
      "59     \t [1.06786958 1.14840605]. \t  \u001b[92m-0.011103639809545702\u001b[0m \t -0.011103639809545702\n",
      "60     \t [0.77652812 0.64179423]. \t  -0.20047054035034761 \t -0.011103639809545702\n",
      "61     \t [1.40380934 2.01648673]. \t  -0.3728815464800568 \t -0.011103639809545702\n",
      "62     \t [1.23200239 1.53433715]. \t  -0.08107407059918498 \t -0.011103639809545702\n",
      "63     \t [0.85594626 0.77790077]. \t  -0.22556899070371514 \t -0.011103639809545702\n",
      "64     \t [0.81165371 0.66051665]. \t  -0.03577531316437254 \t -0.011103639809545702\n",
      "65     \t [0.71189576 0.49877464]. \t  -0.08943759693141584 \t -0.011103639809545702\n",
      "66     \t [-0.05160742 -0.00485861]. \t  -1.1115361134816875 \t -0.011103639809545702\n",
      "67     \t [1.24012681 1.55431216]. \t  -0.0845491987260068 \t -0.011103639809545702\n",
      "68     \t [1.18684762 1.39443435]. \t  -0.05499922344651112 \t -0.011103639809545702\n",
      "69     \t [1.17926304 1.40778684]. \t  -0.06146355998419155 \t -0.011103639809545702\n",
      "70     \t [0.65928634 0.40336556]. \t  -0.2140104453002815 \t -0.011103639809545702\n",
      "71     \t [1.09648559 1.20277312]. \t  \u001b[92m-0.009333722011725979\u001b[0m \t -0.009333722011725979\n",
      "72     \t [1.34994895 1.88010396]. \t  -0.45587560640085384 \t -0.009333722011725979\n",
      "73     \t [1.07142748 1.14945362]. \t  \u001b[92m-0.005325921768279438\u001b[0m \t -0.005325921768279438\n",
      "74     \t [0.75874719 0.53125702]. \t  -0.2556967305851796 \t -0.005325921768279438\n",
      "75     \t [1.37622559 1.90314391]. \t  -0.14991253141547017 \t -0.005325921768279438\n",
      "76     \t [1.34668116 1.81393547]. \t  -0.12020267421931341 \t -0.005325921768279438\n",
      "77     \t [0.70000065 0.45513275]. \t  -0.21157845843482526 \t -0.005325921768279438\n",
      "78     \t [1.08558416 1.17062617]. \t  -0.013513295872727312 \t -0.005325921768279438\n",
      "79     \t [ 2.048      -1.37396961]. \t  -3101.6654005732985 \t -0.005325921768279438\n",
      "80     \t [0.84672634 0.72428213]. \t  -0.02887542887345306 \t -0.005325921768279438\n",
      "81     \t [0.80500547 0.66372675]. \t  -0.06264971269636498 \t -0.005325921768279438\n",
      "82     \t [0.6668837  0.45841444]. \t  -0.1296822894807979 \t -0.005325921768279438\n",
      "83     \t [1.32446392 1.76582399]. \t  -0.11877766252616728 \t -0.005325921768279438\n",
      "84     \t [1.30892953 1.72778762]. \t  -0.1164366407059837 \t -0.005325921768279438\n",
      "85     \t [0.9098575  0.82384627]. \t  -0.009721190694447846 \t -0.005325921768279438\n",
      "86     \t [0.83630591 0.75014825]. \t  -0.2842572802702751 \t -0.005325921768279438\n",
      "87     \t [1.35386769 1.85505995]. \t  -0.17407313833354746 \t -0.005325921768279438\n",
      "88     \t [0.210386   0.01018011]. \t  -0.7396496423938667 \t -0.005325921768279438\n",
      "89     \t [1.02679354 1.05897321]. \t  \u001b[92m-0.0028971238550412897\u001b[0m \t -0.0028971238550412897\n",
      "90     \t [0.81133423 0.64173422]. \t  -0.06291559031576043 \t -0.0028971238550412897\n",
      "91     \t [1.3208001  1.79681123]. \t  -0.3764241336676714 \t -0.0028971238550412897\n",
      "92     \t [0.80531383 0.63660205]. \t  -0.05213116527977018 \t -0.0028971238550412897\n",
      "93     \t [1.37809361 1.94364511]. \t  -0.34100752165125403 \t -0.0028971238550412897\n",
      "94     \t [0.750584   0.57146777]. \t  -0.0687554656026501 \t -0.0028971238550412897\n",
      "95     \t [1.27400261 1.62220449]. \t  -0.07515454372669111 \t -0.0028971238550412897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [0.75559781 0.56438559]. \t  -0.06401281426104552 \t -0.0028971238550412897\n",
      "97     \t [1.22140071 1.547812  ]. \t  -0.3625320022898277 \t -0.0028971238550412897\n",
      "98     \t [1.11634713 1.23366295]. \t  -0.029332051517165343 \t -0.0028971238550412897\n",
      "99     \t [0.71702167 0.50981671]. \t  -0.08192862811679665 \t -0.0028971238550412897\n",
      "100    \t [1.11945846 1.23580042]. \t  -0.04450048162672772 \t -0.0028971238550412897\n"
     ]
    }
   ],
   "source": [
    "### 6(e). Bayesian optimization runs (x20): STP DF1 run number = 5\n",
    "\n",
    "np.random.seed(run_num_5)\n",
    "surrogate_stp_df1_5 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_5 = GPGO(surrogate_stp_df1_3, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_5.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.173298057894102, -5.844036808246775)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(e). Training Regret Minimisation: run number = 5\n",
    "\n",
    "gp_output_5 = np.append(np.max(gpgo_gp_5.GP.y[0:n_init]),gpgo_gp_5.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_5 = np.append(np.max(gpgo_stp_df1_5.GP.y[0:n_init]),gpgo_stp_df1_5.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_5 = np.log(y_global_orig - gp_output_5)\n",
    "regret_stp_df1_5 = np.log(y_global_orig - stp_df1_output_5)\n",
    "\n",
    "train_regret_gp_5 = min_max_array(regret_gp_5)\n",
    "train_regret_stp_df1_5 = min_max_array(regret_stp_df1_5)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 5\n",
    "min_train_regret_gp_5 = min(train_regret_gp_5)\n",
    "min_train_regret_stp_df1_5 = min(train_regret_stp_df1_5)\n",
    "\n",
    "min_train_regret_gp_5, min_train_regret_stp_df1_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.82099045 1.40978849]. \t  -54.16678839674669 \t -16.933801290298337\n",
      "init   \t [0.72300272 0.9333066 ]. \t  -16.933801290298337 \t -16.933801290298337\n",
      "init   \t [ 1.84917179 -1.9959677 ]. \t  -2933.3811709087195 \t -16.933801290298337\n",
      "init   \t [-0.35394479 -1.8480628 ]. \t  -391.24012678773295 \t -16.933801290298337\n",
      "init   \t [-1.63869261  0.03303959]. \t  -710.4183779486988 \t -16.933801290298337\n",
      "1      \t [-1.22778608  1.00005548]. \t  -30.70882952512096 \t -16.933801290298337\n",
      "2      \t [-1.02513149  1.77403238]. \t  -56.39398585094214 \t -16.933801290298337\n",
      "3      \t [-0.45404611  1.03977005]. \t  -71.60517800765678 \t -16.933801290298337\n",
      "4      \t [1.50170878 1.03378983]. \t  -149.41870900493865 \t -16.933801290298337\n",
      "5      \t [-1.88399884  1.56438614]. \t  -402.36594550442203 \t -16.933801290298337\n",
      "6      \t [0.96733942 1.23338157]. \t  \u001b[92m-8.859786989719698\u001b[0m \t -8.859786989719698\n",
      "7      \t [-0.97915977  1.23144805]. \t  -11.353285970978245 \t -8.859786989719698\n",
      "8      \t [-0.98441268  1.12850523]. \t  \u001b[92m-6.47990628833878\u001b[0m \t -6.47990628833878\n",
      "9      \t [1.39305931 1.59810244]. \t  -11.88592784227276 \t -6.47990628833878\n",
      "10     \t [-2.03921494  0.99520542]. \t  -1009.8152847586761 \t -6.47990628833878\n",
      "11     \t [-1.29569475  1.65306356]. \t  \u001b[92m-5.336578897151559\u001b[0m \t -5.336578897151559\n",
      "12     \t [-1.15855031  1.43218314]. \t  -5.468337575957579 \t -5.336578897151559\n",
      "13     \t [-1.45435913  2.048     ]. \t  -6.4749317855175255 \t -5.336578897151559\n",
      "14     \t [-0.65847619 -1.74706305]. \t  -478.27570847357026 \t -5.336578897151559\n",
      "15     \t [-0.10475704  1.0180129 ]. \t  -102.63321594159449 \t -5.336578897151559\n",
      "16     \t [1.52844744 2.048     ]. \t  -8.58238953327681 \t -5.336578897151559\n",
      "17     \t [-0.24281423 -0.32651574]. \t  -16.403645164400135 \t -5.336578897151559\n",
      "18     \t [-0.0223663   0.02749288]. \t  \u001b[92m-1.1180930549160117\u001b[0m \t -1.1180930549160117\n",
      "19     \t [ 0.33160036 -1.31127596]. \t  -202.4375801118951 \t -1.1180930549160117\n",
      "20     \t [ 0.19445553 -0.5338037 ]. \t  -33.3234622026819 \t -1.1180930549160117\n",
      "21     \t [-0.48035622  0.2784312 ]. \t  -2.4188795688076374 \t -1.1180930549160117\n",
      "22     \t [-1.12412331 -0.96220724]. \t  -499.9573739223982 \t -1.1180930549160117\n",
      "23     \t [-0.52465357  1.79526511]. \t  -233.3657076035409 \t -1.1180930549160117\n",
      "24     \t [-1.19857428  1.44358809]. \t  -4.838639766520167 \t -1.1180930549160117\n",
      "25     \t [1.31422236 1.73813017]. \t  \u001b[92m-0.1107254243841127\u001b[0m \t -0.1107254243841127\n",
      "26     \t [-0.17291139  0.07450153]. \t  -1.5746655105475347 \t -0.1107254243841127\n",
      "27     \t [ 0.08153567 -1.51116215]. \t  -231.2183606081168 \t -0.1107254243841127\n",
      "28     \t [ 0.39213075 -1.81085152]. \t  -386.3419118516845 \t -0.1107254243841127\n",
      "29     \t [-0.29597789 -1.73026393]. \t  -332.14354552642766 \t -0.1107254243841127\n",
      "30     \t [0.68516283 0.05254546]. \t  -17.47990460194126 \t -0.1107254243841127\n",
      "31     \t [0.38517771 0.11315894]. \t  -0.5019310510894152 \t -0.1107254243841127\n",
      "32     \t [ 0.32030499 -1.32421215]. \t  -204.0399330070398 \t -0.1107254243841127\n",
      "33     \t [ 0.36426018 -1.72217605]. \t  -344.4552958904694 \t -0.1107254243841127\n",
      "34     \t [ 1.00425394 -0.51826226]. \t  -233.1082503787133 \t -0.1107254243841127\n",
      "35     \t [ 0.10387454 -0.41663796]. \t  -19.07250006427449 \t -0.1107254243841127\n",
      "36     \t [1.17020752 0.360747  ]. \t  -101.76416049053303 \t -0.1107254243841127\n",
      "37     \t [-1.70997552 -0.25722454]. \t  -1019.3732786974238 \t -0.1107254243841127\n",
      "38     \t [-0.83579956  0.58918698]. \t  -4.566425587621502 \t -0.1107254243841127\n",
      "39     \t [ 1.55931996 -0.02973819]. \t  -606.0717234893434 \t -0.1107254243841127\n",
      "40     \t [-0.8328312  -0.12015064]. \t  -69.57955189676824 \t -0.1107254243841127\n",
      "41     \t [0.88806081 0.71830615]. \t  -0.5073842166025236 \t -0.1107254243841127\n",
      "42     \t [-1.69293804 -1.58373144]. \t  -1987.2977924347279 \t -0.1107254243841127\n",
      "43     \t [-0.89105291 -1.87796442]. \t  -717.5022618787785 \t -0.1107254243841127\n",
      "44     \t [-1.82188488  1.30911344]. \t  -412.0337696781512 \t -0.1107254243841127\n",
      "45     \t [-0.25556269 -0.56834242]. \t  -41.72826715450399 \t -0.1107254243841127\n",
      "46     \t [-1.01764738 -1.74871855]. \t  -779.3173291330409 \t -0.1107254243841127\n",
      "47     \t [-1.19004186  1.5743298 ]. \t  -7.296798661530195 \t -0.1107254243841127\n",
      "48     \t [-1.76722307 -1.52495903]. \t  -2168.0817842435545 \t -0.1107254243841127\n",
      "49     \t [ 1.75081842 -0.56705686]. \t  -1320.0126808829923 \t -0.1107254243841127\n",
      "50     \t [ 1.52190786 -0.27983171]. \t  -674.2122967369706 \t -0.1107254243841127\n",
      "51     \t [ 1.74120587 -1.78582387]. \t  -2321.4973256480284 \t -0.1107254243841127\n",
      "52     \t [0.69033399 0.47370563]. \t  \u001b[92m-0.0967083628249838\u001b[0m \t -0.0967083628249838\n",
      "53     \t [1.36423524 2.048     ]. \t  -3.6244162159898345 \t -0.0967083628249838\n",
      "54     \t [-0.92498024 -0.56841049]. \t  -206.4828448561079 \t -0.0967083628249838\n",
      "55     \t [ 0.09031405 -0.54458903]. \t  -31.380304571467033 \t -0.0967083628249838\n",
      "56     \t [0.76366112 0.57919317]. \t  \u001b[92m-0.057444199944013535\u001b[0m \t -0.057444199944013535\n",
      "57     \t [-0.75177222  1.82454727]. \t  -161.6739642083876 \t -0.057444199944013535\n",
      "58     \t [-0.193116    1.67121376]. \t  -268.39297376173096 \t -0.057444199944013535\n",
      "59     \t [-1.2865453 -0.9730846]. \t  -696.0156593793005 \t -0.057444199944013535\n",
      "60     \t [0.64926147 0.43380473]. \t  -0.1380587314186498 \t -0.057444199944013535\n",
      "61     \t [-0.92606694  1.79952897]. \t  -92.43275644338264 \t -0.057444199944013535\n",
      "62     \t [ 1.25268339 -1.99242532]. \t  -1268.5925112342188 \t -0.057444199944013535\n",
      "63     \t [-1.86448536  1.62518525]. \t  -350.86994486800165 \t -0.057444199944013535\n",
      "64     \t [-0.91216713  0.44119237]. \t  -18.933263173028223 \t -0.057444199944013535\n",
      "65     \t [ 1.91959605 -2.00195816]. \t  -3234.823212590103 \t -0.057444199944013535\n",
      "66     \t [-0.29407973  1.19168092]. \t  -123.82091085052964 \t -0.057444199944013535\n",
      "67     \t [-1.59280701  0.7729582 ]. \t  -317.9190514371691 \t -0.057444199944013535\n",
      "68     \t [-0.49202141 -1.95849551]. \t  -486.4816182804944 \t -0.057444199944013535\n",
      "69     \t [-1.30808427  0.49639141]. \t  -152.87517267597545 \t -0.057444199944013535\n",
      "70     \t [ 1.11633129 -0.64530203]. \t  -357.78984117355515 \t -0.057444199944013535\n",
      "71     \t [-0.39462386  0.47848709]. \t  -12.362319757974351 \t -0.057444199944013535\n",
      "72     \t [-1.1368055  1.2366384]. \t  -4.876056961361219 \t -0.057444199944013535\n",
      "73     \t [ 0.8535115  -0.72683466]. \t  -211.8160811430267 \t -0.057444199944013535\n",
      "74     \t [1.05349927 1.10340707]. \t  \u001b[92m-0.007027121021815697\u001b[0m \t -0.007027121021815697\n",
      "75     \t [-0.21375509  1.50988499]. \t  -215.85953601500137 \t -0.007027121021815697\n",
      "76     \t [ 1.06678318 -0.30766504]. \t  -209.0068213227851 \t -0.007027121021815697\n",
      "77     \t [-0.07106254 -0.25581317]. \t  -7.95212835306303 \t -0.007027121021815697\n",
      "78     \t [ 0.84316598 -0.74323172]. \t  -211.4828972139154 \t -0.007027121021815697\n",
      "79     \t [0.72850359 1.00526549]. \t  -22.593290519211944 \t -0.007027121021815697\n",
      "80     \t [ 0.53047885 -2.04637957]. \t  -542.0798584326096 \t -0.007027121021815697\n",
      "81     \t [ 0.39847107 -1.21311121]. \t  -188.57016526873295 \t -0.007027121021815697\n",
      "82     \t [0.89958416 0.84853031]. \t  -0.16436459059615263 \t -0.007027121021815697\n",
      "83     \t [1.32167114 0.4018225 ]. \t  -181.0038454453385 \t -0.007027121021815697\n",
      "84     \t [1.01659156 1.02469461]. \t  -0.007955673217173076 \t -0.007027121021815697\n",
      "85     \t [-1.50193783 -1.61194567]. \t  -1502.2187013244097 \t -0.007027121021815697\n",
      "86     \t [-1.16153891  0.51025573]. \t  -75.050408986123 \t -0.007027121021815697\n",
      "87     \t [-0.14151138  1.22300063]. \t  -146.01797098053376 \t -0.007027121021815697\n",
      "88     \t [ 1.91562991 -0.82077975]. \t  -2017.2235051866194 \t -0.007027121021815697\n",
      "89     \t [ 1.03066391 -0.74407978]. \t  -326.290202827941 \t -0.007027121021815697\n",
      "90     \t [-0.38789928 -2.04162545]. \t  -482.4526920045802 \t -0.007027121021815697\n",
      "91     \t [ 1.09916611 -0.90250135]. \t  -445.50155928319975 \t -0.007027121021815697\n",
      "92     \t [ 0.83603486 -0.42378208]. \t  -126.08058084886726 \t -0.007027121021815697\n",
      "93     \t [0.45880615 0.22054741]. \t  -0.3029796219185962 \t -0.007027121021815697\n",
      "94     \t [-1.93372792  1.36150891]. \t  -573.997544334825 \t -0.007027121021815697\n",
      "95     \t [-1.346838   -1.40058123]. \t  -1038.8432884327158 \t -0.007027121021815697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [ 1.83710787 -0.36972814]. \t  -1402.97365454834 \t -0.007027121021815697\n",
      "97     \t [ 1.82269977 -1.51780651]. \t  -2343.276477826613 \t -0.007027121021815697\n",
      "98     \t [0.6002748  2.02426192]. \t  -277.02677870499963 \t -0.007027121021815697\n",
      "99     \t [-1.7018416  -0.88790085]. \t  -1439.290923634841 \t -0.007027121021815697\n",
      "100    \t [ 0.92458717 -0.70005904]. \t  -241.78345852670682 \t -0.007027121021815697\n"
     ]
    }
   ],
   "source": [
    "### 6(f). Bayesian optimization runs (x20): GP run number = 6\n",
    "\n",
    "np.random.seed(run_num_6)\n",
    "surrogate_gp_6 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_6 = GPGO(surrogate_gp_6, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_6.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.82099045 1.40978849]. \t  -54.16678839674669 \t -16.933801290298337\n",
      "init   \t [0.72300272 0.9333066 ]. \t  -16.933801290298337 \t -16.933801290298337\n",
      "init   \t [ 1.84917179 -1.9959677 ]. \t  -2933.3811709087195 \t -16.933801290298337\n",
      "init   \t [-0.35394479 -1.8480628 ]. \t  -391.24012678773295 \t -16.933801290298337\n",
      "init   \t [-1.63869261  0.03303959]. \t  -710.4183779486988 \t -16.933801290298337\n",
      "1      \t [-2.048  2.048]. \t  -469.9523900415999 \t -16.933801290298337\n",
      "2      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -16.933801290298337\n",
      "3      \t [2.048      0.86502621]. \t  -1109.5073631548737 \t -16.933801290298337\n",
      "4      \t [-0.35379508  2.048     ]. \t  -371.5599127145464 \t -16.933801290298337\n",
      "5      \t [-0.01548494 -0.42797423]. \t  -19.367933456001445 \t -16.933801290298337\n",
      "6      \t [-0.39300177  0.72720786]. \t  -34.745566436595695 \t -16.933801290298337\n",
      "7      \t [2.048 2.048]. \t  -461.7603900415999 \t -16.933801290298337\n",
      "8      \t [-2.048       0.98101102]. \t  -1041.8154798653318 \t -16.933801290298337\n",
      "9      \t [ 1.03394637 -0.36143638]. \t  -204.62888020010013 \t -16.933801290298337\n",
      "10     \t [0.74545986 2.048     ]. \t  -222.75761594886296 \t -16.933801290298337\n",
      "11     \t [ 0.30428518 -1.27288076]. \t  -186.93491361466658 \t -16.933801290298337\n",
      "12     \t [0.17388305 1.19239511]. \t  -135.74400735320881 \t -16.933801290298337\n",
      "13     \t [ 0.20565769 -2.048     ]. \t  -437.56433437503466 \t -16.933801290298337\n",
      "14     \t [-1.23766648  2.048     ]. \t  -31.651504492489185 \t -16.933801290298337\n",
      "15     \t [0.40818831 0.05174369]. \t  \u001b[92m-1.6698450058463847\u001b[0m \t -1.6698450058463847\n",
      "16     \t [-0.96315893  1.30996284]. \t  -18.468382277094978 \t -1.6698450058463847\n",
      "17     \t [ 2.048      -0.42065565]. \t  -2130.883559794438 \t -1.6698450058463847\n",
      "18     \t [ 0.4565993  -0.50265681]. \t  -50.86725619938402 \t -1.6698450058463847\n",
      "19     \t [-0.73827012 -0.6427716 ]. \t  -144.1118831620089 \t -1.6698450058463847\n",
      "20     \t [-0.7571292   0.12787741]. \t  -22.922698707506733 \t -1.6698450058463847\n",
      "21     \t [0.862428   0.21499828]. \t  -27.980152961991866 \t -1.6698450058463847\n",
      "22     \t [1.36619993 2.048     ]. \t  -3.4282454584084325 \t -1.6698450058463847\n",
      "23     \t [-0.94697405  1.68404697]. \t  -65.7728080750292 \t -1.6698450058463847\n",
      "24     \t [-0.19728267 -1.02495107]. \t  -114.61574833338987 \t -1.6698450058463847\n",
      "25     \t [-0.44263713 -0.17162737]. \t  -15.590869544112334 \t -1.6698450058463847\n",
      "26     \t [-0.85090365  0.82226615]. \t  -4.39074058944603 \t -1.6698450058463847\n",
      "27     \t [1.35642492 1.62971926]. \t  -4.544151758997276 \t -1.6698450058463847\n",
      "28     \t [1.26618772 1.8071292 ]. \t  -4.228289226235643 \t -1.6698450058463847\n",
      "29     \t [1.13189612 1.24472013]. \t  \u001b[92m-0.15039318669626256\u001b[0m \t -0.15039318669626256\n",
      "30     \t [-2.048      -0.86495966]. \t  -2568.905182801943 \t -0.15039318669626256\n",
      "31     \t [-1.37707123  1.66748698]. \t  -10.887159252841947 \t -0.15039318669626256\n",
      "32     \t [ 0.93563769 -2.048     ]. \t  -854.6413564491445 \t -0.15039318669626256\n",
      "33     \t [-0.08037917  0.18651223]. \t  -4.409070480169232 \t -0.15039318669626256\n",
      "34     \t [-1.21284437  1.5179385 ]. \t  -5.117082639603288 \t -0.15039318669626256\n",
      "35     \t [ 1.11951625 -1.22034075]. \t  -611.9123628032247 \t -0.15039318669626256\n",
      "36     \t [-1.46706455  2.048     ]. \t  -7.1738055624300205 \t -0.15039318669626256\n",
      "37     \t [0.59123603 0.38953581]. \t  -0.3268941454973016 \t -0.15039318669626256\n",
      "38     \t [-1.04970274 -2.048     ]. \t  -996.3730592444997 \t -0.15039318669626256\n",
      "39     \t [1.19819236 1.48778749]. \t  -0.31095635229759494 \t -0.15039318669626256\n",
      "40     \t [-1.35767059  1.84862991]. \t  -5.561484090259233 \t -0.15039318669626256\n",
      "41     \t [-0.56879421  0.38161718]. \t  -2.7985638537625688 \t -0.15039318669626256\n",
      "42     \t [0.86349178 0.71367847]. \t  \u001b[92m-0.12064826029835335\u001b[0m \t -0.12064826029835335\n",
      "43     \t [-0.98834932 -1.44743104]. \t  -591.6598146449619 \t -0.12064826029835335\n",
      "44     \t [-0.06191307 -0.03706106]. \t  -1.294893655216826 \t -0.12064826029835335\n",
      "45     \t [ 2.048      -1.22522758]. \t  -2938.2305598486137 \t -0.12064826029835335\n",
      "46     \t [0.64955343 0.35258098]. \t  -0.6035980910945368 \t -0.12064826029835335\n",
      "47     \t [1.01103956 1.07917188]. \t  -0.32469008681189065 \t -0.12064826029835335\n",
      "48     \t [1.3907457  1.90558196]. \t  -0.23443048569627747 \t -0.12064826029835335\n",
      "49     \t [-0.77676799  0.55591705]. \t  -3.382068569122757 \t -0.12064826029835335\n",
      "50     \t [0.67470589 0.44572278]. \t  \u001b[92m-0.11485125763084644\u001b[0m \t -0.11485125763084644\n",
      "51     \t [0.17694399 0.04100459]. \t  -0.6868212980781788 \t -0.11485125763084644\n",
      "52     \t [1.21165677 1.47072789]. \t  \u001b[92m-0.04548281099807087\u001b[0m \t -0.04548281099807087\n",
      "53     \t [0.82813436 0.69635502]. \t  \u001b[92m-0.040664869942917646\u001b[0m \t -0.040664869942917646\n",
      "54     \t [1.03199052 1.0966349 ]. \t  -0.101072102140578 \t -0.040664869942917646\n",
      "55     \t [1.25448158 1.58689942]. \t  -0.0821199571310598 \t -0.040664869942917646\n",
      "56     \t [1.35084294 1.83414566]. \t  -0.13186862996529464 \t -0.040664869942917646\n",
      "57     \t [0.97374841 1.00564481]. \t  -0.33084095528297053 \t -0.040664869942917646\n",
      "58     \t [0.62554193 0.39389933]. \t  -0.14089308450539012 \t -0.040664869942917646\n",
      "59     \t [1.24315134 1.55373866]. \t  -0.06603383242757849 \t -0.040664869942917646\n",
      "60     \t [0.71515087 0.53570229]. \t  -0.1400011725448268 \t -0.040664869942917646\n",
      "61     \t [1.3137511  1.73801519]. \t  -0.11301607801115524 \t -0.040664869942917646\n",
      "62     \t [1.13894595 1.33030356]. \t  -0.128904534888934 \t -0.040664869942917646\n",
      "63     \t [0.66724365 0.42830166]. \t  -0.13932978803282234 \t -0.040664869942917646\n",
      "64     \t [0.66667445 0.41874005]. \t  -0.17723086531612994 \t -0.040664869942917646\n",
      "65     \t [0.95194902 0.97898681]. \t  -0.5319997274087095 \t -0.040664869942917646\n",
      "66     \t [1.16620451 1.37744753]. \t  -0.05795064928306434 \t -0.040664869942917646\n",
      "67     \t [1.30694085 1.69705988]. \t  -0.10638873799761009 \t -0.040664869942917646\n",
      "68     \t [0.91643439 0.86266122]. \t  -0.05900932998198242 \t -0.040664869942917646\n",
      "69     \t [0.53414218 0.28713578]. \t  -0.21735763457294754 \t -0.040664869942917646\n",
      "70     \t [0.5777328  0.29487091]. \t  -0.3296638343046784 \t -0.040664869942917646\n",
      "71     \t [1.03035775 1.11698514]. \t  -0.3072622154110734 \t -0.040664869942917646\n",
      "72     \t [1.31306809 1.69162308]. \t  -0.2037974095050204 \t -0.040664869942917646\n",
      "73     \t [0.81805743 0.67626444]. \t  \u001b[92m-0.03806837124553128\u001b[0m \t -0.03806837124553128\n",
      "74     \t [0.67731325 0.45214675]. \t  -0.10849130960266347 \t -0.03806837124553128\n",
      "75     \t [0.60406147 0.35334641]. \t  -0.1700933748725564 \t -0.03806837124553128\n",
      "76     \t [0.4532487  0.22157836]. \t  -0.3249997887357189 \t -0.03806837124553128\n",
      "77     \t [1.25078166 1.60438033]. \t  -0.22229655005236176 \t -0.03806837124553128\n",
      "78     \t [1.23921039 1.55989558]. \t  -0.11604331053561066 \t -0.03806837124553128\n",
      "79     \t [0.76880468 0.57210513]. \t  -0.0893823798393582 \t -0.03806837124553128\n",
      "80     \t [0.93530466 0.89600666]. \t  -0.04917973780054649 \t -0.03806837124553128\n",
      "81     \t [1.25701302 1.60754819]. \t  -0.1414962791253307 \t -0.03806837124553128\n",
      "82     \t [1.27457916 1.62098897]. \t  -0.0766632613909093 \t -0.03806837124553128\n",
      "83     \t [0.67090767 0.4077769 ]. \t  -0.28757110156640675 \t -0.03806837124553128\n",
      "84     \t [0.13679545 0.01077744]. \t  -0.7514193905541233 \t -0.03806837124553128\n",
      "85     \t [0.696294   0.44143655]. \t  -0.28049594620556023 \t -0.03806837124553128\n",
      "86     \t [1.0623622  1.18119947]. \t  -0.2804181166638629 \t -0.03806837124553128\n",
      "87     \t [1.11134483 1.31603769]. \t  -0.6676939269337799 \t -0.03806837124553128\n",
      "88     \t [0.14185554 0.02030622]. \t  -0.7364152661882625 \t -0.03806837124553128\n",
      "89     \t [0.72049549 0.4921975 ]. \t  -0.15057123680753864 \t -0.03806837124553128\n",
      "90     \t [1.34405637 1.75825199]. \t  -0.3510415649574355 \t -0.03806837124553128\n",
      "91     \t [1.10219447 1.223531  ]. \t  \u001b[92m-0.01800985998552991\u001b[0m \t -0.01800985998552991\n",
      "92     \t [0.67374928 0.41261265]. \t  -0.2772187671904881 \t -0.01800985998552991\n",
      "93     \t [0.66477531 0.41741378]. \t  -0.17246152209134546 \t -0.01800985998552991\n",
      "94     \t [1.33363719 1.75421076]. \t  -0.17073946020051467 \t -0.01800985998552991\n",
      "95     \t [1.08990407 1.22864876]. \t  -0.1742032330685666 \t -0.01800985998552991\n",
      "96     \t [0.80120578 0.61054224]. \t  -0.13804269882868275 \t -0.01800985998552991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.7385773  0.54597489]. \t  -0.06836472258899563 \t -0.01800985998552991\n",
      "98     \t [0.65721739 0.42779835]. \t  -0.11921085656850869 \t -0.01800985998552991\n",
      "99     \t [1.03278156 1.08335814]. \t  -0.029031805062003795 \t -0.01800985998552991\n",
      "100    \t [1.05988799 1.18894033]. \t  -0.4336310664481917 \t -0.01800985998552991\n"
     ]
    }
   ],
   "source": [
    "### 6(f). Bayesian optimization runs (x20): STP DF1 run number = 6\n",
    "\n",
    "np.random.seed(run_num_6)\n",
    "surrogate_stp_df1_6 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_6 = GPGO(surrogate_stp_df1_6, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_6.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.957978184518829, -4.016835894087129)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(f). Training Regret Minimisation: run number = 6\n",
    "\n",
    "gp_output_6 = np.append(np.max(gpgo_gp_6.GP.y[0:n_init]),gpgo_gp_6.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_6 = np.append(np.max(gpgo_stp_df1_6.GP.y[0:n_init]),gpgo_stp_df1_6.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_6 = np.log(y_global_orig - gp_output_6)\n",
    "regret_stp_df1_6 = np.log(y_global_orig - stp_df1_output_6)\n",
    "\n",
    "train_regret_gp_6 = min_max_array(regret_gp_6)\n",
    "train_regret_stp_df1_6 = min_max_array(regret_stp_df1_6)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 6\n",
    "min_train_regret_gp_6 = min(train_regret_gp_6)\n",
    "min_train_regret_stp_df1_6 = min(train_regret_stp_df1_6)\n",
    "\n",
    "min_train_regret_gp_6, min_train_regret_stp_df1_6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.42268934 -0.80954733]. \t  -808.7939502616841 \t -2.0077595729598063\n",
      "init   \t [-1.79389885 -0.16441204]. \t  -1151.9264213711547 \t -2.0077595729598063\n",
      "init   \t [1.37319786 1.74897991]. \t  -2.0077595729598063 \t -2.0077595729598063\n",
      "init   \t [0.92974688 1.09976052]. \t  -5.543015908052858 \t -2.0077595729598063\n",
      "init   \t [-0.94533605  0.58994398]. \t  -13.008689168416776 \t -2.0077595729598063\n",
      "1      \t [-0.47273281  1.16874249]. \t  -91.52175707418381 \t -2.0077595729598063\n",
      "2      \t [-0.02450474  0.04538531]. \t  \u001b[92m-1.2501780197199097\u001b[0m \t -1.2501780197199097\n",
      "3      \t [1.68585264 0.78240463]. \t  -424.70453514476327 \t -1.2501780197199097\n",
      "4      \t [-0.42007355  0.486865  ]. \t  -11.651624457822306 \t -1.2501780197199097\n",
      "5      \t [-1.44885198  1.39505365]. \t  -55.57515125944981 \t -1.2501780197199097\n",
      "6      \t [ 0.24875508 -1.16743118]. \t  -151.68474322135503 \t -1.2501780197199097\n",
      "7      \t [0.93084749 2.03834578]. \t  -137.33241456947934 \t -1.2501780197199097\n",
      "8      \t [1.06444123 1.42879822]. \t  -8.75173381079799 \t -1.2501780197199097\n",
      "9      \t [-0.98099823  0.95588429]. \t  -3.928544263348288 \t -1.2501780197199097\n",
      "10     \t [2.048 2.048]. \t  -461.7603900415999 \t -1.2501780197199097\n",
      "11     \t [0.62288294 0.18463974]. \t  -4.277071860372212 \t -1.2501780197199097\n",
      "12     \t [-0.69809527  0.50777279]. \t  -2.925289656046603 \t -1.2501780197199097\n",
      "13     \t [1.47313155 1.22820186]. \t  -88.94418548055519 \t -1.2501780197199097\n",
      "14     \t [0.47519087 0.42362014]. \t  -4.188453817223986 \t -1.2501780197199097\n",
      "15     \t [ 0.26461578 -0.15711781]. \t  -5.700016984471431 \t -1.2501780197199097\n",
      "16     \t [-0.06599621 -0.01552053]. \t  \u001b[92m-1.1758535835385266\u001b[0m \t -1.1758535835385266\n",
      "17     \t [1.24180127 1.48658269]. \t  \u001b[92m-0.3663562110243889\u001b[0m \t -0.3663562110243889\n",
      "18     \t [0.47256492 1.92336581]. \t  -289.29457645503635 \t -0.3663562110243889\n",
      "19     \t [-0.92606685  0.78687317]. \t  -4.209959456551836 \t -0.3663562110243889\n",
      "20     \t [ 1.118485   -1.11392497]. \t  -559.3051604113011 \t -0.3663562110243889\n",
      "21     \t [-0.61359581 -2.048     ]. \t  -590.4236287757818 \t -0.3663562110243889\n",
      "22     \t [0.44493233 0.14422343]. \t  -0.5969133387990369 \t -0.3663562110243889\n",
      "23     \t [ 0.41310572 -1.76305071]. \t  -374.26673998424303 \t -0.3663562110243889\n",
      "24     \t [-0.40424352  0.18651119]. \t  -2.0252533407865503 \t -0.3663562110243889\n",
      "25     \t [-0.23527315  1.89308588]. \t  -339.25194620375197 \t -0.3663562110243889\n",
      "26     \t [1.28518478 1.62368908]. \t  \u001b[92m-0.15979097945501483\u001b[0m \t -0.15979097945501483\n",
      "27     \t [-1.51502555 -0.57082521]. \t  -827.7941113195253 \t -0.15979097945501483\n",
      "28     \t [-1.87469876 -0.93454369]. \t  -1987.6588142819153 \t -0.15979097945501483\n",
      "29     \t [-0.46501394 -0.4439421 ]. \t  -45.730037758046485 \t -0.15979097945501483\n",
      "30     \t [-1.93949334  1.69699813]. \t  -434.9129180923196 \t -0.15979097945501483\n",
      "31     \t [-1.2491973   1.36576703]. \t  -8.850743886580085 \t -0.15979097945501483\n",
      "32     \t [ 1.54002649 -1.83787344]. \t  -1772.3269971951645 \t -0.15979097945501483\n",
      "33     \t [-1.8431759  -1.77951983]. \t  -2688.0272945478355 \t -0.15979097945501483\n",
      "34     \t [-1.280005   1.5420202]. \t  -6.127575986568125 \t -0.15979097945501483\n",
      "35     \t [ 0.2736799  -0.01522965]. \t  -1.3398885876565299 \t -0.15979097945501483\n",
      "36     \t [-0.63864392  1.52983507]. \t  -128.5665997916627 \t -0.15979097945501483\n",
      "37     \t [-0.73283867  0.87632897]. \t  -14.513580664318035 \t -0.15979097945501483\n",
      "38     \t [-1.26947568  2.048     ]. \t  -24.19776588850033 \t -0.15979097945501483\n",
      "39     \t [-1.72517692 -0.55026939]. \t  -1251.0501918294053 \t -0.15979097945501483\n",
      "40     \t [0.05564954 0.60649055]. \t  -37.300190512549484 \t -0.15979097945501483\n",
      "41     \t [-1.82254402  1.35506658]. \t  -394.71835903777065 \t -0.15979097945501483\n",
      "42     \t [1.4493702  1.88796319]. \t  -4.72652160481193 \t -0.15979097945501483\n",
      "43     \t [0.8199031  1.16600161]. \t  -24.41237951303199 \t -0.15979097945501483\n",
      "44     \t [-0.86486021  0.97471617]. \t  -8.61848851357872 \t -0.15979097945501483\n",
      "45     \t [1.34803695 0.03901215]. \t  -316.3176151563217 \t -0.15979097945501483\n",
      "46     \t [1.4062769 2.048    ]. \t  -0.6604695406562099 \t -0.15979097945501483\n",
      "47     \t [ 0.83852599 -0.34052251]. \t  -108.9462605973516 \t -0.15979097945501483\n",
      "48     \t [ 1.28403975 -1.80099872]. \t  -1190.162876097512 \t -0.15979097945501483\n",
      "49     \t [1.34714981 1.81726515]. \t  \u001b[92m-0.1211144876496195\u001b[0m \t -0.1211144876496195\n",
      "50     \t [0.77901913 0.59091417]. \t  \u001b[92m-0.07429396497835944\u001b[0m \t -0.07429396497835944\n",
      "51     \t [-1.01553322 -0.07176961]. \t  -125.74033204142796 \t -0.07429396497835944\n",
      "52     \t [ 0.58352362 -0.23479548]. \t  -33.2699195494349 \t -0.07429396497835944\n",
      "53     \t [1.23015299 1.49750352]. \t  -0.07784874571877454 \t -0.07429396497835944\n",
      "54     \t [ 1.95242307 -1.48669605]. \t  -2808.478305233238 \t -0.07429396497835944\n",
      "55     \t [ 0.40544191 -1.72069599]. \t  -355.7058359961106 \t -0.07429396497835944\n",
      "56     \t [0.24084481 0.08096487]. \t  -0.6290265645835931 \t -0.07429396497835944\n",
      "57     \t [-0.46836524  0.05583377]. \t  -4.830375481641471 \t -0.07429396497835944\n",
      "58     \t [0.69965862 0.47659411]. \t  -0.10691846113177339 \t -0.07429396497835944\n",
      "59     \t [-1.23998148 -0.56124367]. \t  -445.5127150577988 \t -0.07429396497835944\n",
      "60     \t [-0.48624993  1.60285367]. \t  -188.91784469060016 \t -0.07429396497835944\n",
      "61     \t [ 1.7078212  -0.23497913]. \t  -993.779676556309 \t -0.07429396497835944\n",
      "62     \t [1.93673741 0.97984521]. \t  -768.7806515093562 \t -0.07429396497835944\n",
      "63     \t [ 1.97666469 -0.70501524]. \t  -2128.209855573222 \t -0.07429396497835944\n",
      "64     \t [1.07962977 1.14075423]. \t  \u001b[92m-0.0680742831554782\u001b[0m \t -0.0680742831554782\n",
      "65     \t [-1.58125633  0.36595552]. \t  -462.2360771499493 \t -0.0680742831554782\n",
      "66     \t [1.11704441 1.23331088]. \t  \u001b[92m-0.03465873209450108\u001b[0m \t -0.03465873209450108\n",
      "67     \t [ 1.29866214 -0.78551704]. \t  -611.1875774241657 \t -0.03465873209450108\n",
      "68     \t [1.06602172 1.12058133]. \t  \u001b[92m-0.02938919169390068\u001b[0m \t -0.02938919169390068\n",
      "69     \t [1.35655574 1.84607971]. \t  -0.1305381625924016 \t -0.02938919169390068\n",
      "70     \t [-1.453335    0.70777001]. \t  -203.2563341481985 \t -0.02938919169390068\n",
      "71     \t [1.55375794 0.04422647]. \t  -561.9669176444024 \t -0.02938919169390068\n",
      "72     \t [-0.12450811 -1.3949929 ]. \t  -200.21418176685694 \t -0.02938919169390068\n",
      "73     \t [0.60011848 0.36303647]. \t  -0.16074291483504027 \t -0.02938919169390068\n",
      "74     \t [1.36054741 1.85938811]. \t  -0.13688154330794552 \t -0.02938919169390068\n",
      "75     \t [-0.62409191 -0.74202643]. \t  -130.6707793379426 \t -0.02938919169390068\n",
      "76     \t [ 1.84142169 -0.68915833]. \t  -1665.3415997891302 \t -0.02938919169390068\n",
      "77     \t [-1.11398796 -0.24648974]. \t  -225.72234792939003 \t -0.02938919169390068\n",
      "78     \t [-0.09797941  0.996038  ]. \t  -98.51155747480169 \t -0.02938919169390068\n",
      "79     \t [1.03613652 1.03388204]. \t  -0.15888987957400896 \t -0.02938919169390068\n",
      "80     \t [ 1.05092279 -1.43042672]. \t  -642.5568651619753 \t -0.02938919169390068\n",
      "81     \t [0.20377698 0.76973986]. \t  -53.66365112401365 \t -0.02938919169390068\n",
      "82     \t [1.0043492  1.01149819]. \t  \u001b[92m-0.0007922403871347229\u001b[0m \t -0.0007922403871347229\n",
      "83     \t [1.84719157 0.07493504]. \t  -1114.3958721029478 \t -0.0007922403871347229\n",
      "84     \t [ 1.10464633 -1.45254347]. \t  -714.3899783273297 \t -0.0007922403871347229\n",
      "85     \t [1.09999692 1.1991249 ]. \t  -0.021811440807048256 \t -0.0007922403871347229\n",
      "86     \t [-1.15538548 -0.32404392]. \t  -279.8603611900302 \t -0.0007922403871347229\n",
      "87     \t [-0.43085748 -1.0387392 ]. \t  -151.95734865395278 \t -0.0007922403871347229\n",
      "88     \t [-0.33939423  0.24049692]. \t  -3.364198389531944 \t -0.0007922403871347229\n",
      "89     \t [1.35936773 0.81886257]. \t  -106.01696195155297 \t -0.0007922403871347229\n",
      "90     \t [-1.9380262   0.13610953]. \t  -1318.9532876497697 \t -0.0007922403871347229\n",
      "91     \t [ 0.9721382  -0.41205174]. \t  -184.17401640929336 \t -0.0007922403871347229\n",
      "92     \t [ 0.14583905 -0.10642548]. \t  -2.3601797106240374 \t -0.0007922403871347229\n",
      "93     \t [0.01802314 2.0015417 ]. \t  -401.4511721215828 \t -0.0007922403871347229\n",
      "94     \t [ 0.15498551 -0.88449689]. \t  -83.25443505500101 \t -0.0007922403871347229\n",
      "95     \t [0.63363781 0.41420535]. \t  -0.15037179969733092 \t -0.0007922403871347229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [-1.20940169 -1.15883084]. \t  -692.0989167941194 \t -0.0007922403871347229\n",
      "97     \t [1.36083287 1.87749507]. \t  -0.1958847502149283 \t -0.0007922403871347229\n",
      "98     \t [0.63313443 0.41442596]. \t  -0.15299603144374702 \t -0.0007922403871347229\n",
      "99     \t [1.14136481 1.29240515]. \t  -0.030610502743998555 \t -0.0007922403871347229\n",
      "100    \t [-0.54071186  1.67082572]. \t  -192.38799757088222 \t -0.0007922403871347229\n"
     ]
    }
   ],
   "source": [
    "### 6(g). Bayesian optimization runs (x20): GP run number = 7\n",
    "\n",
    "np.random.seed(run_num_7)\n",
    "surrogate_gp_7 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_7 = GPGO(surrogate_gp_7, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_7.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.42268934 -0.80954733]. \t  -808.7939502616841 \t -2.0077595729598063\n",
      "init   \t [-1.79389885 -0.16441204]. \t  -1151.9264213711547 \t -2.0077595729598063\n",
      "init   \t [1.37319786 1.74897991]. \t  -2.0077595729598063 \t -2.0077595729598063\n",
      "init   \t [0.92974688 1.09976052]. \t  -5.543015908052858 \t -2.0077595729598063\n",
      "init   \t [-0.94533605  0.58994398]. \t  -13.008689168416776 \t -2.0077595729598063\n",
      "1      \t [-0.57538407  1.5344344 ]. \t  -147.29118520507217 \t -2.0077595729598063\n",
      "2      \t [0.08522315 0.00582542]. \t  \u001b[92m-0.8370233403748514\u001b[0m \t -0.8370233403748514\n",
      "3      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -0.8370233403748514\n",
      "4      \t [-2.048  2.048]. \t  -469.9523900415999 \t -0.8370233403748514\n",
      "5      \t [2.048      0.69903629]. \t  -1222.7879409039308 \t -0.8370233403748514\n",
      "6      \t [-0.6344856 -2.048    ]. \t  -603.2018463394753 \t -0.8370233403748514\n",
      "7      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -0.8370233403748514\n",
      "8      \t [-0.35301078 -0.94535995]. \t  -116.31562189357906 \t -0.8370233403748514\n",
      "9      \t [0.54409476 2.048     ]. \t  -307.14454706760966 \t -0.8370233403748514\n",
      "10     \t [-0.10410821  0.78255345]. \t  -60.77344849233941 \t -0.8370233403748514\n",
      "11     \t [2.048 2.048]. \t  -461.7603900415999 \t -0.8370233403748514\n",
      "12     \t [-0.64230505 -0.17997132]. \t  -37.80600140412959 \t -0.8370233403748514\n",
      "13     \t [ 0.2362243 -2.048    ]. \t  -443.1816051668438 \t -0.8370233403748514\n",
      "14     \t [ 1.08503056 -0.33869841]. \t  -229.82971485431736 \t -0.8370233403748514\n",
      "15     \t [-1.18033689  2.048     ]. \t  -47.63080415200005 \t -0.8370233403748514\n",
      "16     \t [-1.3490857   1.39178419]. \t  -23.85784086329747 \t -0.8370233403748514\n",
      "17     \t [0.76997933 0.30701285]. \t  -8.224236231998978 \t -0.8370233403748514\n",
      "18     \t [1.24212222 2.048     ]. \t  -25.574496319834694 \t -0.8370233403748514\n",
      "19     \t [-0.89449731  1.08642458]. \t  -11.785840276468562 \t -0.8370233403748514\n",
      "20     \t [-2.048       1.08393706]. \t  -976.7285546563285 \t -0.8370233403748514\n",
      "21     \t [ 0.4828782  -0.78742194]. \t  -104.42848222047466 \t -0.8370233403748514\n",
      "22     \t [0.93962768 1.56604132]. \t  -46.67182744191968 \t -0.8370233403748514\n",
      "23     \t [-0.51909169  0.36001554]. \t  -3.1277392980783727 \t -0.8370233403748514\n",
      "24     \t [0.43521929 0.44148717]. \t  -6.6729736896957075 \t -0.8370233403748514\n",
      "25     \t [ 0.51607136 -0.22320296]. \t  -24.1984050893551 \t -0.8370233403748514\n",
      "26     \t [ 2.048     -0.4733623]. \t  -2179.809168990296 \t -0.8370233403748514\n",
      "27     \t [-0.07632252 -1.57113418]. \t  -249.83853694329378 \t -0.8370233403748514\n",
      "28     \t [-0.61266904  2.048     ]. \t  -282.37203543704237 \t -0.8370233403748514\n",
      "29     \t [-1.19532984  1.63609334]. \t  -9.115969068045533 \t -0.8370233403748514\n",
      "30     \t [1.21389788 1.34085054]. \t  -1.8066159129417965 \t -0.8370233403748514\n",
      "31     \t [ 0.91049229 -1.63372978]. \t  -606.5099375561931 \t -0.8370233403748514\n",
      "32     \t [-1.11734949  1.11360147]. \t  -6.302117702603983 \t -0.8370233403748514\n",
      "33     \t [-1.47536993  2.048     ]. \t  -7.784248520851277 \t -0.8370233403748514\n",
      "34     \t [1.47901549 2.048     ]. \t  -2.175113130161596 \t -0.8370233403748514\n",
      "35     \t [-0.80308657 -1.33508771]. \t  -395.3052786544573 \t -0.8370233403748514\n",
      "36     \t [-1.37798585  1.83973308]. \t  -6.004238729251307 \t -0.8370233403748514\n",
      "37     \t [0.40222396 0.15599381]. \t  \u001b[92m-0.36068895354757197\u001b[0m \t -0.36068895354757197\n",
      "38     \t [1.00481423 0.84999817]. \t  -2.5489463189406796 \t -0.36068895354757197\n",
      "39     \t [-2.048     -1.0376915]. \t  -2746.6679994438787 \t -0.36068895354757197\n",
      "40     \t [1.30069677 1.78260949]. \t  -0.9148355670889315 \t -0.36068895354757197\n",
      "41     \t [ 1.46301826 -1.16475197]. \t  -1092.6321635641937 \t -0.36068895354757197\n",
      "42     \t [0.79276398 0.63683251]. \t  \u001b[92m-0.04993204137246476\u001b[0m \t -0.04993204137246476\n",
      "43     \t [-0.75379059  0.58182232]. \t  -3.0943374977364595 \t -0.04993204137246476\n",
      "44     \t [1.39710195 2.01589451]. \t  -0.5672984056002607 \t -0.04993204137246476\n",
      "45     \t [ 1.12839893 -2.048     ]. \t  -1103.109326027004 \t -0.04993204137246476\n",
      "46     \t [1.22165055 1.51356747]. \t  -0.09380795189153207 \t -0.04993204137246476\n",
      "47     \t [-1.27361604 -2.048     ]. \t  -1352.131129512386 \t -0.04993204137246476\n",
      "48     \t [-0.67508495  0.28709226]. \t  -5.650105088936476 \t -0.04993204137246476\n",
      "49     \t [1.0354204  1.07387655]. \t  \u001b[92m-0.001571852499539838\u001b[0m \t -0.001571852499539838\n",
      "50     \t [0.74619164 0.56240806]. \t  -0.0675615169642535 \t -0.001571852499539838\n",
      "51     \t [0.89478109 0.80995665]. \t  -0.019763676861100213 \t -0.001571852499539838\n",
      "52     \t [0.47003504 0.1922913 ]. \t  -0.36289719314745944 \t -0.001571852499539838\n",
      "53     \t [1.1876401  1.40181498]. \t  -0.0427326715629927 \t -0.001571852499539838\n",
      "54     \t [0.6450004  0.38123743]. \t  -0.24704579484233308 \t -0.001571852499539838\n",
      "55     \t [0.94206068 0.88584777]. \t  -0.0036228346845161093 \t -0.001571852499539838\n",
      "56     \t [-0.23945143  0.05768879]. \t  -1.5362522151847395 \t -0.001571852499539838\n",
      "57     \t [1.37342266 1.90323526]. \t  -0.16815928622435206 \t -0.001571852499539838\n",
      "58     \t [1.40261146 2.0479978 ]. \t  -0.8130042608029273 \t -0.001571852499539838\n",
      "59     \t [0.06437939 0.08164932]. \t  -1.4760824322099166 \t -0.001571852499539838\n",
      "60     \t [0.74384946 0.54818133]. \t  -0.06824549698684859 \t -0.001571852499539838\n",
      "61     \t [0.85739044 0.73303616]. \t  -0.020771044992250638 \t -0.001571852499539838\n",
      "62     \t [1.43018312 2.04799947]. \t  -0.18572094633491085 \t -0.001571852499539838\n",
      "63     \t [0.56155831 0.28962955]. \t  -0.2583736245938666 \t -0.001571852499539838\n",
      "64     \t [1.13768951 1.2982013 ]. \t  -0.02045135019561276 \t -0.001571852499539838\n",
      "65     \t [0.97108911 0.96030652]. \t  -0.030738761196914842 \t -0.001571852499539838\n",
      "66     \t [0.98934211 0.96554913]. \t  -0.017666358325705057 \t -0.001571852499539838\n",
      "67     \t [0.66731035 0.45767762]. \t  -0.12599525546232052 \t -0.001571852499539838\n",
      "68     \t [1.2926222  1.67619139]. \t  -0.0884571753057797 \t -0.001571852499539838\n",
      "69     \t [1.05122819 1.10426477]. \t  -0.0026909000165555555 \t -0.001571852499539838\n",
      "70     \t [0.6416857  0.38427628]. \t  -0.2039275685473807 \t -0.001571852499539838\n",
      "71     \t [0.92628316 0.87905167]. \t  -0.0497493904416827 \t -0.001571852499539838\n",
      "72     \t [2.04799998 1.44179721]. \t  -758.7276324969275 \t -0.001571852499539838\n",
      "73     \t [0.61242375 0.36762312]. \t  -0.15575030243327798 \t -0.001571852499539838\n",
      "74     \t [1.32791019 1.75857146]. \t  -0.10980421143043596 \t -0.001571852499539838\n",
      "75     \t [1.22339663 1.50024859]. \t  -0.051165786094254394 \t -0.001571852499539838\n",
      "76     \t [0.91549216 0.84981974]. \t  -0.020816170114281447 \t -0.001571852499539838\n",
      "77     \t [1.41982711 2.048     ]. \t  -0.27923788627525403 \t -0.001571852499539838\n",
      "78     \t [1.03644528 1.06187621]. \t  -0.016562278460825548 \t -0.001571852499539838\n",
      "79     \t [1.21292878 1.4847007 ]. \t  -0.06357573871571406 \t -0.001571852499539838\n",
      "80     \t [0.785242   0.63192921]. \t  -0.06960416586730465 \t -0.001571852499539838\n",
      "81     \t [1.29468303 1.72357606]. \t  -0.31124794977871817 \t -0.001571852499539838\n",
      "82     \t [1.0043492  1.01149819]. \t  \u001b[92m-0.0007922403871347229\u001b[0m \t -0.0007922403871347229\n",
      "83     \t [1.18687367 1.417975  ]. \t  -0.043581743849111405 \t -0.0007922403871347229\n",
      "84     \t [1.1319121  1.28826536]. \t  -0.022357461014272762 \t -0.0007922403871347229\n",
      "85     \t [1.12337412 1.26949402]. \t  -0.020883145044259768 \t -0.0007922403871347229\n",
      "86     \t [0.71575384 0.51406011]. \t  -0.0811044292872688 \t -0.0007922403871347229\n",
      "87     \t [1.02246421 1.10359227]. \t  -0.33875399600908135 \t -0.0007922403871347229\n",
      "88     \t [0.80620412 0.652613  ]. \t  -0.03825798726729621 \t -0.0007922403871347229\n",
      "89     \t [1.11462052 1.22436866]. \t  -0.04557475977196776 \t -0.0007922403871347229\n",
      "90     \t [1.27476812 1.62866836]. \t  -0.0768185504021595 \t -0.0007922403871347229\n",
      "91     \t [1.04859976 1.11555286]. \t  -0.027934418947486793 \t -0.0007922403871347229\n",
      "92     \t [0.87246866 0.77036423]. \t  -0.02465968309273628 \t -0.0007922403871347229\n",
      "93     \t [1.08922146 1.1541966 ]. \t  -0.11168822057607482 \t -0.0007922403871347229\n",
      "94     \t [0.74327477 0.53617712]. \t  -0.09241256524389896 \t -0.0007922403871347229\n",
      "95     \t [0.94545042 0.89700337]. \t  -0.003953392395830414 \t -0.0007922403871347229\n",
      "96     \t [1.04097829 1.07595833]. \t  -0.007573586605742142 \t -0.0007922403871347229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [1.36083287 1.87749507]. \t  -0.1958847502149283 \t -0.0007922403871347229\n",
      "98     \t [0.63313443 0.41442596]. \t  -0.15299603144374702 \t -0.0007922403871347229\n",
      "99     \t [1.0897319  1.19314776]. \t  -0.011223926151138887 \t -0.0007922403871347229\n",
      "100    \t [1.32668976 1.777149  ]. \t  -0.13577350582000675 \t -0.0007922403871347229\n"
     ]
    }
   ],
   "source": [
    "### 6(g). Bayesian optimization runs (x20): STP DF1 run number = 7\n",
    "\n",
    "np.random.seed(run_num_7)\n",
    "surrogate_stp_df1_7 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_7 = GPGO(surrogate_stp_df1_7, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_7.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.1406456930929565, -7.1406456930929565)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(g). Training Regret Minimisation: run number = 7\n",
    "\n",
    "gp_output_7 = np.append(np.max(gpgo_gp_7.GP.y[0:n_init]),gpgo_gp_7.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_7 = np.append(np.max(gpgo_stp_df1_7.GP.y[0:n_init]),gpgo_stp_df1_7.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_7 = np.log(y_global_orig - gp_output_7)\n",
    "regret_stp_df1_7 = np.log(y_global_orig - stp_df1_output_7)\n",
    "\n",
    "train_regret_gp_7 = min_max_array(regret_gp_7)\n",
    "train_regret_stp_df1_7 = min_max_array(regret_stp_df1_7)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 7\n",
    "min_train_regret_gp_7 = min(train_regret_gp_7)\n",
    "min_train_regret_stp_df1_7 = min(train_regret_stp_df1_7)\n",
    "\n",
    "min_train_regret_gp_7, min_train_regret_stp_df1_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 1.47276024 -1.37392335]. \t  -1255.470193895749 \t -296.9616334519401\n",
      "init   \t [-0.06768247  1.72452768]. \t  -296.9616334519401 \t -296.9616334519401\n",
      "init   \t [-0.29263282 -1.81264346]. \t  -362.0166182125878 \t -296.9616334519401\n",
      "init   \t [1.74083045 0.6455359 ]. \t  -569.3497501878961 \t -296.9616334519401\n",
      "init   \t [-1.50342518  0.1370068 ]. \t  -457.0991287591416 \t -296.9616334519401\n",
      "1      \t [ 1.63626026 -1.03069713]. \t  -1375.3644272127258 \t -296.9616334519401\n",
      "2      \t [1.29374853 1.55751776]. \t  \u001b[92m-1.438101203638172\u001b[0m \t -1.438101203638172\n",
      "3      \t [1.58629014 2.048     ]. \t  -22.275761993959826 \t -1.438101203638172\n",
      "4      \t [1.16765278 1.79772011]. \t  -18.890372107523433 \t -1.438101203638172\n",
      "5      \t [ 0.34878762 -1.36999043]. \t  -222.92403104709194 \t -1.438101203638172\n",
      "6      \t [-0.51562445 -0.9337455 ]. \t  -146.2045101888461 \t -1.438101203638172\n",
      "7      \t [-0.97297087  0.6096733 ]. \t  -15.249447739053148 \t -1.438101203638172\n",
      "8      \t [-0.16188299  0.23313758]. \t  -5.632035721010115 \t -1.438101203638172\n",
      "9      \t [-0.92554921  1.01745241]. \t  -6.293759861776287 \t -1.438101203638172\n",
      "10     \t [-0.57911212  0.57240668]. \t  -8.112193240794976 \t -1.438101203638172\n",
      "11     \t [-0.09963688 -0.45948402]. \t  -23.24391939683102 \t -1.438101203638172\n",
      "12     \t [-1.55887468  1.35649461]. \t  -121.80860423380275 \t -1.438101203638172\n",
      "13     \t [-0.97172427  0.84960935]. \t  -4.7833449732099105 \t -1.438101203638172\n",
      "14     \t [-0.42087606  0.08528723]. \t  -2.862520472607498 \t -1.438101203638172\n",
      "15     \t [-1.25744188  2.048     ]. \t  -26.889994334533508 \t -1.438101203638172\n",
      "16     \t [-0.71120203  0.48964169]. \t  -2.954348378657175 \t -1.438101203638172\n",
      "17     \t [0.73798889 0.98098574]. \t  -19.109492119081292 \t -1.438101203638172\n",
      "18     \t [0.99067284 1.18864248]. \t  -4.293676934529159 \t -1.438101203638172\n",
      "19     \t [1.10715636 1.43749937]. \t  -4.493348082591062 \t -1.438101203638172\n",
      "20     \t [-1.42042635  1.39123046]. \t  -45.093724630079514 \t -1.438101203638172\n",
      "21     \t [-1.1630457   1.61660986]. \t  -11.644912358160747 \t -1.438101203638172\n",
      "22     \t [ 1.91959203 -1.16431394]. \t  -2352.2687938018694 \t -1.438101203638172\n",
      "23     \t [ 0.74807514 -0.5297562 ]. \t  -118.73673571134775 \t -1.438101203638172\n",
      "24     \t [-1.58678321  2.048     ]. \t  -28.77025851799667 \t -1.438101203638172\n",
      "25     \t [-0.29720416 -1.18027663]. \t  -162.61909543216842 \t -1.438101203638172\n",
      "26     \t [1.60240592 0.97464485]. \t  -254.14687077583446 \t -1.438101203638172\n",
      "27     \t [-0.97191125 -1.31120216]. \t  -512.7579472786924 \t -1.438101203638172\n",
      "28     \t [-1.93443032 -1.59798195]. \t  -2860.17367592597 \t -1.438101203638172\n",
      "29     \t [1.37431524 0.87251579]. \t  -103.41175790806396 \t -1.438101203638172\n",
      "30     \t [0.48012632 0.86522217]. \t  -40.55478944324965 \t -1.438101203638172\n",
      "31     \t [0.97356934 0.90868674]. \t  \u001b[92m-0.15397498184599573\u001b[0m \t -0.15397498184599573\n",
      "32     \t [ 1.07787512 -0.71270148]. \t  -351.3871830497844 \t -0.15397498184599573\n",
      "33     \t [ 0.27630163 -0.06582515]. \t  -2.544906100838536 \t -0.15397498184599573\n",
      "34     \t [-1.83540621  1.42552311]. \t  -385.6393670616557 \t -0.15397498184599573\n",
      "35     \t [ 2.01758375 -0.55250594]. \t  -2138.3871925698677 \t -0.15397498184599573\n",
      "36     \t [1.33277398 1.75240119]. \t  -0.16778926329190824 \t -0.15397498184599573\n",
      "37     \t [-1.58043967  1.09431901]. \t  -203.63162708500994 \t -0.15397498184599573\n",
      "38     \t [ 0.1009615  -0.11511411]. \t  -2.378462969876212 \t -0.15397498184599573\n",
      "39     \t [0.98329204 0.94623143]. \t  \u001b[92m-0.04284632460377095\u001b[0m \t -0.04284632460377095\n",
      "40     \t [-0.11054444  1.07468379]. \t  -114.11622386713458 \t -0.04284632460377095\n",
      "41     \t [-0.27221244 -1.38537139]. \t  -214.62408667325332 \t -0.04284632460377095\n",
      "42     \t [1.23782584 1.55936699]. \t  -0.13029606740258434 \t -0.04284632460377095\n",
      "43     \t [-0.58678261  1.08491831]. \t  -57.36737735602679 \t -0.04284632460377095\n",
      "44     \t [1.00027019 0.99184679]. \t  \u001b[92m-0.007558069786652685\u001b[0m \t -0.007558069786652685\n",
      "45     \t [-1.71543391 -1.66400185]. \t  -2129.5562105223717 \t -0.007558069786652685\n",
      "46     \t [ 1.86881213 -1.62186053]. \t  -2616.3810228128805 \t -0.007558069786652685\n",
      "47     \t [ 1.89894847 -1.56535976]. \t  -2675.109764479885 \t -0.007558069786652685\n",
      "48     \t [-0.6204992  -0.12849501]. \t  -28.99570757850575 \t -0.007558069786652685\n",
      "49     \t [ 1.33557791 -1.67960408]. \t  -1199.6074650405383 \t -0.007558069786652685\n",
      "50     \t [-0.69958343  1.86298296]. \t  -191.55693395027663 \t -0.007558069786652685\n",
      "51     \t [0.04832924 0.44549841]. \t  -20.544995009306984 \t -0.007558069786652685\n",
      "52     \t [-0.05012816  1.60719716]. \t  -258.60394968974794 \t -0.007558069786652685\n",
      "53     \t [-1.3900638  -0.54439701]. \t  -619.1039988142749 \t -0.007558069786652685\n",
      "54     \t [-0.72066794  0.80975324]. \t  -11.393389233276237 \t -0.007558069786652685\n",
      "55     \t [ 1.61619333 -0.9777034 ]. \t  -1289.0348075664256 \t -0.007558069786652685\n",
      "56     \t [ 1.24502929 -1.35237391]. \t  -842.4943272245607 \t -0.007558069786652685\n",
      "57     \t [0.76216841 0.46550169]. \t  -1.388256686247513 \t -0.007558069786652685\n",
      "58     \t [0.89434429 0.77915836]. \t  -0.05398460701555751 \t -0.007558069786652685\n",
      "59     \t [0.13343589 0.28419157]. \t  -7.847106573453049 \t -0.007558069786652685\n",
      "60     \t [ 0.57035024 -0.16066759]. \t  -23.800990662689415 \t -0.007558069786652685\n",
      "61     \t [-1.90700438  0.38331027]. \t  -1066.8828352982018 \t -0.007558069786652685\n",
      "62     \t [ 1.21641814 -0.7245077 ]. \t  -485.88813413253445 \t -0.007558069786652685\n",
      "63     \t [-0.78833043 -0.5795984 ]. \t  -147.45342344706532 \t -0.007558069786652685\n",
      "64     \t [0.98248073 0.64646422]. \t  -10.163916454415261 \t -0.007558069786652685\n",
      "65     \t [-1.97987795  0.16622229]. \t  -1417.901825249606 \t -0.007558069786652685\n",
      "66     \t [-0.85924906  0.75841849]. \t  -3.4972464362424946 \t -0.007558069786652685\n",
      "67     \t [-0.40645958  0.18874858]. \t  -2.0335378852916635 \t -0.007558069786652685\n",
      "68     \t [1.06557417 1.6319054 ]. \t  -24.65126491082113 \t -0.007558069786652685\n",
      "69     \t [ 0.39666555 -0.87980079]. \t  -107.9308520938263 \t -0.007558069786652685\n",
      "70     \t [0.90150067 0.80505207]. \t  -0.015556496025575663 \t -0.007558069786652685\n",
      "71     \t [-1.86330956  1.89785785]. \t  -255.96649944597127 \t -0.007558069786652685\n",
      "72     \t [0.54856297 1.68253014]. \t  -191.08808394734422 \t -0.007558069786652685\n",
      "73     \t [0.9893993  0.99470798]. \t  -0.025066924299349917 \t -0.007558069786652685\n",
      "74     \t [ 1.1445549  -0.49733755]. \t  -326.6699392210597 \t -0.007558069786652685\n",
      "75     \t [ 0.44713029 -0.6523755 ]. \t  -72.9473635716628 \t -0.007558069786652685\n",
      "76     \t [-1.74474022  0.00624252]. \t  -930.4026051615525 \t -0.007558069786652685\n",
      "77     \t [ 1.97328908 -1.67983515]. \t  -3107.5659898001627 \t -0.007558069786652685\n",
      "78     \t [2.01018778 0.03133464]. \t  -1608.6457559629016 \t -0.007558069786652685\n",
      "79     \t [-0.3889553  0.5254137]. \t  -15.926333614813318 \t -0.007558069786652685\n",
      "80     \t [-0.08486832 -1.49969936]. \t  -228.2522999486935 \t -0.007558069786652685\n",
      "81     \t [0.45746086 0.21495156]. \t  -0.2975762315616386 \t -0.007558069786652685\n",
      "82     \t [0.42929089 0.18852755]. \t  -0.32750400612599806 \t -0.007558069786652685\n",
      "83     \t [0.40614602 0.16005246]. \t  -0.3550656354836159 \t -0.007558069786652685\n",
      "84     \t [-0.34598502 -0.99547561]. \t  -126.17459755526181 \t -0.007558069786652685\n",
      "85     \t [ 0.89874933 -0.17441584]. \t  -96.47529752979031 \t -0.007558069786652685\n",
      "86     \t [1.03890972 0.95339763]. \t  -1.5874959125091062 \t -0.007558069786652685\n",
      "87     \t [ 0.58036849 -0.34040949]. \t  -46.041095902064626 \t -0.007558069786652685\n",
      "88     \t [1.84136412 2.01029075]. \t  -191.23928252908757 \t -0.007558069786652685\n",
      "89     \t [ 0.6179314  -1.34741354]. \t  -299.1774862121004 \t -0.007558069786652685\n",
      "90     \t [-1.27861302 -1.40388203]. \t  -928.5820778647508 \t -0.007558069786652685\n",
      "91     \t [ 1.17047832 -1.6617158 ]. \t  -919.1709549292482 \t -0.007558069786652685\n",
      "92     \t [-0.21867884 -1.24716079]. \t  -169.1828151249029 \t -0.007558069786652685\n",
      "93     \t [1.42258201 2.048     ]. \t  -0.23743238703054015 \t -0.007558069786652685\n",
      "94     \t [-1.3768308   0.67323351]. \t  -155.0827243354762 \t -0.007558069786652685\n",
      "95     \t [-0.76244879 -1.46566154]. \t  -422.12290597515783 \t -0.007558069786652685\n",
      "96     \t [1.90513331 0.79317711]. \t  -805.3107072330936 \t -0.007558069786652685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.04291074 1.8108865 ]. \t  -328.18046344456866 \t -0.007558069786652685\n",
      "98     \t [-0.97543891 -1.99046969]. \t  -869.409784797572 \t -0.007558069786652685\n",
      "99     \t [-0.55956406 -1.69046154]. \t  -403.8629113574788 \t -0.007558069786652685\n",
      "100    \t [-0.46458056  1.72558511]. \t  -230.0795063977036 \t -0.007558069786652685\n"
     ]
    }
   ],
   "source": [
    "### 6(h). Bayesian optimization runs (x20): GP run number = 8\n",
    "\n",
    "np.random.seed(run_num_8)\n",
    "surrogate_gp_8 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_8 = GPGO(surrogate_gp_8, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_8.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 1.47276024 -1.37392335]. \t  -1255.470193895749 \t -296.9616334519401\n",
      "init   \t [-0.06768247  1.72452768]. \t  -296.9616334519401 \t -296.9616334519401\n",
      "init   \t [-0.29263282 -1.81264346]. \t  -362.0166182125878 \t -296.9616334519401\n",
      "init   \t [1.74083045 0.6455359 ]. \t  -569.3497501878961 \t -296.9616334519401\n",
      "init   \t [-1.50342518  0.1370068 ]. \t  -457.0991287591416 \t -296.9616334519401\n",
      "1      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -296.9616334519401\n",
      "2      \t [-2.048  2.048]. \t  -469.9523900415999 \t -296.9616334519401\n",
      "3      \t [2.048 2.048]. \t  -461.7603900415999 \t -296.9616334519401\n",
      "4      \t [-0.03874669 -0.11205653]. \t  \u001b[92m-2.368532806972481\u001b[0m \t -2.368532806972481\n",
      "5      \t [-0.61546959  0.79056349]. \t  -19.56442692074268 \t -2.368532806972481\n",
      "6      \t [0.4435503  0.76911076]. \t  -33.07082404934476 \t -2.368532806972481\n",
      "7      \t [ 0.44161657 -2.048     ]. \t  -503.42799363133963 \t -2.368532806972481\n",
      "8      \t [-2.048       0.94591985]. \t  -1064.4902618118915 \t -2.368532806972481\n",
      "9      \t [0.96401249 2.048     ]. \t  -125.14576955511481 \t -2.368532806972481\n",
      "10     \t [-0.61759444 -0.07324303]. \t  -23.28872118753306 \t -2.368532806972481\n",
      "11     \t [-1.07896043  2.048     ]. \t  -82.44016787227854 \t -2.368532806972481\n",
      "12     \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -2.368532806972481\n",
      "13     \t [ 1.02818127 -0.46632586]. \t  -232.1007095582366 \t -2.368532806972481\n",
      "14     \t [ 0.27509221 -1.14400056]. \t  -149.28651382044384 \t -2.368532806972481\n",
      "15     \t [ 2.048     -0.3503675]. \t  -2066.502206724484 \t -2.368532806972481\n",
      "16     \t [1.29021475 1.36469198]. \t  -9.081951829114407 \t -2.368532806972481\n",
      "17     \t [-0.30799252  0.36432095]. \t  -8.97179773704144 \t -2.368532806972481\n",
      "18     \t [0.90681876 0.56720644]. \t  -6.5169893855957035 \t -2.368532806972481\n",
      "19     \t [-1.03033735 -0.85844027]. \t  -372.7758304144681 \t -2.368532806972481\n",
      "20     \t [-1.06363254  1.50883588]. \t  -18.510842364917405 \t -2.368532806972481\n",
      "21     \t [-2.048      -0.46308451]. \t  -2178.417075419302 \t -2.368532806972481\n",
      "22     \t [0.46159857 0.1533996 ]. \t  \u001b[92m-0.6459703542752915\u001b[0m \t -0.6459703542752915\n",
      "23     \t [-1.10729084  0.79624974]. \t  -22.91719850853658 \t -0.6459703542752915\n",
      "24     \t [1.03452915 1.04268865]. \t  \u001b[92m-0.07715820868055531\u001b[0m \t -0.07715820868055531\n",
      "25     \t [-0.43457915 -0.89233147]. \t  -118.95530870621002 \t -0.07715820868055531\n",
      "26     \t [1.44009484 2.048     ]. \t  -0.26062542110552633 \t -0.07715820868055531\n",
      "27     \t [-0.57023847  2.048     ]. \t  -299.27931229055497 \t -0.07715820868055531\n",
      "28     \t [-0.89903637 -2.048     ]. \t  -819.4321156910266 \t -0.07715820868055531\n",
      "29     \t [1.22381427 1.73559417]. \t  -5.708439901330627 \t -0.07715820868055531\n",
      "30     \t [ 0.75048393 -1.01608924]. \t  -249.48596361989894 \t -0.07715820868055531\n",
      "31     \t [-1.45598034  1.71871155]. \t  -22.125350954634154 \t -0.07715820868055531\n",
      "32     \t [-0.83512341  0.41614756]. \t  -11.279721930506431 \t -0.07715820868055531\n",
      "33     \t [-1.46542304  2.048     ]. \t  -7.067632992413288 \t -0.07715820868055531\n",
      "34     \t [2.048      1.31073992]. \t  -832.5924836734878 \t -0.07715820868055531\n",
      "35     \t [ 0.28771805 -0.44666638]. \t  -28.538870641164948 \t -0.07715820868055531\n",
      "36     \t [0.17112667 0.19273994]. \t  -3.35880446011379 \t -0.07715820868055531\n",
      "37     \t [-1.32728431  1.82329096]. \t  -5.795798359161752 \t -0.07715820868055531\n",
      "38     \t [-1.19654283  1.35719249]. \t  -5.380156874047175 \t -0.07715820868055531\n",
      "39     \t [1.35278939 2.048     ]. \t  -4.87515410695616 \t -0.07715820868055531\n",
      "40     \t [ 1.11940264 -2.048     ]. \t  -1089.715474412622 \t -0.07715820868055531\n",
      "41     \t [1.12517347 1.36827236]. \t  -1.061318291212608 \t -0.07715820868055531\n",
      "42     \t [ 0.30336541 -0.03739816]. \t  -2.160479582877889 \t -0.07715820868055531\n",
      "43     \t [1.36725073 1.84766722]. \t  -0.1819939058054708 \t -0.07715820868055531\n",
      "44     \t [-0.9045973  -1.52217118]. \t  -551.4062789155892 \t -0.07715820868055531\n",
      "45     \t [-2.048      -1.30435392]. \t  -3032.814194759964 \t -0.07715820868055531\n",
      "46     \t [0.64482999 0.3762902 ]. \t  -0.2822933074981599 \t -0.07715820868055531\n",
      "47     \t [1.13215076 1.23471363]. \t  -0.23885026662270675 \t -0.07715820868055531\n",
      "48     \t [1.19616907 1.40617181]. \t  -0.09923783085674796 \t -0.07715820868055531\n",
      "49     \t [1.19542622 1.41202388]. \t  \u001b[92m-0.06715936773690327\u001b[0m \t -0.06715936773690327\n",
      "50     \t [1.3008175  1.68492962]. \t  -0.09567019037684443 \t -0.06715936773690327\n",
      "51     \t [1.33860851 1.78900491]. \t  -0.11547816429693297 \t -0.06715936773690327\n",
      "52     \t [1.17025214 1.33064048]. \t  -0.1799148139591836 \t -0.06715936773690327\n",
      "53     \t [1.10075808 1.19072899]. \t  \u001b[92m-0.053997914937660006\u001b[0m \t -0.053997914937660006\n",
      "54     \t [0.65826088 0.42574828]. \t  -0.12249963814177704 \t -0.053997914937660006\n",
      "55     \t [1.26769973 1.61820282]. \t  -0.08407359615395643 \t -0.053997914937660006\n",
      "56     \t [1.38537201 1.92205486]. \t  -0.14929516306888052 \t -0.053997914937660006\n",
      "57     \t [1.1351981  1.23873935]. \t  -0.26763277553869963 \t -0.053997914937660006\n",
      "58     \t [1.16324267 1.36800974]. \t  \u001b[92m-0.04877840742985787\u001b[0m \t -0.04877840742985787\n",
      "59     \t [1.24856782 1.5571621 ]. \t  -0.06209555301583079 \t -0.04877840742985787\n",
      "60     \t [1.33108541 1.80747422]. \t  -0.2369655287163978 \t -0.04877840742985787\n",
      "61     \t [1.22533544 1.49988529]. \t  -0.051019937472252565 \t -0.04877840742985787\n",
      "62     \t [0.53058936 0.19365023]. \t  -0.992545054082538 \t -0.04877840742985787\n",
      "63     \t [1.234351   1.51763503]. \t  -0.058505233110688046 \t -0.04877840742985787\n",
      "64     \t [1.22374863 1.47001329]. \t  -0.12594945169413296 \t -0.04877840742985787\n",
      "65     \t [-1.00937979  1.07971313]. \t  -4.408068861882386 \t -0.04877840742985787\n",
      "66     \t [0.79067208 0.61984746]. \t  \u001b[92m-0.04664295995216239\u001b[0m \t -0.04664295995216239\n",
      "67     \t [1.17541944 1.33961317]. \t  -0.2071526091008411 \t -0.04664295995216239\n",
      "68     \t [1.03910827 1.06997116]. \t  \u001b[92m-0.011084184946658023\u001b[0m \t -0.011084184946658023\n",
      "69     \t [1.12727196 1.23261146]. \t  -0.1615924411429275 \t -0.011084184946658023\n",
      "70     \t [1.27247773 1.62485151]. \t  -0.07743854526914713 \t -0.011084184946658023\n",
      "71     \t [1.35682768 1.86050504]. \t  -0.16544337116174293 \t -0.011084184946658023\n",
      "72     \t [0.60827731 0.34688188]. \t  -0.20689734517333147 \t -0.011084184946658023\n",
      "73     \t [0.90989621 0.82336479]. \t  \u001b[92m-0.010185593813629667\u001b[0m \t -0.010185593813629667\n",
      "74     \t [1.42827539 2.048     ]. \t  -0.18986693692946358 \t -0.010185593813629667\n",
      "75     \t [0.59487808 0.32819243]. \t  -0.23010851138980015 \t -0.010185593813629667\n",
      "76     \t [1.0053364  0.96902694]. \t  -0.17370348426316376 \t -0.010185593813629667\n",
      "77     \t [0.77779629 0.58068241]. \t  -0.10834897875396171 \t -0.010185593813629667\n",
      "78     \t [1.03554384 1.03653409]. \t  -0.12954879671181604 \t -0.010185593813629667\n",
      "79     \t [0.55473221 0.21192236]. \t  -1.1161322030241887 \t -0.010185593813629667\n",
      "80     \t [0.91554808 0.8375859 ]. \t  \u001b[92m-0.007173392779100266\u001b[0m \t -0.007173392779100266\n",
      "81     \t [1.0901979  1.14550564]. \t  -0.19325781852594026 \t -0.007173392779100266\n",
      "82     \t [1.16934977 1.34362229]. \t  -0.0851168509194909 \t -0.007173392779100266\n",
      "83     \t [0.75455546 0.50838508]. \t  -0.4319632858075775 \t -0.007173392779100266\n",
      "84     \t [0.157427   0.05259249]. \t  -0.7872645923144361 \t -0.007173392779100266\n",
      "85     \t [0.98989518 0.92818648]. \t  -0.26745308474995527 \t -0.007173392779100266\n",
      "86     \t [1.28200565 1.6981131 ]. \t  -0.37736610536038245 \t -0.007173392779100266\n",
      "87     \t [1.01960751 1.02397272]. \t  -0.02480403285083561 \t -0.007173392779100266\n",
      "88     \t [1.14991722 1.31759679]. \t  -0.024696246716707455 \t -0.007173392779100266\n",
      "89     \t [-0.33093172  0.10196701]. \t  -1.7770776561893116 \t -0.007173392779100266\n",
      "90     \t [1.28054016 1.66152461]. \t  -0.1259721293800765 \t -0.007173392779100266\n",
      "91     \t [0.64461125 0.38953062]. \t  -0.1938650029507435 \t -0.007173392779100266\n",
      "92     \t [0.90377012 0.82465719]. \t  -0.015433066630855242 \t -0.007173392779100266\n",
      "93     \t [1.12582059 1.24634073]. \t  -0.06048386953427186 \t -0.007173392779100266\n",
      "94     \t [0.75036936 0.54301928]. \t  -0.1024551871109291 \t -0.007173392779100266\n",
      "95     \t [1.18560295 1.40426181]. \t  -0.0346423751741689 \t -0.007173392779100266\n",
      "96     \t [0.70748638 0.45923864]. \t  -0.2561194852454017 \t -0.007173392779100266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.87966063 0.76098147]. \t  -0.03092027483104272 \t -0.007173392779100266\n",
      "98     \t [1.43058545 2.04799964]. \t  -0.18560686608788396 \t -0.007173392779100266\n",
      "99     \t [1.20018128 1.42018249]. \t  -0.0810893708340327 \t -0.007173392779100266\n",
      "100    \t [0.95395677 0.89321028]. \t  -0.030422093570887446 \t -0.007173392779100266\n"
     ]
    }
   ],
   "source": [
    "### 6(h). Bayesian optimization runs (x20): STP DF1 run number = 8\n",
    "\n",
    "np.random.seed(run_num_8)\n",
    "surrogate_stp_df1_8 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_8 = GPGO(surrogate_stp_df1_8, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_8.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.885139440616033, -4.937376545341707)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(h). Training Regret Minimisation: run number = 8\n",
    "\n",
    "gp_output_8 = np.append(np.max(gpgo_gp_8.GP.y[0:n_init]),gpgo_gp_8.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_8 = np.append(np.max(gpgo_stp_df1_8.GP.y[0:n_init]),gpgo_stp_df1_8.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_8 = np.log(y_global_orig - gp_output_8)\n",
    "regret_stp_df1_8 = np.log(y_global_orig - stp_df1_output_8)\n",
    "\n",
    "train_regret_gp_8 = min_max_array(regret_gp_8)\n",
    "train_regret_stp_df1_8 = min_max_array(regret_stp_df1_8)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 8\n",
    "min_train_regret_gp_8 = min(train_regret_gp_8)\n",
    "min_train_regret_stp_df1_8 = min(train_regret_stp_df1_8)\n",
    "\n",
    "min_train_regret_gp_8, min_train_regret_stp_df1_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.24284125 0.11273132]. \t  -205.0993354093405 \t -3.486729021084656\n",
      "init   \t [-1.56011944  0.5721352 ]. \t  -353.19808767458017 \t -3.486729021084656\n",
      "init   \t [-1.67557012 -0.68720361]. \t  -1228.4786390381805 \t -3.486729021084656\n",
      "init   \t [-0.29744764  0.22276429]. \t  -3.486729021084656 \t -3.486729021084656\n",
      "init   \t [0.52480624 0.8085215 ]. \t  -28.645360944397154 \t -3.486729021084656\n",
      "1      \t [-0.35245884  1.03403796]. \t  -84.60470065420685 \t -3.486729021084656\n",
      "2      \t [0.11166803 0.22275602]. \t  -5.21116529213173 \t -3.486729021084656\n",
      "3      \t [1.43850333 1.80374641]. \t  -7.243721835599461 \t -3.486729021084656\n",
      "4      \t [-0.12180359  0.4063988 ]. \t  -16.590576655816548 \t -3.486729021084656\n",
      "5      \t [0.83526019 1.58481048]. \t  -78.73080961705095 \t -3.486729021084656\n",
      "6      \t [2.048      1.69396862]. \t  -626.2660077391268 \t -3.486729021084656\n",
      "7      \t [1.29688853 2.048     ]. \t  -13.489609539107784 \t -3.486729021084656\n",
      "8      \t [-1.34460591  1.69415083]. \t  -6.7925444681281935 \t -3.486729021084656\n",
      "9      \t [1.12104144 1.18583823]. \t  \u001b[92m-0.5172708389407034\u001b[0m \t -0.5172708389407034\n",
      "10     \t [ 0.11384119 -0.72029027]. \t  -54.55084598577324 \t -0.5172708389407034\n",
      "11     \t [1.21704989 1.62343012]. \t  -2.069754403585214 \t -0.5172708389407034\n",
      "12     \t [-1.50295768  2.048     ]. \t  -10.71190985250822 \t -0.5172708389407034\n",
      "13     \t [-0.08537922 -0.0735298 ]. \t  -1.8312257213824552 \t -0.5172708389407034\n",
      "14     \t [ 0.64660249 -2.048     ]. \t  -608.2872351231961 \t -0.5172708389407034\n",
      "15     \t [ 0.09374081 -0.03697242]. \t  -1.0307012519318268 \t -0.5172708389407034\n",
      "16     \t [-1.01818261  2.048     ]. \t  -106.34667315301438 \t -0.5172708389407034\n",
      "17     \t [-2.048  2.048]. \t  -469.9523900415999 \t -0.5172708389407034\n",
      "18     \t [1.48783165 2.048     ]. \t  -2.9817407372490847 \t -0.5172708389407034\n",
      "19     \t [0.90433292 0.75453337]. \t  \u001b[92m-0.4096470777557209\u001b[0m \t -0.4096470777557209\n",
      "20     \t [-1.33977817  1.84221986]. \t  -5.697480987981098 \t -0.4096470777557209\n",
      "21     \t [-1.03794394  1.05897625]. \t  -4.186892811438978 \t -0.4096470777557209\n",
      "22     \t [1.37749856 1.9127612 ]. \t  \u001b[92m-0.16578858399526586\u001b[0m \t -0.16578858399526586\n",
      "23     \t [ 0.01302056 -0.09245398]. \t  -1.8320399010465316 \t -0.16578858399526586\n",
      "24     \t [-1.65724606 -0.29914425]. \t  -934.6342357790614 \t -0.16578858399526586\n",
      "25     \t [-0.02961048  0.02975863]. \t  -1.1435138380178542 \t -0.16578858399526586\n",
      "26     \t [0.65057742 0.44426233]. \t  -0.1662438529198646 \t -0.16578858399526586\n",
      "27     \t [1.26573891 1.58644782]. \t  \u001b[92m-0.09510057707852411\u001b[0m \t -0.09510057707852411\n",
      "28     \t [ 0.33099647 -0.06196938]. \t  -3.3897525932751527 \t -0.09510057707852411\n",
      "29     \t [0.77389653 1.50134164]. \t  -81.48835657954703 \t -0.09510057707852411\n",
      "30     \t [-0.69763931 -2.03081911]. \t  -636.6725300454044 \t -0.09510057707852411\n",
      "31     \t [1.26358614 1.25775596]. \t  -11.554389223135653 \t -0.09510057707852411\n",
      "32     \t [-1.87908809 -0.86320108]. \t  -1939.164899354496 \t -0.09510057707852411\n",
      "33     \t [-0.62739221 -0.39194339]. \t  -64.35954479768004 \t -0.09510057707852411\n",
      "34     \t [ 0.36641284 -1.98316568]. \t  -448.7498960902122 \t -0.09510057707852411\n",
      "35     \t [0.81674096 0.68579625]. \t  \u001b[92m-0.06866686581553677\u001b[0m \t -0.06866686581553677\n",
      "36     \t [ 1.54086848 -0.39034657]. \t  -764.6061582740361 \t -0.06866686581553677\n",
      "37     \t [-1.76291285  0.33184661]. \t  -778.2596846220939 \t -0.06866686581553677\n",
      "38     \t [-1.3934541  2.048    ]. \t  -6.858286816463446 \t -0.06866686581553677\n",
      "39     \t [1.22776549 1.72798877]. \t  -4.917460497700735 \t -0.06866686581553677\n",
      "40     \t [ 1.94564389 -1.91509798]. \t  -3250.6103265806732 \t -0.06866686581553677\n",
      "41     \t [-0.78495541  0.53934838]. \t  -3.7759914034687756 \t -0.06866686581553677\n",
      "42     \t [1.29505067 1.66958695]. \t  -0.09278431962313811 \t -0.06866686581553677\n",
      "43     \t [1.31028993 1.7130084 ]. \t  -0.0977630827524278 \t -0.06866686581553677\n",
      "44     \t [0.07171576 0.26056562]. \t  -7.385775480397049 \t -0.06866686581553677\n",
      "45     \t [-0.33431734 -2.04084707]. \t  -465.15560158503024 \t -0.06866686581553677\n",
      "46     \t [-0.14629607  1.7916757 ]. \t  -314.700701713432 \t -0.06866686581553677\n",
      "47     \t [-1.47077142  0.1769497 ]. \t  -400.6112526311111 \t -0.06866686581553677\n",
      "48     \t [-1.03558224 -1.53191971]. \t  -682.4076334891206 \t -0.06866686581553677\n",
      "49     \t [1.64442463 1.04432587]. \t  -275.91104316930546 \t -0.06866686581553677\n",
      "50     \t [1.06401424 1.13038979]. \t  \u001b[92m-0.004399369361117275\u001b[0m \t -0.004399369361117275\n",
      "51     \t [1.1942353  0.22768439]. \t  -143.68120589892874 \t -0.004399369361117275\n",
      "52     \t [ 0.78987751 -1.51559457]. \t  -457.7906284656459 \t -0.004399369361117275\n",
      "53     \t [0.04804446 0.76252009]. \t  -58.69841997645781 \t -0.004399369361117275\n",
      "54     \t [0.8071979  0.64576828]. \t  -0.04053684644146521 \t -0.004399369361117275\n",
      "55     \t [1.49485159 1.91923006]. \t  -10.189517117001081 \t -0.004399369361117275\n",
      "56     \t [-1.19619392  0.17071335]. \t  -163.62523894466185 \t -0.004399369361117275\n",
      "57     \t [-0.75284484 -1.85228591]. \t  -588.2582081167144 \t -0.004399369361117275\n",
      "58     \t [-1.58021718 -2.01265012]. \t  -2040.4298287908657 \t -0.004399369361117275\n",
      "59     \t [1.16695885 1.36114057]. \t  -0.027917818610670653 \t -0.004399369361117275\n",
      "60     \t [-0.09863744 -0.82671789]. \t  -71.17140099575552 \t -0.004399369361117275\n",
      "61     \t [ 0.30945798 -1.54985889]. \t  -271.2843977321502 \t -0.004399369361117275\n",
      "62     \t [1.17162447 1.37152859]. \t  -0.029593097035158465 \t -0.004399369361117275\n",
      "63     \t [-1.0923814   0.53125848]. \t  -48.2075783366854 \t -0.004399369361117275\n",
      "64     \t [1.16670137 1.35970885]. \t  -0.028009341241858287 \t -0.004399369361117275\n",
      "65     \t [-1.58742413  0.45001904]. \t  -435.1418404988087 \t -0.004399369361117275\n",
      "66     \t [-1.6642162   1.48417734]. \t  -172.33319146995365 \t -0.004399369361117275\n",
      "67     \t [-1.81894761 -1.59204837]. \t  -2409.552903706136 \t -0.004399369361117275\n",
      "68     \t [1.44211541 0.57742131]. \t  -225.87864492098993 \t -0.004399369361117275\n",
      "69     \t [0.80570971 0.99418713]. \t  -11.941558882150131 \t -0.004399369361117275\n",
      "70     \t [0.73698876 0.52253246]. \t  -0.1116932349534259 \t -0.004399369361117275\n",
      "71     \t [-1.8643726   0.33477749]. \t  -994.8603984179497 \t -0.004399369361117275\n",
      "72     \t [-1.42959869 -2.03685709]. \t  -1671.0403313316876 \t -0.004399369361117275\n",
      "73     \t [-0.59152446 -1.70527875]. \t  -424.90940960366044 \t -0.004399369361117275\n",
      "74     \t [0.53786214 0.20934617]. \t  -0.8527639398668474 \t -0.004399369361117275\n",
      "75     \t [2.00893922 1.18881421]. \t  -811.5717115591253 \t -0.004399369361117275\n",
      "76     \t [ 0.25671492 -0.77944939]. \t  -72.01446283418205 \t -0.004399369361117275\n",
      "77     \t [1.36234927 1.86051236]. \t  -0.13333716421263292 \t -0.004399369361117275\n",
      "78     \t [ 0.52459974 -1.81062668]. \t  -435.29534074508115 \t -0.004399369361117275\n",
      "79     \t [-1.80970019  1.99554673]. \t  -171.59826666480313 \t -0.004399369361117275\n",
      "80     \t [-1.31303778  1.92791924]. \t  -9.505668304006589 \t -0.004399369361117275\n",
      "81     \t [ 0.47085703 -0.19690158]. \t  -17.803251314143296 \t -0.004399369361117275\n",
      "82     \t [-1.68458839  1.96827392]. \t  -82.82119112419906 \t -0.004399369361117275\n",
      "83     \t [-0.57311672 -1.09308476]. \t  -204.55443634964092 \t -0.004399369361117275\n",
      "84     \t [ 1.45936817 -1.17257701]. \t  -1090.7509885966604 \t -0.004399369361117275\n",
      "85     \t [1.72257009 0.24351203]. \t  -742.3957132989527 \t -0.004399369361117275\n",
      "86     \t [ 1.97804235 -1.42167784]. \t  -2846.463564514072 \t -0.004399369361117275\n",
      "87     \t [-1.59836044 -1.1093949 ]. \t  -1349.3517257757726 \t -0.004399369361117275\n",
      "88     \t [-1.54587828 -0.28536114]. \t  -722.0979281955591 \t -0.004399369361117275\n",
      "89     \t [0.20307544 1.84939778]. \t  -327.5786767404465 \t -0.004399369361117275\n",
      "90     \t [-1.11988954  1.03623854]. \t  -9.242584802662687 \t -0.004399369361117275\n",
      "91     \t [-0.08990894 -0.27126149]. \t  -8.991270284363749 \t -0.004399369361117275\n",
      "92     \t [1.47215928 0.03025106]. \t  -456.90064073092884 \t -0.004399369361117275\n",
      "93     \t [0.14498374 0.7232954 ]. \t  -50.050086043414105 \t -0.004399369361117275\n",
      "94     \t [1.72607307 0.57304589]. \t  -579.5466577998477 \t -0.004399369361117275\n",
      "95     \t [1.3267506  1.75738751]. \t  -0.107595186891045 \t -0.004399369361117275\n",
      "96     \t [1.86548432 1.02986345]. \t  -601.0815239394262 \t -0.004399369361117275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [ 0.77706356 -1.83742936]. \t  -596.0233372042517 \t -0.004399369361117275\n",
      "98     \t [1.06557603 1.20918231]. \t  -0.5479121671335476 \t -0.004399369361117275\n",
      "99     \t [0.93977497 0.84011023]. \t  -0.18910165877702872 \t -0.004399369361117275\n",
      "100    \t [0.24470316 0.1711519 ]. \t  -1.8086248462929102 \t -0.004399369361117275\n"
     ]
    }
   ],
   "source": [
    "### 6(i). Bayesian optimization runs (x20): GP run number = 9\n",
    "\n",
    "np.random.seed(run_num_9)\n",
    "surrogate_gp_9 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_9 = GPGO(surrogate_gp_9, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_9.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.24284125 0.11273132]. \t  -205.0993354093405 \t -3.486729021084656\n",
      "init   \t [-1.56011944  0.5721352 ]. \t  -353.19808767458017 \t -3.486729021084656\n",
      "init   \t [-1.67557012 -0.68720361]. \t  -1228.4786390381805 \t -3.486729021084656\n",
      "init   \t [-0.29744764  0.22276429]. \t  -3.486729021084656 \t -3.486729021084656\n",
      "init   \t [0.52480624 0.8085215 ]. \t  -28.645360944397154 \t -3.486729021084656\n",
      "1      \t [-0.8129518  2.048    ]. \t  -195.69403572118213 \t -3.486729021084656\n",
      "2      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -3.486729021084656\n",
      "3      \t [2.048 2.048]. \t  -461.7603900415999 \t -3.486729021084656\n",
      "4      \t [-2.048  2.048]. \t  -469.9523900415999 \t -3.486729021084656\n",
      "5      \t [-0.46912734 -2.048     ]. \t  -516.5772344645554 \t -3.486729021084656\n",
      "6      \t [0.49372907 2.048     ]. \t  -325.7814780618636 \t -3.486729021084656\n",
      "7      \t [2.048      0.71662708]. \t  -1210.5219774946486 \t -3.486729021084656\n",
      "8      \t [ 0.4241079  -0.32033999]. \t  -25.352405855713442 \t -3.486729021084656\n",
      "9      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -3.486729021084656\n",
      "10     \t [-0.41882608  1.16832932]. \t  -100.600895196647 \t -3.486729021084656\n",
      "11     \t [-0.3158246  -0.96443003]. \t  -114.97828191997681 \t -3.486729021084656\n",
      "12     \t [ 0.27784431 -2.048     ]. \t  -452.1679336706096 \t -3.486729021084656\n",
      "13     \t [0.45782151 0.24941237]. \t  \u001b[92m-0.45245574946386113\u001b[0m \t -0.45245574946386113\n",
      "14     \t [ 2.048      -0.45223003]. \t  -2160.1261530915017 \t -0.45245574946386113\n",
      "15     \t [-0.86013117 -0.08265759]. \t  -71.10795250902245 \t -0.45245574946386113\n",
      "16     \t [1.22096679 1.51586778]. \t  \u001b[92m-0.1118669074006283\u001b[0m \t -0.1118669074006283\n",
      "17     \t [1.02236978 0.81077337]. \t  -5.497959424698203 \t -0.1118669074006283\n",
      "18     \t [1.27753746 2.048     ]. \t  -17.374144449379333 \t -0.1118669074006283\n",
      "19     \t [-1.28246306  1.47234053]. \t  -8.180812914461207 \t -0.1118669074006283\n",
      "20     \t [-0.85092943  0.72744964]. \t  -3.427074598291541 \t -0.1118669074006283\n",
      "21     \t [-2.048       1.26876583]. \t  -865.1676616707905 \t -0.1118669074006283\n",
      "22     \t [-1.3666266  2.048    ]. \t  -8.852875218425813 \t -0.1118669074006283\n",
      "23     \t [0.9281027  1.49958528]. \t  -40.73645312327244 \t -0.1118669074006283\n",
      "24     \t [ 0.13830121 -1.3017452 ]. \t  -175.21292127215966 \t -0.1118669074006283\n",
      "25     \t [-1.14821759  1.66274931]. \t  -16.472232469457836 \t -0.1118669074006283\n",
      "26     \t [-0.14534697 -0.40567056]. \t  -19.527328459674003 \t -0.1118669074006283\n",
      "27     \t [0.77254599 0.27138145]. \t  -10.643235931547007 \t -0.1118669074006283\n",
      "28     \t [-1.04142641  1.17123613]. \t  -4.9185413423439694 \t -0.1118669074006283\n",
      "29     \t [ 1.01467812 -1.26400633]. \t  -526.050231916421 \t -0.1118669074006283\n",
      "30     \t [-0.14366762  0.5443642 ]. \t  -28.73663880332434 \t -0.1118669074006283\n",
      "31     \t [-2.048      -0.10530858]. \t  -1857.9571395932667 \t -0.1118669074006283\n",
      "32     \t [-1.00716621 -1.4214111 ]. \t  -597.3383837463361 \t -0.1118669074006283\n",
      "33     \t [-1.08071183  0.85870802]. \t  -13.891683875060702 \t -0.1118669074006283\n",
      "34     \t [ 0.99180306 -2.048     ]. \t  -919.1043720319633 \t -0.1118669074006283\n",
      "35     \t [1.033022   1.16198474]. \t  -0.9007482540603335 \t -0.1118669074006283\n",
      "36     \t [ 0.06823934 -0.0292183 ]. \t  -0.9829288803957256 \t -0.1118669074006283\n",
      "37     \t [0.79423698 0.64296272]. \t  \u001b[92m-0.057101489066876315\u001b[0m \t -0.057101489066876315\n",
      "38     \t [1.50363486 2.048     ]. \t  -4.787046669761064 \t -0.057101489066876315\n",
      "39     \t [1.34113283 1.84752557]. \t  -0.3553782919292664 \t -0.057101489066876315\n",
      "40     \t [-0.78936619 -0.69704247]. \t  -177.47917448265588 \t -0.057101489066876315\n",
      "41     \t [-0.71494921  0.39935636]. \t  -4.190885402294764 \t -0.057101489066876315\n",
      "42     \t [-1.1606802 -2.048    ]. \t  -1157.3922614400283 \t -0.057101489066876315\n",
      "43     \t [2.048     1.4739028]. \t  -741.1565742197079 \t -0.057101489066876315\n",
      "44     \t [1.4159872 2.048    ]. \t  -0.35777564517822336 \t -0.057101489066876315\n",
      "45     \t [ 0.44767549 -0.91901651]. \t  -125.6173817722498 \t -0.057101489066876315\n",
      "46     \t [ 1.08193064 -0.55882361]. \t  -299.0882932840342 \t -0.057101489066876315\n",
      "47     \t [-1.52304565  2.04401979]. \t  -13.963955147939748 \t -0.057101489066876315\n",
      "48     \t [-1.40590527  1.8137538 ]. \t  -8.439279967393169 \t -0.057101489066876315\n",
      "49     \t [0.93795235 0.88683762]. \t  \u001b[92m-0.008866810692089394\u001b[0m \t -0.008866810692089394\n",
      "50     \t [1.37811476 1.9147238 ]. \t  -0.16706869683831277 \t -0.008866810692089394\n",
      "51     \t [1.15425587 1.35828303]. \t  -0.09127229442369106 \t -0.008866810692089394\n",
      "52     \t [1.02129375 1.0576631 ]. \t  -0.02183423791698583 \t -0.008866810692089394\n",
      "53     \t [ 2.048      -1.29393353]. \t  -3013.1734203824853 \t -0.008866810692089394\n",
      "54     \t [0.89637752 0.81028626]. \t  -0.015352916359872964 \t -0.008866810692089394\n",
      "55     \t [1.43702541 2.033532  ]. \t  -0.2902794416774925 \t -0.008866810692089394\n",
      "56     \t [-2.048      -1.24103349]. \t  -2963.5796692983017 \t -0.008866810692089394\n",
      "57     \t [1.42146917 2.04799968]. \t  -0.252849847566858 \t -0.008866810692089394\n",
      "58     \t [ 0.15121991 -0.01220459]. \t  -0.8434325458515101 \t -0.008866810692089394\n",
      "59     \t [0.89552268 0.79303026]. \t  -0.018891073674488498 \t -0.008866810692089394\n",
      "60     \t [1.16620619 1.38466787]. \t  -0.08829307651698823 \t -0.008866810692089394\n",
      "61     \t [1.28169888 1.6708265 ]. \t  -0.15817187402430538 \t -0.008866810692089394\n",
      "62     \t [0.78707042 0.61434091]. \t  -0.047979871240607895 \t -0.008866810692089394\n",
      "63     \t [1.03038116 1.05236628]. \t  -0.00960749493541681 \t -0.008866810692089394\n",
      "64     \t [1.18641492 1.4226268 ]. \t  -0.05739002473241181 \t -0.008866810692089394\n",
      "65     \t [0.73300044 0.51752922]. \t  -0.11033618207134019 \t -0.008866810692089394\n",
      "66     \t [0.99977465 0.98265069]. \t  -0.028556508106850568 \t -0.008866810692089394\n",
      "67     \t [1.1538384  1.39314269]. \t  -0.405585791578875 \t -0.008866810692089394\n",
      "68     \t [0.92536068 0.86626467]. \t  -0.015515660922257899 \t -0.008866810692089394\n",
      "69     \t [0.97012191 0.97340988]. \t  -0.10504965378961742 \t -0.008866810692089394\n",
      "70     \t [0.66042993 0.43417409]. \t  -0.11570527955560478 \t -0.008866810692089394\n",
      "71     \t [-0.07010816  0.03511211]. \t  -1.2363170578966884 \t -0.008866810692089394\n",
      "72     \t [1.05672348 1.12276967]. \t  \u001b[92m-0.006944842202216574\u001b[0m \t -0.006944842202216574\n",
      "73     \t [0.77815843 0.61206092]. \t  -0.053478270231526404 \t -0.006944842202216574\n",
      "74     \t [1.36247904 1.86772498]. \t  -0.14433204917445253 \t -0.006944842202216574\n",
      "75     \t [0.89872679 0.83228384]. \t  -0.07064439408574395 \t -0.006944842202216574\n",
      "76     \t [1.06915125 1.08817185]. \t  -0.30632071762495383 \t -0.006944842202216574\n",
      "77     \t [0.87945746 0.7338873 ]. \t  -0.1710150503029575 \t -0.006944842202216574\n",
      "78     \t [0.35065479 0.16639323]. \t  -0.6103043464345648 \t -0.006944842202216574\n",
      "79     \t [0.69979442 0.47473914]. \t  -0.11254273666808957 \t -0.006944842202216574\n",
      "80     \t [0.82579583 0.70635207]. \t  -0.08994809223518399 \t -0.006944842202216574\n",
      "81     \t [1.40586642 1.97435188]. \t  -0.16517213614821113 \t -0.006944842202216574\n",
      "82     \t [1.37562559 1.91167758]. \t  -0.17846653603004647 \t -0.006944842202216574\n",
      "83     \t [1.08497037 1.21944243]. \t  -0.18599444985842967 \t -0.006944842202216574\n",
      "84     \t [0.94845886 0.84495176]. \t  -0.30101762687768685 \t -0.006944842202216574\n",
      "85     \t [1.40617657 2.01463429]. \t  -0.30412145556933334 \t -0.006944842202216574\n",
      "86     \t [0.88590458 0.79880099]. \t  -0.032545186638113 \t -0.006944842202216574\n",
      "87     \t [0.7664362  0.61013156]. \t  -0.10611330298036116 \t -0.006944842202216574\n",
      "88     \t [1.43711801 2.03779526]. \t  -0.26676823225017143 \t -0.006944842202216574\n",
      "89     \t [1.14847481 1.31386823]. \t  -0.024672511980920988 \t -0.006944842202216574\n",
      "90     \t [0.83368876 0.69897416]. \t  -0.02920959790718342 \t -0.006944842202216574\n",
      "91     \t [0.92863918 0.83976424]. \t  -0.05619774894683795 \t -0.006944842202216574\n",
      "92     \t [0.8006381  0.65506034]. \t  -0.05945446082410312 \t -0.006944842202216574\n",
      "93     \t [0.27842326 0.11684514]. \t  -0.6753235152620269 \t -0.006944842202216574\n",
      "94     \t [1.41908443 2.01696263]. \t  -0.17663159715838636 \t -0.006944842202216574\n",
      "95     \t [1.3267506  1.75738751]. \t  -0.107595186891045 \t -0.006944842202216574\n",
      "96     \t [1.00819923 1.04269451]. \t  -0.06886235709379718 \t -0.006944842202216574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [ 0.09572807 -0.03233574]. \t  -0.9899294097363213 \t -0.006944842202216574\n",
      "98     \t [1.22354471 1.53009708]. \t  -0.15910617174430863 \t -0.006944842202216574\n",
      "99     \t [0.93977497 0.84011023]. \t  -0.18910165901069703 \t -0.006944842202216574\n",
      "100    \t [0.75552597 0.63719336]. \t  -0.5003165880056363 \t -0.006944842202216574\n"
     ]
    }
   ],
   "source": [
    "### 6(i). Bayesian optimization runs (x20): STP DF1 run number = 9\n",
    "\n",
    "np.random.seed(run_num_9)\n",
    "surrogate_stp_df1_9 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_9 = GPGO(surrogate_stp_df1_9, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_9.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.426294075349022, -4.9697560240970855)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(i). Training Regret Minimisation: run number = 9\n",
    "\n",
    "gp_output_9 = np.append(np.max(gpgo_gp_9.GP.y[0:n_init]),gpgo_gp_9.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_9 = np.append(np.max(gpgo_stp_df1_9.GP.y[0:n_init]),gpgo_stp_df1_9.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_9 = np.log(y_global_orig - gp_output_9)\n",
    "regret_stp_df1_9 = np.log(y_global_orig - stp_df1_output_9)\n",
    "\n",
    "train_regret_gp_9 = min_max_array(regret_gp_9)\n",
    "train_regret_stp_df1_9 = min_max_array(regret_stp_df1_9)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 9\n",
    "min_train_regret_gp_9 = min(train_regret_gp_9)\n",
    "min_train_regret_stp_df1_9 = min(train_regret_stp_df1_9)\n",
    "\n",
    "min_train_regret_gp_9, min_train_regret_stp_df1_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.62910294 -1.57693156]. \t  -389.29291138113445 \t -8.580376531587937\n",
      "init   \t [ 1.84435861 -0.07294402]. \t  -1207.999341247548 \t -8.580376531587937\n",
      "init   \t [ 1.5256557  -1.17828534]. \t  -1229.4172568797705 \t -8.580376531587937\n",
      "init   \t [-1.88125338 -0.42109149]. \t  -1576.6245828972787 \t -8.580376531587937\n",
      "init   \t [-1.09309052  1.39977001]. \t  -8.580376531587937 \t -8.580376531587937\n",
      "1      \t [-0.85767016  2.048     ]. \t  -175.6908136334418 \t -8.580376531587937\n",
      "2      \t [-0.5337917   1.15217037]. \t  -77.5624817749036 \t -8.580376531587937\n",
      "3      \t [-1.87496588  1.74203432]. \t  -322.7824381454903 \t -8.580376531587937\n",
      "4      \t [-0.02273896 -1.98197652]. \t  -394.07407427702145 \t -8.580376531587937\n",
      "5      \t [-0.45198894  1.79927878]. \t  -256.50591736736254 \t -8.580376531587937\n",
      "6      \t [1.82395491 1.22407741]. \t  -442.82797197898645 \t -8.580376531587937\n",
      "7      \t [0.76191163 0.20393692]. \t  -14.237364089085258 \t -8.580376531587937\n",
      "8      \t [0.27906645 0.14523118]. \t  \u001b[92m-0.9733890745006908\u001b[0m \t -0.9733890745006908\n",
      "9      \t [0.53651391 0.48570279]. \t  -4.12950380703965 \t -0.9733890745006908\n",
      "10     \t [0.50753179 0.16639301]. \t  -1.0741870743994264 \t -0.9733890745006908\n",
      "11     \t [0.82681667 0.5140719 ]. \t  -2.904845071877965 \t -0.9733890745006908\n",
      "12     \t [-0.41232629  0.43404086]. \t  -8.965738299335683 \t -0.9733890745006908\n",
      "13     \t [0.09685213 1.14732323]. \t  -130.30708024312105 \t -0.9733890745006908\n",
      "14     \t [-0.05291771 -0.03230177]. \t  -1.2318511063569806 \t -0.9733890745006908\n",
      "15     \t [0.67025368 0.41040456]. \t  \u001b[92m-0.2595517313053912\u001b[0m \t -0.2595517313053912\n",
      "16     \t [ 0.25043895 -0.16555784]. \t  -5.772903627858746 \t -0.2595517313053912\n",
      "17     \t [0.9032652  1.11887836]. \t  -9.189672779314169 \t -0.2595517313053912\n",
      "18     \t [0.8069928  0.78360758]. \t  -1.7894387388656352 \t -0.2595517313053912\n",
      "19     \t [-0.08356907  0.17564774]. \t  -4.018874586808618 \t -0.2595517313053912\n",
      "20     \t [-1.06165874  1.04308969]. \t  -4.956534027361672 \t -0.2595517313053912\n",
      "21     \t [ 0.10750306 -0.01560465]. \t  -0.8703258187119848 \t -0.2595517313053912\n",
      "22     \t [-0.54406621  0.55178079]. \t  -8.926110786722774 \t -0.2595517313053912\n",
      "23     \t [1.40780934 1.88021852]. \t  -1.2007728814974612 \t -0.2595517313053912\n",
      "24     \t [-0.08262942  1.92456551]. \t  -368.94394876270246 \t -0.2595517313053912\n",
      "25     \t [1.36481954 2.048     ]. \t  -3.5655030184028154 \t -0.2595517313053912\n",
      "26     \t [1.45733524 0.6290517 ]. \t  -223.64417807412963 \t -0.2595517313053912\n",
      "27     \t [-0.24544502  1.24586148]. \t  -142.12018927681916 \t -0.2595517313053912\n",
      "28     \t [1.24264226 1.59580016]. \t  -0.3255480460930816 \t -0.2595517313053912\n",
      "29     \t [1.82728722 0.31366993]. \t  -915.9336552102571 \t -0.2595517313053912\n",
      "30     \t [1.13202417 1.170425  ]. \t  -1.250723358076635 \t -0.2595517313053912\n",
      "31     \t [0.98185253 0.925996  ]. \t  \u001b[92m-0.1450212253143451\u001b[0m \t -0.1450212253143451\n",
      "32     \t [-0.31793576  0.82467337]. \t  -54.09523653176086 \t -0.1450212253143451\n",
      "33     \t [0.83897536 0.68296945]. \t  \u001b[92m-0.06965261921905326\u001b[0m \t -0.06965261921905326\n",
      "34     \t [-0.18459878 -0.99157824]. \t  -106.60008293430585 \t -0.06965261921905326\n",
      "35     \t [ 2.04545002 -1.72379955]. \t  -3491.1439590465025 \t -0.06965261921905326\n",
      "36     \t [0.98717698 0.86455261]. \t  -1.2094115911311565 \t -0.06965261921905326\n",
      "37     \t [-0.49143264  0.98704416]. \t  -57.80707919856127 \t -0.06965261921905326\n",
      "38     \t [-1.9731415   1.30257183]. \t  -680.0202743820246 \t -0.06965261921905326\n",
      "39     \t [ 0.55732215 -1.45954397]. \t  -313.5397560590302 \t -0.06965261921905326\n",
      "40     \t [-0.71931561  1.74910406]. \t  -154.66185238171147 \t -0.06965261921905326\n",
      "41     \t [1.02002975 1.02664212]. \t  \u001b[92m-0.019496502639641606\u001b[0m \t -0.019496502639641606\n",
      "42     \t [-1.17017422 -0.53387238]. \t  -366.9190964188499 \t -0.019496502639641606\n",
      "43     \t [ 1.09423273 -1.03254202]. \t  -497.2486072284271 \t -0.019496502639641606\n",
      "44     \t [-1.87395402  0.49278705]. \t  -919.6453670223667 \t -0.019496502639641606\n",
      "45     \t [-0.39384294  0.0615181 ]. \t  -2.8187848803398134 \t -0.019496502639641606\n",
      "46     \t [ 1.89366666 -1.78216789]. \t  -2882.4927331825857 \t -0.019496502639641606\n",
      "47     \t [1.44715632 2.048     ]. \t  -0.41396057693322685 \t -0.019496502639641606\n",
      "48     \t [1.03146909 1.0606558 ]. \t  \u001b[92m-0.0020613424379800566\u001b[0m \t -0.0020613424379800566\n",
      "49     \t [1.02723961 1.0510306 ]. \t  -0.002498118235959069 \t -0.0020613424379800566\n",
      "50     \t [1.36800466 1.89960656]. \t  -0.21478131777178672 \t -0.0020613424379800566\n",
      "51     \t [ 0.75641574 -1.40332656]. \t  -390.315934888768 \t -0.0020613424379800566\n",
      "52     \t [-0.84502623 -1.83974622]. \t  -655.6015088704874 \t -0.0020613424379800566\n",
      "53     \t [0.84464057 1.90600766]. \t  -142.25122111186738 \t -0.0020613424379800566\n",
      "54     \t [1.90861306 1.11266196]. \t  -640.9873500056517 \t -0.0020613424379800566\n",
      "55     \t [-1.49630139  1.46255007]. \t  -66.50621539864875 \t -0.0020613424379800566\n",
      "56     \t [-0.77159888  0.08083053]. \t  -29.613117616473627 \t -0.0020613424379800566\n",
      "57     \t [-1.44741526  2.048     ]. \t  -6.210844126167613 \t -0.0020613424379800566\n",
      "58     \t [-1.34492631  1.79668451]. \t  -5.51342289535544 \t -0.0020613424379800566\n",
      "59     \t [1.31417954 1.98169538]. \t  -6.582225985731442 \t -0.0020613424379800566\n",
      "60     \t [1.22482415 1.48101094]. \t  -0.08734566556302667 \t -0.0020613424379800566\n",
      "61     \t [-1.66270093 -1.55400635]. \t  -1872.1039474825202 \t -0.0020613424379800566\n",
      "62     \t [ 1.8351678  -0.07827489]. \t  -1188.26887670644 \t -0.0020613424379800566\n",
      "63     \t [-1.81823939  1.2990678 ]. \t  -410.71794193666307 \t -0.0020613424379800566\n",
      "64     \t [0.47241056 1.13269949]. \t  -83.00242487243595 \t -0.0020613424379800566\n",
      "65     \t [ 1.2739886  -1.98423576]. \t  -1301.3239220270361 \t -0.0020613424379800566\n",
      "66     \t [-1.4064444  -0.22099504]. \t  -489.3866516394009 \t -0.0020613424379800566\n",
      "67     \t [-1.0497881   1.62391789]. \t  -31.43571377729516 \t -0.0020613424379800566\n",
      "68     \t [-0.34965343 -1.95956872]. \t  -435.221610964645 \t -0.0020613424379800566\n",
      "69     \t [ 1.51152057 -1.89587699]. \t  -1747.9794032094064 \t -0.0020613424379800566\n",
      "70     \t [-1.40558332 -1.91251359]. \t  -1517.579699438475 \t -0.0020613424379800566\n",
      "71     \t [ 1.40517301 -0.85657528]. \t  -801.669225988052 \t -0.0020613424379800566\n",
      "72     \t [ 0.30886344 -0.26784294]. \t  -13.67196772240941 \t -0.0020613424379800566\n",
      "73     \t [ 1.63415265 -1.63483115]. \t  -1853.9509454567055 \t -0.0020613424379800566\n",
      "74     \t [2.03618554 0.66993058]. \t  -1209.415371467293 \t -0.0020613424379800566\n",
      "75     \t [-1.73400181  1.72905703]. \t  -170.72783899706164 \t -0.0020613424379800566\n",
      "76     \t [ 0.66620021 -1.06959045]. \t  -229.15336766252585 \t -0.0020613424379800566\n",
      "77     \t [1.13565467 1.28906184]. \t  -0.01844439989813728 \t -0.0020613424379800566\n",
      "78     \t [ 0.29383177 -1.78799774]. \t  -351.8117852221128 \t -0.0020613424379800566\n",
      "79     \t [0.35188336 2.00297952]. \t  -353.54339364049775 \t -0.0020613424379800566\n",
      "80     \t [-1.91804923  0.41488613]. \t  -1073.902053974256 \t -0.0020613424379800566\n",
      "81     \t [ 2.02131551 -1.66183259]. \t  -3304.4750197844164 \t -0.0020613424379800566\n",
      "82     \t [0.93146012 0.87206571]. \t  -0.006675966162530198 \t -0.0020613424379800566\n",
      "83     \t [-1.16956642  1.40716474]. \t  -4.861303510122351 \t -0.0020613424379800566\n",
      "84     \t [0.93293501 0.90391066]. \t  -0.11701051986194459 \t -0.0020613424379800566\n",
      "85     \t [ 1.66561392 -1.2937774 ]. \t  -1655.3437923316073 \t -0.0020613424379800566\n",
      "86     \t [ 0.22527611 -1.7089182 ]. \t  -310.24317612133376 \t -0.0020613424379800566\n",
      "87     \t [0.91301691 0.83808082]. \t  -0.009573947868652628 \t -0.0020613424379800566\n",
      "88     \t [ 1.45792617 -0.2476256 ]. \t  -563.4053281955346 \t -0.0020613424379800566\n",
      "89     \t [-1.67514889 -0.19090665]. \t  -905.3755728724991 \t -0.0020613424379800566\n",
      "90     \t [0.36759214 0.11399194]. \t  -0.44459603837614603 \t -0.0020613424379800566\n",
      "91     \t [1.25243998 1.57576806]. \t  -0.06885558467895661 \t -0.0020613424379800566\n",
      "92     \t [0.78705217 0.06078357]. \t  -31.25628888559174 \t -0.0020613424379800566\n",
      "93     \t [1.19064195 1.63726879]. \t  -4.860540991330615 \t -0.0020613424379800566\n",
      "94     \t [ 0.45046954 -1.93188098]. \t  -456.04070283784597 \t -0.0020613424379800566\n",
      "95     \t [-0.29073196 -0.0322581 ]. \t  -3.0298199791996803 \t -0.0020613424379800566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [-0.81057464  1.07467568]. \t  -20.720868440719848 \t -0.0020613424379800566\n",
      "97     \t [-0.79374399  1.80956559]. \t  -142.348050764057 \t -0.0020613424379800566\n",
      "98     \t [-0.65314311 -0.35198627]. \t  -63.351906424072624 \t -0.0020613424379800566\n",
      "99     \t [ 1.97285981 -1.2448696 ]. \t  -2639.870017628281 \t -0.0020613424379800566\n",
      "100    \t [2.01579377 0.71686644]. \t  -1120.9769394817645 \t -0.0020613424379800566\n"
     ]
    }
   ],
   "source": [
    "### 6(j). Bayesian optimization runs (x20): GP run number = 10\n",
    "\n",
    "np.random.seed(run_num_10)\n",
    "surrogate_gp_10 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_10 = GPGO(surrogate_gp_10, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_10.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.62910294 -1.57693156]. \t  -389.29291138113445 \t -8.580376531587937\n",
      "init   \t [ 1.84435861 -0.07294402]. \t  -1207.999341247548 \t -8.580376531587937\n",
      "init   \t [ 1.5256557  -1.17828534]. \t  -1229.4172568797705 \t -8.580376531587937\n",
      "init   \t [-1.88125338 -0.42109149]. \t  -1576.6245828972787 \t -8.580376531587937\n",
      "init   \t [-1.09309052  1.39977001]. \t  -8.580376531587937 \t -8.580376531587937\n",
      "1      \t [0.28236162 2.048     ]. \t  -387.92443739260824 \t -8.580376531587937\n",
      "2      \t [-2.048  2.048]. \t  -469.9523900415999 \t -8.580376531587937\n",
      "3      \t [-0.54449947 -2.048     ]. \t  -552.0439701204687 \t -8.580376531587937\n",
      "4      \t [2.048 2.048]. \t  -461.7603900415999 \t -8.580376531587937\n",
      "5      \t [-0.13348147  0.63226755]. \t  -39.03969092029878 \t -8.580376531587937\n",
      "6      \t [-0.79901122  2.048     ]. \t  -201.92832173389496 \t -8.580376531587937\n",
      "7      \t [-0.51117975  1.17490443]. \t  -85.75010387439133 \t -8.580376531587937\n",
      "8      \t [-0.00831909 -0.48702543]. \t  -24.74282574145066 \t -8.580376531587937\n",
      "9      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -8.580376531587937\n",
      "10     \t [-0.79614969  0.31568666]. \t  -13.349220183716493 \t -8.580376531587937\n",
      "11     \t [-2.048       0.88122679]. \t  -1106.9383617763256 \t -8.580376531587937\n",
      "12     \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -8.580376531587937\n",
      "13     \t [ 0.73331164 -0.48552562]. \t  -104.77959472732142 \t -8.580376531587937\n",
      "14     \t [1.10555356 1.29397948]. \t  \u001b[92m-0.5256725629142965\u001b[0m \t -0.5256725629142965\n",
      "15     \t [1.20298938 2.048     ]. \t  -36.13925730290099 \t -0.5256725629142965\n",
      "16     \t [ 0.00388128 -1.26679466]. \t  -161.47293962306227 \t -0.5256725629142965\n",
      "17     \t [ 0.07789504 -2.048     ]. \t  -422.76966356912806 \t -0.5256725629142965\n",
      "18     \t [2.048      1.19268884]. \t  -902.0676611934596 \t -0.5256725629142965\n",
      "19     \t [0.81688715 1.50518769]. \t  -70.23833509513018 \t -0.5256725629142965\n",
      "20     \t [0.75371707 0.6158295 ]. \t  \u001b[92m-0.28856677424574256\u001b[0m \t -0.28856677424574256\n",
      "21     \t [-0.72057656 -0.60696514]. \t  -129.7920656312814 \t -0.28856677424574256\n",
      "22     \t [-0.42821716  0.00107249]. \t  -5.363040310085042 \t -0.28856677424574256\n",
      "23     \t [-0.84312623  0.88340748]. \t  -6.374313822367206 \t -0.28856677424574256\n",
      "24     \t [0.77008236 0.95701631]. \t  -13.301696151521028 \t -0.28856677424574256\n",
      "25     \t [0.33641209 0.20605049]. \t  -1.3029700479054616 \t -0.28856677424574256\n",
      "26     \t [-1.39303288  2.048     ]. \t  -6.881358775512646 \t -0.28856677424574256\n",
      "27     \t [1.2897524  1.70120876]. \t  \u001b[92m-0.2264437757272446\u001b[0m \t -0.2264437757272446\n",
      "28     \t [-1.24085452  1.80500136]. \t  -12.058853001399775 \t -0.2264437757272446\n",
      "29     \t [ 0.45694056 -0.91790172]. \t  -127.23938861612048 \t -0.2264437757272446\n",
      "30     \t [0.54132324 0.4512894 ]. \t  -2.7149612956633162 \t -0.2264437757272446\n",
      "31     \t [1.48318751 2.048     ]. \t  -2.539166269933985 \t -0.2264437757272446\n",
      "32     \t [-1.45275126  1.5592403 ]. \t  -36.40319496762942 \t -0.2264437757272446\n",
      "33     \t [-1.1481913   0.83934424]. \t  -27.55873108440108 \t -0.2264437757272446\n",
      "34     \t [-0.9470743  -1.39963391]. \t  -531.2207372463464 \t -0.2264437757272446\n",
      "35     \t [-0.60032609  0.41171046]. \t  -2.8244080289934193 \t -0.2264437757272446\n",
      "36     \t [0.56757574 0.17154448]. \t  -2.4549586969463575 \t -0.2264437757272446\n",
      "37     \t [1.40904412 2.048     ]. \t  -0.559126267528834 \t -0.2264437757272446\n",
      "38     \t [ 1.00370997 -2.048     ]. \t  -933.5675217502148 \t -0.2264437757272446\n",
      "39     \t [ 2.048      -0.83056121]. \t  -2526.025346295632 \t -0.2264437757272446\n",
      "40     \t [-2.048     -1.1914576]. \t  -2909.9331032049377 \t -0.2264437757272446\n",
      "41     \t [-0.43723729 -1.0667393 ]. \t  -160.30085224163065 \t -0.2264437757272446\n",
      "42     \t [-0.01925323 -0.00551587]. \t  -1.042342303785964 \t -0.2264437757272446\n",
      "43     \t [1.11109359 0.93544259]. \t  -8.957608167375545 \t -0.2264437757272446\n",
      "44     \t [-1.13083742  1.18875433]. \t  -5.351168977431547 \t -0.2264437757272446\n",
      "45     \t [0.8515684  0.70793921]. \t  \u001b[92m-0.05171764480181718\u001b[0m \t -0.05171764480181718\n",
      "46     \t [ 0.21899879 -0.10001885]. \t  -2.7997508555227486 \t -0.05171764480181718\n",
      "47     \t [1.39076422 1.98056817]. \t  -0.3674645555199486 \t -0.05171764480181718\n",
      "48     \t [1.15529984 1.37043288]. \t  -0.1516753743353633 \t -0.05171764480181718\n",
      "49     \t [0.99621325 0.97594887]. \t  \u001b[92m-0.027212858517945904\u001b[0m \t -0.027212858517945904\n",
      "50     \t [0.74900687 0.49267408]. \t  -0.5299950293790364 \t -0.027212858517945904\n",
      "51     \t [0.77148732 0.58393711]. \t  -0.06488684571752519 \t -0.027212858517945904\n",
      "52     \t [-1.23963186 -2.048     ]. \t  -1290.0141430593765 \t -0.027212858517945904\n",
      "53     \t [1.41372377 2.048     ]. \t  -0.41505613086279824 \t -0.027212858517945904\n",
      "54     \t [1.42194729 2.04018223]. \t  -0.2113389732742653 \t -0.027212858517945904\n",
      "55     \t [0.70509888 0.47478791]. \t  -0.13703753225338744 \t -0.027212858517945904\n",
      "56     \t [1.2845137  1.69240095]. \t  -0.26094038593262847 \t -0.027212858517945904\n",
      "57     \t [0.87464682 0.77202184]. \t  \u001b[92m-0.020634128748442983\u001b[0m \t -0.020634128748442983\n",
      "58     \t [1.18092966 1.41135911]. \t  -0.060839586759303836 \t -0.020634128748442983\n",
      "59     \t [0.44053691 0.19299311]. \t  -0.31311551516302 \t -0.020634128748442983\n",
      "60     \t [1.08456041 1.20010137]. \t  -0.06393771016642694 \t -0.020634128748442983\n",
      "61     \t [0.98751784 0.97540007]. \t  \u001b[92m-0.00016015489714129894\u001b[0m \t -0.00016015489714129894\n",
      "62     \t [1.15859983 1.37818047]. \t  -0.15351056146473563 \t -0.00016015489714129894\n",
      "63     \t [1.29395585 1.76873439]. \t  -0.9777849662310802 \t -0.00016015489714129894\n",
      "64     \t [0.70017416 0.47502953]. \t  -0.11304309579097178 \t -0.00016015489714129894\n",
      "65     \t [1.01245202 1.02189454]. \t  -0.0011564884643971408 \t -0.00016015489714129894\n",
      "66     \t [0.96714302 0.94441216]. \t  -0.009263551868407794 \t -0.00016015489714129894\n",
      "67     \t [1.08865535 1.22581037]. \t  -0.1730199260313738 \t -0.00016015489714129894\n",
      "68     \t [0.29322623 0.06135098]. \t  -0.5601960180144318 \t -0.00016015489714129894\n",
      "69     \t [0.68734392 0.45297087]. \t  -0.13566500848199717 \t -0.00016015489714129894\n",
      "70     \t [0.68397208 0.42803545]. \t  -0.2581372329062662 \t -0.00016015489714129894\n",
      "71     \t [0.67275962 0.44752982]. \t  -0.10966251946414926 \t -0.00016015489714129894\n",
      "72     \t [1.0721011  1.18180896]. \t  -0.11022771847640155 \t -0.00016015489714129894\n",
      "73     \t [1.03298404 1.05983346]. \t  -0.006304494902969051 \t -0.00016015489714129894\n",
      "74     \t [ 0.01913403 -0.00093501]. \t  -0.9622673380127003 \t -0.00016015489714129894\n",
      "75     \t [0.6394364  0.40010878]. \t  -0.1376976326084145 \t -0.00016015489714129894\n",
      "76     \t [1.08167293 1.21526853]. \t  -0.21144668733765362 \t -0.00016015489714129894\n",
      "77     \t [1.03019749 1.06277831]. \t  -0.0011284028602427027 \t -0.00016015489714129894\n",
      "78     \t [0.86407134 0.7229448 ]. \t  -0.07452471555804466 \t -0.00016015489714129894\n",
      "79     \t [1.42381588 2.048     ]. \t  -0.2226692973109296 \t -0.00016015489714129894\n",
      "80     \t [0.87855024 0.74561286]. \t  -0.08359151023802665 \t -0.00016015489714129894\n",
      "81     \t [0.9232123  0.83949557]. \t  -0.022345382141713714 \t -0.00016015489714129894\n",
      "82     \t [1.01320049 1.02499616]. \t  -0.0004236009684988236 \t -0.00016015489714129894\n",
      "83     \t [1.42162088 2.048     ]. \t  -0.25063223361858866 \t -0.00016015489714129894\n",
      "84     \t [0.66035221 0.43464408]. \t  -0.11556253334619233 \t -0.00016015489714129894\n",
      "85     \t [1.20622109 1.40129801]. \t  -0.33058804222597354 \t -0.00016015489714129894\n",
      "86     \t [1.31999489 1.77923688]. \t  -0.23819179518256167 \t -0.00016015489714129894\n",
      "87     \t [0.94173384 0.90664859]. \t  -0.04254340689019411 \t -0.00016015489714129894\n",
      "88     \t [1.05355285 1.11687548]. \t  -0.00763149068014299 \t -0.00016015489714129894\n",
      "89     \t [1.18556672 1.35932009]. \t  -0.24832596302329496 \t -0.00016015489714129894\n",
      "90     \t [0.82190891 0.6747925 ]. \t  -0.03177145657127562 \t -0.00016015489714129894\n",
      "91     \t [1.22762998 1.53356027]. \t  -0.12196035733472323 \t -0.00016015489714129894\n",
      "92     \t [1.07160962 1.1644247 ]. \t  -0.030976590367696115 \t -0.00016015489714129894\n",
      "93     \t [1.1099972 1.2682354]. \t  -0.14272094083027115 \t -0.00016015489714129894\n",
      "94     \t [1.28168497 1.63891431]. \t  -0.08079198733383214 \t -0.00016015489714129894\n",
      "95     \t [1.03620868 1.09038133]. \t  -0.029042997038268306 \t -0.00016015489714129894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [0.70080025 0.47927805]. \t  -0.10354601285520507 \t -0.00016015489714129894\n",
      "97     \t [0.84205515 0.70167677]. \t  -0.030393162736164322 \t -0.00016015489714129894\n",
      "98     \t [1.20964909 1.49299373]. \t  -0.1324161609513858 \t -0.00016015489714129894\n",
      "99     \t [ 0.01525856 -0.00553073]. \t  -0.9730375579462195 \t -0.00016015489714129894\n",
      "100    \t [0.92385782 0.86503358]. \t  -0.01906936646457945 \t -0.00016015489714129894\n"
     ]
    }
   ],
   "source": [
    "### 6(j). Bayesian optimization runs (x20): STP DF1 run number = 10\n",
    "\n",
    "np.random.seed(run_num_10)\n",
    "surrogate_stp_df1_10 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_10 = GPGO(surrogate_stp_df1_10, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_10.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.184397839502278, -8.739369103910812)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(j). Training Regret Minimisation: run number = 10\n",
    "\n",
    "gp_output_10 = np.append(np.max(gpgo_gp_10.GP.y[0:n_init]),gpgo_gp_10.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_10 = np.append(np.max(gpgo_stp_df1_10.GP.y[0:n_init]),gpgo_stp_df1_10.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_10 = np.log(y_global_orig - gp_output_10)\n",
    "regret_stp_df1_10 = np.log(y_global_orig - stp_df1_output_10)\n",
    "\n",
    "train_regret_gp_10 = min_max_array(regret_gp_10)\n",
    "train_regret_stp_df1_10 = min_max_array(regret_stp_df1_10)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 10\n",
    "min_train_regret_gp_10 = min(train_regret_gp_10)\n",
    "min_train_regret_stp_df1_10 = min(train_regret_stp_df1_10)\n",
    "\n",
    "min_train_regret_gp_10, min_train_regret_stp_df1_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.65663048  1.74081516]. \t  -107.78086518824989 \t -7.804966561968033\n",
      "init   \t [-0.64072326 -0.77628645]. \t  -143.54442082683784 \t -7.804966561968033\n",
      "init   \t [-2.0397677  -1.08300401]. \t  -2758.8332857615223 \t -7.804966561968033\n",
      "init   \t [-1.07400511  0.96631142]. \t  -7.804966561968033 \t -7.804966561968033\n",
      "init   \t [-0.01856276  1.16500623]. \t  -136.68114660882065 \t -7.804966561968033\n",
      "1      \t [ 0.13836103 -0.70324295]. \t  -52.926680242575635 \t -7.804966561968033\n",
      "2      \t [-0.42385416 -0.0275847 ]. \t  \u001b[92m-6.322079975768323\u001b[0m \t -6.322079975768323\n",
      "3      \t [-0.12931465 -1.22764295]. \t  -156.1198337706684 \t -6.322079975768323\n",
      "4      \t [-0.29117704 -0.49323903]. \t  -35.07820878766442 \t -6.322079975768323\n",
      "5      \t [ 1.46784402 -0.61960542]. \t  -769.8216269531654 \t -6.322079975768323\n",
      "6      \t [-0.80367132  0.47673289]. \t  \u001b[92m-6.114561430483431\u001b[0m \t -6.114561430483431\n",
      "7      \t [-0.52887413  0.43992983]. \t  \u001b[92m-4.90456428244924\u001b[0m \t -4.90456428244924\n",
      "8      \t [ 0.28192382 -0.03645324]. \t  \u001b[92m-1.8597090872109192\u001b[0m \t -1.8597090872109192\n",
      "9      \t [-0.94958853 -0.2592429 ]. \t  -138.58400305222708 \t -1.8597090872109192\n",
      "10     \t [-0.87079256 -1.2931408 ]. \t  -424.3324642573477 \t -1.8597090872109192\n",
      "11     \t [ 0.03313813 -1.50071776]. \t  -226.4799202958743 \t -1.8597090872109192\n",
      "12     \t [ 0.09150725 -0.02530041]. \t  \u001b[92m-0.9387528318581627\u001b[0m \t -0.9387528318581627\n",
      "13     \t [-0.93093567  1.30403359]. \t  -22.85972111961096 \t -0.9387528318581627\n",
      "14     \t [-1.58697296 -0.58138521]. \t  -967.610823158014 \t -0.9387528318581627\n",
      "15     \t [1.74912154 1.88681135]. \t  -138.06372783067945 \t -0.9387528318581627\n",
      "16     \t [-2.048       0.90723086]. \t  -1089.7752858066847 \t -0.9387528318581627\n",
      "17     \t [1.00367366 1.27857866]. \t  -7.355924706037502 \t -0.9387528318581627\n",
      "18     \t [0.86125323 1.64652555]. \t  -81.87984232863701 \t -0.9387528318581627\n",
      "19     \t [0.946485   0.93972544]. \t  \u001b[92m-0.19551099182009382\u001b[0m \t -0.19551099182009382\n",
      "20     \t [ 0.13806195 -0.18071883]. \t  -4.734139441531492 \t -0.19551099182009382\n",
      "21     \t [0.70871181 0.90248202]. \t  -16.101621071017227 \t -0.19551099182009382\n",
      "22     \t [-0.91146207  0.91322129]. \t  -4.333622391797463 \t -0.19551099182009382\n",
      "23     \t [-1.42816646  2.048     ]. \t  -5.902948856211343 \t -0.19551099182009382\n",
      "24     \t [1.28506474 1.18370703]. \t  -21.95412698581979 \t -0.19551099182009382\n",
      "25     \t [-1.24443738  1.56966562]. \t  -5.081772456998699 \t -0.19551099182009382\n",
      "26     \t [ 0.51583606 -0.21091126]. \t  -22.9871337380959 \t -0.19551099182009382\n",
      "27     \t [-1.42187703  1.84415679]. \t  -9.018865037509716 \t -0.19551099182009382\n",
      "28     \t [0.96725552 0.95545225]. \t  \u001b[92m-0.040549969079409394\u001b[0m \t -0.040549969079409394\n",
      "29     \t [-0.62205685 -1.1494334 ]. \t  -238.67991411630183 \t -0.040549969079409394\n",
      "30     \t [-1.35755558  0.73645252]. \t  -127.9933165693609 \t -0.040549969079409394\n",
      "31     \t [-0.20629381  0.05129449]. \t  -1.462778888191517 \t -0.040549969079409394\n",
      "32     \t [-0.22784281 -1.19496483]. \t  -156.97786812617278 \t -0.040549969079409394\n",
      "33     \t [-1.25072808 -1.83040198]. \t  -1157.480006409276 \t -0.040549969079409394\n",
      "34     \t [0.68612391 0.35626632]. \t  -1.4095363695453063 \t -0.040549969079409394\n",
      "35     \t [-1.81524173 -0.58571462]. \t  -1513.9997580500465 \t -0.040549969079409394\n",
      "36     \t [-1.30231385 -1.39449853]. \t  -960.4319677015552 \t -0.040549969079409394\n",
      "37     \t [ 1.00645727 -0.61192325]. \t  -264.02337786905093 \t -0.040549969079409394\n",
      "38     \t [-0.34300462  1.08822544]. \t  -96.00490918968295 \t -0.040549969079409394\n",
      "39     \t [-0.52323131  1.9390012 ]. \t  -279.61939532952573 \t -0.040549969079409394\n",
      "40     \t [-0.14991958 -0.19361636]. \t  -5.991900867642769 \t -0.040549969079409394\n",
      "41     \t [0.12641456 0.06884223]. \t  -1.0425863129707396 \t -0.040549969079409394\n",
      "42     \t [-1.93385947  0.2631088 ]. \t  -1217.3543611888938 \t -0.040549969079409394\n",
      "43     \t [ 0.90909522 -0.90131699]. \t  -298.52756457626134 \t -0.040549969079409394\n",
      "44     \t [-1.47471401 -1.82762384]. \t  -1608.048987663958 \t -0.040549969079409394\n",
      "45     \t [ 0.2262611  -0.55789666]. \t  -37.69782551251487 \t -0.040549969079409394\n",
      "46     \t [-1.79051923 -0.52968549]. \t  -1403.2910553408872 \t -0.040549969079409394\n",
      "47     \t [-1.99484907 -0.45180172]. \t  -1972.544214695796 \t -0.040549969079409394\n",
      "48     \t [0.44543629 0.22373773]. \t  -0.371672629434573 \t -0.040549969079409394\n",
      "49     \t [-1.77513078 -0.52512611]. \t  -1359.1573186217313 \t -0.040549969079409394\n",
      "50     \t [-1.95501245 -0.60708615]. \t  -1970.4777715083762 \t -0.040549969079409394\n",
      "51     \t [-1.77286875 -0.69450957]. \t  -1480.3855954158353 \t -0.040549969079409394\n",
      "52     \t [-1.77817813  0.65302463]. \t  -637.1725998455703 \t -0.040549969079409394\n",
      "53     \t [-1.08218179 -1.28958123]. \t  -609.8392667815132 \t -0.040549969079409394\n",
      "54     \t [ 1.11588236 -1.76433276]. \t  -905.7382278777496 \t -0.040549969079409394\n",
      "55     \t [-1.19542116  1.37233266]. \t  -5.141352788307927 \t -0.040549969079409394\n",
      "56     \t [-1.95700736 -0.4160486 ]. \t  -1811.5330117818355 \t -0.040549969079409394\n",
      "57     \t [ 1.68637808 -0.25071331]. \t  -958.1163350176158 \t -0.040549969079409394\n",
      "58     \t [ 1.40450512 -0.48641041]. \t  -604.8538693555874 \t -0.040549969079409394\n",
      "59     \t [-1.23268943 -0.37490204]. \t  -363.86961423722823 \t -0.040549969079409394\n",
      "60     \t [ 0.9518345  -0.85687494]. \t  -310.77121429820045 \t -0.040549969079409394\n",
      "61     \t [1.01566549 1.05880227]. \t  -0.07437033828681291 \t -0.040549969079409394\n",
      "62     \t [ 0.55323613 -2.02214808]. \t  -542.2596452468648 \t -0.040549969079409394\n",
      "63     \t [-1.20246802 -1.18109718]. \t  -694.9776948927804 \t -0.040549969079409394\n",
      "64     \t [ 0.51262486 -0.69123983]. \t  -91.25372875032043 \t -0.040549969079409394\n",
      "65     \t [1.58506591 0.02880552]. \t  -617.1833194930828 \t -0.040549969079409394\n",
      "66     \t [-1.27864601 -1.43033777]. \t  -944.7823195334834 \t -0.040549969079409394\n",
      "67     \t [1.01569761 1.64115725]. \t  -37.15117631232276 \t -0.040549969079409394\n",
      "68     \t [-1.10016939  1.29176417]. \t  -5.0731687629514095 \t -0.040549969079409394\n",
      "69     \t [ 0.55383117 -0.15969407]. \t  -21.954111615077686 \t -0.040549969079409394\n",
      "70     \t [-1.10121962 -1.57881899]. \t  -783.664380936801 \t -0.040549969079409394\n",
      "71     \t [-0.61583073  0.81437228]. \t  -21.544267485138892 \t -0.040549969079409394\n",
      "72     \t [1.6783921  0.08532671]. \t  -746.6641329293619 \t -0.040549969079409394\n",
      "73     \t [ 1.42955769 -0.77240591]. \t  -793.1932677680414 \t -0.040549969079409394\n",
      "74     \t [-1.84437951  0.89443584]. \t  -636.7457875571044 \t -0.040549969079409394\n",
      "75     \t [0.36207658 0.12170817]. \t  -0.4157658942955602 \t -0.040549969079409394\n",
      "76     \t [-1.4311532  -0.16488206]. \t  -495.6834952200254 \t -0.040549969079409394\n",
      "77     \t [0.40591012 0.86924004]. \t  -49.981729595159 \t -0.040549969079409394\n",
      "78     \t [ 0.27439676 -1.18864729]. \t  -160.28115227481288 \t -0.040549969079409394\n",
      "79     \t [0.69528975 0.85437309]. \t  -13.852886672785472 \t -0.040549969079409394\n",
      "80     \t [-1.89849563  1.03959359]. \t  -666.1658257332668 \t -0.040549969079409394\n",
      "81     \t [-1.05645716 -1.75008205]. \t  -825.729958349443 \t -0.040549969079409394\n",
      "82     \t [-1.98698229  0.87464756]. \t  -953.5322043554869 \t -0.040549969079409394\n",
      "83     \t [-1.13141121  1.74718492]. \t  -26.36055506364469 \t -0.040549969079409394\n",
      "84     \t [0.93193853 0.85707704]. \t  \u001b[92m-0.017702306147356888\u001b[0m \t -0.017702306147356888\n",
      "85     \t [-1.6754206  -0.12230027]. \t  -865.2579003616511 \t -0.017702306147356888\n",
      "86     \t [0.81217334 1.86238174]. \t  -144.69752911271752 \t -0.017702306147356888\n",
      "87     \t [-1.87977129 -0.83305806]. \t  -1915.0110490215084 \t -0.017702306147356888\n",
      "88     \t [-0.8798521   1.14546936]. \t  -17.32241430250007 \t -0.017702306147356888\n",
      "89     \t [-0.63390291  2.00317301]. \t  -259.09865414034357 \t -0.017702306147356888\n",
      "90     \t [-1.45590133  1.40059136]. \t  -57.735795191446094 \t -0.017702306147356888\n",
      "91     \t [ 0.63935344 -1.95910994]. \t  -560.8169411245423 \t -0.017702306147356888\n",
      "92     \t [-1.10437835  0.11880316]. \t  -125.61512358495087 \t -0.017702306147356888\n",
      "93     \t [-0.10786704  1.83372413]. \t  -333.2281413060393 \t -0.017702306147356888\n",
      "94     \t [1.9107507 0.1634554]. \t  -1217.1040362935332 \t -0.017702306147356888\n",
      "95     \t [0.92161959 0.82986629]. \t  -0.04423237549561027 \t -0.017702306147356888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [-0.72601976 -1.53048598]. \t  -426.3470803640435 \t -0.017702306147356888\n",
      "97     \t [-0.11751471  0.60297111]. \t  -35.959954554997054 \t -0.017702306147356888\n",
      "98     \t [-1.36777488  1.19940628]. \t  -50.68440108319978 \t -0.017702306147356888\n",
      "99     \t [ 1.54176778 -2.02914152]. \t  -1941.744013420752 \t -0.017702306147356888\n",
      "100    \t [-2.01292876  0.78354333]. \t  -1077.2816314435727 \t -0.017702306147356888\n"
     ]
    }
   ],
   "source": [
    "### 6(k). Bayesian optimization runs (x20): GP run number = 11\n",
    "\n",
    "np.random.seed(run_num_11)\n",
    "surrogate_gp_11 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_11 = GPGO(surrogate_gp_11, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_11.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.65663048  1.74081516]. \t  -107.78086518824989 \t -7.804966561968033\n",
      "init   \t [-0.64072326 -0.77628645]. \t  -143.54442082683784 \t -7.804966561968033\n",
      "init   \t [-2.0397677  -1.08300401]. \t  -2758.8332857615223 \t -7.804966561968033\n",
      "init   \t [-1.07400511  0.96631142]. \t  -7.804966561968033 \t -7.804966561968033\n",
      "init   \t [-0.01856276  1.16500623]. \t  -136.68114660882065 \t -7.804966561968033\n",
      "1      \t [ 0.58936931 -0.9763201 ]. \t  -175.38050854003657 \t -7.804966561968033\n",
      "2      \t [2.048 2.048]. \t  -461.7603900415999 \t -7.804966561968033\n",
      "3      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -7.804966561968033\n",
      "4      \t [ 0.11070019 -0.06983258]. \t  \u001b[92m-1.4646835250193881\u001b[0m \t -1.4646835250193881\n",
      "5      \t [-0.26700469 -2.048     ]. \t  -450.7449488590215 \t -1.4646835250193881\n",
      "6      \t [2.048      0.42402685]. \t  -1422.5972850858432 \t -1.4646835250193881\n",
      "7      \t [-0.45851693  2.048     ]. \t  -339.8642720108833 \t -1.4646835250193881\n",
      "8      \t [0.83171808 2.048     ]. \t  -183.96837843773972 \t -1.4646835250193881\n",
      "9      \t [-2.048       0.93689599]. \t  -1070.3609988570463 \t -1.4646835250193881\n",
      "10     \t [-0.03237185 -0.87195883]. \t  -77.2798739071382 \t -1.4646835250193881\n",
      "11     \t [-0.61988812  0.21370591]. \t  -5.532951176706268 \t -1.4646835250193881\n",
      "12     \t [0.92259086 0.90053439]. \t  \u001b[92m-0.24963807841720215\u001b[0m \t -0.24963807841720215\n",
      "13     \t [ 0.89020614 -0.11350137]. \t  -82.08991850856603 \t -0.24963807841720215\n",
      "14     \t [-1.29695444  2.048     ]. \t  -18.6649529910887 \t -0.24963807841720215\n",
      "15     \t [-1.20964836 -2.048     ]. \t  -1237.7696160851067 \t -0.24963807841720215\n",
      "16     \t [-2.048  2.048]. \t  -469.9523900415999 \t -0.24963807841720215\n",
      "17     \t [-1.08026795  1.52836665]. \t  -17.38762971110724 \t -0.24963807841720215\n",
      "18     \t [0.50814012 0.57975882]. \t  -10.58152326905096 \t -0.24963807841720215\n",
      "19     \t [0.74183627 1.33344953]. \t  -61.3956704183847 \t -0.24963807841720215\n",
      "20     \t [ 0.54348938 -2.048     ]. \t  -549.3517171098395 \t -0.24963807841720215\n",
      "21     \t [1.40356616 1.54800176]. \t  -17.970946681761635 \t -0.24963807841720215\n",
      "22     \t [-0.52276432  0.69034291]. \t  -19.71274691444238 \t -0.24963807841720215\n",
      "23     \t [ 0.45749567 -0.32114091]. \t  -28.431310272588806 \t -0.24963807841720215\n",
      "24     \t [-0.35964671 -0.30329713]. \t  -20.566626098681706 \t -0.24963807841720215\n",
      "25     \t [1.40927059 2.048     ]. \t  -0.5513620454222281 \t -0.24963807841720215\n",
      "26     \t [ 2.048      -0.72655041]. \t  -2422.5791166274494 \t -0.24963807841720215\n",
      "27     \t [0.62950752 0.22559427]. \t  -3.0506168732497887 \t -0.24963807841720215\n",
      "28     \t [1.15612999 1.37107199]. \t  \u001b[92m-0.1429564849887838\u001b[0m \t -0.1429564849887838\n",
      "29     \t [-0.3078394   0.17979143]. \t  -2.4333916768834865 \t -0.1429564849887838\n",
      "30     \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -0.1429564849887838\n",
      "31     \t [-2.048      -0.05713809]. \t  -1816.7662845200093 \t -0.1429564849887838\n",
      "32     \t [1.30725617 1.79694944]. \t  -0.8693475911260596 \t -0.1429564849887838\n",
      "33     \t [-0.53569943 -1.49687931]. \t  -320.57159174921287 \t -0.1429564849887838\n",
      "34     \t [-1.31482202  1.72486062]. \t  -5.359919127798319 \t -0.1429564849887838\n",
      "35     \t [-1.21575418  1.39595493]. \t  -5.583661783007311 \t -0.1429564849887838\n",
      "36     \t [ 0.21090388 -1.55016627]. \t  -254.91248968022217 \t -0.1429564849887838\n",
      "37     \t [-1.50441531  2.048     ]. \t  -10.906016416114808 \t -0.1429564849887838\n",
      "38     \t [-0.93389852  0.97623857]. \t  -4.823064065233458 \t -0.1429564849887838\n",
      "39     \t [2.048     1.3357692]. \t  -818.2204248542537 \t -0.1429564849887838\n",
      "40     \t [-0.73682368  0.50795036]. \t  -3.1387680883846754 \t -0.1429564849887838\n",
      "41     \t [0.77588314 0.56291808]. \t  -0.20292617861468 \t -0.1429564849887838\n",
      "42     \t [ 1.21779831 -2.048     ]. \t  -1246.8666440394613 \t -0.1429564849887838\n",
      "43     \t [1.3167011  1.69139912]. \t  -0.27925113704939203 \t -0.1429564849887838\n",
      "44     \t [-1.24670902 -0.24687296]. \t  -329.4641204657676 \t -0.1429564849887838\n",
      "45     \t [ 1.4248473  -1.30292304]. \t  -1111.1446410761666 \t -0.1429564849887838\n",
      "46     \t [1.16095074 0.83016522]. \t  -26.8211662206416 \t -0.1429564849887838\n",
      "47     \t [1.11204677 1.19775807]. \t  -0.16379728525139806 \t -0.1429564849887838\n",
      "48     \t [1.48539377 2.048     ]. \t  -2.7444932924775896 \t -0.1429564849887838\n",
      "49     \t [0.26958272 0.1241228 ]. \t  -0.7981986750625147 \t -0.1429564849887838\n",
      "50     \t [1.29720714 1.67300919]. \t  \u001b[92m-0.09781334313705595\u001b[0m \t -0.09781334313705595\n",
      "51     \t [1.00526142 0.97121345]. \t  -0.15476825067314223 \t -0.09781334313705595\n",
      "52     \t [0.86562676 0.73996585]. \t  \u001b[92m-0.02678688805266308\u001b[0m \t -0.02678688805266308\n",
      "53     \t [1.39057075 1.91730631]. \t  -0.179378263000886 \t -0.02678688805266308\n",
      "54     \t [1.26496487 1.59185902]. \t  -0.07705742406739033 \t -0.02678688805266308\n",
      "55     \t [-1.33010631 -1.39958353]. \t  -1009.5373995570072 \t -0.02678688805266308\n",
      "56     \t [0.81435477 0.62940324]. \t  -0.14850856087589012 \t -0.02678688805266308\n",
      "57     \t [0.72823303 0.54059975]. \t  -0.08441773827746125 \t -0.02678688805266308\n",
      "58     \t [1.18065696 1.3772928 ]. \t  -0.06038602998171963 \t -0.02678688805266308\n",
      "59     \t [1.1360327  1.31304967]. \t  -0.06903706539100463 \t -0.02678688805266308\n",
      "60     \t [-0.01605842 -0.00746795]. \t  -1.0383435433262254 \t -0.02678688805266308\n",
      "61     \t [1.24307161 1.53366734]. \t  -0.07244644213372668 \t -0.02678688805266308\n",
      "62     \t [1.05001845 1.05473506]. \t  -0.23102108844750224 \t -0.02678688805266308\n",
      "63     \t [1.23776589 1.53467359]. \t  -0.05721340692286355 \t -0.02678688805266308\n",
      "64     \t [1.14748893 1.31253322]. \t  \u001b[92m-0.023514988732724743\u001b[0m \t -0.023514988732724743\n",
      "65     \t [1.05742782 1.100401  ]. \t  -0.03481339434106858 \t -0.023514988732724743\n",
      "66     \t [0.70309006 0.46699748]. \t  -0.16289294002613092 \t -0.023514988732724743\n",
      "67     \t [1.1540078  1.31369288]. \t  -0.056266630644469594 \t -0.023514988732724743\n",
      "68     \t [1.31131434 1.71204389]. \t  -0.10254371766316629 \t -0.023514988732724743\n",
      "69     \t [1.37232709 1.88616108]. \t  -0.13945657786174173 \t -0.023514988732724743\n",
      "70     \t [0.81828041 0.66941737]. \t  -0.03302474672838821 \t -0.023514988732724743\n",
      "71     \t [1.1437363  1.28689769]. \t  -0.06575281268083374 \t -0.023514988732724743\n",
      "72     \t [1.33928033 1.74994039]. \t  -0.3063548415577112 \t -0.023514988732724743\n",
      "73     \t [-0.24972466  0.057571  ]. \t  -1.5641074986938632 \t -0.023514988732724743\n",
      "74     \t [1.20610829 1.43518506]. \t  -0.0805529717349521 \t -0.023514988732724743\n",
      "75     \t [1.00111318 0.99347508]. \t  \u001b[92m-0.007661900710037588\u001b[0m \t -0.007661900710037588\n",
      "76     \t [1.154164   1.32015626]. \t  -0.038018763644907055 \t -0.007661900710037588\n",
      "77     \t [1.11748524 1.21863755]. \t  -0.10461890215128206 \t -0.007661900710037588\n",
      "78     \t [0.7935808  0.61916842]. \t  -0.05384927802313645 \t -0.007661900710037588\n",
      "79     \t [1.37602191 1.88483996]. \t  -0.14878220877245946 \t -0.007661900710037588\n",
      "80     \t [1.1718786  1.32468195]. \t  -0.26590843510699425 \t -0.007661900710037588\n",
      "81     \t [1.37244767 1.89975074]. \t  -0.16476121124310836 \t -0.007661900710037588\n",
      "82     \t [1.12385845 1.24659108]. \t  -0.042456214591016485 \t -0.007661900710037588\n",
      "83     \t [1.11919534 1.29241466]. \t  -0.17274243848472143 \t -0.007661900710037588\n",
      "84     \t [0.91004341 0.83731961]. \t  -0.016447241082252206 \t -0.007661900710037588\n",
      "85     \t [0.87741045 0.75108637]. \t  -0.05023216581506553 \t -0.007661900710037588\n",
      "86     \t [ 0.00405245 -0.02993245]. \t  -1.081605001502801 \t -0.007661900710037588\n",
      "87     \t [0.83647245 0.73109235]. \t  -0.12537614815847278 \t -0.007661900710037588\n",
      "88     \t [1.14397534 1.3175779 ]. \t  -0.028646925534280863 \t -0.007661900710037588\n",
      "89     \t [1.07534559 1.13465222]. \t  -0.05283503625523234 \t -0.007661900710037588\n",
      "90     \t [1.3857017 1.9405748]. \t  -0.1904047114602032 \t -0.007661900710037588\n",
      "91     \t [0.95636291 0.86166235]. \t  -0.2824615658212135 \t -0.007661900710037588\n",
      "92     \t [0.74542038 0.54728253]. \t  -0.07181482489564175 \t -0.007661900710037588\n",
      "93     \t [0.38759934 0.1678908 ]. \t  -0.40621346524570395 \t -0.007661900710037588\n",
      "94     \t [0.86077152 0.66646268]. \t  -0.5738871079586377 \t -0.007661900710037588\n",
      "95     \t [0.81754913 0.67516152]. \t  -0.0378783049648152 \t -0.007661900710037588\n",
      "96     \t [1.17120404 1.42285994]. \t  -0.29085142736820224 \t -0.007661900710037588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.68480174 0.45789867]. \t  -0.11157070130269588 \t -0.007661900710037588\n",
      "98     \t [0.8742192  0.78025045]. \t  -0.04139280906982396 \t -0.007661900710037588\n",
      "99     \t [ 0.11169198 -0.08455896]. \t  -1.730651967569892 \t -0.007661900710037588\n",
      "100    \t [1.01918154 1.02168711]. \t  -0.029417386622712312 \t -0.007661900710037588\n"
     ]
    }
   ],
   "source": [
    "### 6(k). Bayesian optimization runs (x20): STP DF1 run number = 11\n",
    "\n",
    "np.random.seed(run_num_11)\n",
    "surrogate_stp_df1_11 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_11 = GPGO(surrogate_stp_df1_11, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_11.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.03406035707834, -4.871495191540244)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(k). Training Regret Minimisation: run number = 11\n",
    "\n",
    "gp_output_11 = np.append(np.max(gpgo_gp_11.GP.y[0:n_init]),gpgo_gp_11.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_11 = np.append(np.max(gpgo_stp_df1_11.GP.y[0:n_init]),gpgo_stp_df1_11.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_11 = np.log(y_global_orig - gp_output_11)\n",
    "regret_stp_df1_11 = np.log(y_global_orig - stp_df1_output_11)\n",
    "\n",
    "train_regret_gp_11 = min_max_array(regret_gp_11)\n",
    "train_regret_stp_df1_11 = min_max_array(regret_stp_df1_11)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 11\n",
    "min_train_regret_gp_11 = min(train_regret_gp_11)\n",
    "min_train_regret_stp_df1_11 = min(train_regret_stp_df1_11)\n",
    "\n",
    "min_train_regret_gp_11, min_train_regret_stp_df1_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.7715803 -0.6760735]. \t  -1462.7762688008106 \t -15.169214528755909\n",
      "init   \t [-0.53905717 -0.06719548]. \t  -15.169214528755909 \t -15.169214528755909\n",
      "init   \t [-0.148223   -1.89284293]. \t  -367.9692927379269 \t -15.169214528755909\n",
      "init   \t [-1.77910071 -1.69247663]. \t  -2367.4249879838953 \t -15.169214528755909\n",
      "init   \t [ 1.86658778 -1.32804541]. \t  -2316.4733881526763 \t -15.169214528755909\n",
      "1      \t [-0.30890784  0.63383301]. \t  -30.701659525510834 \t -15.169214528755909\n",
      "2      \t [-0.27680778  0.07878349]. \t  \u001b[92m-1.6307050811293318\u001b[0m \t -1.6307050811293318\n",
      "3      \t [-0.63030485  0.37848519]. \t  -2.6932342273860703 \t -1.6307050811293318\n",
      "4      \t [-0.44276724  0.1553155 ]. \t  -2.2474487802313865 \t -1.6307050811293318\n",
      "5      \t [-1.22868127  1.53746065]. \t  -5.044320761271964 \t -1.6307050811293318\n",
      "6      \t [-1.03971098  1.01375569]. \t  -4.612586251663874 \t -1.6307050811293318\n",
      "7      \t [-0.32804073  2.048     ]. \t  -378.2747470768518 \t -1.6307050811293318\n",
      "8      \t [-2.048  2.048]. \t  -469.9523900415999 \t -1.6307050811293318\n",
      "9      \t [-1.03586049  1.45764504]. \t  -18.93937304539411 \t -1.6307050811293318\n",
      "10     \t [0.91661302 0.92308795]. \t  \u001b[92m-0.6943356034027871\u001b[0m \t -0.6943356034027871\n",
      "11     \t [1.1206796  1.24205987]. \t  \u001b[92m-0.03378158540410756\u001b[0m \t -0.03378158540410756\n",
      "12     \t [2.048      1.77580186]. \t  -586.0135653796962 \t -0.03378158540410756\n",
      "13     \t [0.81507503 1.1859939 ]. \t  -27.245713605943187 \t -0.03378158540410756\n",
      "14     \t [-0.13097475 -0.60803001]. \t  -40.36465628306977 \t -0.03378158540410756\n",
      "15     \t [1.85218188 0.52122347]. \t  -847.1604376225006 \t -0.03378158540410756\n",
      "16     \t [-0.37040642 -0.09826048]. \t  -7.422220694261904 \t -0.03378158540410756\n",
      "17     \t [1.0011733  1.09989742]. \t  -0.9515908426548506 \t -0.03378158540410756\n",
      "18     \t [0.45070623 0.50297764]. \t  -9.292218371705609 \t -0.03378158540410756\n",
      "19     \t [1.20675024 2.048     ]. \t  -35.06000904967684 \t -0.03378158540410756\n",
      "20     \t [-1.47563182  0.26661576]. \t  -371.2725133501059 \t -0.03378158540410756\n",
      "21     \t [1.13565199 1.579036  ]. \t  -8.389618409136478 \t -0.03378158540410756\n",
      "22     \t [-0.58488151  1.56015087]. \t  -150.87995857047935 \t -0.03378158540410756\n",
      "23     \t [-1.22787838  1.345448  ]. \t  -7.595536453297777 \t -0.03378158540410756\n",
      "24     \t [-1.11939495 -1.64418247]. \t  -843.8845645127006 \t -0.03378158540410756\n",
      "25     \t [-1.93983494  1.35023555]. \t  -590.7663648872098 \t -0.03378158540410756\n",
      "26     \t [0.02325034 1.70280387]. \t  -290.72407156506216 \t -0.03378158540410756\n",
      "27     \t [0.57999421 0.50013356]. \t  -2.85749244019362 \t -0.03378158540410756\n",
      "28     \t [ 0.84380056 -1.20784025]. \t  -368.60281875307027 \t -0.03378158540410756\n",
      "29     \t [ 0.32777924 -0.1990316 ]. \t  -9.844317655997887 \t -0.03378158540410756\n",
      "30     \t [-1.60999621  0.8765869 ]. \t  -301.1064157020683 \t -0.03378158540410756\n",
      "31     \t [0.54799247 2.00584868]. \t  -291.09539128168115 \t -0.03378158540410756\n",
      "32     \t [-0.99426681  1.40285918]. \t  -21.140942932041007 \t -0.03378158540410756\n",
      "33     \t [0.86690836 0.84576145]. \t  -0.9056681577449148 \t -0.03378158540410756\n",
      "34     \t [1.39260219 0.09746176]. \t  -339.40599778196906 \t -0.03378158540410756\n",
      "35     \t [0.64772986 0.35755597]. \t  -0.508469588076434 \t -0.03378158540410756\n",
      "36     \t [ 0.48852525 -0.38401236]. \t  -39.0333095429431 \t -0.03378158540410756\n",
      "37     \t [-0.54334912  0.33749923]. \t  -2.5606099486204004 \t -0.03378158540410756\n",
      "38     \t [ 1.54108737 -0.65365128]. \t  -917.535525211517 \t -0.03378158540410756\n",
      "39     \t [1.73935368 0.64715055]. \t  -566.1304949861255 \t -0.03378158540410756\n",
      "40     \t [0.23082674 0.06056912]. \t  -0.5969391868339943 \t -0.03378158540410756\n",
      "41     \t [0.93973442 0.83030652]. \t  -0.2823553413601574 \t -0.03378158540410756\n",
      "42     \t [2.03321067 0.07891062]. \t  -1645.3984017570983 \t -0.03378158540410756\n",
      "43     \t [1.60636384 1.41777072]. \t  -135.53947348947753 \t -0.03378158540410756\n",
      "44     \t [1.12625145 1.20475869]. \t  -0.42149989736182064 \t -0.03378158540410756\n",
      "45     \t [ 0.50139066 -0.6345547 ]. \t  -78.73887291292435 \t -0.03378158540410756\n",
      "46     \t [-0.40913352 -0.68747682]. \t  -75.06542607379731 \t -0.03378158540410756\n",
      "47     \t [0.795907   0.61732798]. \t  -0.06770382296875109 \t -0.03378158540410756\n",
      "48     \t [1.83332707 1.8932937 ]. \t  -216.13649006742253 \t -0.03378158540410756\n",
      "49     \t [-0.80097342 -1.55635068]. \t  -486.32394889539603 \t -0.03378158540410756\n",
      "50     \t [1.42592468 1.98980139]. \t  -0.3702871929070631 \t -0.03378158540410756\n",
      "51     \t [-0.9200971  -0.15763342]. \t  -104.5309673781609 \t -0.03378158540410756\n",
      "52     \t [-0.15929574  1.05257369]. \t  -106.8576543974204 \t -0.03378158540410756\n",
      "53     \t [0.400992   0.12580887]. \t  -0.48121062094058625 \t -0.03378158540410756\n",
      "54     \t [0.11572207 1.63951437]. \t  -265.2094742158048 \t -0.03378158540410756\n",
      "55     \t [1.21916604 1.11583787]. \t  -13.777130795213644 \t -0.03378158540410756\n",
      "56     \t [0.93506648 1.64890941]. \t  -59.99854861314872 \t -0.03378158540410756\n",
      "57     \t [1.00314083 1.88286122]. \t  -76.83745336355284 \t -0.03378158540410756\n",
      "58     \t [-1.89982321 -0.46902648]. \t  -1671.7066741667015 \t -0.03378158540410756\n",
      "59     \t [-1.54326142 -1.70918371]. \t  -1679.9649820807017 \t -0.03378158540410756\n",
      "60     \t [-1.74825605  1.19909187]. \t  -352.51196470884867 \t -0.03378158540410756\n",
      "61     \t [1.43637694 2.048     ]. \t  -0.21346415116331924 \t -0.03378158540410756\n",
      "62     \t [-1.7540292  -0.68109795]. \t  -1419.627913183113 \t -0.03378158540410756\n",
      "63     \t [1.31538183 1.7202902 ]. \t  -0.1093444006330142 \t -0.03378158540410756\n",
      "64     \t [1.82544543 0.23020752]. \t  -962.9487434281237 \t -0.03378158540410756\n",
      "65     \t [1.26070827 1.57201424]. \t  -0.09814435331376498 \t -0.03378158540410756\n",
      "66     \t [-0.33903358  1.18021526]. \t  -115.27334603609714 \t -0.03378158540410756\n",
      "67     \t [-0.99046666 -0.22387404]. \t  -149.13993602271097 \t -0.03378158540410756\n",
      "68     \t [0.88936778 1.55671422]. \t  -58.647888788476045 \t -0.03378158540410756\n",
      "69     \t [-1.31160348  2.01321988]. \t  -13.923500698257207 \t -0.03378158540410756\n",
      "70     \t [ 1.69168399 -1.54098336]. \t  -1938.92390275805 \t -0.03378158540410756\n",
      "71     \t [ 0.22221743 -1.16745051]. \t  -148.67273683512812 \t -0.03378158540410756\n",
      "72     \t [1.27468836 1.60631809]. \t  -0.10972434829752101 \t -0.03378158540410756\n",
      "73     \t [1.27259528 1.60141378]. \t  -0.10701482471586321 \t -0.03378158540410756\n",
      "74     \t [-0.13692349 -0.30269382]. \t  -11.625082003954505 \t -0.03378158540410756\n",
      "75     \t [1.2090069  0.24986272]. \t  -146.8980844262273 \t -0.03378158540410756\n",
      "76     \t [ 1.07353966 -0.30767424]. \t  -213.2126084445324 \t -0.03378158540410756\n",
      "77     \t [-1.97650887 -0.12716408]. \t  -1635.9746356185497 \t -0.03378158540410756\n",
      "78     \t [0.83442213 0.69851596]. \t  \u001b[92m-0.02792483739546861\u001b[0m \t -0.02792483739546861\n",
      "79     \t [-0.66858574 -1.02581251]. \t  -219.70387533207486 \t -0.02792483739546861\n",
      "80     \t [ 0.99850593 -1.8123555 ]. \t  -789.2557497564856 \t -0.02792483739546861\n",
      "81     \t [-1.33676801 -1.92192237]. \t  -1381.0329605580614 \t -0.02792483739546861\n",
      "82     \t [-1.92356498 -0.99957446]. \t  -2217.24334203531 \t -0.02792483739546861\n",
      "83     \t [-1.21050838  0.01793053]. \t  -214.3830221426361 \t -0.02792483739546861\n",
      "84     \t [ 1.4372923  -1.97180851]. \t  -1630.4268770041074 \t -0.02792483739546861\n",
      "85     \t [1.35655043 1.00192918]. \t  -70.40179681775035 \t -0.02792483739546861\n",
      "86     \t [ 0.43521006 -1.46970591]. \t  -275.58481728590897 \t -0.02792483739546861\n",
      "87     \t [0.66000979 0.8407562 ]. \t  -16.529700688769406 \t -0.02792483739546861\n",
      "88     \t [-2.03396351 -1.28111603]. \t  -2944.811272952865 \t -0.02792483739546861\n",
      "89     \t [0.84416446 0.71382681]. \t  \u001b[92m-0.024431893366276502\u001b[0m \t -0.024431893366276502\n",
      "90     \t [1.01796419 1.79335831]. \t  -57.3214564415182 \t -0.024431893366276502\n",
      "91     \t [1.96990779 0.78749192]. \t  -957.6333290628664 \t -0.024431893366276502\n",
      "92     \t [-0.82466838 -0.76894662]. \t  -213.296629246476 \t -0.024431893366276502\n",
      "93     \t [0.67424682 1.88340635]. \t  -204.25236610537053 \t -0.024431893366276502\n",
      "94     \t [0.35444366 0.83182147]. \t  -50.28733834769944 \t -0.024431893366276502\n",
      "95     \t [-0.31244831 -1.90604388]. \t  -403.19099530272445 \t -0.024431893366276502\n",
      "96     \t [0.8428569  0.71393653]. \t  -0.02593918165587603 \t -0.024431893366276502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [ 0.80657467 -1.36985356]. \t  -408.24559643630806 \t -0.024431893366276502\n",
      "98     \t [1.28572897 1.64183901]. \t  -0.09431971845216769 \t -0.024431893366276502\n",
      "99     \t [ 1.65827006 -1.77029802]. \t  -2043.615792905497 \t -0.024431893366276502\n",
      "100    \t [ 1.31874439 -0.91789264]. \t  -706.0555525638417 \t -0.024431893366276502\n"
     ]
    }
   ],
   "source": [
    "### 6(l). Bayesian optimization runs (x20): GP run number = 12\n",
    "\n",
    "np.random.seed(run_num_12)\n",
    "surrogate_gp_12 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_12 = GPGO(surrogate_gp_12, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_12.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.7715803 -0.6760735]. \t  -1462.7762688008106 \t -15.169214528755909\n",
      "init   \t [-0.53905717 -0.06719548]. \t  -15.169214528755909 \t -15.169214528755909\n",
      "init   \t [-0.148223   -1.89284293]. \t  -367.9692927379269 \t -15.169214528755909\n",
      "init   \t [-1.77910071 -1.69247663]. \t  -2367.4249879838953 \t -15.169214528755909\n",
      "init   \t [ 1.86658778 -1.32804541]. \t  -2316.4733881526763 \t -15.169214528755909\n",
      "1      \t [-0.30443552  1.73307088]. \t  -270.7894521521318 \t -15.169214528755909\n",
      "2      \t [2.048 2.048]. \t  -461.7603900415999 \t -15.169214528755909\n",
      "3      \t [-2.048  2.048]. \t  -469.9523900415999 \t -15.169214528755909\n",
      "4      \t [0.62850881 0.62277928]. \t  \u001b[92m-5.325283113550827\u001b[0m \t -5.325283113550827\n",
      "5      \t [-2.048       0.75005526]. \t  -1195.5752419123455 \t -5.325283113550827\n",
      "6      \t [ 0.13953098 -0.44280824]. \t  -22.110421767803206 \t -5.325283113550827\n",
      "7      \t [2.048      0.72246824]. \t  -1206.4626555370287 \t -5.325283113550827\n",
      "8      \t [0.76066826 2.048     ]. \t  -215.9661539681495 \t -5.325283113550827\n",
      "9      \t [0.00635019 0.40473645]. \t  -17.365235573615745 \t -5.325283113550827\n",
      "10     \t [0.53706642 1.23007752]. \t  -88.88236641852372 \t -5.325283113550827\n",
      "11     \t [-0.33362223 -0.60454593]. \t  -53.022630603715655 \t -5.325283113550827\n",
      "12     \t [ 0.6141588 -2.048    ]. \t  -588.3040277533491 \t -5.325283113550827\n",
      "13     \t [-1.11451285  2.048     ]. \t  -69.41237766205752 \t -5.325283113550827\n",
      "14     \t [-0.09649818 -0.13069137]. \t  \u001b[92m-3.1623997017158505\u001b[0m \t -3.1623997017158505\n",
      "15     \t [-0.91760505  1.09397493]. \t  -10.026394987507517 \t -3.1623997017158505\n",
      "16     \t [-0.67893156  0.61233042]. \t  -5.110473133951475 \t -3.1623997017158505\n",
      "17     \t [1.27683855 1.55825335]. \t  \u001b[92m-0.5959519226556337\u001b[0m \t -0.5959519226556337\n",
      "18     \t [1.3399653 2.048    ]. \t  -6.490847172031452 \t -0.5959519226556337\n",
      "19     \t [ 0.15516224 -1.22002864]. \t  -155.49321797199838 \t -0.5959519226556337\n",
      "20     \t [-0.70371602  1.19944264]. \t  -52.49613097687713 \t -0.5959519226556337\n",
      "21     \t [1.21112623 1.74772431]. \t  -7.934917853106483 \t -0.5959519226556337\n",
      "22     \t [0.96404187 1.14581849]. \t  -4.685996987960417 \t -0.5959519226556337\n",
      "23     \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -0.5959519226556337\n",
      "24     \t [ 1.16181798 -0.31022926]. \t  -275.60287566557275 \t -0.5959519226556337\n",
      "25     \t [-1.30636503  1.64186318]. \t  -5.738270426219311 \t -0.5959519226556337\n",
      "26     \t [ 2.048      -0.37426341]. \t  -2088.279122514874 \t -0.5959519226556337\n",
      "27     \t [ 0.57090425 -0.11064693]. \t  -19.244209874191963 \t -0.5959519226556337\n",
      "28     \t [ 0.77211909 -0.84109295]. \t  -206.6238009000626 \t -0.5959519226556337\n",
      "29     \t [-1.11353741  1.56772025]. \t  -15.209354342177765 \t -0.5959519226556337\n",
      "30     \t [-1.46482502  2.048     ]. \t  -7.030132380386467 \t -0.5959519226556337\n",
      "31     \t [1.00578329 0.60644918]. \t  -16.414754032354306 \t -0.5959519226556337\n",
      "32     \t [-1.20478696  0.32897313]. \t  -130.87034984017734 \t -0.5959519226556337\n",
      "33     \t [-0.96338087 -2.048     ]. \t  -889.5735878869705 \t -0.5959519226556337\n",
      "34     \t [0.707505   0.37090031]. \t  -1.7668029939335523 \t -0.5959519226556337\n",
      "35     \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -0.5959519226556337\n",
      "36     \t [-0.82695686 -1.28326717]. \t  -390.29577502694326 \t -0.5959519226556337\n",
      "37     \t [-0.98120673  0.77573064]. \t  -7.423427030280289 \t -0.5959519226556337\n",
      "38     \t [1.14431425 1.26340687]. \t  \u001b[92m-0.2328705312583904\u001b[0m \t -0.2328705312583904\n",
      "39     \t [0.92345301 0.8057856 ]. \t  \u001b[92m-0.22657020105498785\u001b[0m \t -0.22657020105498785\n",
      "40     \t [-1.34711516  1.87075341]. \t  -5.822932285913451 \t -0.22657020105498785\n",
      "41     \t [ 1.25275399 -2.048     ]. \t  -1308.616769556072 \t -0.22657020105498785\n",
      "42     \t [-0.45547007  0.23927506]. \t  -2.2196575654498703 \t -0.22657020105498785\n",
      "43     \t [-0.72294322  0.35643269]. \t  -5.731249656793217 \t -0.22657020105498785\n",
      "44     \t [2.048      1.49247528]. \t  -731.0861498077375 \t -0.22657020105498785\n",
      "45     \t [-2.048      -0.07055986]. \t  -1828.196679395021 \t -0.22657020105498785\n",
      "46     \t [1.18901084 1.4258943 ]. \t  \u001b[92m-0.05048133542657628\u001b[0m \t -0.05048133542657628\n",
      "47     \t [0.84211412 0.70380056]. \t  \u001b[92m-0.02779623545334168\u001b[0m \t -0.02779623545334168\n",
      "48     \t [1.34911087 1.81227066]. \t  -0.1280084562270077 \t -0.02779623545334168\n",
      "49     \t [1.46891658 2.048     ]. \t  -1.4236407920319085 \t -0.02779623545334168\n",
      "50     \t [0.87775534 0.75869231]. \t  -0.028778539021668954 \t -0.02779623545334168\n",
      "51     \t [ 0.82459762 -1.57773818]. \t  -509.75143114907775 \t -0.02779623545334168\n",
      "52     \t [1.16794981 1.36900895]. \t  -0.03061028202718121 \t -0.02779623545334168\n",
      "53     \t [1.04866616 1.10744064]. \t  \u001b[92m-0.008359041161911152\u001b[0m \t -0.008359041161911152\n",
      "54     \t [0.85267156 0.69124913]. \t  -0.14986721338729783 \t -0.008359041161911152\n",
      "55     \t [1.4138405  2.04596332]. \t  -0.39233667640573955 \t -0.008359041161911152\n",
      "56     \t [1.25047373 1.59126546]. \t  -0.13880771416010795 \t -0.008359041161911152\n",
      "57     \t [0.8477863  0.70958275]. \t  -0.0315575038555408 \t -0.008359041161911152\n",
      "58     \t [1.37641792 1.89824422]. \t  -0.14307275529405897 \t -0.008359041161911152\n",
      "59     \t [0.82246368 0.66934891]. \t  -0.036556734015067156 \t -0.008359041161911152\n",
      "60     \t [1.42690102 2.04426057]. \t  -0.1889915481583286 \t -0.008359041161911152\n",
      "61     \t [1.26747275 1.62379767]. \t  -0.10150702164270821 \t -0.008359041161911152\n",
      "62     \t [-0.44964669 -1.55491528]. \t  -310.84061294542494 \t -0.008359041161911152\n",
      "63     \t [1.24166073 1.55702142]. \t  -0.08180903292129063 \t -0.008359041161911152\n",
      "64     \t [0.82159804 0.63999418]. \t  -0.15453146112135763 \t -0.008359041161911152\n",
      "65     \t [1.22914966 1.52826412]. \t  -0.08297811136897422 \t -0.008359041161911152\n",
      "66     \t [1.08149951 1.16120578]. \t  -0.013757791610910201 \t -0.008359041161911152\n",
      "67     \t [1.37543163 1.89833776]. \t  -0.14520725797270018 \t -0.008359041161911152\n",
      "68     \t [0.70429931 0.47328988]. \t  -0.1391844153094758 \t -0.008359041161911152\n",
      "69     \t [1.04673343 1.10895946]. \t  -0.01989587963152048 \t -0.008359041161911152\n",
      "70     \t [0.92965627 0.89152725]. \t  -0.07929421970038088 \t -0.008359041161911152\n",
      "71     \t [-1.19157314  1.35764773]. \t  -5.189862067534147 \t -0.008359041161911152\n",
      "72     \t [1.20473792 1.43778994]. \t  -0.06042314118506878 \t -0.008359041161911152\n",
      "73     \t [1.05797152 1.12229052]. \t  \u001b[92m-0.004252782455249789\u001b[0m \t -0.004252782455249789\n",
      "74     \t [0.82860639 0.6776057 ]. \t  -0.03744492700592813 \t -0.004252782455249789\n",
      "75     \t [0.9436381  0.94124406]. \t  -0.2611511712099666 \t -0.004252782455249789\n",
      "76     \t [0.8563502  0.72045143]. \t  -0.03723564491500554 \t -0.004252782455249789\n",
      "77     \t [1.37890928 1.92170338]. \t  -0.18483228159883708 \t -0.004252782455249789\n",
      "78     \t [0.82817786 0.66283654]. \t  -0.08261631918162679 \t -0.004252782455249789\n",
      "79     \t [1.0749663  1.12038132]. \t  -0.12932152291338758 \t -0.004252782455249789\n",
      "80     \t [1.06040933 1.20043123]. \t  -0.5806912130407343 \t -0.004252782455249789\n",
      "81     \t [1.06837725 1.12075877]. \t  -0.047405184413371736 \t -0.004252782455249789\n",
      "82     \t [0.82279781 0.66880069]. \t  -0.03811730526972061 \t -0.004252782455249789\n",
      "83     \t [1.37080693 1.84711822]. \t  -0.23985568738740032 \t -0.004252782455249789\n",
      "84     \t [1.2341279  1.54740506]. \t  -0.11402724629280064 \t -0.004252782455249789\n",
      "85     \t [0.87964658 0.75832624]. \t  -0.038360976255176184 \t -0.004252782455249789\n",
      "86     \t [1.41764035 2.0415427 ]. \t  -0.2757927602741216 \t -0.004252782455249789\n",
      "87     \t [1.19876753 1.46458916]. \t  -0.11538441068736599 \t -0.004252782455249789\n",
      "88     \t [0.81590876 0.6577886 ]. \t  -0.040159871400742383 \t -0.004252782455249789\n",
      "89     \t [1.35165953 1.84801842]. \t  -0.16791129457301096 \t -0.004252782455249789\n",
      "90     \t [0.94346448 0.89351677]. \t  -0.004346514299317407 \t -0.004252782455249789\n",
      "91     \t [1.09955903 1.232365  ]. \t  -0.06436399437434205 \t -0.004252782455249789\n",
      "92     \t [0.82001828 0.62558986]. \t  -0.25179311695168843 \t -0.004252782455249789\n",
      "93     \t [1.3269822  1.78964695]. \t  -0.18966096350874923 \t -0.004252782455249789\n",
      "94     \t [0.96630733 0.96519465]. \t  -0.10001276703875504 \t -0.004252782455249789\n",
      "95     \t [0.83371129 0.64796728]. \t  -0.24956100729133948 \t -0.004252782455249789\n",
      "96     \t [0.89072532 0.79623022]. \t  -0.012746736272316555 \t -0.004252782455249789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.78480076 0.61133127]. \t  -0.048409234952770795 \t -0.004252782455249789\n",
      "98     \t [0.84223318 0.68383523]. \t  -0.09002504170790093 \t -0.004252782455249789\n",
      "99     \t [0.41373676 0.17681553]. \t  -0.34688263074226633 \t -0.004252782455249789\n",
      "100    \t [0.65277896 0.42428584]. \t  -0.12089900013409988 \t -0.004252782455249789\n"
     ]
    }
   ],
   "source": [
    "### 6(l). Bayesian optimization runs (x20): STP DF1 run number = 12\n",
    "\n",
    "np.random.seed(run_num_12)\n",
    "surrogate_stp_df1_12 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_12 = GPGO(surrogate_stp_df1_12, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_12.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.711865895026006, -5.460181814912429)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(l). Training Regret Minimisation: run number = 12\n",
    "\n",
    "gp_output_12 = np.append(np.max(gpgo_gp_12.GP.y[0:n_init]),gpgo_gp_12.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_12 = np.append(np.max(gpgo_stp_df1_12.GP.y[0:n_init]),gpgo_stp_df1_12.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_12 = np.log(y_global_orig - gp_output_12)\n",
    "regret_stp_df1_12 = np.log(y_global_orig - stp_df1_output_12)\n",
    "\n",
    "train_regret_gp_12 = min_max_array(regret_gp_12)\n",
    "train_regret_stp_df1_12 = min_max_array(regret_stp_df1_12)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 12\n",
    "min_train_regret_gp_12 = min(train_regret_gp_12)\n",
    "min_train_regret_stp_df1_12 = min(train_regret_stp_df1_12)\n",
    "\n",
    "min_train_regret_gp_12, min_train_regret_stp_df1_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-0.8208981  -1.99651393]. \t  -716.4126721879244 \t -107.6541410279816\n",
      "init   \t [-0.46382593  1.2423217 ]. \t  -107.6541410279816 \t -107.6541410279816\n",
      "init   \t [0.3268096  1.28959969]. \t  -140.3536270807936 \t -107.6541410279816\n",
      "init   \t [1.78518834 0.36608001]. \t  -796.3176016434189 \t -107.6541410279816\n",
      "init   \t [1.74530189 0.58981651]. \t  -603.8778674329584 \t -107.6541410279816\n",
      "1      \t [1.93057357 1.97309436]. \t  -308.52456683342075 \t -107.6541410279816\n",
      "2      \t [-2.01464432  0.8987222 ]. \t  -1007.6920352914161 \t -107.6541410279816\n",
      "3      \t [ 1.58875759 -0.185879  ]. \t  -734.7727184307275 \t -107.6541410279816\n",
      "4      \t [ 1.41925154 -1.78205732]. \t  -1441.3896342630328 \t -107.6541410279816\n",
      "5      \t [0.3530401  0.08550828]. \t  \u001b[92m-0.5716652227759614\u001b[0m \t -0.5716652227759614\n",
      "6      \t [0.41483347 0.41182012]. \t  -6.089626228682619 \t -0.5716652227759614\n",
      "7      \t [1.32250756 1.71086465]. \t  \u001b[92m-0.24964190349217585\u001b[0m \t -0.24964190349217585\n",
      "8      \t [1.2027476  1.35513828]. \t  -0.8776638466356955 \t -0.24964190349217585\n",
      "9      \t [0.41055787 0.20340211]. \t  -0.4688548626516984 \t -0.24964190349217585\n",
      "10     \t [-0.0010779   0.32962813]. \t  -11.867550901641994 \t -0.24964190349217585\n",
      "11     \t [-0.19004171 -0.43482272]. \t  -23.594513491440765 \t -0.24964190349217585\n",
      "12     \t [1.24313986 1.57194744]. \t  \u001b[92m-0.129611095856332\u001b[0m \t -0.129611095856332\n",
      "13     \t [-0.13863256 -0.08103837]. \t  -2.30163779475921 \t -0.129611095856332\n",
      "14     \t [1.65448345 1.59071459]. \t  -131.89770661198486 \t -0.129611095856332\n",
      "15     \t [ 1.32527398 -0.32276531]. \t  -432.3783113240334 \t -0.129611095856332\n",
      "16     \t [1.20617554 2.048     ]. \t  -35.224080903963596 \t -0.129611095856332\n",
      "17     \t [0.60579066 0.48756085]. \t  -1.6093192551795765 \t -0.129611095856332\n",
      "18     \t [1.86031838 1.59712175]. \t  -348.06402542646725 \t -0.129611095856332\n",
      "19     \t [-0.72444471  1.07667263]. \t  -33.427826441122896 \t -0.129611095856332\n",
      "20     \t [-0.78768998  0.26307911]. \t  -15.967624165337757 \t -0.129611095856332\n",
      "21     \t [-0.28596039  1.06425799]. \t  -98.18130223084289 \t -0.129611095856332\n",
      "22     \t [-0.56544978  0.38877823]. \t  -2.927351084889641 \t -0.129611095856332\n",
      "23     \t [0.56671352 0.26987483]. \t  -0.45079724137459143 \t -0.129611095856332\n",
      "24     \t [1.28320557 1.58791831]. \t  -0.42475355178673513 \t -0.129611095856332\n",
      "25     \t [ 0.21001334 -0.90908527]. \t  -91.48136207499327 \t -0.129611095856332\n",
      "26     \t [ 0.07680608 -2.03883674]. \t  -418.9467812796095 \t -0.129611095856332\n",
      "27     \t [-1.62113051  1.25951145]. \t  -194.16396698307742 \t -0.129611095856332\n",
      "28     \t [-1.61100934  2.048     ]. \t  -36.7766914257178 \t -0.129611095856332\n",
      "29     \t [-1.31939561  1.60039934]. \t  -7.350964879007824 \t -0.129611095856332\n",
      "30     \t [-0.47119457  0.08491809]. \t  -4.04422533299079 \t -0.129611095856332\n",
      "31     \t [ 2.0336462 -1.6552067]. \t  -3354.5479864002623 \t -0.129611095856332\n",
      "32     \t [0.8756905  0.64958438]. \t  -1.390196779795226 \t -0.129611095856332\n",
      "33     \t [ 0.60093681 -1.75639189]. \t  -448.54704996694505 \t -0.129611095856332\n",
      "34     \t [0.50642858 1.05056316]. \t  -63.302021670949365 \t -0.129611095856332\n",
      "35     \t [-1.99308299  2.048     ]. \t  -379.28231276329836 \t -0.129611095856332\n",
      "36     \t [-1.25063365  2.048     ]. \t  -28.482769795655976 \t -0.129611095856332\n",
      "37     \t [-1.12390397  1.2164048 ]. \t  -4.729574213663719 \t -0.129611095856332\n",
      "38     \t [ 0.12000026 -0.00789096]. \t  -0.8240885240524046 \t -0.129611095856332\n",
      "39     \t [0.68079089 1.95951813]. \t  -223.91602753217694 \t -0.129611095856332\n",
      "40     \t [ 0.26938388 -1.36894291]. \t  -208.3290760642387 \t -0.129611095856332\n",
      "41     \t [0.20134829 2.03631301]. \t  -398.94838266605785 \t -0.129611095856332\n",
      "42     \t [-1.01201391 -1.18021123]. \t  -489.97881328433306 \t -0.129611095856332\n",
      "43     \t [ 1.65235002 -0.83161989]. \t  -1269.1248132456026 \t -0.129611095856332\n",
      "44     \t [-1.89143761  1.26090272]. \t  -545.0394859312903 \t -0.129611095856332\n",
      "45     \t [0.97691478 0.93878799]. \t  \u001b[92m-0.02478940156075643\u001b[0m \t -0.02478940156075643\n",
      "46     \t [ 0.89215809 -1.49706796]. \t  -525.8029607622615 \t -0.02478940156075643\n",
      "47     \t [0.1622317  1.50521979]. \t  -219.41657376410578 \t -0.02478940156075643\n",
      "48     \t [0.91699555 0.83734741]. \t  \u001b[92m-0.008138249959218939\u001b[0m \t -0.008138249959218939\n",
      "49     \t [ 0.83839449 -0.50096953]. \t  -144.95757999313173 \t -0.008138249959218939\n",
      "50     \t [-0.00736619  1.57566971]. \t  -249.2711917221177 \t -0.008138249959218939\n",
      "51     \t [-1.45845145  0.16881552]. \t  -389.52421401585957 \t -0.008138249959218939\n",
      "52     \t [-0.67414484 -0.65269028]. \t  -125.38343070259172 \t -0.008138249959218939\n",
      "53     \t [ 1.89680568 -1.12988072]. \t  -2235.9686451940115 \t -0.008138249959218939\n",
      "54     \t [0.21727156 1.13365056]. \t  -118.64863989858512 \t -0.008138249959218939\n",
      "55     \t [0.55786537 1.74811843]. \t  -206.66498433556234 \t -0.008138249959218939\n",
      "56     \t [-0.25101218 -0.88322821]. \t  -91.10115925033104 \t -0.008138249959218939\n",
      "57     \t [1.36523357 1.86935675]. \t  -0.1364140026619194 \t -0.008138249959218939\n",
      "58     \t [1.86617695 0.91804572]. \t  -658.4525373999514 \t -0.008138249959218939\n",
      "59     \t [ 1.38083895 -1.13000726]. \t  -922.3139875385981 \t -0.008138249959218939\n",
      "60     \t [-0.88538224 -1.42468646]. \t  -491.3408338709173 \t -0.008138249959218939\n",
      "61     \t [-1.58526417 -0.86935862]. \t  -1150.7608483433687 \t -0.008138249959218939\n",
      "62     \t [-1.87428893  0.39267539]. \t  -981.8785080666945 \t -0.008138249959218939\n",
      "63     \t [ 0.2924306  -1.03838348]. \t  -126.8155813612845 \t -0.008138249959218939\n",
      "64     \t [0.07645749 0.39673813]. \t  -16.132616515891186 \t -0.008138249959218939\n",
      "65     \t [ 0.00060979 -0.01040851]. \t  -1.0096152833284298 \t -0.008138249959218939\n",
      "66     \t [-2.01083461 -0.17067982]. \t  -1784.9590430501473 \t -0.008138249959218939\n",
      "67     \t [-1.95615494 -0.1351866 ]. \t  -1578.2683201749462 \t -0.008138249959218939\n",
      "68     \t [1.8340878  1.83600742]. \t  -234.1345757354884 \t -0.008138249959218939\n",
      "69     \t [1.02014954 1.00259853]. \t  -0.14561692212931496 \t -0.008138249959218939\n",
      "70     \t [-0.95764658 -0.42431531]. \t  -183.76838930976595 \t -0.008138249959218939\n",
      "71     \t [-0.04604618  1.31955674]. \t  -174.6581018901523 \t -0.008138249959218939\n",
      "72     \t [-1.03673798  0.79785833]. \t  -11.81939083100503 \t -0.008138249959218939\n",
      "73     \t [ 0.41827585 -0.60824765]. \t  -61.678993408673605 \t -0.008138249959218939\n",
      "74     \t [ 1.48295801 -2.01948449]. \t  -1779.9331458754982 \t -0.008138249959218939\n",
      "75     \t [0.40283998 1.78931525]. \t  -265.0809547695368 \t -0.008138249959218939\n",
      "76     \t [ 1.09377415 -0.18231735]. \t  -190.07892077531676 \t -0.008138249959218939\n",
      "77     \t [ 0.07106593 -0.75124526]. \t  -58.06122583385718 \t -0.008138249959218939\n",
      "78     \t [ 0.02326732 -1.83945505]. \t  -339.51268860144603 \t -0.008138249959218939\n",
      "79     \t [-1.29740262  1.75712178]. \t  -5.823710411830224 \t -0.008138249959218939\n",
      "80     \t [ 1.83921562 -1.87852308]. \t  -2768.7659657602317 \t -0.008138249959218939\n",
      "81     \t [0.65526423 1.92694656]. \t  -224.39203544551773 \t -0.008138249959218939\n",
      "82     \t [1.27266733 0.74961962]. \t  -75.77522523179843 \t -0.008138249959218939\n",
      "83     \t [ 0.00534458 -1.8677047 ]. \t  -349.83209534800903 \t -0.008138249959218939\n",
      "84     \t [-1.78156803  0.34557921]. \t  -807.724854737565 \t -0.008138249959218939\n",
      "85     \t [-0.72338256 -0.10542981]. \t  -42.49794136185081 \t -0.008138249959218939\n",
      "86     \t [-1.67572491  1.97551873]. \t  -76.47099598371405 \t -0.008138249959218939\n",
      "87     \t [ 0.18746651 -1.9943166 ]. \t  -412.53111848806657 \t -0.008138249959218939\n",
      "88     \t [-0.28548993 -0.74666325]. \t  -70.23866662317941 \t -0.008138249959218939\n",
      "89     \t [-1.02171148 -0.84387339]. \t  -360.45401520147857 \t -0.008138249959218939\n",
      "90     \t [ 1.92278947 -1.60551883]. \t  -2812.6486852664934 \t -0.008138249959218939\n",
      "91     \t [1.65754755 1.03431596]. \t  -293.9199525990663 \t -0.008138249959218939\n",
      "92     \t [ 1.46267369 -1.04330324]. \t  -1013.1831751017762 \t -0.008138249959218939\n",
      "93     \t [-1.00630904  1.94476309]. \t  -90.90728646286223 \t -0.008138249959218939\n",
      "94     \t [ 1.06922122 -0.90129315]. \t  -418.01393040335967 \t -0.008138249959218939\n",
      "95     \t [-0.95722189 -1.62230515]. \t  -648.2690012930171 \t -0.008138249959218939\n",
      "96     \t [-2.01259796 -1.60484267]. \t  -3207.4229721205893 \t -0.008138249959218939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [-0.61642984 -0.80475691]. \t  -142.9743618760859 \t -0.008138249959218939\n",
      "98     \t [ 1.80403501 -1.8959974 ]. \t  -2653.452420915192 \t -0.008138249959218939\n",
      "99     \t [-1.05798941 -1.21723447]. \t  -550.19409068371 \t -0.008138249959218939\n",
      "100    \t [ 1.26230841 -1.28353419]. \t  -827.7567937818976 \t -0.008138249959218939\n"
     ]
    }
   ],
   "source": [
    "### 6(m). Bayesian optimization runs (x20): GP run number = 13\n",
    "\n",
    "np.random.seed(run_num_13)\n",
    "surrogate_gp_13 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_13 = GPGO(surrogate_gp_13, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_13.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-0.8208981  -1.99651393]. \t  -716.4126721879244 \t -107.6541410279816\n",
      "init   \t [-0.46382593  1.2423217 ]. \t  -107.6541410279816 \t -107.6541410279816\n",
      "init   \t [0.3268096  1.28959969]. \t  -140.3536270807936 \t -107.6541410279816\n",
      "init   \t [1.78518834 0.36608001]. \t  -796.3176016434189 \t -107.6541410279816\n",
      "init   \t [1.74530189 0.58981651]. \t  -603.8778674329584 \t -107.6541410279816\n",
      "1      \t [2.048 2.048]. \t  -461.7603900415999 \t -107.6541410279816\n",
      "2      \t [-2.048  2.048]. \t  -469.9523900415999 \t -107.6541410279816\n",
      "3      \t [-2.048      -0.08346736]. \t  -1839.223088846932 \t -107.6541410279816\n",
      "4      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -107.6541410279816\n",
      "5      \t [-0.3719652  2.048    ]. \t  -366.55550294512256 \t -107.6541410279816\n",
      "6      \t [ 0.00676345 -0.13172664]. \t  \u001b[92m-2.7229148842966295\u001b[0m \t -2.7229148842966295\n",
      "7      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -2.7229148842966295\n",
      "8      \t [ 0.02560885 -1.51569698]. \t  -230.882017791843 \t -2.7229148842966295\n",
      "9      \t [-0.56318756 -0.76084038]. \t  -118.65639788332591 \t -2.7229148842966295\n",
      "10     \t [0.98570529 2.048     ]. \t  -115.86068731931819 \t -2.7229148842966295\n",
      "11     \t [-0.56435729  0.29563566]. \t  \u001b[92m-2.49948759377433\u001b[0m \t -2.49948759377433\n",
      "12     \t [-1.54992427  1.14953789]. \t  -163.4346925567193 \t -2.49948759377433\n",
      "13     \t [-0.1367731 -2.048    ]. \t  -428.419986615951 \t -2.49948759377433\n",
      "14     \t [0.74576027 0.55601407]. \t  \u001b[92m-0.06463992530481903\u001b[0m \t -0.06463992530481903\n",
      "15     \t [-1.24504977  2.048     ]. \t  -29.825816460423265 \t -0.06463992530481903\n",
      "16     \t [1.12780762 1.33880583]. \t  -0.46330463130057464 \t -0.06463992530481903\n",
      "17     \t [0.01097875 0.51188608]. \t  -27.16856046436635 \t -0.06463992530481903\n",
      "18     \t [-0.98518601  1.00883862]. \t  -4.087247879606964 \t -0.06463992530481903\n",
      "19     \t [-1.1928818   1.57851685]. \t  -7.228306094642173 \t -0.06463992530481903\n",
      "20     \t [-0.16674747 -0.85963099]. \t  -80.11551391255524 \t -0.06463992530481903\n",
      "21     \t [ 0.80266458 -0.59074622]. \t  -152.5655526006365 \t -0.06463992530481903\n",
      "22     \t [ 0.57743948 -0.04419945]. \t  -14.439438114004039 \t -0.06463992530481903\n",
      "23     \t [0.90310684 1.04244616]. \t  -5.155216955893984 \t -0.06463992530481903\n",
      "24     \t [ 0.77227622 -2.048     ]. \t  -699.3425790430048 \t -0.06463992530481903\n",
      "25     \t [1.43945806 2.048     ]. \t  -0.25091320189746197 \t -0.06463992530481903\n",
      "26     \t [ 0.4109914  -0.89246672]. \t  -112.99981823258756 \t -0.06463992530481903\n",
      "27     \t [1.32188057 1.77840898]. \t  -0.19995979252560667 \t -0.06463992530481903\n",
      "28     \t [-0.35898971 -0.08485078]. \t  -6.414664539881684 \t -0.06463992530481903\n",
      "29     \t [0.41399944 0.26973428]. \t  -1.310447411247591 \t -0.06463992530481903\n",
      "30     \t [-0.28759136  0.20500148]. \t  -3.153441760501373 \t -0.06463992530481903\n",
      "31     \t [ 2.048      -0.86799715]. \t  -2563.7875927806303 \t -0.06463992530481903\n",
      "32     \t [-1.46723738  1.84330517]. \t  -15.66507011639743 \t -0.06463992530481903\n",
      "33     \t [1.41019882 1.4992959 ]. \t  -24.116055459172603 \t -0.06463992530481903\n",
      "34     \t [-0.72196425  0.68916324]. \t  -5.785238409096332 \t -0.06463992530481903\n",
      "35     \t [-2.048      -1.03815855]. \t  -2747.1567373229846 \t -0.06463992530481903\n",
      "36     \t [1.03258054 0.95223308]. \t  -1.3004217835540217 \t -0.06463992530481903\n",
      "37     \t [-0.99732395  0.6795455 ]. \t  -13.918706411376428 \t -0.06463992530481903\n",
      "38     \t [ 1.0743388  -1.47274497]. \t  -690.0915455132742 \t -0.06463992530481903\n",
      "39     \t [1.36443748 2.048     ]. \t  -3.603970196045696 \t -0.06463992530481903\n",
      "40     \t [-1.45145064  2.048     ]. \t  -6.3542844066336555 \t -0.06463992530481903\n",
      "41     \t [-0.54438137 -1.47437335]. \t  -315.9316139620971 \t -0.06463992530481903\n",
      "42     \t [-1.21642248 -0.2435889 ]. \t  -301.87935641908246 \t -0.06463992530481903\n",
      "43     \t [0.20546461 0.06325238]. \t  -0.6755406480573563 \t -0.06463992530481903\n",
      "44     \t [-2.048       1.05650734]. \t  -993.8670900934933 \t -0.06463992530481903\n",
      "45     \t [-1.27802589  1.49401512]. \t  -7.130828092988495 \t -0.06463992530481903\n",
      "46     \t [-1.33388461 -1.45473883]. \t  -1051.3141973506115 \t -0.06463992530481903\n",
      "47     \t [0.60526167 0.28257167]. \t  -0.8575599614945966 \t -0.06463992530481903\n",
      "48     \t [1.11358919 1.21877554]. \t  \u001b[92m-0.05829431149247659\u001b[0m \t -0.05829431149247659\n",
      "49     \t [0.91637678 0.84882598]. \t  \u001b[92m-0.015236694693191534\u001b[0m \t -0.015236694693191534\n",
      "50     \t [1.00501609 1.02906512]. \t  -0.03615472950502434 \t -0.015236694693191534\n",
      "51     \t [1.40404545 1.9663339 ]. \t  -0.1657624562692316 \t -0.015236694693191534\n",
      "52     \t [1.13016005 1.26528779]. \t  -0.031279170768178446 \t -0.015236694693191534\n",
      "53     \t [1.03318388 1.07266783]. \t  \u001b[92m-0.0038040269052671107\u001b[0m \t -0.0038040269052671107\n",
      "54     \t [1.04286866 1.08112027]. \t  -0.006004111434833615 \t -0.0038040269052671107\n",
      "55     \t [1.34194795 1.77641194]. \t  -0.17652471878403309 \t -0.0038040269052671107\n",
      "56     \t [0.61992379 0.39966068]. \t  -0.1680360743171081 \t -0.0038040269052671107\n",
      "57     \t [1.39867115 1.92682566]. \t  -0.24570038521999044 \t -0.0038040269052671107\n",
      "58     \t [2.048      1.30958983]. \t  -833.2558878780992 \t -0.0038040269052671107\n",
      "59     \t [0.60403616 0.39389535]. \t  -0.24109438341070996 \t -0.0038040269052671107\n",
      "60     \t [0.84716752 0.79670706]. \t  -0.6476830540092354 \t -0.0038040269052671107\n",
      "61     \t [0.54236208 0.27227152]. \t  -0.2573282375303782 \t -0.0038040269052671107\n",
      "62     \t [-1.32047938  1.84385072]. \t  -6.388326735554204 \t -0.0038040269052671107\n",
      "63     \t [1.33034354 1.76127988]. \t  -0.11640985052159146 \t -0.0038040269052671107\n",
      "64     \t [1.29306158 1.62483438]. \t  -0.30842257870810025 \t -0.0038040269052671107\n",
      "65     \t [1.27333855 1.57435986]. \t  -0.29590725291314934 \t -0.0038040269052671107\n",
      "66     \t [0.64751822 0.44672539]. \t  -0.19956920117693944 \t -0.0038040269052671107\n",
      "67     \t [0.7006229  0.46162785]. \t  -0.17515129020847225 \t -0.0038040269052671107\n",
      "68     \t [0.63171407 0.38813402]. \t  -0.1475780496606001 \t -0.0038040269052671107\n",
      "69     \t [1.08713739 1.12318457]. \t  -0.3519639122865644 \t -0.0038040269052671107\n",
      "70     \t [0.56609867 0.30077068]. \t  -0.22706764763117473 \t -0.0038040269052671107\n",
      "71     \t [0.01085252 0.01316983]. \t  -0.9954483635494571 \t -0.0038040269052671107\n",
      "72     \t [1.10329616 1.15238269]. \t  -0.4316080834157545 \t -0.0038040269052671107\n",
      "73     \t [0.95865223 0.90979751]. \t  -0.010204181054352805 \t -0.0038040269052671107\n",
      "74     \t [0.85683215 0.74638509]. \t  -0.03543907405899707 \t -0.0038040269052671107\n",
      "75     \t [0.66326067 0.46728366]. \t  -0.1882992886803335 \t -0.0038040269052671107\n",
      "76     \t [1.29390738 1.65051169]. \t  -0.14247770417212527 \t -0.0038040269052671107\n",
      "77     \t [0.96504213 0.95876958]. \t  -0.07664520762975077 \t -0.0038040269052671107\n",
      "78     \t [0.96591508 0.94749994]. \t  -0.022209992526764012 \t -0.0038040269052671107\n",
      "79     \t [1.16437012 1.32144365]. \t  -0.1447635477582875 \t -0.0038040269052671107\n",
      "80     \t [1.33389685 1.79135768]. \t  -0.1260722191703725 \t -0.0038040269052671107\n",
      "81     \t [1.01962707 1.03892815]. \t  \u001b[92m-0.0004358024311814609\u001b[0m \t -0.0004358024311814609\n",
      "82     \t [0.82029201 0.70191414]. \t  -0.11659898666517929 \t -0.0004358024311814609\n",
      "83     \t [1.42953243 2.03985305]. \t  -0.18587445554366364 \t -0.0004358024311814609\n",
      "84     \t [1.19231917 1.40201428]. \t  -0.07544475775420875 \t -0.0004358024311814609\n",
      "85     \t [0.77192682 0.61830511]. \t  -0.1023462056600567 \t -0.0004358024311814609\n",
      "86     \t [0.964087  0.9316433]. \t  -0.0017647884185525917 \t -0.0004358024311814609\n",
      "87     \t [0.66049551 0.37184876]. \t  -0.5300709913075471 \t -0.0004358024311814609\n",
      "88     \t [0.60832784 0.36927206]. \t  -0.1534696015807517 \t -0.0004358024311814609\n",
      "89     \t [1.04790089 1.13923587]. \t  -0.1715410907022859 \t -0.0004358024311814609\n",
      "90     \t [0.93913138 0.95235093]. \t  -0.4990842509067233 \t -0.0004358024311814609\n",
      "91     \t [1.27116849 1.59134514]. \t  -0.13367600206808286 \t -0.0004358024311814609\n",
      "92     \t [0.78293669 0.61876886]. \t  -0.050456172638526926 \t -0.0004358024311814609\n",
      "93     \t [1.14944985 1.28931577]. \t  -0.12421870670342805 \t -0.0004358024311814609\n",
      "94     \t [1.01846421 0.98602636]. \t  -0.26292523964715037 \t -0.0004358024311814609\n",
      "95     \t [1.17818888 1.36472286]. \t  -0.08653621666112424 \t -0.0004358024311814609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [1.32350055 1.73613516]. \t  -0.128735087129404 \t -0.0004358024311814609\n",
      "97     \t [1.22594656 1.47802352]. \t  -0.11315970735385766 \t -0.0004358024311814609\n",
      "98     \t [0.734296   0.57240696]. \t  -0.18093115055112546 \t -0.0004358024311814609\n",
      "99     \t [0.45213886 0.18096964]. \t  -0.35518854099812397 \t -0.0004358024311814609\n",
      "100    \t [0.98651324 0.96861397]. \t  -0.002292740680637315 \t -0.0004358024311814609\n"
     ]
    }
   ],
   "source": [
    "### 6(m). Bayesian optimization runs (x20): STP DF1 run number = 13\n",
    "\n",
    "np.random.seed(run_num_13)\n",
    "surrogate_stp_df1_13 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_13 = GPGO(surrogate_stp_df1_13, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_13.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.811180114806883, -7.738321556806027)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(m). Training Regret Minimisation: run number = 13\n",
    "\n",
    "gp_output_13 = np.append(np.max(gpgo_gp_13.GP.y[0:n_init]),gpgo_gp_13.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_13 = np.append(np.max(gpgo_stp_df1_13.GP.y[0:n_init]),gpgo_stp_df1_13.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_13 = np.log(y_global_orig - gp_output_13)\n",
    "regret_stp_df1_13 = np.log(y_global_orig - stp_df1_output_13)\n",
    "\n",
    "train_regret_gp_13 = min_max_array(regret_gp_13)\n",
    "train_regret_stp_df1_13 = min_max_array(regret_stp_df1_13)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 13\n",
    "min_train_regret_gp_13 = min(train_regret_gp_13)\n",
    "min_train_regret_stp_df1_13 = min(train_regret_stp_df1_13)\n",
    "\n",
    "min_train_regret_gp_13, min_train_regret_stp_df1_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-0.95207587  1.28398064]. \t  -18.06365568198427 \t -7.680895540316377\n",
      "init   \t [-0.03200931  0.25823759]. \t  -7.680895540316377 \t -7.680895540316377\n",
      "init   \t [-1.94877207 -1.17264485]. \t  -2479.1405543124242 \t -7.680895540316377\n",
      "init   \t [-1.2336859  -1.81538252]. \t  -1118.7888193512965 \t -7.680895540316377\n",
      "init   \t [ 1.85882541 -0.24536028]. \t  -1370.1758477347046 \t -7.680895540316377\n",
      "1      \t [-0.17518205  0.98452207]. \t  -92.36085352171476 \t -7.680895540316377\n",
      "2      \t [-1.74363132  1.97995771]. \t  -119.9495210143544 \t -7.680895540316377\n",
      "3      \t [-1.83118595  1.92192372]. \t  -212.88281566688215 \t -7.680895540316377\n",
      "4      \t [-0.91099209  2.048     ]. \t  -152.02704499699732 \t -7.680895540316377\n",
      "5      \t [-0.51502079  0.61518837]. \t  -14.541225363632957 \t -7.680895540316377\n",
      "6      \t [ 1.26576947 -1.51745376]. \t  -973.2773436691255 \t -7.680895540316377\n",
      "7      \t [-0.18267204  0.47603799]. \t  -20.994289914640785 \t -7.680895540316377\n",
      "8      \t [ 0.00852149 -0.27549587]. \t  -8.576828607685012 \t -7.680895540316377\n",
      "9      \t [-1.00754874 -1.93265809]. \t  -872.9901323758442 \t -7.680895540316377\n",
      "10     \t [ 0.00569735 -0.03604954]. \t  \u001b[92m-1.1188288337017622\u001b[0m \t -1.1188288337017622\n",
      "11     \t [ 0.13578386 -0.1423382 ]. \t  -3.3317442895226645 \t -1.1188288337017622\n",
      "12     \t [-0.86407807  0.93816351]. \t  -7.143260534057358 \t -1.1188288337017622\n",
      "13     \t [ 1.37533976 -0.47964318]. \t  -562.4010803744658 \t -1.1188288337017622\n",
      "14     \t [0.51700128 0.59757902]. \t  -11.142350332659154 \t -1.1188288337017622\n",
      "15     \t [-1.55999967  1.31410132]. \t  -131.8811007789856 \t -1.1188288337017622\n",
      "16     \t [-1.38979798  2.048     ]. \t  -7.067464482195737 \t -1.1188288337017622\n",
      "17     \t [0.91376942 2.048     ]. \t  -147.15050968243258 \t -1.1188288337017622\n",
      "18     \t [-0.3755814   0.15540452]. \t  -1.9127967324755837 \t -1.1188288337017622\n",
      "19     \t [0.43879535 0.12204586]. \t  \u001b[92m-0.8119121147300745\u001b[0m \t -0.8119121147300745\n",
      "20     \t [ 1.92273667 -0.23509496]. \t  -1546.9227033599025 \t -0.8119121147300745\n",
      "21     \t [0.97851957 0.38085495]. \t  -33.25247603978675 \t -0.8119121147300745\n",
      "22     \t [0.6901092  0.24011539]. \t  -5.672021301696904 \t -0.8119121147300745\n",
      "23     \t [-0.81763923  0.56214091]. \t  -4.435759337290493 \t -0.8119121147300745\n",
      "24     \t [1.00410717 1.21829873]. \t  -4.4128528814511165 \t -0.8119121147300745\n",
      "25     \t [ 1.13709157 -0.87513729]. \t  -470.09085730591266 \t -0.8119121147300745\n",
      "26     \t [-1.73654475  1.10767006]. \t  -371.5036408144991 \t -0.8119121147300745\n",
      "27     \t [-1.28216695  1.79677447]. \t  -7.543754285631854 \t -0.8119121147300745\n",
      "28     \t [-1.18840812  1.36777343]. \t  -4.987514981617812 \t -0.8119121147300745\n",
      "29     \t [1.63527843 1.96003845]. \t  -51.397043833243416 \t -0.8119121147300745\n",
      "30     \t [1.26361851 1.60606191]. \t  \u001b[92m-0.0781999407336279\u001b[0m \t -0.0781999407336279\n",
      "31     \t [0.50524981 0.28773126]. \t  -0.35010324308745056 \t -0.0781999407336279\n",
      "32     \t [1.1593952 1.5203914]. \t  -3.129845043174371 \t -0.0781999407336279\n",
      "33     \t [1.22714171 1.43028303]. \t  -0.6230348671707846 \t -0.0781999407336279\n",
      "34     \t [-0.23624848 -0.75459673]. \t  -67.20475922070855 \t -0.0781999407336279\n",
      "35     \t [1.199174   1.52188118]. \t  -0.742968866138144 \t -0.0781999407336279\n",
      "36     \t [ 0.2592911  -1.06394764]. \t  -128.50535933741313 \t -0.0781999407336279\n",
      "37     \t [ 0.41646406 -0.40312716]. \t  -33.58374982205175 \t -0.0781999407336279\n",
      "38     \t [ 1.10294207 -0.6917231 ]. \t  -364.13496963096725 \t -0.0781999407336279\n",
      "39     \t [-0.41597997  1.71638002]. \t  -240.19504527366388 \t -0.0781999407336279\n",
      "40     \t [1.80588474 0.58761274]. \t  -715.4668721690052 \t -0.0781999407336279\n",
      "41     \t [-1.68236734  1.27305324]. \t  -249.71548380117878 \t -0.0781999407336279\n",
      "42     \t [ 0.18259053 -1.83525825]. \t  -349.83383947086736 \t -0.0781999407336279\n",
      "43     \t [ 0.06946537 -0.57546322]. \t  -34.53938711962986 \t -0.0781999407336279\n",
      "44     \t [ 0.94345942 -0.53625928]. \t  -203.45774705103705 \t -0.0781999407336279\n",
      "45     \t [0.36508448 0.15501258]. \t  -0.4503191614023864 \t -0.0781999407336279\n",
      "46     \t [ 0.12664627 -0.32264805]. \t  -12.233657481689983 \t -0.0781999407336279\n",
      "47     \t [-0.84553887  0.85055453]. \t  -5.2452525079591785 \t -0.0781999407336279\n",
      "48     \t [ 1.32332782 -1.47508543]. \t  -1040.9940632089 \t -0.0781999407336279\n",
      "49     \t [1.00259269 1.36776284]. \t  -13.145760891175255 \t -0.0781999407336279\n",
      "50     \t [-2.01154425 -1.27278053]. \t  -2838.3420999787054 \t -0.0781999407336279\n",
      "51     \t [-0.65321145 -0.14115752]. \t  -34.97764297279375 \t -0.0781999407336279\n",
      "52     \t [1.21497642 0.96598252]. \t  -26.075106979637713 \t -0.0781999407336279\n",
      "53     \t [0.85285965 0.31931414]. \t  -16.67257435789083 \t -0.0781999407336279\n",
      "54     \t [1.14761504 1.31751163]. \t  \u001b[92m-0.021814342631514286\u001b[0m \t -0.021814342631514286\n",
      "55     \t [0.74813698 1.43054344]. \t  -75.89870659110974 \t -0.021814342631514286\n",
      "56     \t [-1.13243691  1.14037304]. \t  -6.564832440115241 \t -0.021814342631514286\n",
      "57     \t [-1.32711378  0.404947  ]. \t  -189.36608456089357 \t -0.021814342631514286\n",
      "58     \t [-1.69134674  0.29969771]. \t  -663.0929437127381 \t -0.021814342631514286\n",
      "59     \t [ 0.50801032 -1.13301629]. \t  -193.75540790828515 \t -0.021814342631514286\n",
      "60     \t [-0.37135242 -0.4254419 ]. \t  -33.61631273069818 \t -0.021814342631514286\n",
      "61     \t [-0.75507009 -0.59082773]. \t  -137.86275189585967 \t -0.021814342631514286\n",
      "62     \t [ 0.98717702 -1.86919354]. \t  -808.669961390619 \t -0.021814342631514286\n",
      "63     \t [1.98354446 1.46217673]. \t  -612.1801942477559 \t -0.021814342631514286\n",
      "64     \t [1.44951369 1.97530668]. \t  -1.7842051107884187 \t -0.021814342631514286\n",
      "65     \t [-1.20184512  1.23782035]. \t  -9.116947111235397 \t -0.021814342631514286\n",
      "66     \t [-1.40463969  0.52253694]. \t  -216.17027039301146 \t -0.021814342631514286\n",
      "67     \t [0.25871498 0.71248495]. \t  -42.22317926998595 \t -0.021814342631514286\n",
      "68     \t [-1.98775205 -0.85022197]. \t  -2314.251835718782 \t -0.021814342631514286\n",
      "69     \t [0.58316975 1.47250468]. \t  -128.4107356145852 \t -0.021814342631514286\n",
      "70     \t [ 0.3925926 -0.1168641]. \t  -7.712666964285644 \t -0.021814342631514286\n",
      "71     \t [1.70274549 2.04685561]. \t  -73.16719325197012 \t -0.021814342631514286\n",
      "72     \t [-0.12067663 -1.08575747]. \t  -122.32639758583859 \t -0.021814342631514286\n",
      "73     \t [ 1.42677023 -1.83608466]. \t  -1499.233089995006 \t -0.021814342631514286\n",
      "74     \t [0.75224973 0.04377878]. \t  -27.320313333627237 \t -0.021814342631514286\n",
      "75     \t [0.43764734 0.1928298 ]. \t  -0.31640811576207184 \t -0.021814342631514286\n",
      "76     \t [2.02741504 0.12719493]. \t  -1587.6572167562865 \t -0.021814342631514286\n",
      "77     \t [-1.74207901 -0.40744455]. \t  -1192.4507827073994 \t -0.021814342631514286\n",
      "78     \t [ 1.69034619 -1.49163225]. \t  -1891.7718745952416 \t -0.021814342631514286\n",
      "79     \t [1.35637508 1.83647154]. \t  -0.12808022645553735 \t -0.021814342631514286\n",
      "80     \t [-0.14926405 -1.2731217 ]. \t  -169.12730099543649 \t -0.021814342631514286\n",
      "81     \t [ 0.74856236 -1.53873836]. \t  -440.67856819724375 \t -0.021814342631514286\n",
      "82     \t [-0.79560391  0.30160219]. \t  -14.20568858716473 \t -0.021814342631514286\n",
      "83     \t [1.76518129 0.09431138]. \t  -913.5641150412637 \t -0.021814342631514286\n",
      "84     \t [1.13231658 0.54098285]. \t  -54.94902588307828 \t -0.021814342631514286\n",
      "85     \t [-1.79693273 -0.29269363]. \t  -1248.0323547048515 \t -0.021814342631514286\n",
      "86     \t [0.13624652 1.53801604]. \t  -231.61978795039755 \t -0.021814342631514286\n",
      "87     \t [ 1.52195554 -0.35295596]. \t  -712.7911531816468 \t -0.021814342631514286\n",
      "88     \t [ 2.0088331  -0.77518967]. \t  -2315.2050712955356 \t -0.021814342631514286\n",
      "89     \t [-1.75257995  0.92728673]. \t  -467.357400354562 \t -0.021814342631514286\n",
      "90     \t [0.59690343 0.35392087]. \t  -0.16304988046508118 \t -0.021814342631514286\n",
      "91     \t [-2.01796864 -1.46192302]. \t  -3071.757039037938 \t -0.021814342631514286\n",
      "92     \t [-0.73148856 -0.4575214 ]. \t  -101.52291609034397 \t -0.021814342631514286\n",
      "93     \t [ 0.81819108 -1.16039683]. \t  -334.86211094373385 \t -0.021814342631514286\n",
      "94     \t [-1.86700644 -0.31415538]. \t  -1452.119720941825 \t -0.021814342631514286\n",
      "95     \t [1.33655493 1.77887736]. \t  -0.11889680615125214 \t -0.021814342631514286\n",
      "96     \t [-0.4784592  -0.07455943]. \t  -11.39601267697597 \t -0.021814342631514286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [1.28785128 1.65931638]. \t  -0.08291543247046759 \t -0.021814342631514286\n",
      "98     \t [-0.4903189  -0.67374305]. \t  -85.78911022126209 \t -0.021814342631514286\n",
      "99     \t [0.55722437 1.1772122 ]. \t  -75.3152281042585 \t -0.021814342631514286\n",
      "100    \t [-0.43197104  1.05365272]. \t  -77.22876035046332 \t -0.021814342631514286\n"
     ]
    }
   ],
   "source": [
    "### 6(n). Bayesian optimization runs (x20): GP run number = 14\n",
    "\n",
    "np.random.seed(run_num_14)\n",
    "surrogate_gp_14 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_14 = GPGO(surrogate_gp_14, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_14.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-0.95207587  1.28398064]. \t  -18.06365568198427 \t -7.680895540316377\n",
      "init   \t [-0.03200931  0.25823759]. \t  -7.680895540316377 \t -7.680895540316377\n",
      "init   \t [-1.94877207 -1.17264485]. \t  -2479.1405543124242 \t -7.680895540316377\n",
      "init   \t [-1.2336859  -1.81538252]. \t  -1118.7888193512965 \t -7.680895540316377\n",
      "init   \t [ 1.85882541 -0.24536028]. \t  -1370.1758477347046 \t -7.680895540316377\n",
      "1      \t [0.65634004 2.048     ]. \t  -261.6574287258485 \t -7.680895540316377\n",
      "2      \t [ 0.39715173 -2.048     ]. \t  -486.88768734215813 \t -7.680895540316377\n",
      "3      \t [-2.048  2.048]. \t  -469.9523900415999 \t -7.680895540316377\n",
      "4      \t [2.048 2.048]. \t  -461.7603900415999 \t -7.680895540316377\n",
      "5      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -7.680895540316377\n",
      "6      \t [-0.0308573  -0.94495833]. \t  -90.53733446074386 \t -7.680895540316377\n",
      "7      \t [-0.52679065  2.048     ]. \t  -315.7951455174673 \t -7.680895540316377\n",
      "8      \t [-2.048       0.78589218]. \t  -1171.0174186771733 \t -7.680895540316377\n",
      "9      \t [0.87077708 0.98387008]. \t  \u001b[92m-5.1070179109889\u001b[0m \t -5.1070179109889\n",
      "10     \t [-0.06448434  1.11657658]. \t  -124.88058449825859 \t -5.1070179109889\n",
      "11     \t [2.048      0.98165092]. \t  -1033.2122825178394 \t -5.1070179109889\n",
      "12     \t [ 0.60466445 -0.07353876]. \t  -19.44225238158892 \t -5.1070179109889\n",
      "13     \t [-0.29741985 -2.048     ]. \t  -458.1288188553588 \t -5.1070179109889\n",
      "14     \t [0.51241698 0.51113161]. \t  -6.415966900242299 \t -5.1070179109889\n",
      "15     \t [-0.83683679  0.51567748]. \t  -6.782362366215201 \t -5.1070179109889\n",
      "16     \t [ 0.49519837 -0.97853677]. \t  -150.01323704149996 \t -5.1070179109889\n",
      "17     \t [-0.67324131  0.81482447]. \t  -15.873066863012586 \t -5.1070179109889\n",
      "18     \t [-1.29931545  2.048     ]. \t  -18.230970655866365 \t -5.1070179109889\n",
      "19     \t [ 0.1792528  -0.38758938]. \t  -18.290193523678386 \t -5.1070179109889\n",
      "20     \t [-0.54462999 -0.09347578]. \t  -17.603496110078638 \t -5.1070179109889\n",
      "21     \t [1.33450894 2.048     ]. \t  -7.2453840972700485 \t -5.1070179109889\n",
      "22     \t [1.06340826 1.6087286 ]. \t  -22.842045814867127 \t -5.1070179109889\n",
      "23     \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -5.1070179109889\n",
      "24     \t [-0.77668095 -1.0485813 ]. \t  -276.00574245894694 \t -5.1070179109889\n",
      "25     \t [-1.53718235 -0.13294629]. \t  -629.3769232841382 \t -5.1070179109889\n",
      "26     \t [-1.09692059  1.7510776 ]. \t  -34.410250816581005 \t -5.1070179109889\n",
      "27     \t [1.06769689 0.51565515]. \t  -38.98231593805802 \t -5.1070179109889\n",
      "28     \t [-1.45763369  1.53801023]. \t  -40.459980479025305 \t -5.1070179109889\n",
      "29     \t [1.39009142 1.51128012]. \t  -17.88250646404713 \t -5.1070179109889\n",
      "30     \t [1.14507537 1.20946628]. \t  \u001b[92m-1.0559731032593767\u001b[0m \t -1.0559731032593767\n",
      "31     \t [-0.56303833  0.288054  ]. \t  -2.526946364925646 \t -1.0559731032593767\n",
      "32     \t [-1.15241269  1.22422417]. \t  -5.710964499768808 \t -1.0559731032593767\n",
      "33     \t [1.31881891 1.76523862]. \t  \u001b[92m-0.16901326322734347\u001b[0m \t -0.16901326322734347\n",
      "34     \t [0.71022721 0.39271122]. \t  -1.331913268733323 \t -0.16901326322734347\n",
      "35     \t [ 1.08647854 -2.048     ]. \t  -1042.2871361607301 \t -0.16901326322734347\n",
      "36     \t [ 1.31831563 -0.95226003]. \t  -723.8276045339861 \t -0.16901326322734347\n",
      "37     \t [-1.36810408  1.82524342]. \t  -5.823819896068331 \t -0.16901326322734347\n",
      "38     \t [-0.17432841 -0.12338349]. \t  -3.7436880638608243 \t -0.16901326322734347\n",
      "39     \t [1.18996308 1.4109328 ]. \t  \u001b[92m-0.038665921949672735\u001b[0m \t -0.038665921949672735\n",
      "40     \t [-0.3716065  -1.56646016]. \t  -292.43090355365416 \t -0.038665921949672735\n",
      "41     \t [0.84374744 0.70067669]. \t  \u001b[92m-0.0370330146669029\u001b[0m \t -0.0370330146669029\n",
      "42     \t [1.49288421 2.04799999]. \t  -3.50830282768723 \t -0.0370330146669029\n",
      "43     \t [0.27122017 0.04958778]. \t  -0.5885886196778112 \t -0.0370330146669029\n",
      "44     \t [ 2.048      -1.13996107]. \t  -2846.53668358146 \t -0.0370330146669029\n",
      "45     \t [-1.24230929  1.54629817]. \t  -5.028830539402621 \t -0.0370330146669029\n",
      "46     \t [-2.048      -0.30494493]. \t  -2033.6143956602155 \t -0.0370330146669029\n",
      "47     \t [ 0.06747117 -0.00404925]. \t  -0.8770087897703143 \t -0.0370330146669029\n",
      "48     \t [1.36227794 1.84633268]. \t  -0.1402105830595308 \t -0.0370330146669029\n",
      "49     \t [1.2403978  1.56434305]. \t  -0.12413001258168564 \t -0.0370330146669029\n",
      "50     \t [-1.49904049  2.048     ]. \t  -10.210176445751593 \t -0.0370330146669029\n",
      "51     \t [0.69064008 0.41834789]. \t  -0.4395196434666606 \t -0.0370330146669029\n",
      "52     \t [ 0.72752726 -1.60568044]. \t  -455.8866456505729 \t -0.0370330146669029\n",
      "53     \t [1.0383843  1.08129787]. \t  \u001b[92m-0.002407212027457438\u001b[0m \t -0.002407212027457438\n",
      "54     \t [1.15177441 1.30666265]. \t  -0.06272267798959454 \t -0.002407212027457438\n",
      "55     \t [1.42328988 2.048     ]. \t  -0.22866244123339793 \t -0.002407212027457438\n",
      "56     \t [1.09893715 1.20782292]. \t  -0.009791121160317625 \t -0.002407212027457438\n",
      "57     \t [0.92994924 0.82068089]. \t  -0.1996059861858241 \t -0.002407212027457438\n",
      "58     \t [1.14964192 1.27443745]. \t  -0.24554598870049646 \t -0.002407212027457438\n",
      "59     \t [1.38018075 1.90296784]. \t  -0.1449103063043354 \t -0.002407212027457438\n",
      "60     \t [1.2993034  1.68098147]. \t  -0.09477784743451449 \t -0.002407212027457438\n",
      "61     \t [0.73866593 0.58490376]. \t  -0.22255899839882815 \t -0.002407212027457438\n",
      "62     \t [1.4125758 2.048    ]. \t  -0.44720625329564195 \t -0.002407212027457438\n",
      "63     \t [0.71611453 0.51986313]. \t  -0.08555150121026721 \t -0.002407212027457438\n",
      "64     \t [1.24587771 1.54316542]. \t  -0.06863859827910439 \t -0.002407212027457438\n",
      "65     \t [1.11083372 1.24488383]. \t  -0.02423558510976874 \t -0.002407212027457438\n",
      "66     \t [1.2529763  1.54306822]. \t  -0.13625798833088246 \t -0.002407212027457438\n",
      "67     \t [ 0.03671985 -0.0280323 ]. \t  -1.0142308759648306 \t -0.002407212027457438\n",
      "68     \t [1.01157171 1.00106597]. \t  -0.049468304524787336 \t -0.002407212027457438\n",
      "69     \t [0.5629124  0.32694341]. \t  -0.20119217329507436 \t -0.002407212027457438\n",
      "70     \t [1.17223093 1.37323386]. \t  -0.02974297024985586 \t -0.002407212027457438\n",
      "71     \t [0.72460916 0.52547404]. \t  -0.07585738474578856 \t -0.002407212027457438\n",
      "72     \t [1.44821337 2.04799979]. \t  -0.44416291328628427 \t -0.002407212027457438\n",
      "73     \t [1.42469648 2.04799621]. \t  -0.2136227899798503 \t -0.002407212027457438\n",
      "74     \t [1.04057301 1.07271849]. \t  -0.011794112821075724 \t -0.002407212027457438\n",
      "75     \t [0.69364314 0.47652781]. \t  -0.09598249198701814 \t -0.002407212027457438\n",
      "76     \t [1.08352885 1.1752689 ]. \t  -0.007129376334468503 \t -0.002407212027457438\n",
      "77     \t [0.9027725  0.81607526]. \t  -0.009569197177909262 \t -0.002407212027457438\n",
      "78     \t [0.69104119 0.46212963]. \t  -0.11919712205243473 \t -0.002407212027457438\n",
      "79     \t [1.33329957 1.78455376]. \t  -0.11580282849636045 \t -0.002407212027457438\n",
      "80     \t [0.73043434 0.5311806 ]. \t  -0.07321964436167928 \t -0.002407212027457438\n",
      "81     \t [1.12126704 1.26552829]. \t  -0.021575646126717373 \t -0.002407212027457438\n",
      "82     \t [0.87140959 0.68877383]. \t  -0.5147010793236113 \t -0.002407212027457438\n",
      "83     \t [0.86517432 0.7074524 ]. \t  -0.18688701575102135 \t -0.002407212027457438\n",
      "84     \t [1.18530276 1.45360919]. \t  -0.27118056742076274 \t -0.002407212027457438\n",
      "85     \t [0.73577538 0.54440224]. \t  -0.07073688955628027 \t -0.002407212027457438\n",
      "86     \t [1.03297933 1.08589335]. \t  -0.03660876451109897 \t -0.002407212027457438\n",
      "87     \t [1.05275006 1.11269839]. \t  -0.004732413172531291 \t -0.002407212027457438\n",
      "88     \t [0.74812455 0.51739006]. \t  -0.24237258496829822 \t -0.002407212027457438\n",
      "89     \t [1.0830265 1.1748416]. \t  -0.007252577887733453 \t -0.002407212027457438\n",
      "90     \t [1.10482193 1.21705097]. \t  -0.01226965297301508 \t -0.002407212027457438\n",
      "91     \t [1.03654602 1.08383974]. \t  -0.010194374666319828 \t -0.002407212027457438\n",
      "92     \t [0.9840558  0.95438345]. \t  -0.01980486649758173 \t -0.002407212027457438\n",
      "93     \t [0.71193893 0.52076083]. \t  -0.10231072022396556 \t -0.002407212027457438\n",
      "94     \t [0.83983302 0.68692144]. \t  -0.059502317098522314 \t -0.002407212027457438\n",
      "95     \t [1.12199648 1.27633815]. \t  -0.045375471519667074 \t -0.002407212027457438\n",
      "96     \t [1.24000651 1.53469377]. \t  -0.05845715470186229 \t -0.002407212027457438\n",
      "97     \t [1.28785128 1.65931638]. \t  -0.08291543247046759 \t -0.002407212027457438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98     \t [1.21610026 1.42847589]. \t  -0.3009568575048268 \t -0.002407212027457438\n",
      "99     \t [1.19143345 1.38704498]. \t  -0.14206835362697395 \t -0.002407212027457438\n",
      "100    \t [1.42316192 2.048     ]. \t  -0.23018787255775436 \t -0.002407212027457438\n"
     ]
    }
   ],
   "source": [
    "### 6(n). Bayesian optimization runs (x20): STP DF1 run number = 14\n",
    "\n",
    "np.random.seed(run_num_14)\n",
    "surrogate_stp_df1_14 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_14 = GPGO(surrogate_stp_df1_14, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_14.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.8251876066440342, -6.029286036209675)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(n). Training Regret Minimisation: run number = 14\n",
    "\n",
    "gp_output_14 = np.append(np.max(gpgo_gp_14.GP.y[0:n_init]),gpgo_gp_14.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_14 = np.append(np.max(gpgo_stp_df1_14.GP.y[0:n_init]),gpgo_stp_df1_14.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_14 = np.log(y_global_orig - gp_output_14)\n",
    "regret_stp_df1_14 = np.log(y_global_orig - stp_df1_output_14)\n",
    "\n",
    "train_regret_gp_14 = min_max_array(regret_gp_14)\n",
    "train_regret_stp_df1_14 = min_max_array(regret_stp_df1_14)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 14\n",
    "min_train_regret_gp_14 = min(train_regret_gp_14)\n",
    "min_train_regret_stp_df1_14 = min(train_regret_stp_df1_14)\n",
    "\n",
    "min_train_regret_gp_14, min_train_regret_stp_df1_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.78925929  1.06790389]. \t  -462.98135799363985 \t -174.6665587456034\n",
      "init   \t [0.37808183 1.46309653]. \t  -174.6665587456034 \t -174.6665587456034\n",
      "init   \t [2.0362116 1.1002948]. \t  -928.8017963597329 \t -174.6665587456034\n",
      "init   \t [-1.131497   -1.81071027]. \t  -959.9687406625251 \t -174.6665587456034\n",
      "init   \t [1.79168794 1.86178159]. \t  -182.4353421998091 \t -174.6665587456034\n",
      "1      \t [1.06002045 2.048     ]. \t  \u001b[92m-85.44712223726904\u001b[0m \t -85.44712223726904\n",
      "2      \t [ 1.92080442 -1.92014161]. \t  -3147.6441476869113 \t -85.44712223726904\n",
      "3      \t [-0.31050119 -1.29186984]. \t  -194.44977949890415 \t -85.44712223726904\n",
      "4      \t [-0.16557971 -0.39231132]. \t  \u001b[92m-18.975732356138067\u001b[0m \t -18.975732356138067\n",
      "5      \t [0.51466912 0.14232677]. \t  \u001b[92m-1.7375810748695644\u001b[0m \t -1.7375810748695644\n",
      "6      \t [ 0.21896314 -0.16700022]. \t  -5.230157133468382 \t -1.7375810748695644\n",
      "7      \t [0.31543856 0.31812205]. \t  -5.248119350588316 \t -1.7375810748695644\n",
      "8      \t [0.40317225 0.17320406]. \t  \u001b[92m-0.3675588347035967\u001b[0m \t -0.3675588347035967\n",
      "9      \t [0.23740205 1.0784588 ]. \t  -105.05020536711594 \t -0.3675588347035967\n",
      "10     \t [ 0.04239174 -0.59405367]. \t  -36.42082232187817 \t -0.3675588347035967\n",
      "11     \t [-0.36260455  0.23739039]. \t  -2.978348613710421 \t -0.3675588347035967\n",
      "12     \t [1.27484611 1.11906228]. \t  -25.696378860683883 \t -0.3675588347035967\n",
      "13     \t [0.96232231 1.18687482]. \t  -6.803635332128922 \t -0.3675588347035967\n",
      "14     \t [0.95399846 0.65848328]. \t  -6.333871178886407 \t -0.3675588347035967\n",
      "15     \t [1.23267154 1.54674052]. \t  \u001b[92m-0.12845448314394\u001b[0m \t -0.12845448314394\n",
      "16     \t [-0.12670992  0.21952494]. \t  -5.409460435024046 \t -0.12845448314394\n",
      "17     \t [1.10258517 1.17640956]. \t  -0.16485091463326612 \t -0.12845448314394\n",
      "18     \t [-1.0455148   0.02841693]. \t  -117.53938948796171 \t -0.12845448314394\n",
      "19     \t [ 1.42264436 -0.74824789]. \t  -768.6684266570154 \t -0.12845448314394\n",
      "20     \t [-0.34436696  0.4247642 ]. \t  -11.181671892577347 \t -0.12845448314394\n",
      "21     \t [-1.14297815 -0.25521422]. \t  -248.4559588670746 \t -0.12845448314394\n",
      "22     \t [1.25178462 0.21333064]. \t  -183.29592235336585 \t -0.12845448314394\n",
      "23     \t [1.08076371 1.82939289]. \t  -43.743939812192096 \t -0.12845448314394\n",
      "24     \t [ 0.17000911 -0.54236342]. \t  -33.32342798885383 \t -0.12845448314394\n",
      "25     \t [-1.72866729 -0.80802069]. \t  -1448.6435788995977 \t -0.12845448314394\n",
      "26     \t [1.04473533 1.06417575]. \t  \u001b[92m-0.0765093111867689\u001b[0m \t -0.0765093111867689\n",
      "27     \t [-1.46633463  1.10849256]. \t  -114.58517348119503 \t -0.0765093111867689\n",
      "28     \t [-1.33573048  1.87626111]. \t  -6.303605143494204 \t -0.0765093111867689\n",
      "29     \t [-1.12880164  1.377747  ]. \t  -5.604136577698043 \t -0.0765093111867689\n",
      "30     \t [-0.41343217  1.53071721]. \t  -186.9009618057654 \t -0.0765093111867689\n",
      "31     \t [-1.27001549  2.048     ]. \t  -24.08074733189524 \t -0.0765093111867689\n",
      "32     \t [-1.04213515  1.04566775]. \t  -4.3333536728898014 \t -0.0765093111867689\n",
      "33     \t [1.08489238 1.15556895]. \t  \u001b[92m-0.053099130054461555\u001b[0m \t -0.053099130054461555\n",
      "34     \t [1.43463121 2.048     ]. \t  -0.19924045324790438 \t -0.053099130054461555\n",
      "35     \t [-1.36834322 -0.67105742]. \t  -652.5078709143129 \t -0.053099130054461555\n",
      "36     \t [0.0693972  1.73827906]. \t  -301.3554505929759 \t -0.053099130054461555\n",
      "37     \t [-0.7469279   0.47631851]. \t  -3.7173319985752116 \t -0.053099130054461555\n",
      "38     \t [1.70046406 0.84078555]. \t  -421.0656230516085 \t -0.053099130054461555\n",
      "39     \t [1.13468424 0.54010811]. \t  -55.878848310041725 \t -0.053099130054461555\n",
      "40     \t [-1.61064738  0.9194804 ]. \t  -287.27902872374705 \t -0.053099130054461555\n",
      "41     \t [0.35619173 0.10363129]. \t  -0.4685047022172942 \t -0.053099130054461555\n",
      "42     \t [1.03535211 1.04427375]. \t  -0.07786933698444903 \t -0.053099130054461555\n",
      "43     \t [1.06000229 1.1013996 ]. \t  \u001b[92m-0.05290761594110712\u001b[0m \t -0.05290761594110712\n",
      "44     \t [-0.3403214  -1.90450699]. \t  -409.96803399350495 \t -0.05290761594110712\n",
      "45     \t [1.09755231 1.19316549]. \t  \u001b[92m-0.022639468244276026\u001b[0m \t -0.022639468244276026\n",
      "46     \t [1.07657565 1.14147888]. \t  -0.036615861598239735 \t -0.022639468244276026\n",
      "47     \t [-1.28616525 -0.72796354]. \t  -572.70690078627 \t -0.022639468244276026\n",
      "48     \t [ 0.09500574 -0.78824056]. \t  -64.38242619815719 \t -0.022639468244276026\n",
      "49     \t [ 1.6734121  -0.89747183]. \t  -1367.8110823165425 \t -0.022639468244276026\n",
      "50     \t [ 1.07884034 -0.77391733]. \t  -375.51845267332675 \t -0.022639468244276026\n",
      "51     \t [1.10509042 1.21305053]. \t  \u001b[92m-0.017725906549569518\u001b[0m \t -0.017725906549569518\n",
      "52     \t [1.06787596 1.50220612]. \t  -13.097936834894565 \t -0.017725906549569518\n",
      "53     \t [-1.91575767  0.80636003]. \t  -828.6180337602005 \t -0.017725906549569518\n",
      "54     \t [ 1.33640129 -1.98497196]. \t  -1422.112288207265 \t -0.017725906549569518\n",
      "55     \t [1.36150796 0.10950186]. \t  -304.3547724944085 \t -0.017725906549569518\n",
      "56     \t [0.86087526 0.87608249]. \t  -1.8412153640303923 \t -0.017725906549569518\n",
      "57     \t [0.78199885 1.84257723]. \t  -151.59717337699607 \t -0.017725906549569518\n",
      "58     \t [1.11989231 1.43787492]. \t  -3.3895361513381856 \t -0.017725906549569518\n",
      "59     \t [1.33985866 0.61183215]. \t  -140.15647537331878 \t -0.017725906549569518\n",
      "60     \t [-1.30236794  0.33364756]. \t  -190.94553042720017 \t -0.017725906549569518\n",
      "61     \t [ 0.96605829 -1.70308143]. \t  -695.0353118378537 \t -0.017725906549569518\n",
      "62     \t [1.01128723 1.02304843]. \t  \u001b[92m-0.00013941255840303575\u001b[0m \t -0.00013941255840303575\n",
      "63     \t [1.1398112  0.20376816]. \t  -120.00997134785284 \t -0.00013941255840303575\n",
      "64     \t [0.59817056 0.0475923 ]. \t  -9.784846114456338 \t -0.00013941255840303575\n",
      "65     \t [-1.77277655  1.52298021]. \t  -270.04939509499866 \t -0.00013941255840303575\n",
      "66     \t [1.62328524 0.2425944 ]. \t  -572.7752459608489 \t -0.00013941255840303575\n",
      "67     \t [ 0.11045704 -0.56234626]. \t  -33.80171367090699 \t -0.00013941255840303575\n",
      "68     \t [0.90469727 0.74188447]. \t  -0.5957265545794443 \t -0.00013941255840303575\n",
      "69     \t [ 0.6223199  -1.17647918]. \t  -244.67756110001804 \t -0.00013941255840303575\n",
      "70     \t [0.70305428 0.49803023]. \t  -0.08957918866815748 \t -0.00013941255840303575\n",
      "71     \t [-0.00563666 -0.00470741]. \t  -1.0135510653789883 \t -0.00013941255840303575\n",
      "72     \t [ 0.64858514 -0.42238037]. \t  -71.19564986807805 \t -0.00013941255840303575\n",
      "73     \t [0.6816371  0.46556625]. \t  -0.10144275638778609 \t -0.00013941255840303575\n",
      "74     \t [0.05196484 0.87258143]. \t  -76.56808046490394 \t -0.00013941255840303575\n",
      "75     \t [-1.75397821  1.70608458]. \t  -195.3716718709708 \t -0.00013941255840303575\n",
      "76     \t [-1.97451512  0.71631577]. \t  -1021.6110062785283 \t -0.00013941255840303575\n",
      "77     \t [1.10741729 1.35267582]. \t  -1.6067772912141183 \t -0.00013941255840303575\n",
      "78     \t [1.30049088 1.08980651]. \t  -36.266911823135416 \t -0.00013941255840303575\n",
      "79     \t [1.63050026 1.93695047]. \t  -52.4653915293326 \t -0.00013941255840303575\n",
      "80     \t [-1.82189299 -0.21325121]. \t  -1255.8506822738773 \t -0.00013941255840303575\n",
      "81     \t [1.94760256 1.20542001]. \t  -670.535561913655 \t -0.00013941255840303575\n",
      "82     \t [ 2.01634525 -1.84747102]. \t  -3497.5308035624903 \t -0.00013941255840303575\n",
      "83     \t [ 0.15389382 -1.82459734]. \t  -342.3300302336196 \t -0.00013941255840303575\n",
      "84     \t [1.36532384 1.85886787]. \t  -0.13620864958795775 \t -0.00013941255840303575\n",
      "85     \t [ 1.44441036 -1.50784592]. \t  -1292.0013008349574 \t -0.00013941255840303575\n",
      "86     \t [-0.78246444 -0.2849564 ]. \t  -83.67521992782655 \t -0.00013941255840303575\n",
      "87     \t [-1.61366319 -0.50230961]. \t  -971.6905797738854 \t -0.00013941255840303575\n",
      "88     \t [-1.2066017   0.82761983]. \t  -44.34113608716555 \t -0.00013941255840303575\n",
      "89     \t [ 0.28571035 -1.11243923]. \t  -143.09043920326812 \t -0.00013941255840303575\n",
      "90     \t [0.8293305  0.65332881]. \t  -0.14787914903096827 \t -0.00013941255840303575\n",
      "91     \t [0.78414171 0.63104523]. \t  -0.07273200346704696 \t -0.00013941255840303575\n",
      "92     \t [0.28499792 0.64516159]. \t  -32.313808839882356 \t -0.00013941255840303575\n",
      "93     \t [1.96566566 0.57193336]. \t  -1084.5984136418876 \t -0.00013941255840303575\n",
      "94     \t [1.23842987 0.23367128]. \t  -169.06654011705808 \t -0.00013941255840303575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95     \t [-1.27450582 -0.04055642]. \t  -282.369739842911 \t -0.00013941255840303575\n",
      "96     \t [2.01883811 0.44932336]. \t  -1316.1040813791585 \t -0.00013941255840303575\n",
      "97     \t [1.28196761 1.63049493]. \t  -0.09626567367141381 \t -0.00013941255840303575\n",
      "98     \t [1.27079709 1.60424069]. \t  -0.08474702215660249 \t -0.00013941255840303575\n",
      "99     \t [-1.21145443 -0.2025936 ]. \t  -283.8524872612958 \t -0.00013941255840303575\n",
      "100    \t [-1.32003346 -1.33258478]. \t  -950.9900196015825 \t -0.00013941255840303575\n"
     ]
    }
   ],
   "source": [
    "### 6(o). Bayesian optimization runs (x20): GP run number = 15\n",
    "\n",
    "np.random.seed(run_num_15)\n",
    "surrogate_gp_15 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_15 = GPGO(surrogate_gp_15, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_15.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.78925929  1.06790389]. \t  -462.98135799363985 \t -174.6665587456034\n",
      "init   \t [0.37808183 1.46309653]. \t  -174.6665587456034 \t -174.6665587456034\n",
      "init   \t [2.0362116 1.1002948]. \t  -928.8017963597329 \t -174.6665587456034\n",
      "init   \t [-1.131497   -1.81071027]. \t  -959.9687406625251 \t -174.6665587456034\n",
      "init   \t [1.79168794 1.86178159]. \t  -182.4353421998091 \t -174.6665587456034\n",
      "1      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -174.6665587456034\n",
      "2      \t [-0.16564603 -0.09049465]. \t  \u001b[92m-2.749555970448356\u001b[0m \t -2.749555970448356\n",
      "3      \t [-2.048     -0.4277565]. \t  -2145.634628362264 \t -2.749555970448356\n",
      "4      \t [-1.03536706  2.048     ]. \t  -99.40325512256334 \t -2.749555970448356\n",
      "5      \t [-2.048  2.048]. \t  -469.9523900415999 \t -2.749555970448356\n",
      "6      \t [-0.54612403  0.91342765]. \t  -40.23467433141954 \t -2.749555970448356\n",
      "7      \t [ 0.74009387 -0.11421008]. \t  -43.88520171331874 \t -2.749555970448356\n",
      "8      \t [ 0.17457031 -1.15791107]. \t  -141.90743056787738 \t -2.749555970448356\n",
      "9      \t [0.86639077 2.048     ]. \t  -168.33397288012347 \t -2.749555970448356\n",
      "10     \t [-0.06512382 -2.048     ]. \t  -422.30384669170735 \t -2.749555970448356\n",
      "11     \t [-0.2075649  2.048    ]. \t  -403.42735564041465 \t -2.749555970448356\n",
      "12     \t [0.2647907  0.41449311]. \t  -12.400221695049527 \t -2.749555970448356\n",
      "13     \t [ 0.26422152 -0.38457064]. \t  -21.187820693232332 \t -2.749555970448356\n",
      "14     \t [ 2.048      -0.26507774]. \t  -1989.7068528841571 \t -2.749555970448356\n",
      "15     \t [0.99004864 0.92189883]. \t  \u001b[92m-0.3399585792471699\u001b[0m \t -0.3399585792471699\n",
      "16     \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -0.3399585792471699\n",
      "17     \t [-0.49731503 -1.12387339]. \t  -190.25969796523947 \t -0.3399585792471699\n",
      "18     \t [-0.95439518  0.37757875]. \t  -32.25963287799368 \t -0.3399585792471699\n",
      "19     \t [1.14589301 1.53447708]. \t  -4.923359462270791 \t -0.3399585792471699\n",
      "20     \t [-1.14264912  1.42400077]. \t  -5.991706539660113 \t -0.3399585792471699\n",
      "21     \t [-0.58871054  0.3848794 ]. \t  -2.6706848202854943 \t -0.3399585792471699\n",
      "22     \t [0.67485877 0.36294018]. \t  -0.961234283958383 \t -0.3399585792471699\n",
      "23     \t [1.42728443 2.048     ]. \t  \u001b[92m-0.19436410351088762\u001b[0m \t -0.19436410351088762\n",
      "24     \t [-0.77146078 -0.28653563]. \t  -80.87533539961875 \t -0.19436410351088762\n",
      "25     \t [-0.60361785 -2.048     ]. \t  -584.5170187962701 \t -0.19436410351088762\n",
      "26     \t [ 0.78376242 -2.048     ]. \t  -708.8221191762182 \t -0.19436410351088762\n",
      "27     \t [0.79976192 1.03820003]. \t  -15.926769375355814 \t -0.19436410351088762\n",
      "28     \t [-0.84499491  1.55467608]. \t  -74.07487654837456 \t -0.19436410351088762\n",
      "29     \t [-1.03131358  0.98555837]. \t  -4.735404740238378 \t -0.19436410351088762\n",
      "30     \t [ 0.90679645 -1.12721231]. \t  -380.06063446518596 \t -0.19436410351088762\n",
      "31     \t [-1.4567574  2.048    ]. \t  -6.585362285406912 \t -0.19436410351088762\n",
      "32     \t [0.3619848  0.03012261]. \t  -1.4253539644599527 \t -0.19436410351088762\n",
      "33     \t [2.048 2.048]. \t  -461.7603900415999 \t -0.19436410351088762\n",
      "34     \t [1.35819595 1.78778643]. \t  -0.45217707065754276 \t -0.19436410351088762\n",
      "35     \t [1.25742672 1.40113189]. \t  -3.3059115124583003 \t -0.19436410351088762\n",
      "36     \t [-1.32833652  1.83359794]. \t  -5.898908762231651 \t -0.19436410351088762\n",
      "37     \t [-2.048       0.38344885]. \t  -1461.5520017722404 \t -0.19436410351088762\n",
      "38     \t [ 2.048      -1.11161069]. \t  -2816.371373727551 \t -0.19436410351088762\n",
      "39     \t [-0.21998641  0.13066274]. \t  -2.165180999102723 \t -0.19436410351088762\n",
      "40     \t [-0.46575307  0.06656495]. \t  -4.409274101294532 \t -0.19436410351088762\n",
      "41     \t [1.1426701  1.33573703]. \t  \u001b[92m-0.11060742255798409\u001b[0m \t -0.11060742255798409\n",
      "42     \t [0.827941   0.71620837]. \t  -0.12398889720301288 \t -0.11060742255798409\n",
      "43     \t [-1.51624523 -1.15046487]. \t  -1196.2120026706648 \t -0.11060742255798409\n",
      "44     \t [0.10959751 0.01397923]. \t  -0.7932037433083686 \t -0.11060742255798409\n",
      "45     \t [1.12735004 1.2775959 ]. \t  \u001b[92m-0.02067730523865495\u001b[0m \t -0.02067730523865495\n",
      "46     \t [0.81168356 0.66921129]. \t  -0.04623977763718967 \t -0.02067730523865495\n",
      "47     \t [1.23383499 1.4973899 ]. \t  -0.1169733287352853 \t -0.02067730523865495\n",
      "48     \t [1.24676071 1.54895027]. \t  -0.0638741931311451 \t -0.02067730523865495\n",
      "49     \t [1.40647616 2.04799818]. \t  -0.6527478859759537 \t -0.02067730523865495\n",
      "50     \t [0.94251138 0.92230478]. \t  -0.11874909201400691 \t -0.02067730523865495\n",
      "51     \t [1.04179606 1.09190928]. \t  \u001b[92m-0.006063719310549428\u001b[0m \t -0.006063719310549428\n",
      "52     \t [1.30698122 1.67319718]. \t  -0.21675650871263583 \t -0.006063719310549428\n",
      "53     \t [-0.81543008  0.65552989]. \t  -3.3046154698081476 \t -0.006063719310549428\n",
      "54     \t [ 0.51069956 -1.60682988]. \t  -349.04879562139075 \t -0.006063719310549428\n",
      "55     \t [0.56371282 0.25194022]. \t  -0.6237306841709642 \t -0.006063719310549428\n",
      "56     \t [0.67903221 0.46773642]. \t  -0.1074448070646639 \t -0.006063719310549428\n",
      "57     \t [1.17472977 1.40092143]. \t  -0.074342824832183 \t -0.006063719310549428\n",
      "58     \t [0.80767114 0.6445394 ]. \t  -0.04306390899897354 \t -0.006063719310549428\n",
      "59     \t [1.07773018 1.19674552]. \t  -0.13025018172316616 \t -0.006063719310549428\n",
      "60     \t [1.2319358  1.52367322]. \t  -0.05740311557665126 \t -0.006063719310549428\n",
      "61     \t [1.39235621 1.94879744]. \t  -0.16422866385296622 \t -0.006063719310549428\n",
      "62     \t [1.02153759 1.06237719]. \t  -0.03595140720622198 \t -0.006063719310549428\n",
      "63     \t [0.99169173 1.02412249]. \t  -0.16547389239080015 \t -0.006063719310549428\n",
      "64     \t [0.40016472 0.19727705]. \t  -0.4977792994022607 \t -0.006063719310549428\n",
      "65     \t [0.16916703 0.05608714]. \t  -0.76574162144391 \t -0.006063719310549428\n",
      "66     \t [0.77421707 0.60879544]. \t  -0.05978267896163174 \t -0.006063719310549428\n",
      "67     \t [0.70969262 0.45565887]. \t  -0.3147239230015585 \t -0.006063719310549428\n",
      "68     \t [0.66361713 0.44383155]. \t  -0.11433944523595177 \t -0.006063719310549428\n",
      "69     \t [0.18891455 0.03225501]. \t  -0.6590386323847499 \t -0.006063719310549428\n",
      "70     \t [1.22712866 1.50812939]. \t  -0.052109387181242826 \t -0.006063719310549428\n",
      "71     \t [1.01430551 1.04023564]. \t  -0.013246245018075817 \t -0.006063719310549428\n",
      "72     \t [1.16327848 1.31291407]. \t  -0.18909104963336515 \t -0.006063719310549428\n",
      "73     \t [0.63528724 0.38839436]. \t  -0.15610575501536725 \t -0.006063719310549428\n",
      "74     \t [0.73309073 0.56826732]. \t  -0.16638381250032072 \t -0.006063719310549428\n",
      "75     \t [0.94123979 0.92748217]. \t  -0.17609157120507588 \t -0.006063719310549428\n",
      "76     \t [1.29123344 1.66022527]. \t  -0.08979919438119134 \t -0.006063719310549428\n",
      "77     \t [1.00127339 1.0367718 ]. \t  -0.11712568134625413 \t -0.006063719310549428\n",
      "78     \t [0.59210896 0.38038974]. \t  -0.25515959654417275 \t -0.006063719310549428\n",
      "79     \t [1.11451944 1.27478479]. \t  -0.11959430929198253 \t -0.006063719310549428\n",
      "80     \t [1.03532635 1.11414249]. \t  -0.17968528317472365 \t -0.006063719310549428\n",
      "81     \t [1.01703104 1.06892681]. \t  -0.119830923343986 \t -0.006063719310549428\n",
      "82     \t [0.81092094 0.65106295]. \t  -0.04001475521305543 \t -0.006063719310549428\n",
      "83     \t [0.56426452 0.32727458]. \t  -0.1977510970446585 \t -0.006063719310549428\n",
      "84     \t [1.07726498 1.16935759]. \t  -0.013815864944230564 \t -0.006063719310549428\n",
      "85     \t [1.10962885 1.26728645]. \t  -0.14169237707328886 \t -0.006063719310549428\n",
      "86     \t [0.79759686 0.64197562]. \t  -0.04434830674154306 \t -0.006063719310549428\n",
      "87     \t [1.03103844 1.09000407]. \t  -0.07366810999586819 \t -0.006063719310549428\n",
      "88     \t [1.00452466 1.02088925]. \t  -0.013990457628239947 \t -0.006063719310549428\n",
      "89     \t [0.5355999  0.24504381]. \t  -0.390587470481143 \t -0.006063719310549428\n",
      "90     \t [0.82933042 0.65332873]. \t  -0.1478787614503339 \t -0.006063719310549428\n",
      "91     \t [1.07698914 1.19916988]. \t  -0.16009569156857967 \t -0.006063719310549428\n",
      "92     \t [1.19369604 1.42062178]. \t  -0.03935723708793521 \t -0.006063719310549428\n",
      "93     \t [1.14729203 1.36169693]. \t  -0.22797365333013672 \t -0.006063719310549428\n",
      "94     \t [1.2224537  1.45962623]. \t  -0.17035884878553054 \t -0.006063719310549428\n",
      "95     \t [1.14079394 1.32250905]. \t  -0.06433650953285687 \t -0.006063719310549428\n",
      "96     \t [1.12881245 1.30876706]. \t  -0.1359595051992429 \t -0.006063719310549428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [1.31352156 1.67478905]. \t  -0.35382432767015354 \t -0.006063719310549428\n",
      "98     \t [1.32518296 1.71530198]. \t  -0.27227246687274526 \t -0.006063719310549428\n",
      "99     \t [1.20326572 1.49253639]. \t  -0.24101859483350419 \t -0.006063719310549428\n",
      "100    \t [1.02804677 1.07851711]. \t  -0.0476023515560391 \t -0.006063719310549428\n"
     ]
    }
   ],
   "source": [
    "### 6(o). Bayesian optimization runs (x20): STP DF1 run number = 15\n",
    "\n",
    "np.random.seed(run_num_15)\n",
    "surrogate_stp_df1_15 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_15 = GPGO(surrogate_stp_df1_15, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_15.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.878072974721187, -5.1054319195515365)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(o). Training Regret Minimisation: run number = 15\n",
    "\n",
    "gp_output_15 = np.append(np.max(gpgo_gp_15.GP.y[0:n_init]),gpgo_gp_15.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_15 = np.append(np.max(gpgo_stp_df1_15.GP.y[0:n_init]),gpgo_stp_df1_15.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_15 = np.log(y_global_orig - gp_output_15)\n",
    "regret_stp_df1_15 = np.log(y_global_orig - stp_df1_output_15)\n",
    "\n",
    "train_regret_gp_15 = min_max_array(regret_gp_15)\n",
    "train_regret_stp_df1_15 = min_max_array(regret_stp_df1_15)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 15\n",
    "min_train_regret_gp_15 = min(train_regret_gp_15)\n",
    "min_train_regret_stp_df1_15 = min(train_regret_stp_df1_15)\n",
    "\n",
    "min_train_regret_gp_15, min_train_regret_stp_df1_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 1.49073237 -0.75216486]. \t  -884.9748202573794 \t -21.690996320546372\n",
      "init   \t [0.70512959 0.03240619]. \t  -21.690996320546372 \t -21.690996320546372\n",
      "init   \t [ 1.15368111 -0.88603985]. \t  -491.54136063574043 \t -21.690996320546372\n",
      "init   \t [-1.09072882  0.26132352]. \t  -90.5574614167091 \t -21.690996320546372\n",
      "init   \t [1.5360998 0.8967902]. \t  -214.26941031258198 \t -21.690996320546372\n",
      "1      \t [ 0.01925238 -1.03263826]. \t  -107.6726081479984 \t -21.690996320546372\n",
      "2      \t [0.24241728 0.64168894]. \t  -34.55383093432714 \t -21.690996320546372\n",
      "3      \t [ 0.32122443 -0.08712067]. \t  \u001b[92m-4.082366258943083\u001b[0m \t -4.082366258943083\n",
      "4      \t [-2.048       0.58434351]. \t  -1312.4717794830356 \t -4.082366258943083\n",
      "5      \t [-0.67957813  0.06097681]. \t  -18.889024881428004 \t -4.082366258943083\n",
      "6      \t [ 0.44883147 -2.048     ]. \t  -506.30617494681 \t -4.082366258943083\n",
      "7      \t [-0.57582727  0.77096452]. \t  -21.789366611641395 \t -4.082366258943083\n",
      "8      \t [ 0.42941534 -0.34734035]. \t  -28.600084395312557 \t -4.082366258943083\n",
      "9      \t [0.51073819 0.28090357]. \t  \u001b[92m-0.27957764573446076\u001b[0m \t -0.27957764573446076\n",
      "10     \t [-1.36096462 -1.46986068]. \t  -1109.199269898038 \t -0.27957764573446076\n",
      "11     \t [0.22563357 0.02868629]. \t  -0.6490349679910357 \t -0.27957764573446076\n",
      "12     \t [-0.55348877  0.39689321]. \t  -3.23313791311665 \t -0.27957764573446076\n",
      "13     \t [-0.34728729  2.048     ]. \t  -373.29899710270627 \t -0.27957764573446076\n",
      "14     \t [0.38766804 0.15411857]. \t  -0.3764188948712501 \t -0.27957764573446076\n",
      "15     \t [0.44758652 1.78406243]. \t  -251.12483395628925 \t -0.27957764573446076\n",
      "16     \t [-1.52930951 -1.01038496]. \t  -1128.0930833336422 \t -0.27957764573446076\n",
      "17     \t [-0.48561958 -1.32420417]. \t  -245.5765963866809 \t -0.27957764573446076\n",
      "18     \t [1.28959433 1.43567933]. \t  -5.2537672055258255 \t -0.27957764573446076\n",
      "19     \t [1.64144605 2.048     ]. \t  -42.18765782388896 \t -0.27957764573446076\n",
      "20     \t [1.14214693 1.42611605]. \t  -1.49926144304751 \t -0.27957764573446076\n",
      "21     \t [0.68986958 1.53523052]. \t  -112.31005072817484 \t -0.27957764573446076\n",
      "22     \t [-1.09066884  1.80179203]. \t  -41.85388301514736 \t -0.27957764573446076\n",
      "23     \t [1.25311608 1.8460984 ]. \t  -7.670547811694383 \t -0.27957764573446076\n",
      "24     \t [1.26689939 1.61194796]. \t  \u001b[92m-0.07601546513115132\u001b[0m \t -0.07601546513115132\n",
      "25     \t [0.2693997  1.07008029]. \t  -100.03521822356028 \t -0.07601546513115132\n",
      "26     \t [-0.28520894  1.99131112]. \t  -366.44914700758426 \t -0.07601546513115132\n",
      "27     \t [ 0.67906291 -1.46483459]. \t  -371.0355872844689 \t -0.07601546513115132\n",
      "28     \t [-1.99274381  0.30019054]. \t  -1356.4611941865257 \t -0.07601546513115132\n",
      "29     \t [-1.08543708  1.22942987]. \t  -4.611767778568927 \t -0.07601546513115132\n",
      "30     \t [-0.83656415  0.66117106]. \t  -3.5224932624062006 \t -0.07601546513115132\n",
      "31     \t [ 0.79193639 -1.45821261]. \t  -434.9225345066252 \t -0.07601546513115132\n",
      "32     \t [-0.40342255 -1.92282347]. \t  -436.9311602155533 \t -0.07601546513115132\n",
      "33     \t [0.44858559 0.14463035]. \t  -0.6243989373758893 \t -0.07601546513115132\n",
      "34     \t [-1.22722795 -0.38785209]. \t  -363.66161351077665 \t -0.07601546513115132\n",
      "35     \t [-1.5064874   1.90884896]. \t  -19.289705956716983 \t -0.07601546513115132\n",
      "36     \t [ 0.23034354 -0.58857712]. \t  -41.761952530407115 \t -0.07601546513115132\n",
      "37     \t [-0.29731575  0.14691306]. \t  -2.0254451751424076 \t -0.07601546513115132\n",
      "38     \t [-1.12743965  1.91984752]. \t  -46.610718111637404 \t -0.07601546513115132\n",
      "39     \t [-1.69585202 -1.39566601]. \t  -1831.9072668479507 \t -0.07601546513115132\n",
      "40     \t [ 0.07572925 -2.0285615 ]. \t  -414.69046851086 \t -0.07601546513115132\n",
      "41     \t [-0.33921788  2.02645588]. \t  -367.13357261498413 \t -0.07601546513115132\n",
      "42     \t [1.51433978 2.00771194]. \t  -8.416314764337956 \t -0.07601546513115132\n",
      "43     \t [ 1.27618886 -1.3273556 ]. \t  -873.8779230470094 \t -0.07601546513115132\n",
      "44     \t [-1.46052524  2.048     ]. \t  -6.778963925105607 \t -0.07601546513115132\n",
      "45     \t [-0.61286995 -1.65116907]. \t  -413.3845153643779 \t -0.07601546513115132\n",
      "46     \t [0.67686122 1.11927547]. \t  -43.81428231245156 \t -0.07601546513115132\n",
      "47     \t [-0.22066691 -0.38020652]. \t  -19.885583106297887 \t -0.07601546513115132\n",
      "48     \t [1.35015396 2.04109485]. \t  -4.8828212273132925 \t -0.07601546513115132\n",
      "49     \t [1.39051078 1.8553051 ]. \t  -0.7642594133898644 \t -0.07601546513115132\n",
      "50     \t [-0.03078867 -0.10215075]. \t  -2.1254592892524284 \t -0.07601546513115132\n",
      "51     \t [-1.64505925  0.84496156]. \t  -353.4246094702246 \t -0.07601546513115132\n",
      "52     \t [-0.67517123 -1.00998659]. \t  -217.67570332419444 \t -0.07601546513115132\n",
      "53     \t [-1.27228905 -1.86451717]. \t  -1218.457017748896 \t -0.07601546513115132\n",
      "54     \t [ 0.82517819 -1.33677215]. \t  -407.1383404308359 \t -0.07601546513115132\n",
      "55     \t [-0.64063064 -1.4676662 ]. \t  -355.40779388843447 \t -0.07601546513115132\n",
      "56     \t [ 1.44253993 -0.83813951]. \t  -852.2875350360233 \t -0.07601546513115132\n",
      "57     \t [-1.20340356  0.65695278]. \t  -67.45905943685975 \t -0.07601546513115132\n",
      "58     \t [ 1.74567009 -1.89656171]. \t  -2444.796244157968 \t -0.07601546513115132\n",
      "59     \t [0.02346288 1.9066815 ]. \t  -364.2871597262516 \t -0.07601546513115132\n",
      "60     \t [0.00200424 1.56567155]. \t  -246.12747811354427 \t -0.07601546513115132\n",
      "61     \t [-0.78139034  0.53479172]. \t  -3.747599573318423 \t -0.07601546513115132\n",
      "62     \t [ 1.35482936 -0.40326941]. \t  -501.3627715286027 \t -0.07601546513115132\n",
      "63     \t [-0.19401555 -0.5657402 ]. \t  -37.83268513239098 \t -0.07601546513115132\n",
      "64     \t [-1.88164839 -0.66326923]. \t  -1775.5560972745068 \t -0.07601546513115132\n",
      "65     \t [-0.35956237  1.98789795]. \t  -347.292581304873 \t -0.07601546513115132\n",
      "66     \t [-1.5604096  -1.72930828]. \t  -1740.6005414601545 \t -0.07601546513115132\n",
      "67     \t [-0.51937017 -1.56237223]. \t  -337.97397823813054 \t -0.07601546513115132\n",
      "68     \t [ 1.47032429 -0.11759852]. \t  -519.8113640209032 \t -0.07601546513115132\n",
      "69     \t [1.29801797 1.061399  ]. \t  -38.95801006777799 \t -0.07601546513115132\n",
      "70     \t [ 1.27704013 -0.05560941]. \t  -284.48504812707824 \t -0.07601546513115132\n",
      "71     \t [1.02643429 1.05579493]. \t  \u001b[92m-0.0011949783326834463\u001b[0m \t -0.0011949783326834463\n",
      "72     \t [-0.20521007 -0.20636756]. \t  -7.626699547511159 \t -0.0011949783326834463\n",
      "73     \t [1.1016562  1.21192855]. \t  -0.010629080062384524 \t -0.0011949783326834463\n",
      "74     \t [1.09911722 1.20612694]. \t  -0.01019737319415176 \t -0.0011949783326834463\n",
      "75     \t [-1.33548973  0.16839956]. \t  -266.3200555030319 \t -0.0011949783326834463\n",
      "76     \t [-1.13398124  1.03745487]. \t  -10.727043227510059 \t -0.0011949783326834463\n",
      "77     \t [-1.27488388  0.72116571]. \t  -86.92620525398058 \t -0.0011949783326834463\n",
      "78     \t [-0.0209748   0.02390357]. \t  -1.097443739468415 \t -0.0011949783326834463\n",
      "79     \t [ 1.95609107 -0.37593049]. \t  -1766.7817341777504 \t -0.0011949783326834463\n",
      "80     \t [1.91253661 0.98388592]. \t  -715.8123979341622 \t -0.0011949783326834463\n",
      "81     \t [-1.97445608 -2.00286589]. \t  -3491.4319350150254 \t -0.0011949783326834463\n",
      "82     \t [ 1.40973898 -1.13316608]. \t  -973.9386714775475 \t -0.0011949783326834463\n",
      "83     \t [ 1.67192921 -1.86254559]. \t  -2170.0480973974777 \t -0.0011949783326834463\n",
      "84     \t [ 0.51738178 -0.67274971]. \t  -88.67445975258771 \t -0.0011949783326834463\n",
      "85     \t [-0.72281118 -1.29658803]. \t  -333.8601983413895 \t -0.0011949783326834463\n",
      "86     \t [0.56832542 0.35812604]. \t  -0.3097705252017462 \t -0.0011949783326834463\n",
      "87     \t [ 0.52141901 -1.73419679]. \t  -402.66255897447763 \t -0.0011949783326834463\n",
      "88     \t [0.49179881 0.24537686]. \t  -0.25950100831749945 \t -0.0011949783326834463\n",
      "89     \t [0.12518397 0.9027846 ]. \t  -79.46235216551702 \t -0.0011949783326834463\n",
      "90     \t [ 0.27307719 -1.38925742]. \t  -214.80782634268718 \t -0.0011949783326834463\n",
      "91     \t [1.04560963 1.57958228]. \t  -23.64917436500178 \t -0.0011949783326834463\n",
      "92     \t [-0.07028959 -1.58607329]. \t  -254.27804647879904 \t -0.0011949783326834463\n",
      "93     \t [-1.5765528  -1.26771701]. \t  -1415.3164776664685 \t -0.0011949783326834463\n",
      "94     \t [-0.93985372  1.36091761]. \t  -26.572501212386467 \t -0.0011949783326834463\n",
      "95     \t [-0.6762613   1.75609806]. \t  -171.48987023474416 \t -0.0011949783326834463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [ 0.61478593 -0.26500832]. \t  -41.48944069562792 \t -0.0011949783326834463\n",
      "97     \t [-1.16529491  1.41904107]. \t  -5.062175677754481 \t -0.0011949783326834463\n",
      "98     \t [1.03446245 1.09305449]. \t  -0.05382082520092298 \t -0.0011949783326834463\n",
      "99     \t [-1.45038161  1.64952399]. \t  -26.623491401680013 \t -0.0011949783326834463\n",
      "100    \t [-1.31115942  1.94872672]. \t  -10.612508665163395 \t -0.0011949783326834463\n"
     ]
    }
   ],
   "source": [
    "### 6(p). Bayesian optimization runs (x20): GP run number = 16\n",
    "\n",
    "np.random.seed(run_num_16)\n",
    "surrogate_gp_16 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_16 = GPGO(surrogate_gp_16, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_16.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 1.49073237 -0.75216486]. \t  -884.9748202573794 \t -21.690996320546372\n",
      "init   \t [0.70512959 0.03240619]. \t  -21.690996320546372 \t -21.690996320546372\n",
      "init   \t [ 1.15368111 -0.88603985]. \t  -491.54136063574043 \t -21.690996320546372\n",
      "init   \t [-1.09072882  0.26132352]. \t  -90.5574614167091 \t -21.690996320546372\n",
      "init   \t [1.5360998 0.8967902]. \t  -214.26941031258198 \t -21.690996320546372\n",
      "1      \t [-0.10511704 -1.21466191]. \t  -151.4581516222752 \t -21.690996320546372\n",
      "2      \t [0.14462394 1.45090604]. \t  -205.21879457665017 \t -21.690996320546372\n",
      "3      \t [-2.048  2.048]. \t  -469.9523900415999 \t -21.690996320546372\n",
      "4      \t [-2.048 -2.048]. \t  -3905.9262268416055 \t -21.690996320546372\n",
      "5      \t [2.048 2.048]. \t  -461.7603900415999 \t -21.690996320546372\n",
      "6      \t [ 0.74851864 -2.048     ]. \t  -680.3757809691035 \t -21.690996320546372\n",
      "7      \t [-0.04936231 -0.3197445 ]. \t  \u001b[92m-11.481229633157227\u001b[0m \t -11.481229633157227\n",
      "8      \t [-2.048       0.58386638]. \t  -1312.816284462508 \t -11.481229633157227\n",
      "9      \t [-0.83390202  2.048     ]. \t  -186.3178817913458 \t -11.481229633157227\n",
      "10     \t [-0.57679537  0.82674093]. \t  -26.894628600209007 \t -11.481229633157227\n",
      "11     \t [0.94279394 2.048     ]. \t  -134.3637297493764 \t -11.481229633157227\n",
      "12     \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -11.481229633157227\n",
      "13     \t [2.048      0.40728343]. \t  -1435.2507837604894 \t -11.481229633157227\n",
      "14     \t [0.95762336 1.15251065]. \t  \u001b[92m-5.546320299943908\u001b[0m \t -5.546320299943908\n",
      "15     \t [-0.04212114 -2.048     ]. \t  -421.24343974070763 \t -5.546320299943908\n",
      "16     \t [-0.82231746 -0.44675631]. \t  -129.42527571404526 \t -5.546320299943908\n",
      "17     \t [-0.56071944  0.1693334 ]. \t  \u001b[92m-4.540459548456107\u001b[0m \t -4.540459548456107\n",
      "18     \t [1.37737131 1.53232351]. \t  -13.452372717100479 \t -4.540459548456107\n",
      "19     \t [ 0.38798356 -0.75822462]. \t  -82.95828501987003 \t -4.540459548456107\n",
      "20     \t [-1.12469439  1.33319573]. \t  -4.980245388378682 \t -4.540459548456107\n",
      "21     \t [0.0070457 2.048    ]. \t  -420.39602518827724 \t -4.540459548456107\n",
      "22     \t [-0.78570735  1.40674678]. \t  -65.50568120641518 \t -4.540459548456107\n",
      "23     \t [-1.4068381  2.048    ]. \t  -6.266303961548777 \t -4.540459548456107\n",
      "24     \t [0.33105461 0.5021779 ]. \t  -15.859452105651405 \t -4.540459548456107\n",
      "25     \t [-2.048      -0.60552779]. \t  -2313.128827414774 \t -4.540459548456107\n",
      "26     \t [2.048      1.40998888]. \t  -776.3393740849422 \t -4.540459548456107\n",
      "27     \t [0.91031609 0.61202438]. \t  -4.701809046754492 \t -4.540459548456107\n",
      "28     \t [1.44034846 2.048     ]. \t  \u001b[92m-0.26468245921785616\u001b[0m \t -0.26468245921785616\n",
      "29     \t [-0.97890712  0.86734619]. \t  -4.742590097083503 \t -0.26468245921785616\n",
      "30     \t [-0.86886352 -2.048     ]. \t  -789.1308468907318 \t -0.26468245921785616\n",
      "31     \t [-1.29738217  1.78285536]. \t  -6.271074090011861 \t -0.26468245921785616\n",
      "32     \t [1.14654627 1.11012901]. \t  -4.20102007336312 \t -0.26468245921785616\n",
      "33     \t [-0.33453948 -0.53963768]. \t  -44.23330177023803 \t -0.26468245921785616\n",
      "34     \t [1.28445641 1.76841927]. \t  -1.4872982475334542 \t -0.26468245921785616\n",
      "35     \t [-0.76612679 -1.32649587]. \t  -369.2468132201336 \t -0.26468245921785616\n",
      "36     \t [0.360978   0.05470195]. \t  -0.9799329362339316 \t -0.26468245921785616\n",
      "37     \t [ 0.48765455 -1.50908399]. \t  -305.42529787533226 \t -0.26468245921785616\n",
      "38     \t [-0.0484214   0.10271708]. \t  -2.106650211600801 \t -0.26468245921785616\n",
      "39     \t [-0.79210597  0.58871917]. \t  -3.361511073070003 \t -0.26468245921785616\n",
      "40     \t [1.39051319 1.87628103]. \t  -0.48020978338084647 \t -0.26468245921785616\n",
      "41     \t [-2.048       1.44111181]. \t  -767.2970272143916 \t -0.26468245921785616\n",
      "42     \t [-0.92706921  1.01874794]. \t  -6.250945949803674 \t -0.26468245921785616\n",
      "43     \t [ 2.048      -1.23153536]. \t  -2945.0715746518163 \t -0.26468245921785616\n",
      "44     \t [ 0.1393837  -0.01744618]. \t  -0.8766296084952218 \t -0.26468245921785616\n",
      "45     \t [1.41395629 2.04799999]. \t  -0.4087978355584805 \t -0.26468245921785616\n",
      "46     \t [0.83399625 0.74500536]. \t  -0.27214304027771463 \t -0.26468245921785616\n",
      "47     \t [0.95770757 0.90818216]. \t  \u001b[92m-0.009927621317832295\u001b[0m \t -0.009927621317832295\n",
      "48     \t [1.35668294 1.8983668 ]. \t  -0.46105478041088677 \t -0.009927621317832295\n",
      "49     \t [1.23777543 1.55937098]. \t  -0.13097321309493098 \t -0.009927621317832295\n",
      "50     \t [-1.56887063 -1.34084319]. \t  -1452.2702505538016 \t -0.009927621317832295\n",
      "51     \t [0.77707073 0.60472233]. \t  -0.04977549792612022 \t -0.009927621317832295\n",
      "52     \t [0.6286933 0.4074683]. \t  -0.1527845159716363 \t -0.009927621317832295\n",
      "53     \t [0.65257111 0.40968437]. \t  -0.14683654614052263 \t -0.009927621317832295\n",
      "54     \t [-1.29309941  2.048     ]. \t  -19.387928768385358 \t -0.009927621317832295\n",
      "55     \t [1.3425452 1.784615 ]. \t  -0.14906611237391756 \t -0.009927621317832295\n",
      "56     \t [0.52753665 0.27807375]. \t  -0.22322651189162537 \t -0.009927621317832295\n",
      "57     \t [1.13864973 1.30401606]. \t  -0.024838008796595767 \t -0.009927621317832295\n",
      "58     \t [1.31215734 1.71526275]. \t  -0.10165960273288929 \t -0.009927621317832295\n",
      "59     \t [1.20528464 1.43240506]. \t  -0.0833751364925287 \t -0.009927621317832295\n",
      "60     \t [1.06216161 1.14081248]. \t  -0.01980362789774294 \t -0.009927621317832295\n",
      "61     \t [1.32091488 1.80196498]. \t  -0.4295855667962535 \t -0.009927621317832295\n",
      "62     \t [0.23328617 0.0812592 ]. \t  -0.6598712871177529 \t -0.009927621317832295\n",
      "63     \t [-0.10133665 -0.02122619]. \t  -1.312137893621095 \t -0.009927621317832295\n",
      "64     \t [0.57623598 0.29820817]. \t  -0.2940886491341256 \t -0.009927621317832295\n",
      "65     \t [1.09956888 1.17462139]. \t  -0.12845883353741983 \t -0.009927621317832295\n",
      "66     \t [0.52248363 0.2877346 ]. \t  -0.24976471362434333 \t -0.009927621317832295\n",
      "67     \t [0.98060879 0.93912368]. \t  -0.05086573637070012 \t -0.009927621317832295\n",
      "68     \t [0.60721492 0.35047452]. \t  -0.18753321882462362 \t -0.009927621317832295\n",
      "69     \t [0.86730473 0.74696053]. \t  -0.020371594728275592 \t -0.009927621317832295\n",
      "70     \t [1.38168582 2.00779318]. \t  -1.120592738578175 \t -0.009927621317832295\n",
      "71     \t [0.92004086 0.85367122]. \t  -0.011571753467106455 \t -0.009927621317832295\n",
      "72     \t [1.17521454 1.39556105]. \t  -0.051527888910838884 \t -0.009927621317832295\n",
      "73     \t [1.25918494 1.5972388 ]. \t  -0.08084734349879602 \t -0.009927621317832295\n",
      "74     \t [1.17001987 1.3447501 ]. \t  -0.08745329084247008 \t -0.009927621317832295\n",
      "75     \t [1.15645376 1.28980836]. \t  -0.2508342077925243 \t -0.009927621317832295\n",
      "76     \t [0.49402913 0.22594906]. \t  -0.28882444719442163 \t -0.009927621317832295\n",
      "77     \t [1.10379319 1.1785308 ]. \t  -0.16940488468440726 \t -0.009927621317832295\n",
      "78     \t [1.28765011 1.66810655]. \t  -0.0928704777577084 \t -0.009927621317832295\n",
      "79     \t [0.95566284 0.89958729]. \t  -0.020746230957359956 \t -0.009927621317832295\n",
      "80     \t [1.04595521 1.13890742]. \t  -0.20357921511280738 \t -0.009927621317832295\n",
      "81     \t [0.81457759 0.6411396 ]. \t  -0.08454422775101345 \t -0.009927621317832295\n",
      "82     \t [1.13301348 1.28381517]. \t  -0.01769349934826888 \t -0.009927621317832295\n",
      "83     \t [0.78816269 0.63470278]. \t  -0.06310639777230717 \t -0.009927621317832295\n",
      "84     \t [0.92477028 0.85084606]. \t  \u001b[92m-0.0075552598508329795\u001b[0m \t -0.0075552598508329795\n",
      "85     \t [0.74152806 0.51782367]. \t  -0.16946507434910912 \t -0.0075552598508329795\n",
      "86     \t [1.38667447 1.92515473]. \t  -0.15004093510485278 \t -0.0075552598508329795\n",
      "87     \t [1.07137905 1.10805622]. \t  -0.1634738766332788 \t -0.0075552598508329795\n",
      "88     \t [0.49652896 0.24105326]. \t  -0.256494624176258 \t -0.0075552598508329795\n",
      "89     \t [0.59741746 0.34394379]. \t  -0.17887880404873907 \t -0.0075552598508329795\n",
      "90     \t [0.86413727 0.7457258 ]. \t  -0.018560171771786472 \t -0.0075552598508329795\n",
      "91     \t [1.23205315 1.49513766]. \t  -0.10591164894483905 \t -0.0075552598508329795\n",
      "92     \t [0.87661417 0.79530389]. \t  -0.0873243508554715 \t -0.0075552598508329795\n",
      "93     \t [0.86164503 0.76995757]. \t  -0.09490697593454858 \t -0.0075552598508329795\n",
      "94     \t [1.33756067 1.76975285]. \t  -0.1512568009925046 \t -0.0075552598508329795\n",
      "95     \t [0.93637046 0.87096123]. \t  \u001b[92m-0.007445752656953233\u001b[0m \t -0.007445752656953233\n",
      "96     \t [0.59679598 0.3383634 ]. \t  -0.19426473593530308 \t -0.007445752656953233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.73340407 0.55774155]. \t  -0.11051540211014049 \t -0.007445752656953233\n",
      "98     \t [1.03446245 1.09305449]. \t  -0.05382082520092298 \t -0.007445752656953233\n",
      "99     \t [0.084143   0.00645478]. \t  -0.8388331387526423 \t -0.007445752656953233\n",
      "100    \t [0.8066092  0.64895099]. \t  -0.037678027346164496 \t -0.007445752656953233\n"
     ]
    }
   ],
   "source": [
    "### 6(p). Bayesian optimization runs (x20): STP DF1 run number = 16\n",
    "\n",
    "np.random.seed(run_num_16)\n",
    "surrogate_stp_df1_16 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_16 = GPGO(surrogate_stp_df1_16, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_16.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.729627225408695, -4.900111522327611)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(p). Training Regret Minimisation: run number = 16\n",
    "\n",
    "gp_output_16 = np.append(np.max(gpgo_gp_16.GP.y[0:n_init]),gpgo_gp_16.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_16 = np.append(np.max(gpgo_stp_df1_16.GP.y[0:n_init]),gpgo_stp_df1_16.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_16 = np.log(y_global_orig - gp_output_16)\n",
    "regret_stp_df1_16 = np.log(y_global_orig - stp_df1_output_16)\n",
    "\n",
    "train_regret_gp_16 = min_max_array(regret_gp_16)\n",
    "train_regret_stp_df1_16 = min_max_array(regret_stp_df1_16)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 16\n",
    "min_train_regret_gp_16 = min(train_regret_gp_16)\n",
    "min_train_regret_stp_df1_16 = min(train_regret_stp_df1_16)\n",
    "\n",
    "min_train_regret_gp_16, min_train_regret_stp_df1_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.92257877 -1.72323712]. \t  -2945.6896231815967 \t -1.2855394201877957\n",
      "init   \t [0.56295847 0.21230226]. \t  -1.2855394201877957 \t -1.2855394201877957\n",
      "init   \t [ 0.98653632 -0.11490556]. \t  -118.409285147173 \t -1.2855394201877957\n",
      "init   \t [0.914304   0.04294898]. \t  -62.89269011463567 \t -1.2855394201877957\n",
      "init   \t [-1.39848733 -0.80111063]. \t  -765.7900661642135 \t -1.2855394201877957\n",
      "1      \t [-1.11561189  0.21897775]. \t  -109.66384038613539 \t -1.2855394201877957\n",
      "2      \t [1.08551154 1.13437563]. \t  \u001b[92m-0.20055758502053156\u001b[0m \t -0.20055758502053156\n",
      "3      \t [-0.41349755 -0.3364445 ]. \t  -27.74596018951266 \t -0.20055758502053156\n",
      "4      \t [0.76833006 0.68983442]. \t  -1.0437624906634055 \t -0.20055758502053156\n",
      "5      \t [1.99703198 1.87876442]. \t  -445.93922080108007 \t -0.20055758502053156\n",
      "6      \t [0.98374514 0.88865655]. \t  -0.6259127426980962 \t -0.20055758502053156\n",
      "7      \t [0.58652491 2.048     ]. \t  -290.52865387526384 \t -0.20055758502053156\n",
      "8      \t [0.67387858 0.39091128]. \t  -0.5057926460877085 \t -0.20055758502053156\n",
      "9      \t [0.95685139 1.10198215]. \t  -3.4770127805689577 \t -0.20055758502053156\n",
      "10     \t [-0.84873464  1.70362303]. \t  -100.10030818943068 \t -0.20055758502053156\n",
      "11     \t [-1.93229765  2.00659746]. \t  -306.912320615356 \t -0.20055758502053156\n",
      "12     \t [0.62819257 1.15925956]. \t  -58.60470256334628 \t -0.20055758502053156\n",
      "13     \t [0.3583443  0.71761131]. \t  -35.12746553900054 \t -0.20055758502053156\n",
      "14     \t [-0.8354714   0.64089374]. \t  -3.695210107486544 \t -0.20055758502053156\n",
      "15     \t [-0.90078725  1.0743789 ]. \t  -10.527852738493802 \t -0.20055758502053156\n",
      "16     \t [-0.66908303  0.8445268 ]. \t  -18.53520269789352 \t -0.20055758502053156\n",
      "17     \t [-0.78622509 -0.34950879]. \t  -96.8269329011346 \t -0.20055758502053156\n",
      "18     \t [-0.77694323  1.84335777]. \t  -156.84734821093582 \t -0.20055758502053156\n",
      "19     \t [-0.68868716 -1.91410205]. \t  -573.2933235116582 \t -0.20055758502053156\n",
      "20     \t [ 0.13131559 -2.048     ]. \t  -427.2778019368797 \t -0.20055758502053156\n",
      "21     \t [ 0.53966965 -0.04768862]. \t  -11.699391148421888 \t -0.20055758502053156\n",
      "22     \t [-0.70346946 -1.38161866]. \t  -355.02250663803227 \t -0.20055758502053156\n",
      "23     \t [-0.29802778  1.1143413 ]. \t  -106.85415535198688 \t -0.20055758502053156\n",
      "24     \t [-1.2203966   0.09859707]. \t  -198.35450011439653 \t -0.20055758502053156\n",
      "25     \t [0.21779775 1.40455132]. \t  -184.78807669482597 \t -0.20055758502053156\n",
      "26     \t [0.59573878 0.36787177]. \t  \u001b[92m-0.18024165395529287\u001b[0m \t -0.18024165395529287\n",
      "27     \t [-1.34565203  1.39068733]. \t  -23.149816032658414 \t -0.18024165395529287\n",
      "28     \t [-0.61830742  0.34066604]. \t  -2.7922913760530013 \t -0.18024165395529287\n",
      "29     \t [ 1.51938719 -1.88530177]. \t  -1759.09850241174 \t -0.18024165395529287\n",
      "30     \t [ 1.17762392 -1.99274741]. \t  -1142.1643301981562 \t -0.18024165395529287\n",
      "31     \t [0.51330725 1.96100274]. \t  -288.3937418908541 \t -0.18024165395529287\n",
      "32     \t [0.58395649 0.37120919]. \t  -0.26432039478374464 \t -0.18024165395529287\n",
      "33     \t [-1.41754007  1.01992341]. \t  -103.75482047126485 \t -0.18024165395529287\n",
      "34     \t [-1.50387448  1.22264288]. \t  -114.22056803052358 \t -0.18024165395529287\n",
      "35     \t [-1.82835455  1.93124232]. \t  -207.2717907887309 \t -0.18024165395529287\n",
      "36     \t [-1.37469179  2.048     ]. \t  -8.142596590079306 \t -0.18024165395529287\n",
      "37     \t [1.1685561 1.8614435]. \t  -24.62208894602702 \t -0.18024165395529287\n",
      "38     \t [ 0.1115712  -0.00980897]. \t  -0.8388435873279545 \t -0.18024165395529287\n",
      "39     \t [-1.99038151 -0.16946836]. \t  -1715.5302830959315 \t -0.18024165395529287\n",
      "40     \t [-1.63342063  0.26973473]. \t  -582.1327259981563 \t -0.18024165395529287\n",
      "41     \t [1.94985643 1.14528055]. \t  -706.6862221561046 \t -0.18024165395529287\n",
      "42     \t [-0.20553658  0.08895356]. \t  -1.6714847744796868 \t -0.18024165395529287\n",
      "43     \t [0.74450404 0.5468075 ]. \t  \u001b[92m-0.07087137373020451\u001b[0m \t -0.07087137373020451\n",
      "44     \t [0.86023892 0.58405455]. \t  -2.451774542383613 \t -0.07087137373020451\n",
      "45     \t [-1.32443669  1.78664407]. \t  -5.508705817576718 \t -0.07087137373020451\n",
      "46     \t [-1.87883414 -1.63524026]. \t  -2676.2767109313468 \t -0.07087137373020451\n",
      "47     \t [ 0.39035904 -1.69233555]. \t  -340.6692754888371 \t -0.07087137373020451\n",
      "48     \t [ 0.66374859 -1.90789083]. \t  -551.6362196520979 \t -0.07087137373020451\n",
      "49     \t [-0.12037633  0.1624915 ]. \t  -3.4456740140606454 \t -0.07087137373020451\n",
      "50     \t [-0.55336313 -0.07056726]. \t  -16.609103921671412 \t -0.07087137373020451\n",
      "51     \t [-1.88899676  0.151418  ]. \t  -1175.8605564287416 \t -0.07087137373020451\n",
      "52     \t [-1.36906637 -1.05241835]. \t  -862.2055187318228 \t -0.07087137373020451\n",
      "53     \t [-0.42147075  2.04232026]. \t  -349.724723499616 \t -0.07087137373020451\n",
      "54     \t [0.01730213 0.45377082]. \t  -21.529330850556953 \t -0.07087137373020451\n",
      "55     \t [-0.32873578  1.73082128]. \t  -265.0986155477626 \t -0.07087137373020451\n",
      "56     \t [0.82304503 0.2879483 ]. \t  -15.198819267136848 \t -0.07087137373020451\n",
      "57     \t [-0.48199011  1.42205914]. \t  -143.74553413094134 \t -0.07087137373020451\n",
      "58     \t [1.22647388 0.06459706]. \t  -207.30794493919853 \t -0.07087137373020451\n",
      "59     \t [-0.13071265 -1.35820395]. \t  -190.42070117247692 \t -0.07087137373020451\n",
      "60     \t [ 1.43794771 -1.51633424]. \t  -1284.7173769960737 \t -0.07087137373020451\n",
      "61     \t [1.11884493 0.57299671]. \t  -46.09341087947555 \t -0.07087137373020451\n",
      "62     \t [1.59848461 0.07689577]. \t  -614.5340929366018 \t -0.07087137373020451\n",
      "63     \t [ 0.19117969 -1.22496964]. \t  -159.79728772919964 \t -0.07087137373020451\n",
      "64     \t [0.80370225 2.04668278]. \t  -196.24731895446516 \t -0.07087137373020451\n",
      "65     \t [-0.15594905 -1.48675059]. \t  -229.66968380559655 \t -0.07087137373020451\n",
      "66     \t [1.10700978 1.36262743]. \t  -1.8926495438415685 \t -0.07087137373020451\n",
      "67     \t [-1.813539   -1.51827444]. \t  -2318.8313949284957 \t -0.07087137373020451\n",
      "68     \t [ 2.00789457 -1.72090265]. \t  -3310.191259642298 \t -0.07087137373020451\n",
      "69     \t [-1.0875278  -1.79802158]. \t  -892.8378501252045 \t -0.07087137373020451\n",
      "70     \t [-0.67494875 -1.1783849 ]. \t  -269.78167829454793 \t -0.07087137373020451\n",
      "71     \t [1.38705111 0.95945909]. \t  -93.16651381601785 \t -0.07087137373020451\n",
      "72     \t [1.2841232  1.70644576]. \t  -0.411044868807932 \t -0.07087137373020451\n",
      "73     \t [-0.3280146  -0.53287133]. \t  -42.78315212404404 \t -0.07087137373020451\n",
      "74     \t [ 1.36966015 -1.50912317]. \t  -1146.0214968349853 \t -0.07087137373020451\n",
      "75     \t [-1.46302816  0.0778866 ]. \t  -431.4838650625267 \t -0.07087137373020451\n",
      "76     \t [-0.51618973 -1.93305714]. \t  -486.0828074916629 \t -0.07087137373020451\n",
      "77     \t [0.9635294  0.38378635]. \t  -29.660524877504447 \t -0.07087137373020451\n",
      "78     \t [1.02000321 1.27482462]. \t  -5.495582850074201 \t -0.07087137373020451\n",
      "79     \t [-1.48302599  0.63094446]. \t  -252.1600553216384 \t -0.07087137373020451\n",
      "80     \t [0.82128154 0.82593988]. \t  -2.3252419443573715 \t -0.07087137373020451\n",
      "81     \t [1.21411235 1.48358321]. \t  \u001b[92m-0.054896492733107385\u001b[0m \t -0.054896492733107385\n",
      "82     \t [-0.8320426  -0.77211577]. \t  -217.806238796374 \t -0.054896492733107385\n",
      "83     \t [-1.77360091  0.69732733]. \t  -607.1262402230498 \t -0.054896492733107385\n",
      "84     \t [-1.38102191 -0.80522878]. \t  -741.4079298182677 \t -0.054896492733107385\n",
      "85     \t [0.22334567 2.02196816]. \t  -389.5150675027305 \t -0.054896492733107385\n",
      "86     \t [-0.73887324  1.6806743 ]. \t  -131.78731045582677 \t -0.054896492733107385\n",
      "87     \t [0.50816433 1.10549151]. \t  -72.02694115717362 \t -0.054896492733107385\n",
      "88     \t [1.11988499 1.24346844]. \t  \u001b[92m-0.02576574949636641\u001b[0m \t -0.02576574949636641\n",
      "89     \t [-0.6435903  -1.86198225]. \t  -520.8058107850665 \t -0.02576574949636641\n",
      "90     \t [0.21796723 1.25855059]. \t  -147.27357549823023 \t -0.02576574949636641\n",
      "91     \t [0.92122953 1.53254323]. \t  -46.77530478282131 \t -0.02576574949636641\n",
      "92     \t [-1.92701999  1.54020635]. \t  -480.84713777047796 \t -0.02576574949636641\n",
      "93     \t [-0.2635168  -1.05635504]. \t  -128.33817115786437 \t -0.02576574949636641\n",
      "94     \t [-0.61253362  0.06725509]. \t  -12.083113810213671 \t -0.02576574949636641\n",
      "95     \t [1.1493321  1.31745892]. \t  \u001b[92m-0.023528822938271177\u001b[0m \t -0.023528822938271177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [-0.52471057  0.68139254]. \t  -18.81413722369031 \t -0.023528822938271177\n",
      "97     \t [-0.62926669 -0.09925503]. \t  -27.17994386429338 \t -0.023528822938271177\n",
      "98     \t [-1.57410819  0.46283783]. \t  -412.6399762734405 \t -0.023528822938271177\n",
      "99     \t [0.19900445 1.22254033]. \t  -140.5757203426576 \t -0.023528822938271177\n",
      "100    \t [1.1725631  1.13893093]. \t  -5.598117778113587 \t -0.023528822938271177\n"
     ]
    }
   ],
   "source": [
    "### 6(q). Bayesian optimization runs (x20): GP run number = 17\n",
    "\n",
    "np.random.seed(run_num_17)\n",
    "surrogate_gp_17 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_17 = GPGO(surrogate_gp_17, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_17.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.92257877 -1.72323712]. \t  -2945.6896231815967 \t -1.2855394201877957\n",
      "init   \t [0.56295847 0.21230226]. \t  -1.2855394201877957 \t -1.2855394201877957\n",
      "init   \t [ 0.98653632 -0.11490556]. \t  -118.409285147173 \t -1.2855394201877957\n",
      "init   \t [0.914304   0.04294898]. \t  -62.89269011463567 \t -1.2855394201877957\n",
      "init   \t [-1.39848733 -0.80111063]. \t  -765.7900661642135 \t -1.2855394201877957\n",
      "1      \t [-1.53584274  0.69544512]. \t  -283.10974146500666 \t -1.2855394201877957\n",
      "2      \t [1.65583801 2.01086875]. \t  -53.85610362798296 \t -1.2855394201877957\n",
      "3      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -1.2855394201877957\n",
      "4      \t [-0.18825386  2.048     ]. \t  -406.45191736243896 \t -1.2855394201877957\n",
      "5      \t [-2.048  2.048]. \t  -469.9523900415999 \t -1.2855394201877957\n",
      "6      \t [-0.23724379 -0.6732519 ]. \t  -54.75312464835126 \t -1.2855394201877957\n",
      "7      \t [2.048      0.77751097]. \t  -1168.545764183999 \t -1.2855394201877957\n",
      "8      \t [0.8518645 2.048    ]. \t  -174.87677883862827 \t -1.2855394201877957\n",
      "9      \t [-0.03235246 -2.048     ]. \t  -420.92498200617285 \t -1.2855394201877957\n",
      "10     \t [-2.048      0.0933151]. \t  -1691.1012960773157 \t -1.2855394201877957\n",
      "11     \t [-0.72093332  0.4294667 ]. \t  -3.77662591087104 \t -1.2855394201877957\n",
      "12     \t [-1.07617181  1.36649181]. \t  -8.651297388134909 \t -1.2855394201877957\n",
      "13     \t [0.48565957 1.15818613]. \t  -85.33213166531105 \t -1.2855394201877957\n",
      "14     \t [2.048 2.048]. \t  -461.7603900415999 \t -1.2855394201877957\n",
      "15     \t [-0.7799122  -0.31022011]. \t  -87.52921670925242 \t -1.2855394201877957\n",
      "16     \t [-0.58760705 -1.31298888]. \t  -277.50674415840285 \t -1.2855394201877957\n",
      "17     \t [1.21657295 1.47648135]. \t  \u001b[92m-0.04817719087615801\u001b[0m \t -0.04817719087615801\n",
      "18     \t [ 0.37913422 -1.19995658]. \t  -180.9382637229969 \t -0.04817719087615801\n",
      "19     \t [-0.95231646  0.91863019]. \t  -3.8252837241611637 \t -0.04817719087615801\n",
      "20     \t [-1.18542808  2.048     ]. \t  -46.09017073392517 \t -0.04817719087615801\n",
      "21     \t [ 2.048      -0.41467627]. \t  -2125.368217354991 \t -0.04817719087615801\n",
      "22     \t [ 0.4604276  -0.44923269]. \t  -44.013156147265995 \t -0.04817719087615801\n",
      "23     \t [-1.52703754  1.40743816]. \t  -91.8384674000338 \t -0.04817719087615801\n",
      "24     \t [1.35522078 2.048     ]. \t  -4.59419037723352 \t -0.04817719087615801\n",
      "25     \t [1.35920737 1.77898201]. \t  -0.5977434867080635 \t -0.04817719087615801\n",
      "26     \t [0.78902158 0.75853837]. \t  -1.8936583475540782 \t -0.04817719087615801\n",
      "27     \t [ 0.72499449 -2.048     ]. \t  -662.4260761538725 \t -0.04817719087615801\n",
      "28     \t [-0.17557204  0.57084602]. \t  -30.544180850635737 \t -0.04817719087615801\n",
      "29     \t [-0.23454951  0.04624293]. \t  -1.5318047421071501 \t -0.04817719087615801\n",
      "30     \t [-2.048       1.17770815]. \t  -919.2753579885735 \t -0.04817719087615801\n",
      "31     \t [-1.19255672  1.14442504]. \t  -12.522728086448588 \t -0.04817719087615801\n",
      "32     \t [-1.3687398   1.82968656]. \t  -5.802440128859979 \t -0.04817719087615801\n",
      "33     \t [-0.93647567 -2.048     ]. \t  -859.3046444683727 \t -0.04817719087615801\n",
      "34     \t [ 1.13237657 -1.22114071]. \t  -626.7273953458534 \t -0.04817719087615801\n",
      "35     \t [1.42420918 1.4127154 ]. \t  -38.083230995927956 \t -0.04817719087615801\n",
      "36     \t [ 0.11719802 -0.01257293]. \t  -0.8485520470385693 \t -0.04817719087615801\n",
      "37     \t [-1.47717272  2.048     ]. \t  -7.933036399836574 \t -0.04817719087615801\n",
      "38     \t [1.03739136 1.00424405]. \t  -0.518888030795611 \t -0.04817719087615801\n",
      "39     \t [0.78491188 0.54201369]. \t  -0.5949434198058681 \t -0.04817719087615801\n",
      "40     \t [-2.048      -0.89816158]. \t  -2602.6108772730327 \t -0.04817719087615801\n",
      "41     \t [1.03381759 1.15784008]. \t  -0.7943347093630237 \t -0.04817719087615801\n",
      "42     \t [ 2.048      -1.22460974]. \t  -2937.5609170809125 \t -0.04817719087615801\n",
      "43     \t [-1.16611722  0.11771163]. \t  -158.97771189735215 \t -0.04817719087615801\n",
      "44     \t [1.41961645 1.97519296]. \t  -0.33702263664944515 \t -0.04817719087615801\n",
      "45     \t [0.03320698 0.0614217 ]. \t  -1.298526825311955 \t -0.04817719087615801\n",
      "46     \t [1.04297811 1.08870664]. \t  \u001b[92m-0.001928712941465646\u001b[0m \t -0.001928712941465646\n",
      "47     \t [1.02772822 1.0714608 ]. \t  -0.0239809056881857 \t -0.001928712941465646\n",
      "48     \t [-0.06574701 -0.07588336]. \t  -1.7791173971534326 \t -0.001928712941465646\n",
      "49     \t [0.90211132 0.83505932]. \t  -0.054757544336985216 \t -0.001928712941465646\n",
      "50     \t [1.05050704 1.13196978]. \t  -0.08323384904267102 \t -0.001928712941465646\n",
      "51     \t [0.93128301 0.88473565]. \t  -0.03516390318577723 \t -0.001928712941465646\n",
      "52     \t [-0.33390935  1.4960477 ]. \t  -193.47780698667515 \t -0.001928712941465646\n",
      "53     \t [1.05981876 1.15388969]. \t  -0.09766702021010201 \t -0.001928712941465646\n",
      "54     \t [0.91583967 0.85137525]. \t  -0.02299160190033428 \t -0.001928712941465646\n",
      "55     \t [0.72121161 0.45375792]. \t  -0.518463179640314 \t -0.001928712941465646\n",
      "56     \t [0.88959791 0.79898685]. \t  -0.017968269049307088 \t -0.001928712941465646\n",
      "57     \t [1.39547322 2.00068319]. \t  -0.4408899136417727 \t -0.001928712941465646\n",
      "58     \t [1.12294558 1.29332744]. \t  -0.11957809650655629 \t -0.001928712941465646\n",
      "59     \t [1.21931722 1.43143816]. \t  -0.3538684610263495 \t -0.001928712941465646\n",
      "60     \t [1.04231929 1.11429946]. \t  -0.07946433664583961 \t -0.001928712941465646\n",
      "61     \t [1.17547192 1.38161379]. \t  -0.030791844598517255 \t -0.001928712941465646\n",
      "62     \t [1.40850802 2.048     ]. \t  -0.5778258497248426 \t -0.001928712941465646\n",
      "63     \t [1.02038604 1.08880452]. \t  -0.22715194142114364 \t -0.001928712941465646\n",
      "64     \t [1.42785334 1.980659  ]. \t  -0.5206911127053327 \t -0.001928712941465646\n",
      "65     \t [0.95610579 0.89003359]. \t  -0.06003027440075271 \t -0.001928712941465646\n",
      "66     \t [1.41375017 2.04799983]. \t  -0.4143395775312811 \t -0.001928712941465646\n",
      "67     \t [0.83932045 0.68300396]. \t  -0.07184902195863571 \t -0.001928712941465646\n",
      "68     \t [0.83096682 0.68498696]. \t  -0.03161803268858988 \t -0.001928712941465646\n",
      "69     \t [0.88483367 0.77626647]. \t  -0.017704380368180752 \t -0.001928712941465646\n",
      "70     \t [0.91614716 0.87086617]. \t  -0.10651185880699844 \t -0.001928712941465646\n",
      "71     \t [0.93391726 0.93382081]. \t  -0.3840615317305439 \t -0.001928712941465646\n",
      "72     \t [1.14228823 1.30331188]. \t  -0.020474109611976283 \t -0.001928712941465646\n",
      "73     \t [0.78324553 0.61994625]. \t  -0.05117205593239308 \t -0.001928712941465646\n",
      "74     \t [1.16281545 1.30441318]. \t  -0.25429157889066234 \t -0.001928712941465646\n",
      "75     \t [1.273913   1.57732017]. \t  -0.2823643334959542 \t -0.001928712941465646\n",
      "76     \t [1.10843375 1.25199474]. \t  -0.06637061742752302 \t -0.001928712941465646\n",
      "77     \t [0.7377527  0.45546163]. \t  -0.8576270235194104 \t -0.001928712941465646\n",
      "78     \t [0.97800533 0.97731454]. \t  -0.04383152386469975 \t -0.001928712941465646\n",
      "79     \t [-0.07444453  0.10488462]. \t  -2.1413268222674824 \t -0.001928712941465646\n",
      "80     \t [0.90013413 0.81451826]. \t  -0.01180229796149357 \t -0.001928712941465646\n",
      "81     \t [1.15488049 1.30569104]. \t  -0.10271251812525449 \t -0.001928712941465646\n",
      "82     \t [1.34478632 1.78705714]. \t  -0.16464412005016832 \t -0.001928712941465646\n",
      "83     \t [1.4265986 2.048    ]. \t  -0.19841245939028646 \t -0.001928712941465646\n",
      "84     \t [-1.25999026  1.55587108]. \t  -5.208072622432549 \t -0.001928712941465646\n",
      "85     \t [1.42465348 2.04799995]. \t  -0.2140483799201055 \t -0.001928712941465646\n",
      "86     \t [1.0555929  1.12274569]. \t  -0.010263510334864464 \t -0.001928712941465646\n",
      "87     \t [0.96801872 0.98773719]. \t  -0.25783813104798115 \t -0.001928712941465646\n",
      "88     \t [1.19816576 1.40128096]. \t  -0.15705757702185114 \t -0.001928712941465646\n",
      "89     \t [1.00475661 1.01308555]. \t  \u001b[92m-0.0012826624923980632\u001b[0m \t -0.0012826624923980632\n",
      "90     \t [0.70095595 0.47652763]. \t  -0.11136573347250671 \t -0.0012826624923980632\n",
      "91     \t [1.41088323 1.95720496]. \t  -0.28029099696432974 \t -0.0012826624923980632\n",
      "92     \t [1.40596136 1.93982312]. \t  -0.3009967586975595 \t -0.0012826624923980632\n",
      "93     \t [1.10267693 1.20627122]. \t  -0.01980698694990999 \t -0.0012826624923980632\n",
      "94     \t [0.58152212 0.32042911]. \t  -0.2065905048768734 \t -0.0012826624923980632\n",
      "95     \t [0.99585644 1.00411711]. \t  -0.015361081302139132 \t -0.0012826624923980632\n",
      "96     \t [1.07003734 1.12795211]. \t  -0.033899822016174294 \t -0.0012826624923980632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [1.42441561 2.048     ]. \t  -0.2163814003257875 \t -0.0012826624923980632\n",
      "98     \t [0.83128389 0.66246042]. \t  -0.11010384401917592 \t -0.0012826624923980632\n",
      "99     \t [0.67318911 0.45051498]. \t  -0.10751749787752288 \t -0.0012826624923980632\n",
      "100    \t [0.78860717 0.61896724]. \t  -0.045547782764973135 \t -0.0012826624923980632\n"
     ]
    }
   ],
   "source": [
    "### 6(q). Bayesian optimization runs (x20): STP DF1 run number = 17\n",
    "\n",
    "np.random.seed(run_num_17)\n",
    "surrogate_stp_df1_17 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_17 = GPGO(surrogate_stp_df1_17, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_17.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.7495291013669796, -6.658817289219496)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(q). Training Regret Minimisation: run number = 17\n",
    "\n",
    "gp_output_17 = np.append(np.max(gpgo_gp_17.GP.y[0:n_init]),gpgo_gp_17.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_17 = np.append(np.max(gpgo_stp_df1_17.GP.y[0:n_init]),gpgo_stp_df1_17.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_17 = np.log(y_global_orig - gp_output_17)\n",
    "regret_stp_df1_17 = np.log(y_global_orig - stp_df1_output_17)\n",
    "\n",
    "train_regret_gp_17 = min_max_array(regret_gp_17)\n",
    "train_regret_stp_df1_17 = min_max_array(regret_stp_df1_17)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 17\n",
    "min_train_regret_gp_17 = min(train_regret_gp_17)\n",
    "min_train_regret_stp_df1_17 = min(train_regret_stp_df1_17)\n",
    "\n",
    "min_train_regret_gp_17, min_train_regret_stp_df1_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.28500433 2.03942998]. \t  -383.9669247437713 \t -86.99615505222792\n",
      "init   \t [-1.73083914  0.68111838]. \t  -543.2344862917479 \t -86.99615505222792\n",
      "init   \t [0.39168995 1.08415253]. \t  -86.99615505222792 \t -86.99615505222792\n",
      "init   \t [-1.82494137  0.77337859]. \t  -661.8217769130504 \t -86.99615505222792\n",
      "init   \t [-0.48189538 -1.09099011]. \t  -177.28534938676964 \t -86.99615505222792\n",
      "1      \t [-0.62779595  0.15006756]. \t  \u001b[92m-8.606257839115505\u001b[0m \t -8.606257839115505\n",
      "2      \t [-1.57128423 -0.56455803]. \t  -926.8189659623977 \t -8.606257839115505\n",
      "3      \t [ 0.34421193 -1.648392  ]. \t  -312.61438099720993 \t -8.606257839115505\n",
      "4      \t [-0.62823577  0.67466725]. \t  -10.49042762805836 \t -8.606257839115505\n",
      "5      \t [1.30917194 0.60257172]. \t  -123.60756747056408 \t -8.606257839115505\n",
      "6      \t [-0.32983518  0.31053017]. \t  \u001b[92m-5.838321018826753\u001b[0m \t -5.838321018826753\n",
      "7      \t [-0.65711585  0.42064736]. \t  \u001b[92m-2.7584738793354466\u001b[0m \t -2.7584738793354466\n",
      "8      \t [-0.0671728 -0.435906 ]. \t  -20.535675826943944 \t -2.7584738793354466\n",
      "9      \t [-1.00608382  0.08563643]. \t  -89.87723987024016 \t -2.7584738793354466\n",
      "10     \t [ 0.9203992  -0.83870982]. \t  -284.213509228413 \t -2.7584738793354466\n",
      "11     \t [ 0.36177814 -1.06233387]. \t  -142.784078328484 \t -2.7584738793354466\n",
      "12     \t [ 1.7942845  -1.84802011]. \t  -2568.563164145012 \t -2.7584738793354466\n",
      "13     \t [ 0.8091956  -0.06807799]. \t  -52.29130737416532 \t -2.7584738793354466\n",
      "14     \t [0.92746398 1.08750217]. \t  -5.172369588100374 \t -2.7584738793354466\n",
      "15     \t [1.84148542 1.8358606 ]. \t  -242.57527958111936 \t -2.7584738793354466\n",
      "16     \t [-1.14424271  1.90539429]. \t  -40.13164394664246 \t -2.7584738793354466\n",
      "17     \t [ 0.17197732 -0.09229572]. \t  \u001b[92m-2.170897942185967\u001b[0m \t -2.170897942185967\n",
      "18     \t [-0.59879717  0.23018084]. \t  -4.204223199219763 \t -2.170897942185967\n",
      "19     \t [-1.2645625  1.7221277]. \t  -6.6413741007733496 \t -2.170897942185967\n",
      "20     \t [-1.05009563  1.34080321]. \t  -9.87216668424647 \t -2.170897942185967\n",
      "21     \t [1.59653483 1.97943016]. \t  -32.78811620800815 \t -2.170897942185967\n",
      "22     \t [1.21374015 2.048     ]. \t  -33.08919443552697 \t -2.170897942185967\n",
      "23     \t [0.81995181 0.78142458]. \t  \u001b[92m-1.2227771695578962\u001b[0m \t -1.2227771695578962\n",
      "24     \t [-1.14674476 -0.38717417]. \t  -294.3562166490043 \t -1.2227771695578962\n",
      "25     \t [-0.95947803  0.87896857]. \t  -4.012855937966593 \t -1.2227771695578962\n",
      "26     \t [ 1.45588969 -0.30586487]. \t  -588.5029972144636 \t -1.2227771695578962\n",
      "27     \t [ 0.03086654 -2.02832179]. \t  -412.73473438319525 \t -1.2227771695578962\n",
      "28     \t [-1.73462664  0.09702097]. \t  -855.3993646172465 \t -1.2227771695578962\n",
      "29     \t [-0.05147116  0.11613571]. \t  -2.3935084953314143 \t -1.2227771695578962\n",
      "30     \t [-1.62223609  1.81657941]. \t  -73.31011956406287 \t -1.2227771695578962\n",
      "31     \t [1.81197168 0.90883056]. \t  -564.4419624292781 \t -1.2227771695578962\n",
      "32     \t [-0.94777365 -0.48335307]. \t  -194.6834019045557 \t -1.2227771695578962\n",
      "33     \t [-0.16253196 -0.0311044 ]. \t  -1.6823475563015364 \t -1.2227771695578962\n",
      "34     \t [-1.62681672  1.28735144]. \t  -191.6375242556237 \t -1.2227771695578962\n",
      "35     \t [0.93392519 0.82441822]. \t  \u001b[92m-0.2328311259704203\u001b[0m \t -0.2328311259704203\n",
      "36     \t [ 2.00879447 -0.19493744]. \t  -1790.4706557837094 \t -0.2328311259704203\n",
      "37     \t [-2.01245403 -1.6271326 ]. \t  -3232.0256504142994 \t -0.2328311259704203\n",
      "38     \t [ 2.00621607 -0.31039019]. \t  -1880.4891021646722 \t -0.2328311259704203\n",
      "39     \t [-1.70043346  1.77834872]. \t  -131.197115978299 \t -0.2328311259704203\n",
      "40     \t [-1.50055984  0.07432238]. \t  -480.3413519793498 \t -0.2328311259704203\n",
      "41     \t [ 1.40974003 -0.19419299]. \t  -476.088270986778 \t -0.2328311259704203\n",
      "42     \t [-1.1116057   0.05941893]. \t  -142.81488834799205 \t -0.2328311259704203\n",
      "43     \t [-1.97850792  0.49994397]. \t  -1174.7864290098578 \t -0.2328311259704203\n",
      "44     \t [1.67595235 2.04113011]. \t  -59.39111959831813 \t -0.2328311259704203\n",
      "45     \t [1.27526455 1.29807746]. \t  -10.848753130941615 \t -0.2328311259704203\n",
      "46     \t [-0.23904153 -1.26708559]. \t  -176.8927902751648 \t -0.2328311259704203\n",
      "47     \t [1.30707    1.75238275]. \t  -0.28745907054897235 \t -0.2328311259704203\n",
      "48     \t [1.02119016 1.01266795]. \t  \u001b[92m-0.0914199989508906\u001b[0m \t -0.0914199989508906\n",
      "49     \t [1.00708192 0.99747419]. \t  \u001b[92m-0.028072247545169335\u001b[0m \t -0.028072247545169335\n",
      "50     \t [1.42892894 2.048     ]. \t  -0.1877771697758641 \t -0.028072247545169335\n",
      "51     \t [0.70751038 1.32428755]. \t  -67.93645757446878 \t -0.028072247545169335\n",
      "52     \t [1.84145517 1.99751385]. \t  -194.8764718631536 \t -0.028072247545169335\n",
      "53     \t [-1.20950633  1.34112142]. \t  -6.365055963667403 \t -0.028072247545169335\n",
      "54     \t [0.44349845 0.13020974]. \t  -0.751668190531777 \t -0.028072247545169335\n",
      "55     \t [1.24387067 1.90398537]. \t  -12.788035895611081 \t -0.028072247545169335\n",
      "56     \t [ 1.66528177 -0.38708119]. \t  -999.1571736418817 \t -0.028072247545169335\n",
      "57     \t [0.76013576 0.51396462]. \t  -0.4651117111528098 \t -0.028072247545169335\n",
      "58     \t [1.41933139 1.43273651]. \t  -34.02090039122564 \t -0.028072247545169335\n",
      "59     \t [-1.44648279  2.048     ]. \t  -6.181637315964092 \t -0.028072247545169335\n",
      "60     \t [1.7190514  0.64379237]. \t  -534.7487666814831 \t -0.028072247545169335\n",
      "61     \t [1.29954615 1.67322008]. \t  -0.11406423731821601 \t -0.028072247545169335\n",
      "62     \t [1.65786458 0.78860556]. \t  -384.5572725601725 \t -0.028072247545169335\n",
      "63     \t [0.41712476 1.57362739]. \t  -196.23736655512533 \t -0.028072247545169335\n",
      "64     \t [-0.75596112  0.65313445]. \t  -3.7501897234674924 \t -0.028072247545169335\n",
      "65     \t [0.1318565  0.46801133]. \t  -21.059979076460625 \t -0.028072247545169335\n",
      "66     \t [-1.83605573 -1.06734837]. \t  -1978.026170614163 \t -0.028072247545169335\n",
      "67     \t [ 1.2590946  -0.15183433]. \t  -301.83737473704144 \t -0.028072247545169335\n",
      "68     \t [-1.08508553 -0.1813522 ]. \t  -188.97121646658076 \t -0.028072247545169335\n",
      "69     \t [-0.90218863  0.94830232]. \t  -5.4235286626686765 \t -0.028072247545169335\n",
      "70     \t [-0.22943239  0.71180107]. \t  -44.96093886656874 \t -0.028072247545169335\n",
      "71     \t [ 0.17268229 -1.62224187]. \t  -273.6150246116202 \t -0.028072247545169335\n",
      "72     \t [ 0.05387804 -0.6060075 ]. \t  -37.9723271726159 \t -0.028072247545169335\n",
      "73     \t [ 0.44164987 -0.77555148]. \t  -94.51937245304981 \t -0.028072247545169335\n",
      "74     \t [1.64353095 1.47785427]. \t  -150.07013601165988 \t -0.028072247545169335\n",
      "75     \t [0.16290925 0.09108187]. \t  -1.1172936632291222 \t -0.028072247545169335\n",
      "76     \t [0.30416304 1.65616715]. \t  -244.9849442386117 \t -0.028072247545169335\n",
      "77     \t [ 1.86746994 -1.05170493]. \t  -2061.139778631496 \t -0.028072247545169335\n",
      "78     \t [-0.68209469  1.6195771 ]. \t  -136.07581609428564 \t -0.028072247545169335\n",
      "79     \t [0.56175037 0.34470117]. \t  -0.27696324855616916 \t -0.028072247545169335\n",
      "80     \t [ 0.03557787 -0.2342593 ]. \t  -6.477316482531068 \t -0.028072247545169335\n",
      "81     \t [-1.87870381 -0.72881594]. \t  -1821.6362628816562 \t -0.028072247545169335\n",
      "82     \t [0.49826055 0.24187488]. \t  -0.25582401754643863 \t -0.028072247545169335\n",
      "83     \t [ 0.87228019 -1.84296133]. \t  -678.0114880533556 \t -0.028072247545169335\n",
      "84     \t [1.39387526 1.93705226]. \t  -0.15854358146157582 \t -0.028072247545169335\n",
      "85     \t [-1.49512412 -1.77849703]. \t  -1617.3594838344652 \t -0.028072247545169335\n",
      "86     \t [-1.66136542  1.02401858]. \t  -308.49290419528285 \t -0.028072247545169335\n",
      "87     \t [ 1.22571365 -0.02541604]. \t  -233.46517445800004 \t -0.028072247545169335\n",
      "88     \t [-0.5402675  -1.89211014]. \t  -479.3576351478513 \t -0.028072247545169335\n",
      "89     \t [1.6181452  1.29868207]. \t  -174.54603187704615 \t -0.028072247545169335\n",
      "90     \t [-0.29161065  0.17530089]. \t  -2.4830191421768193 \t -0.028072247545169335\n",
      "91     \t [-0.42303286 -2.02062987]. \t  -485.843175433453 \t -0.028072247545169335\n",
      "92     \t [0.63764425 0.41034683]. \t  -0.13271291936212903 \t -0.028072247545169335\n",
      "93     \t [ 0.91153079 -0.99186605]. \t  -332.25119771497685 \t -0.028072247545169335\n",
      "94     \t [1.43101773 2.048     ]. \t  -0.18577982745421248 \t -0.028072247545169335\n",
      "95     \t [-1.31755929  1.0657361 ]. \t  -50.29142128177795 \t -0.028072247545169335\n",
      "96     \t [ 1.66185672 -0.23434305]. \t  -898.1060616588734 \t -0.028072247545169335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [ 0.97832679 -1.34353458]. \t  -529.3031398358194 \t -0.028072247545169335\n",
      "98     \t [0.5708896  0.73585978]. \t  -16.989613226266925 \t -0.028072247545169335\n",
      "99     \t [ 1.81131361 -1.44785837]. \t  -2236.7331300918627 \t -0.028072247545169335\n",
      "100    \t [1.39738476 1.94953857]. \t  -0.15890412829233563 \t -0.028072247545169335\n"
     ]
    }
   ],
   "source": [
    "### 6(r). Bayesian optimization runs (x20): GP run number = 18\n",
    "\n",
    "np.random.seed(run_num_18)\n",
    "surrogate_gp_18 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_18 = GPGO(surrogate_gp_18, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_18.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.28500433 2.03942998]. \t  -383.9669247437713 \t -86.99615505222792\n",
      "init   \t [-1.73083914  0.68111838]. \t  -543.2344862917479 \t -86.99615505222792\n",
      "init   \t [0.39168995 1.08415253]. \t  -86.99615505222792 \t -86.99615505222792\n",
      "init   \t [-1.82494137  0.77337859]. \t  -661.8217769130504 \t -86.99615505222792\n",
      "init   \t [-0.48189538 -1.09099011]. \t  -177.28534938676964 \t -86.99615505222792\n",
      "1      \t [ 2.048      -0.04174394]. \t  -1795.508520968466 \t -86.99615505222792\n",
      "2      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -86.99615505222792\n",
      "3      \t [ 0.86887256 -2.048     ]. \t  -785.664195548758 \t -86.99615505222792\n",
      "4      \t [-0.35878105  0.02540655]. \t  \u001b[92m-2.9137322154706347\u001b[0m \t -2.9137322154706347\n",
      "5      \t [2.048 2.048]. \t  -461.7603900415999 \t -2.9137322154706347\n",
      "6      \t [-1.04711551  2.048     ]. \t  -94.73525188574419 \t -2.9137322154706347\n",
      "7      \t [-0.55168261  1.10046806]. \t  -65.78752687483546 \t -2.9137322154706347\n",
      "8      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -2.9137322154706347\n",
      "9      \t [ 0.01509433 -2.048     ]. \t  -420.49376713800865 \t -2.9137322154706347\n",
      "10     \t [ 0.36533039 -0.91529147]. \t  -110.39208911107433 \t -2.9137322154706347\n",
      "11     \t [-2.048  2.048]. \t  -469.9523900415999 \t -2.9137322154706347\n",
      "12     \t [-2.048      -0.29164796]. \t  -2021.6667988342513 \t -2.9137322154706347\n",
      "13     \t [1.33640775 1.27110024]. \t  -26.62387059930785 \t -2.9137322154706347\n",
      "14     \t [1.18459741 2.048     ]. \t  -41.60162298149784 \t -2.9137322154706347\n",
      "15     \t [-0.89756713  0.48141432]. \t  -14.112131879527697 \t -2.9137322154706347\n",
      "16     \t [-0.15810491 -0.70084084]. \t  -54.02528724010742 \t -2.9137322154706347\n",
      "17     \t [0.66600766 0.26103345]. \t  -3.4433713876327396 \t -2.9137322154706347\n",
      "18     \t [0.17014162 0.3786591 ]. \t  -12.918438406064988 \t -2.9137322154706347\n",
      "19     \t [-1.19281702  1.40619133]. \t  -4.836072633644628 \t -2.9137322154706347\n",
      "20     \t [1.07016719 1.55410435]. \t  -16.720471713207104 \t -2.9137322154706347\n",
      "21     \t [0.9057904  0.84011795]. \t  \u001b[92m-0.047533734719720756\u001b[0m \t -0.047533734719720756\n",
      "22     \t [-0.82755798 -0.32297552]. \t  -104.91164414391676 \t -0.047533734719720756\n",
      "23     \t [ 0.22091155 -1.48577352]. \t  -236.0991564103828 \t -0.047533734719720756\n",
      "24     \t [2.048      1.11460272]. \t  -949.5543017281286 \t -0.047533734719720756\n",
      "25     \t [ 0.31932748 -0.13653239]. \t  -6.151655860790801 \t -0.047533734719720756\n",
      "26     \t [ 1.19102523 -0.8603815 ]. \t  -519.3853114380761 \t -0.047533734719720756\n",
      "27     \t [-1.05399206  1.02272076]. \t  -4.996428185780489 \t -0.047533734719720756\n",
      "28     \t [-0.88047232  1.58471348]. \t  -69.06228429173476 \t -0.047533734719720756\n",
      "29     \t [-1.43929443  2.048     ]. \t  -6.005704440932386 \t -0.047533734719720756\n",
      "30     \t [-0.81623454 -2.048     ]. \t  -740.0079517593091 \t -0.047533734719720756\n",
      "31     \t [1.38450858 1.74047928]. \t  -3.259004732478956 \t -0.047533734719720756\n",
      "32     \t [1.20015335 1.41090764]. \t  -0.12685298200395012 \t -0.047533734719720756\n",
      "33     \t [-1.30907536  1.8323686 ]. \t  -6.740567997413992 \t -0.047533734719720756\n",
      "34     \t [1.46667901 2.048     ]. \t  -1.2817262340403717 \t -0.047533734719720756\n",
      "35     \t [0.458318   0.25807701]. \t  -0.5240270607919661 \t -0.047533734719720756\n",
      "36     \t [1.03119571 0.83515607]. \t  -5.2088855834418855 \t -0.047533734719720756\n",
      "37     \t [ 2.048     -1.0409331]. \t  -2741.8690580582715 \t -0.047533734719720756\n",
      "38     \t [-1.44530358 -1.236672  ]. \t  -1111.92404180687 \t -0.047533734719720756\n",
      "39     \t [-0.0352863  -0.10471885]. \t  -2.1946540607912346 \t -0.047533734719720756\n",
      "40     \t [1.38132145 1.96434271]. \t  -0.46230475898452517 \t -0.047533734719720756\n",
      "41     \t [ 0.88847891 -1.46105084]. \t  -506.4629775071988 \t -0.047533734719720756\n",
      "42     \t [0.62598497 0.45316374]. \t  -0.5157366918885508 \t -0.047533734719720756\n",
      "43     \t [-2.048      -1.16318584]. \t  -2879.5600461468794 \t -0.047533734719720756\n",
      "44     \t [-0.7035175   0.59076239]. \t  -3.8202249110275956 \t -0.047533734719720756\n",
      "45     \t [-1.3512808  2.048    ]. \t  -10.458706812559875 \t -0.047533734719720756\n",
      "46     \t [0.93164175 0.85767778]. \t  \u001b[92m-0.015237767175645317\u001b[0m \t -0.015237767175645317\n",
      "47     \t [1.33512036 1.88853399]. \t  -1.2356428367780807 \t -0.015237767175645317\n",
      "48     \t [1.10200519 1.16684541]. \t  -0.23669591211628235 \t -0.015237767175645317\n",
      "49     \t [0.78293868 0.59904214]. \t  -0.06657818320229056 \t -0.015237767175645317\n",
      "50     \t [1.39156313 1.99258625]. \t  -0.46847253788301835 \t -0.015237767175645317\n",
      "51     \t [1.25352982 1.57238717]. \t  -0.06438765335737018 \t -0.015237767175645317\n",
      "52     \t [0.75923756 0.56648798]. \t  -0.06787415466684808 \t -0.015237767175645317\n",
      "53     \t [1.41489232 2.048     ]. \t  -0.3844696396548706 \t -0.015237767175645317\n",
      "54     \t [1.27492089 1.64928618]. \t  -0.1325253437263249 \t -0.015237767175645317\n",
      "55     \t [1.23362815 1.4852077 ]. \t  -0.18876309154056964 \t -0.015237767175645317\n",
      "56     \t [1.00314183 1.0043509 ]. \t  \u001b[92m-0.0003872482221779839\u001b[0m \t -0.0003872482221779839\n",
      "57     \t [1.19038316 1.41325868]. \t  -0.03765454393499498 \t -0.0003872482221779839\n",
      "58     \t [0.72876754 0.48253097]. \t  -0.30948283877512883 \t -0.0003872482221779839\n",
      "59     \t [1.1391214  1.29674672]. \t  -0.01942715526673327 \t -0.0003872482221779839\n",
      "60     \t [0.65249549 0.4104883 ]. \t  -0.1440524413606684 \t -0.0003872482221779839\n",
      "61     \t [1.04173362 1.08887393]. \t  -0.003084921375850593 \t -0.0003872482221779839\n",
      "62     \t [-0.1756963   0.07503097]. \t  -1.5772880575175232 \t -0.0003872482221779839\n",
      "63     \t [1.01336117 1.02130312]. \t  -0.0033119971932457745 \t -0.0003872482221779839\n",
      "64     \t [0.61083367 0.39811673]. \t  -0.21394517135108682 \t -0.0003872482221779839\n",
      "65     \t [0.88209774 0.78539988]. \t  -0.019235002574930195 \t -0.0003872482221779839\n",
      "66     \t [1.07368201 1.10593436]. \t  -0.22500278399757717 \t -0.0003872482221779839\n",
      "67     \t [1.26539235 1.66203054]. \t  -0.44025204799655526 \t -0.0003872482221779839\n",
      "68     \t [1.328859   1.74109729]. \t  -0.16949838923296923 \t -0.0003872482221779839\n",
      "69     \t [1.24470502 1.5443492 ]. \t  -0.06232227317475134 \t -0.0003872482221779839\n",
      "70     \t [0.57907729 0.30031774]. \t  -0.2997653318101517 \t -0.0003872482221779839\n",
      "71     \t [0.70430823 0.48998681]. \t  -0.09110994653934086 \t -0.0003872482221779839\n",
      "72     \t [1.12576863 1.2484889 ]. \t  -0.051410768760362976 \t -0.0003872482221779839\n",
      "73     \t [1.41500372 2.04799994]. \t  -0.38166636322464603 \t -0.0003872482221779839\n",
      "74     \t [0.81453485 0.61398324]. \t  -0.27926183528071824 \t -0.0003872482221779839\n",
      "75     \t [0.60810599 0.35608633]. \t  -0.17236789739641079 \t -0.0003872482221779839\n",
      "76     \t [1.08754147 1.16142351]. \t  -0.05313022213881654 \t -0.0003872482221779839\n",
      "77     \t [1.28137904 1.64721735]. \t  -0.08196740859665581 \t -0.0003872482221779839\n",
      "78     \t [1.41383098 2.048     ]. \t  -0.4121599187147773 \t -0.0003872482221779839\n",
      "79     \t [1.02396346 1.03049475]. \t  -0.03299734563744671 \t -0.0003872482221779839\n",
      "80     \t [0.79616212 0.63701216]. \t  -0.04253461905598492 \t -0.0003872482221779839\n",
      "81     \t [1.02258549 1.01429827]. \t  -0.09899828251159175 \t -0.0003872482221779839\n",
      "82     \t [0.93401182 0.841415  ]. \t  -0.1002257484227775 \t -0.0003872482221779839\n",
      "83     \t [1.23194351 1.49839862]. \t  -0.09099354366184986 \t -0.0003872482221779839\n",
      "84     \t [1.13583602 1.27754005]. \t  -0.03428565323183788 \t -0.0003872482221779839\n",
      "85     \t [1.25730688 1.55868731]. \t  -0.11519509825889712 \t -0.0003872482221779839\n",
      "86     \t [0.87783158 0.76053013]. \t  -0.025041756735694566 \t -0.0003872482221779839\n",
      "87     \t [1.19926704 1.442242  ]. \t  -0.041307808364915016 \t -0.0003872482221779839\n",
      "88     \t [1.16718178 1.37960239]. \t  -0.05784097139345976 \t -0.0003872482221779839\n",
      "89     \t [0.97367223 0.92569416]. \t  -0.050616166880449155 \t -0.0003872482221779839\n",
      "90     \t [1.04277101 1.06642801]. \t  -0.0456918327885827 \t -0.0003872482221779839\n",
      "91     \t [0.39554957 0.15451658]. \t  -0.36573779914320037 \t -0.0003872482221779839\n",
      "92     \t [0.6376451  0.41034225]. \t  -0.13270805780578085 \t -0.0003872482221779839\n",
      "93     \t [0.91507564 0.81570138]. \t  -0.05413657729968844 \t -0.0003872482221779839\n",
      "94     \t [0.66454752 0.42360123]. \t  -0.14500825366176143 \t -0.0003872482221779839\n",
      "95     \t [0.75146784 0.52542056]. \t  -0.21608637633430355 \t -0.0003872482221779839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96     \t [1.31143137 1.72980974]. \t  -0.10690467336455003 \t -0.0003872482221779839\n",
      "97     \t [1.18696551 1.37833687]. \t  -0.12828782356943724 \t -0.0003872482221779839\n",
      "98     \t [0.75554325 0.54661552]. \t  -0.11846878219549713 \t -0.0003872482221779839\n",
      "99     \t [1.13017107 1.2464082 ]. \t  -0.11229241921440575 \t -0.0003872482221779839\n",
      "100    \t [0.96272004 0.91778093]. \t  -0.009578119008763226 \t -0.0003872482221779839\n"
     ]
    }
   ],
   "source": [
    "### 6(r). Bayesian optimization runs (x20): STP DF1 run number = 18\n",
    "\n",
    "np.random.seed(run_num_18)\n",
    "surrogate_stp_df1_18 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_18 = GPGO(surrogate_stp_df1_18, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_18.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.5729738225166305, -7.856444669567482)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(r). Training Regret Minimisation: run number = 18\n",
    "\n",
    "gp_output_18 = np.append(np.max(gpgo_gp_18.GP.y[0:n_init]),gpgo_gp_18.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_18 = np.append(np.max(gpgo_stp_df1_18.GP.y[0:n_init]),gpgo_stp_df1_18.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_18 = np.log(y_global_orig - gp_output_18)\n",
    "regret_stp_df1_18 = np.log(y_global_orig - stp_df1_output_18)\n",
    "\n",
    "train_regret_gp_18 = min_max_array(regret_gp_18)\n",
    "train_regret_stp_df1_18 = min_max_array(regret_stp_df1_18)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 18\n",
    "min_train_regret_gp_18 = min(train_regret_gp_18)\n",
    "min_train_regret_stp_df1_18 = min(train_regret_stp_df1_18)\n",
    "\n",
    "min_train_regret_gp_18, min_train_regret_stp_df1_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.32923463 1.9850312 ]. \t  -4.868057505654614 \t -4.868057505654614\n",
      "init   \t [ 1.61031994 -0.73872624]. \t  -1110.4992966214563 \t -4.868057505654614\n",
      "init   \t [ 0.38197946 -1.24726347]. \t  -194.47470912529033 \t -4.868057505654614\n",
      "init   \t [1.47544785 1.49217491]. \t  -47.11724466380912 \t -4.868057505654614\n",
      "init   \t [-1.7259813   0.88847186]. \t  -444.4665457038575 \t -4.868057505654614\n",
      "1      \t [-0.46895506 -1.76485884]. \t  -396.09207774598804 \t -4.868057505654614\n",
      "2      \t [2.048 2.048]. \t  -461.7603900415999 \t -4.868057505654614\n",
      "3      \t [0.58467625 1.74544277]. \t  -197.18079262176772 \t -4.868057505654614\n",
      "4      \t [-0.96382412 -0.98232194]. \t  -369.1552996118504 \t -4.868057505654614\n",
      "5      \t [1.13233766 2.048     ]. \t  -58.66422852650463 \t -4.868057505654614\n",
      "6      \t [1.22346828 1.66464822]. \t  \u001b[92m-2.8647353466795265\u001b[0m \t -2.8647353466795265\n",
      "7      \t [-0.73537777  1.7923015 ]. \t  -159.6420246907342 \t -2.8647353466795265\n",
      "8      \t [-0.96952584 -1.79315004]. \t  -750.8792112231802 \t -2.8647353466795265\n",
      "9      \t [1.34031268 1.79006619]. \t  \u001b[92m-0.11987282846469786\u001b[0m \t -0.11987282846469786\n",
      "10     \t [-0.09390545  0.67848066]. \t  -46.04140523866785 \t -0.11987282846469786\n",
      "11     \t [-0.51688289 -0.74238554]. \t  -104.22075274902684 \t -0.11987282846469786\n",
      "12     \t [-0.62652576 -1.67805146]. \t  -431.3782197105984 \t -0.11987282846469786\n",
      "13     \t [0.31111379 0.74071515]. \t  -41.93829350010854 \t -0.11987282846469786\n",
      "14     \t [-1.21316288 -0.80891151]. \t  -525.0462487005237 \t -0.11987282846469786\n",
      "15     \t [1.28389387 1.68206555]. \t  -0.19404391986244232 \t -0.11987282846469786\n",
      "16     \t [-0.85862936  0.32261873]. \t  -20.64594626241304 \t -0.11987282846469786\n",
      "17     \t [0.8768996  0.25039658]. \t  -26.905219772239164 \t -0.11987282846469786\n",
      "18     \t [0.90208427 0.68173026]. \t  -1.7526681319824304 \t -0.11987282846469786\n",
      "19     \t [-0.70840064  0.57632483]. \t  -3.4735588143731606 \t -0.11987282846469786\n",
      "20     \t [0.55821641 0.09005449]. \t  -5.103660231173275 \t -0.11987282846469786\n",
      "21     \t [0.63533128 0.3857905 ]. \t  -0.1648645878195782 \t -0.11987282846469786\n",
      "22     \t [ 0.35022589 -1.88355894]. \t  -402.9129178502337 \t -0.11987282846469786\n",
      "23     \t [ 1.28826233 -2.04304888]. \t  -1371.0586572172904 \t -0.11987282846469786\n",
      "24     \t [-2.01360385  1.25674491]. \t  -791.8813766276302 \t -0.11987282846469786\n",
      "25     \t [0.71146273 0.45946649]. \t  -0.30146162452351616 \t -0.11987282846469786\n",
      "26     \t [ 1.37512384 -0.57814561]. \t  -609.7917160195433 \t -0.11987282846469786\n",
      "27     \t [-0.35878752  0.32321931]. \t  -5.628971567845688 \t -0.11987282846469786\n",
      "28     \t [ 1.05494228 -1.21520997]. \t  -542.0141223085407 \t -0.11987282846469786\n",
      "29     \t [0.88254732 0.80860741]. \t  \u001b[92m-0.10210893927976396\u001b[0m \t -0.10210893927976396\n",
      "30     \t [-1.32054668  0.88690491]. \t  -78.81931766157847 \t -0.10210893927976396\n",
      "31     \t [-0.96331014  0.98134026]. \t  -4.139463386432332 \t -0.10210893927976396\n",
      "32     \t [-0.74301536 -1.30933537]. \t  -349.521780294212 \t -0.10210893927976396\n",
      "33     \t [-0.9297854   0.79160712]. \t  -4.255422007488429 \t -0.10210893927976396\n",
      "34     \t [ 1.0758484 -1.0105182]. \t  -470.01427077320494 \t -0.10210893927976396\n",
      "35     \t [-0.74219547  0.39982339]. \t  -5.316272851915009 \t -0.10210893927976396\n",
      "36     \t [ 0.28779854 -0.29638536]. \t  -14.887508012226917 \t -0.10210893927976396\n",
      "37     \t [0.73246566 0.51624433]. \t  -0.11262789276013373 \t -0.10210893927976396\n",
      "38     \t [0.79580843 0.59474046]. \t  -0.1904632103903337 \t -0.10210893927976396\n",
      "39     \t [-1.57773637 -1.55742005]. \t  -1644.200227590735 \t -0.10210893927976396\n",
      "40     \t [-1.94131048 -0.64456538]. \t  -1956.3304253588783 \t -0.10210893927976396\n",
      "41     \t [1.33737742 0.89947074]. \t  -79.16506085950081 \t -0.10210893927976396\n",
      "42     \t [1.31401865 1.74324425]. \t  -0.12616115969470165 \t -0.10210893927976396\n",
      "43     \t [-0.54134264 -0.11116492]. \t  -18.714857414617896 \t -0.10210893927976396\n",
      "44     \t [0.4864249 1.5088892]. \t  -162.1334023003635 \t -0.10210893927976396\n",
      "45     \t [-0.22593279 -0.37699517]. \t  -19.82480378007512 \t -0.10210893927976396\n",
      "46     \t [ 0.03754683 -0.01592005]. \t  -0.9563483509016583 \t -0.10210893927976396\n",
      "47     \t [1.86675092 1.17833976]. \t  -532.7082306774877 \t -0.10210893927976396\n",
      "48     \t [-0.50485376 -0.52902694]. \t  -63.71517343722567 \t -0.10210893927976396\n",
      "49     \t [1.18240576 1.33989327]. \t  -0.37188067872029823 \t -0.10210893927976396\n",
      "50     \t [ 1.66099803 -0.20076309]. \t  -876.4060265473996 \t -0.10210893927976396\n",
      "51     \t [1.15500379 0.97806726]. \t  -12.695240323084825 \t -0.10210893927976396\n",
      "52     \t [-2.01047941  1.51453357]. \t  -647.8855259865878 \t -0.10210893927976396\n",
      "53     \t [-1.46676994  2.048     ]. \t  -7.154400809229212 \t -0.10210893927976396\n",
      "54     \t [1.28043293 1.6156764 ]. \t  -0.1354395369810242 \t -0.10210893927976396\n",
      "55     \t [-0.48343753 -0.07627361]. \t  -11.809685159824312 \t -0.10210893927976396\n",
      "56     \t [-0.38492981 -0.42444918]. \t  -34.707412167115635 \t -0.10210893927976396\n",
      "57     \t [ 0.67851871 -0.49524815]. \t  -91.42732678098899 \t -0.10210893927976396\n",
      "58     \t [-1.54187884  1.42631577]. \t  -96.9154375265456 \t -0.10210893927976396\n",
      "59     \t [-1.31150236  1.70813956]. \t  -5.357201475266017 \t -0.10210893927976396\n",
      "60     \t [0.40792322 1.45919249]. \t  -167.48144704227366 \t -0.10210893927976396\n",
      "61     \t [ 1.14273613 -0.08051936]. \t  -192.22122779342888 \t -0.10210893927976396\n",
      "62     \t [-0.57149989  1.43381252]. \t  -125.05888178867077 \t -0.10210893927976396\n",
      "63     \t [-0.04156479 -1.41274047]. \t  -201.15685786830568 \t -0.10210893927976396\n",
      "64     \t [ 0.9069145  -1.80226038]. \t  -688.9421727166364 \t -0.10210893927976396\n",
      "65     \t [-0.14345579  1.79695216]. \t  -316.8574503868963 \t -0.10210893927976396\n",
      "66     \t [0.39195136 1.86719497]. \t  -294.00163114251893 \t -0.10210893927976396\n",
      "67     \t [ 1.1610543  -1.36553938]. \t  -736.381088013056 \t -0.10210893927976396\n",
      "68     \t [1.97161585 0.01905404]. \t  -1497.2527754453217 \t -0.10210893927976396\n",
      "69     \t [-0.18769764 -0.31906288]. \t  -13.962998755716589 \t -0.10210893927976396\n",
      "70     \t [-1.16683458 -0.463864  ]. \t  -337.89162161777665 \t -0.10210893927976396\n",
      "71     \t [ 1.74610647 -0.65934242]. \t  -1375.6538028086516 \t -0.10210893927976396\n",
      "72     \t [0.58275485 0.34925506]. \t  -0.18340932735987753 \t -0.10210893927976396\n",
      "73     \t [0.06617496 0.88734982]. \t  -78.8357535955873 \t -0.10210893927976396\n",
      "74     \t [ 0.04972566 -0.9092513 ]. \t  -84.02707633242898 \t -0.10210893927976396\n",
      "75     \t [0.70508684 0.50211071]. \t  \u001b[92m-0.08943716935196437\u001b[0m \t -0.08943716935196437\n",
      "76     \t [0.95822809 1.11157757]. \t  -3.7411918000491626 \t -0.08943716935196437\n",
      "77     \t [0.78002209 0.61101359]. \t  \u001b[92m-0.04905547314516469\u001b[0m \t -0.04905547314516469\n",
      "78     \t [-2.04582326 -0.3285616 ]. \t  -2046.8554887796602 \t -0.04905547314516469\n",
      "79     \t [1.27559926 1.16962711]. \t  -21.008991899108807 \t -0.04905547314516469\n",
      "80     \t [1.26210505 1.58910313]. \t  -0.07014763296925902 \t -0.04905547314516469\n",
      "81     \t [-0.06608506  0.80914616]. \t  -65.90344905197144 \t -0.04905547314516469\n",
      "82     \t [ 0.03187748 -0.97713218]. \t  -96.61468176551305 \t -0.04905547314516469\n",
      "83     \t [-0.76867205  0.32801399]. \t  -10.036831275962305 \t -0.04905547314516469\n",
      "84     \t [0.77871797 0.61020787]. \t  -0.05041445000931351 \t -0.04905547314516469\n",
      "85     \t [0.72585777 0.56094948]. \t  -0.1912984601782065 \t -0.04905547314516469\n",
      "86     \t [1.51835932 1.13934622]. \t  -136.24033904722302 \t -0.04905547314516469\n",
      "87     \t [-1.35096765 -1.62412536]. \t  -1195.2519911132674 \t -0.04905547314516469\n",
      "88     \t [ 0.09317528 -1.13351746]. \t  -131.28420751278443 \t -0.04905547314516469\n",
      "89     \t [-0.69919572  1.87985453]. \t  -196.3697685312902 \t -0.04905547314516469\n",
      "90     \t [-0.46017653 -0.81307598]. \t  -107.1614937961938 \t -0.04905547314516469\n",
      "91     \t [-0.83809514 -0.8940872 ]. \t  -258.25683924078925 \t -0.04905547314516469\n",
      "92     \t [0.5177177  0.27207664]. \t  -0.2342324386842044 \t -0.04905547314516469\n",
      "93     \t [-1.77227969  0.48776818]. \t  -711.6363285816858 \t -0.04905547314516469\n",
      "94     \t [ 1.19922756 -1.84860627]. \t  -1080.3142262022764 \t -0.04905547314516469\n",
      "95     \t [0.63878732 0.4139358 ]. \t  -0.13393975969122518 \t -0.04905547314516469\n",
      "96     \t [-1.95810625 -1.01690816]. \t  -2362.056119449148 \t -0.04905547314516469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.48700967 0.6075774 ]. \t  -13.982699066887886 \t -0.04905547314516469\n",
      "98     \t [0.94626634 1.94421001]. \t  -109.99893651529146 \t -0.04905547314516469\n",
      "99     \t [-1.13765188 -1.11455887]. \t  -584.8064357059055 \t -0.04905547314516469\n",
      "100    \t [-1.82464665  0.73949455]. \t  -678.7061883533198 \t -0.04905547314516469\n"
     ]
    }
   ],
   "source": [
    "### 6(s). Bayesian optimization runs (x20): GP run number = 19\n",
    "\n",
    "np.random.seed(run_num_19)\n",
    "surrogate_gp_19 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_19 = GPGO(surrogate_gp_19, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_19.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.32923463 1.9850312 ]. \t  -4.868057505654614 \t -4.868057505654614\n",
      "init   \t [ 1.61031994 -0.73872624]. \t  -1110.4992966214563 \t -4.868057505654614\n",
      "init   \t [ 0.38197946 -1.24726347]. \t  -194.47470912529033 \t -4.868057505654614\n",
      "init   \t [1.47544785 1.49217491]. \t  -47.11724466380912 \t -4.868057505654614\n",
      "init   \t [-1.7259813   0.88847186]. \t  -444.4665457038575 \t -4.868057505654614\n",
      "1      \t [-0.81828317 -2.048     ]. \t  -741.8342515749213 \t -4.868057505654614\n",
      "2      \t [-0.15559246  2.048     ]. \t  -410.9083899837017 \t -4.868057505654614\n",
      "3      \t [2.048 2.048]. \t  -461.7603900415999 \t -4.868057505654614\n",
      "4      \t [-0.24521755 -0.09305422]. \t  \u001b[92m-3.89715783928557\u001b[0m \t -3.89715783928557\n",
      "5      \t [-2.048      -0.67784208]. \t  -2383.0710486922026 \t -3.89715783928557\n",
      "6      \t [-2.048  2.048]. \t  -469.9523900415999 \t -3.89715783928557\n",
      "7      \t [0.36526901 0.80053649]. \t  -44.90713092046094 \t -3.89715783928557\n",
      "8      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -3.89715783928557\n",
      "9      \t [ 0.60631541 -0.16806361]. \t  -28.850506618521052 \t -3.89715783928557\n",
      "10     \t [2.048      0.39772213]. \t  -1442.5016910221916 \t -3.89715783928557\n",
      "11     \t [-0.7409916   1.01844922]. \t  -25.062873781489685 \t -3.89715783928557\n",
      "12     \t [0.8602311  1.55754872]. \t  -66.85852908080392 \t -3.89715783928557\n",
      "13     \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -3.89715783928557\n",
      "14     \t [-0.03302791 -2.048     ]. \t  -420.9444747663517 \t -3.89715783928557\n",
      "15     \t [-0.28315791 -1.07795096]. \t  -135.77285563441345 \t -3.89715783928557\n",
      "16     \t [-1.14441563  2.048     ]. \t  -59.10910576282056 \t -3.89715783928557\n",
      "17     \t [ 0.22312684 -0.56805949]. \t  -38.77678578637084 \t -3.89715783928557\n",
      "18     \t [-0.86727972  0.38593228]. \t  -16.90004135675305 \t -3.89715783928557\n",
      "19     \t [-0.32899509  0.46278632]. \t  -14.336695384145811 \t -3.89715783928557\n",
      "20     \t [0.97141576 0.82237373]. \t  \u001b[92m-1.4715756563623457\u001b[0m \t -1.4715756563623457\n",
      "21     \t [-1.24153575  1.50951357]. \t  -5.1262272533789 \t -1.4715756563623457\n",
      "22     \t [0.438317  0.3111783]. \t  -1.732932962002965 \t -1.4715756563623457\n",
      "23     \t [1.14096802 1.39881551]. \t  \u001b[92m-0.9609173483981541\u001b[0m \t -0.9609173483981541\n",
      "24     \t [-0.95447394  1.63236211]. \t  -55.85333972554076 \t -0.9609173483981541\n",
      "25     \t [1.00288959 2.048     ]. \t  -108.62069078234546 \t -0.9609173483981541\n",
      "26     \t [0.72524654 0.55714764]. \t  \u001b[92m-0.17261573420032966\u001b[0m \t -0.17261573420032966\n",
      "27     \t [-1.06268153  0.99348216]. \t  -6.099087524441019 \t -0.17261573420032966\n",
      "28     \t [-0.90597569 -0.69210021]. \t  -232.51701258433096 \t -0.17261573420032966\n",
      "29     \t [ 0.84239651 -2.048     ]. \t  -760.4782020837156 \t -0.17261573420032966\n",
      "30     \t [ 0.85911904 -0.9539665 ]. \t  -286.32385604352504 \t -0.17261573420032966\n",
      "31     \t [-1.47216423  2.048     ]. \t  -7.534069892499299 \t -0.17261573420032966\n",
      "32     \t [1.32330473 1.7606664 ]. \t  \u001b[92m-0.11360992987066072\u001b[0m \t -0.11360992987066072\n",
      "33     \t [-1.34102394  1.84961711]. \t  -5.743273927106603 \t -0.11360992987066072\n",
      "34     \t [-0.56108987  0.26569128]. \t  -2.678382816590238 \t -0.11360992987066072\n",
      "35     \t [-2.048       0.18734566]. \t  -1614.8618198166182 \t -0.11360992987066072\n",
      "36     \t [-0.96863387 -1.4043998 ]. \t  -552.6770655740038 \t -0.11360992987066072\n",
      "37     \t [ 0.17864512 -0.02725835]. \t  -1.0247614228598687 \t -0.11360992987066072\n",
      "38     \t [0.85088136 0.42045541]. \t  -9.236112940679734 \t -0.11360992987066072\n",
      "39     \t [ 2.048      -1.20078445]. \t  -2911.7962392628847 \t -0.11360992987066072\n",
      "40     \t [1.45554772 2.048     ]. \t  -0.7062302213791382 \t -0.11360992987066072\n",
      "41     \t [-0.06111385  0.0915098 ]. \t  -1.8964058486184865 \t -0.11360992987066072\n",
      "42     \t [-0.80401735  0.63984929]. \t  -3.2588274844247485 \t -0.11360992987066072\n",
      "43     \t [-0.07738902  1.41973564]. \t  -201.0287063338104 \t -0.11360992987066072\n",
      "44     \t [1.25072548 1.55078505]. \t  \u001b[92m-0.08116710566947852\u001b[0m \t -0.08116710566947852\n",
      "45     \t [1.37177382 1.84870599]. \t  -0.2474951634183004 \t -0.08116710566947852\n",
      "46     \t [1.03311397 1.09076422]. \t  \u001b[92m-0.05603876570964385\u001b[0m \t -0.05603876570964385\n",
      "47     \t [0.8202295  0.68944668]. \t  -0.06010715462323115 \t -0.05603876570964385\n",
      "48     \t [0.87365569 0.78125259]. \t  \u001b[92m-0.04828491396653066\u001b[0m \t -0.04828491396653066\n",
      "49     \t [1.42819317 2.048     ]. \t  -0.19017920951925926 \t -0.04828491396653066\n",
      "50     \t [1.1150458  1.24596878]. \t  \u001b[92m-0.01393336289789581\u001b[0m \t -0.01393336289789581\n",
      "51     \t [1.1533973  1.32439597]. \t  -0.027046475007596618 \t -0.01393336289789581\n",
      "52     \t [1.25090937 1.55125194]. \t  -0.08124077180005884 \t -0.01393336289789581\n",
      "53     \t [1.33294879 1.78370845]. \t  -0.1156934589426258 \t -0.01393336289789581\n",
      "54     \t [0.73701666 0.51920553]. \t  -0.12670281344739834 \t -0.01393336289789581\n",
      "55     \t [-2.048       1.43465437]. \t  -770.8569123173344 \t -0.01393336289789581\n",
      "56     \t [1.22343997 1.49353849]. \t  -0.050992662789036455 \t -0.01393336289789581\n",
      "57     \t [0.89550025 0.7625436 ]. \t  -0.16597581558472962 \t -0.01393336289789581\n",
      "58     \t [0.88148067 0.79076165]. \t  -0.03296267520364787 \t -0.01393336289789581\n",
      "59     \t [1.10821498 1.23839938]. \t  -0.022235037763372587 \t -0.01393336289789581\n",
      "60     \t [0.69695975 0.44910405]. \t  -0.22614710011164302 \t -0.01393336289789581\n",
      "61     \t [0.63470691 0.41766086]. \t  -0.15536673808082774 \t -0.01393336289789581\n",
      "62     \t [0.8152473  0.65771258]. \t  -0.03891608411600048 \t -0.01393336289789581\n",
      "63     \t [0.88229758 0.76563779]. \t  -0.030266642143475853 \t -0.01393336289789581\n",
      "64     \t [0.77086906 0.57850183]. \t  -0.07726716851540733 \t -0.01393336289789581\n",
      "65     \t [1.41392279 2.04799983]. \t  -0.4096926057322127 \t -0.01393336289789581\n",
      "66     \t [0.09469904 0.01891283]. \t  -0.8294599795881087 \t -0.01393336289789581\n",
      "67     \t [0.81610748 0.66427506]. \t  -0.03412493708371453 \t -0.01393336289789581\n",
      "68     \t [1.05163348 1.13307778]. \t  -0.07635011421753624 \t -0.01393336289789581\n",
      "69     \t [1.00593176 0.99073132]. \t  -0.04484099082577192 \t -0.01393336289789581\n",
      "70     \t [1.05501893 1.07549158]. \t  -0.14420275437548677 \t -0.01393336289789581\n",
      "71     \t [1.15019694 1.30161304]. \t  -0.06809856305107961 \t -0.01393336289789581\n",
      "72     \t [1.051051   1.12439418]. \t  -0.04136000048313244 \t -0.01393336289789581\n",
      "73     \t [0.83910944 0.70848055]. \t  -0.027800623606179457 \t -0.01393336289789581\n",
      "74     \t [1.2301193  1.52293193]. \t  -0.062438589165639394 \t -0.01393336289789581\n",
      "75     \t [0.74967578 0.56989262]. \t  -0.0688698197379089 \t -0.01393336289789581\n",
      "76     \t [0.85049065 0.6934734 ]. \t  -0.11152065977810142 \t -0.01393336289789581\n",
      "77     \t [0.77344185 0.62490091]. \t  -0.12255686319711007 \t -0.01393336289789581\n",
      "78     \t [1.42943663 2.0479997 ]. \t  -0.18663482106763965 \t -0.01393336289789581\n",
      "79     \t [1.12704665 1.24384673]. \t  -0.08577041917534983 \t -0.01393336289789581\n",
      "80     \t [1.23443214 1.55256476]. \t  -0.1375690507874113 \t -0.01393336289789581\n",
      "81     \t [1.30574002 1.68934717]. \t  -0.11784359069988719 \t -0.01393336289789581\n",
      "82     \t [0.92141537 0.85391716]. \t  \u001b[92m-0.008587217892191771\u001b[0m \t -0.008587217892191771\n",
      "83     \t [ 2.048      -0.35990516]. \t  -2075.1804103710706 \t -0.008587217892191771\n",
      "84     \t [0.75114145 0.57711867]. \t  -0.07858500010969785 \t -0.008587217892191771\n",
      "85     \t [1.21452853 1.456178  ]. \t  -0.0817493241693775 \t -0.008587217892191771\n",
      "86     \t [1.17575377 1.36566028]. \t  -0.05890089255222947 \t -0.008587217892191771\n",
      "87     \t [0.89648667 0.80377544]. \t  -0.01071576832225835 \t -0.008587217892191771\n",
      "88     \t [1.05031048 1.09503483]. \t  -0.009120158613310144 \t -0.008587217892191771\n",
      "89     \t [0.77669388 0.59335085]. \t  -0.05967163059889585 \t -0.008587217892191771\n",
      "90     \t [1.11910235 1.26473943]. \t  -0.02943600740874286 \t -0.008587217892191771\n",
      "91     \t [ 1.31986889 -1.69311829]. \t  -1180.1431023513 \t -0.008587217892191771\n",
      "92     \t [0.2534587  0.01074086]. \t  -0.8435537010001775 \t -0.008587217892191771\n",
      "93     \t [1.12018761 1.28149819]. \t  -0.08561619483655447 \t -0.008587217892191771\n",
      "94     \t [0.84718579 0.69909158]. \t  -0.05806798990331752 \t -0.008587217892191771\n",
      "95     \t [1.13830304 1.29101724]. \t  -0.021352349127530538 \t -0.008587217892191771\n",
      "96     \t [0.30147568 0.03029361]. \t  -0.8550992309727257 \t -0.008587217892191771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [1.14204879 1.30921164]. \t  -0.022614466630046588 \t -0.008587217892191771\n",
      "98     \t [0.84369098 0.73201566]. \t  -0.06524134204657786 \t -0.008587217892191771\n",
      "99     \t [1.0293642  1.08308022]. \t  -0.05603826026502494 \t -0.008587217892191771\n",
      "100    \t [1.30129264 1.7258107 ]. \t  -0.1960656520373633 \t -0.008587217892191771\n"
     ]
    }
   ],
   "source": [
    "### 6(s). Bayesian optimization runs (x20): STP DF1 run number = 19\n",
    "\n",
    "np.random.seed(run_num_19)\n",
    "surrogate_stp_df1_19 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_19 = GPGO(surrogate_stp_df1_19, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_19.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.0148035162157707, -4.75748047295531)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(s). Training Regret Minimisation: run number = 19\n",
    "\n",
    "gp_output_19 = np.append(np.max(gpgo_gp_19.GP.y[0:n_init]),gpgo_gp_19.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_19 = np.append(np.max(gpgo_stp_df1_19.GP.y[0:n_init]),gpgo_stp_df1_19.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_19 = np.log(y_global_orig - gp_output_19)\n",
    "regret_stp_df1_19 = np.log(y_global_orig - stp_df1_output_19)\n",
    "\n",
    "train_regret_gp_19 = min_max_array(regret_gp_19)\n",
    "train_regret_stp_df1_19 = min_max_array(regret_stp_df1_19)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 19\n",
    "min_train_regret_gp_19 = min(train_regret_gp_19)\n",
    "min_train_regret_stp_df1_19 = min(train_regret_stp_df1_19)\n",
    "\n",
    "min_train_regret_gp_19, min_train_regret_stp_df1_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.2888388  0.26430978]. \t  -3.777577453542735 \t -3.777577453542735\n",
      "init   \t [-0.04734225 -0.66978712]. \t  -46.25914429040042 \t -3.777577453542735\n",
      "init   \t [-0.50844394  0.13121892]. \t  -3.895838569726608 \t -3.777577453542735\n",
      "init   \t [-1.76903664  0.34623103]. \t  -782.3209705533411 \t -3.777577453542735\n",
      "init   \t [-1.07357076 -1.38954104]. \t  -650.524506936468 \t -3.777577453542735\n",
      "1      \t [-0.1332695   0.13267709]. \t  \u001b[92m-2.6048761032215726\u001b[0m \t -2.6048761032215726\n",
      "2      \t [1.52601541 0.49362155]. \t  -337.0364385207258 \t -2.6048761032215726\n",
      "3      \t [0.06323371 1.41284359]. \t  -199.36197910212854 \t -2.6048761032215726\n",
      "4      \t [ 0.93462177 -1.1475014 ]. \t  -408.4561526610949 \t -2.6048761032215726\n",
      "5      \t [-0.37159174 -0.18318743]. \t  -12.202567518285928 \t -2.6048761032215726\n",
      "6      \t [-1.42024952  1.13391263]. \t  -83.86113639867138 \t -2.6048761032215726\n",
      "7      \t [-1.41345509  2.048     ]. \t  -6.076214748452913 \t -2.6048761032215726\n",
      "8      \t [-0.97540759  1.26259145]. \t  -13.585004270013465 \t -2.6048761032215726\n",
      "9      \t [-1.88679976  2.048     ]. \t  -236.95204278328035 \t -2.6048761032215726\n",
      "10     \t [-0.29297422  0.0569491 ]. \t  \u001b[92m-1.7552154726016567\u001b[0m \t -1.7552154726016567\n",
      "11     \t [-1.19530179  2.048     ]. \t  -43.166856507005015 \t -1.7552154726016567\n",
      "12     \t [0.53419755 0.81150118]. \t  -27.89868780118036 \t -1.7552154726016567\n",
      "13     \t [-1.30576961  1.59695035]. \t  -6.4847866573740385 \t -1.7552154726016567\n",
      "14     \t [-0.78860523  0.73563684]. \t  -4.492756357031491 \t -1.7552154726016567\n",
      "15     \t [-0.3983729  -1.64194288]. \t  -326.1872740695626 \t -1.7552154726016567\n",
      "16     \t [0.32302253 0.4999506 ]. \t  -16.108791642617973 \t -1.7552154726016567\n",
      "17     \t [1.31746954 2.048     ]. \t  -9.852292008826455 \t -1.7552154726016567\n",
      "18     \t [ 0.25799003 -0.24867382]. \t  -10.4877429368878 \t -1.7552154726016567\n",
      "19     \t [-1.10942519  1.18087668]. \t  -4.69915070053261 \t -1.7552154726016567\n",
      "20     \t [0.18617438 0.02314946]. \t  \u001b[92m-0.6755634641487609\u001b[0m \t -0.6755634641487609\n",
      "21     \t [0.95289162 1.25393753]. \t  -11.969327146174747 \t -0.6755634641487609\n",
      "22     \t [-0.19580929  0.08150855]. \t  -1.616301184436927 \t -0.6755634641487609\n",
      "23     \t [ 1.66764852 -1.71888722]. \t  -2025.3906879916842 \t -0.6755634641487609\n",
      "24     \t [-1.69537024 -1.39278119]. \t  -1828.0463414122016 \t -0.6755634641487609\n",
      "25     \t [0.23677012 0.4709882 ]. \t  -17.799052926002027 \t -0.6755634641487609\n",
      "26     \t [ 0.8501451  -0.35546572]. \t  -116.27665665103598 \t -0.6755634641487609\n",
      "27     \t [ 0.14364922 -0.89507096]. \t  -84.58509496095981 \t -0.6755634641487609\n",
      "28     \t [1.80318636 1.94411307]. \t  -171.56621188478246 \t -0.6755634641487609\n",
      "29     \t [1.12297123 1.95386466]. \t  -48.01234459704146 \t -0.6755634641487609\n",
      "30     \t [-1.1342216  -0.37006358]. \t  -278.9614916305373 \t -0.6755634641487609\n",
      "31     \t [0.43348374 0.24789285]. \t  -0.6807571136465769 \t -0.6755634641487609\n",
      "32     \t [1.20459609 1.79563618]. \t  -11.915702706226021 \t -0.6755634641487609\n",
      "33     \t [-0.47830041 -1.52576977]. \t  -310.02680065959424 \t -0.6755634641487609\n",
      "34     \t [-1.20550988 -0.05889056]. \t  -233.52241158111184 \t -0.6755634641487609\n",
      "35     \t [-0.52674853  0.54617333]. \t  -9.55143065929903 \t -0.6755634641487609\n",
      "36     \t [0.74304755 0.56833344]. \t  \u001b[92m-0.09231322521092325\u001b[0m \t -0.09231322521092325\n",
      "37     \t [1.32115648 1.18152797]. \t  -31.904447673878682 \t -0.09231322521092325\n",
      "38     \t [-0.3040362   0.76544083]. \t  -46.9937903703847 \t -0.09231322521092325\n",
      "39     \t [0.85087995 0.77008763]. \t  -0.23467415583651066 \t -0.09231322521092325\n",
      "40     \t [1.2235113  1.48007268]. \t  \u001b[92m-0.07854271887158469\u001b[0m \t -0.07854271887158469\n",
      "41     \t [0.71711674 0.58197332]. \t  -0.5385807862798063 \t -0.07854271887158469\n",
      "42     \t [-0.4068628  -1.28073464]. \t  -211.14952512344544 \t -0.07854271887158469\n",
      "43     \t [0.17529204 1.15916279]. \t  -128.0168083834562 \t -0.07854271887158469\n",
      "44     \t [0.48382867 1.77067549]. \t  -236.37587193199764 \t -0.07854271887158469\n",
      "45     \t [0.47964708 1.26569985]. \t  -107.52548316444184 \t -0.07854271887158469\n",
      "46     \t [-1.50941603 -1.10529415]. \t  -1151.1929674840562 \t -0.07854271887158469\n",
      "47     \t [ 1.27091858 -1.70898462]. \t  -1105.116363693183 \t -0.07854271887158469\n",
      "48     \t [1.51949793 0.87348176]. \t  -206.30495661161856 \t -0.07854271887158469\n",
      "49     \t [-1.86573362  0.37119973]. \t  -975.2745320400953 \t -0.07854271887158469\n",
      "50     \t [0.67134476 0.46935239]. \t  -0.14279133921161213 \t -0.07854271887158469\n",
      "51     \t [1.13804661 1.29403069]. \t  \u001b[92m-0.01918217352277103\u001b[0m \t -0.01918217352277103\n",
      "52     \t [1.95650081 1.38439042]. \t  -597.9865725043503 \t -0.01918217352277103\n",
      "53     \t [ 1.71219045 -1.9877464 ]. \t  -2420.500308270193 \t -0.01918217352277103\n",
      "54     \t [0.46888773 1.61398374]. \t  -194.64137800239578 \t -0.01918217352277103\n",
      "55     \t [ 1.15212581 -1.08914448]. \t  -583.9889106648615 \t -0.01918217352277103\n",
      "56     \t [1.10529464 0.8664695 ]. \t  -12.628270272037758 \t -0.01918217352277103\n",
      "57     \t [1.06935378 1.13393017]. \t  \u001b[92m-0.014001663557947071\u001b[0m \t -0.014001663557947071\n",
      "58     \t [-1.66676799  0.66994422]. \t  -451.5502786295779 \t -0.014001663557947071\n",
      "59     \t [-0.99523387  0.24252604]. \t  -59.926034914967154 \t -0.014001663557947071\n",
      "60     \t [1.17397494 1.40563929]. \t  -0.10546463932844857 \t -0.014001663557947071\n",
      "61     \t [0.56737488 0.32786006]. \t  -0.19069974901014686 \t -0.014001663557947071\n",
      "62     \t [-0.94001591  2.04528928]. \t  -138.70891112332072 \t -0.014001663557947071\n",
      "63     \t [ 0.57187407 -1.66012158]. \t  -395.0643876039098 \t -0.014001663557947071\n",
      "64     \t [0.44374421 1.12386373]. \t  -86.23394152062177 \t -0.014001663557947071\n",
      "65     \t [1.18674958 1.09267993]. \t  -10.00118618641607 \t -0.014001663557947071\n",
      "66     \t [-0.91082315 -1.26232069]. \t  -441.26396375882774 \t -0.014001663557947071\n",
      "67     \t [0.0821836  0.58251462]. \t  -33.99239946621883 \t -0.014001663557947071\n",
      "68     \t [1.15112364 0.41629861]. \t  -82.61222519369333 \t -0.014001663557947071\n",
      "69     \t [0.59009551 0.32546583]. \t  -0.21976376023887195 \t -0.014001663557947071\n",
      "70     \t [0.59952771 0.34114459]. \t  -0.19382641283464597 \t -0.014001663557947071\n",
      "71     \t [1.13543971 1.28979535]. \t  -0.018376635143200797 \t -0.014001663557947071\n",
      "72     \t [2.02236401 0.80552465]. \t  -1079.7942702821092 \t -0.014001663557947071\n",
      "73     \t [-0.62886151 -1.17512401]. \t  -249.32873851716164 \t -0.014001663557947071\n",
      "74     \t [1.52137197 0.73026457]. \t  -251.27504800338738 \t -0.014001663557947071\n",
      "75     \t [0.38581887 1.73789702]. \t  -252.88229059851358 \t -0.014001663557947071\n",
      "76     \t [-1.96944417 -0.5409523 ]. \t  -1962.1593894476853 \t -0.014001663557947071\n",
      "77     \t [ 1.154773   -0.95401997]. \t  -523.2990278949036 \t -0.014001663557947071\n",
      "78     \t [-0.51051861  1.68444812]. \t  -205.0076833315466 \t -0.014001663557947071\n",
      "79     \t [-1.06095289 -0.39755859]. \t  -236.25514667039812 \t -0.014001663557947071\n",
      "80     \t [ 0.36031694 -0.00897675]. \t  -2.335878478975027 \t -0.014001663557947071\n",
      "81     \t [0.50321713 0.25309516]. \t  -0.24679496978740006 \t -0.014001663557947071\n",
      "82     \t [-0.82949027  1.47402342]. \t  -65.12181013587157 \t -0.014001663557947071\n",
      "83     \t [ 0.10348957 -1.23911708]. \t  -157.01052777221707 \t -0.014001663557947071\n",
      "84     \t [1.78402586 0.47746595]. \t  -732.4699348470266 \t -0.014001663557947071\n",
      "85     \t [-1.05457877  1.81289119]. \t  -53.32702467490017 \t -0.014001663557947071\n",
      "86     \t [-0.85440648 -1.43697053]. \t  -473.019468218265 \t -0.014001663557947071\n",
      "87     \t [-1.23659192 -0.58198804]. \t  -450.69676966562554 \t -0.014001663557947071\n",
      "88     \t [-1.42980548  1.22539506]. \t  -72.97164514750482 \t -0.014001663557947071\n",
      "89     \t [-1.88312686  1.82949245]. \t  -303.00949927111895 \t -0.014001663557947071\n",
      "90     \t [-1.4660533   1.66046065]. \t  -29.979010274014193 \t -0.014001663557947071\n",
      "91     \t [-0.0655655   0.64578957]. \t  -42.28646587945757 \t -0.014001663557947071\n",
      "92     \t [1.59988677 0.83088525]. \t  -299.2183568062418 \t -0.014001663557947071\n",
      "93     \t [-0.18625368  0.67477663]. \t  -42.37823194204345 \t -0.014001663557947071\n",
      "94     \t [1.19295637 0.88925704]. \t  -28.540856130884436 \t -0.014001663557947071\n",
      "95     \t [ 1.25493264 -0.61556837]. \t  -479.8608501814786 \t -0.014001663557947071\n",
      "96     \t [1.5768618  1.87960322]. \t  -37.1643059079143 \t -0.014001663557947071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.6027097  1.82522772]. \t  -213.89309756821692 \t -0.014001663557947071\n",
      "98     \t [-1.99286282 -1.79067893]. \t  -3329.230399486352 \t -0.014001663557947071\n",
      "99     \t [ 1.5240691  -0.14424668]. \t  -608.8999803784616 \t -0.014001663557947071\n",
      "100    \t [-0.71917525  1.86097463]. \t  -183.5250858961645 \t -0.014001663557947071\n"
     ]
    }
   ],
   "source": [
    "### 6(t). Bayesian optimization runs (x20): GP run number = 20\n",
    "\n",
    "np.random.seed(run_num_20)\n",
    "surrogate_gp_20 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_20 = GPGO(surrogate_gp_20, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_20.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.2888388  0.26430978]. \t  -3.777577453542735 \t -3.777577453542735\n",
      "init   \t [-0.04734225 -0.66978712]. \t  -46.25914429040042 \t -3.777577453542735\n",
      "init   \t [-0.50844394  0.13121892]. \t  -3.895838569726608 \t -3.777577453542735\n",
      "init   \t [-1.76903664  0.34623103]. \t  -782.3209705533411 \t -3.777577453542735\n",
      "init   \t [-1.07357076 -1.38954104]. \t  -650.524506936468 \t -3.777577453542735\n",
      "1      \t [ 2.048 -2.048]. \t  -3897.7342268415996 \t -3.777577453542735\n",
      "2      \t [2.048 2.048]. \t  -461.7603900415999 \t -3.777577453542735\n",
      "3      \t [-0.48441591  2.048     ]. \t  -331.0241297468861 \t -3.777577453542735\n",
      "4      \t [-2.048  2.048]. \t  -469.9523900415999 \t -3.777577453542735\n",
      "5      \t [2.048      0.47281148]. \t  -1386.048958420329 \t -3.777577453542735\n",
      "6      \t [-2.048 -2.048]. \t  -3905.9262268415996 \t -3.777577453542735\n",
      "7      \t [-0.13310924 -2.048     ]. \t  -428.00305099618674 \t -3.777577453542735\n",
      "8      \t [0.7422317 2.048    ]. \t  -224.19492020549404 \t -3.777577453542735\n",
      "9      \t [0.07159436 1.12709968]. \t  -126.7444870382572 \t -3.777577453542735\n",
      "10     \t [-0.7198027  -0.64267802]. \t  -137.70198147098264 \t -3.777577453542735\n",
      "11     \t [-1.09179444  1.23171484]. \t  -4.533210949291769 \t -3.777577453542735\n",
      "12     \t [ 1.05321474 -0.50033319]. \t  -259.08227252423546 \t -3.777577453542735\n",
      "13     \t [-0.58272823  0.85618776]. \t  -29.194193613131535 \t -3.777577453542735\n",
      "14     \t [1.10235695 1.26338688]. \t  \u001b[92m-0.24276268930048506\u001b[0m \t -0.24276268930048506\n",
      "15     \t [-1.27675634  2.048     ]. \t  -22.6470952855721 \t -0.24276268930048506\n",
      "16     \t [-0.37769066 -1.35167664]. \t  -225.19931326171485 \t -0.24276268930048506\n",
      "17     \t [ 0.47771316 -0.28161313]. \t  -26.26473183030912 \t -0.24276268930048506\n",
      "18     \t [ 0.58665492 -1.30972134]. \t  -273.7045224223848 \t -0.24276268930048506\n",
      "19     \t [1.27625561 1.79471584]. \t  -2.828182347912781 \t -0.24276268930048506\n",
      "20     \t [-2.048       1.23473743]. \t  -885.1937302839003 \t -0.24276268930048506\n",
      "21     \t [-2.048     -0.6266211]. \t  -2333.4221880549326 \t -0.24276268930048506\n",
      "22     \t [0.8967287  1.43294662]. \t  -39.55266006913633 \t -0.24276268930048506\n",
      "23     \t [1.34832982 2.048     ]. \t  -5.411642265110659 \t -0.24276268930048506\n",
      "24     \t [-0.99627739  1.61392106]. \t  -42.59300556046223 \t -0.24276268930048506\n",
      "25     \t [0.66618229 0.75326024]. \t  -9.688070150066897 \t -0.24276268930048506\n",
      "26     \t [-0.75340604 -2.048     ]. \t  -687.2215783391651 \t -0.24276268930048506\n",
      "27     \t [ 0.50944014 -0.74095327]. \t  -100.33717726206237 \t -0.24276268930048506\n",
      "28     \t [-0.16690904 -0.13951773]. \t  -4.163161269146963 \t -0.24276268930048506\n",
      "29     \t [-0.96849152  0.66690322]. \t  -11.222994654023836 \t -0.24276268930048506\n",
      "30     \t [ 2.048      -0.69913504]. \t  -2395.672871043429 \t -0.24276268930048506\n",
      "31     \t [0.96440788 0.34507128]. \t  -34.22508633162144 \t -0.24276268930048506\n",
      "32     \t [ 0.70512997 -2.048     ]. \t  -647.8954608710038 \t -0.24276268930048506\n",
      "33     \t [-1.36772962  1.73128875]. \t  -7.549256311882402 \t -0.24276268930048506\n",
      "34     \t [-0.3197127   0.33575416]. \t  -7.195639006239514 \t -0.24276268930048506\n",
      "35     \t [0.63278432 0.27828629]. \t  -1.626414010743834 \t -0.24276268930048506\n",
      "36     \t [2.048      1.38607283]. \t  -789.7145334325043 \t -0.24276268930048506\n",
      "37     \t [-1.49545239  2.048     ]. \t  -9.775904040782555 \t -0.24276268930048506\n",
      "38     \t [1.19280933 1.49893807]. \t  -0.6169657979352551 \t -0.24276268930048506\n",
      "39     \t [ 1.31318164 -1.42040501]. \t  -989.1068806017096 \t -0.24276268930048506\n",
      "40     \t [-0.71417409  0.53213075]. \t  -2.987172454471446 \t -0.24276268930048506\n",
      "41     \t [-1.19891955 -0.1499241 ]. \t  -256.797591552247 \t -0.24276268930048506\n",
      "42     \t [0.84398166 0.68794465]. \t  \u001b[92m-0.08368461768391156\u001b[0m \t -0.08368461768391156\n",
      "43     \t [ 0.05329757 -0.07498371]. \t  -1.501908231947116 \t -0.08368461768391156\n",
      "44     \t [1.53188083 2.048     ]. \t  -9.202609972868123 \t -0.08368461768391156\n",
      "45     \t [1.35081963 1.78026161]. \t  -0.3206730794272731 \t -0.08368461768391156\n",
      "46     \t [1.40846544 2.048     ]. \t  -0.5793305147606108 \t -0.08368461768391156\n",
      "47     \t [1.24005157 1.59620333]. \t  -0.3995623829220381 \t -0.08368461768391156\n",
      "48     \t [0.72497597 0.50090595]. \t  -0.1365692341932695 \t -0.08368461768391156\n",
      "49     \t [0.9438413  0.93526853]. \t  -0.20057516084871418 \t -0.08368461768391156\n",
      "50     \t [-1.34682181  1.88077929]. \t  -5.954468851390533 \t -0.08368461768391156\n",
      "51     \t [1.4271557  2.03567143]. \t  -0.18258342036378059 \t -0.08368461768391156\n",
      "52     \t [-1.24444506  1.55958584]. \t  -5.049507084886759 \t -0.08368461768391156\n",
      "53     \t [1.36675782 1.84556785]. \t  -0.184952355700777 \t -0.08368461768391156\n",
      "54     \t [1.42372175 2.03844515]. \t  -0.19267681201196815 \t -0.08368461768391156\n",
      "55     \t [1.40761913 1.98114445]. \t  -0.1661594643993337 \t -0.08368461768391156\n",
      "56     \t [0.7339618  0.52325682]. \t  -0.094625280180371 \t -0.08368461768391156\n",
      "57     \t [0.73488451 0.51157967]. \t  -0.15137206679479087 \t -0.08368461768391156\n",
      "58     \t [1.04791314 1.15383304]. \t  -0.3126682756863546 \t -0.08368461768391156\n",
      "59     \t [0.02999574 0.01810875]. \t  -0.9705232643186096 \t -0.08368461768391156\n",
      "60     \t [1.17397494 1.40563929]. \t  -0.10546463932844857 \t -0.08368461768391156\n",
      "61     \t [1.18712628 1.44887855]. \t  -0.19190937424671595 \t -0.08368461768391156\n",
      "62     \t [0.93590989 0.96165168]. \t  -0.7389740220695274 \t -0.08368461768391156\n",
      "63     \t [1.42268615 2.04799872]. \t  -0.2360853061098642 \t -0.08368461768391156\n",
      "64     \t [1.04090531 1.11211794]. \t  \u001b[92m-0.08366433692247016\u001b[0m \t -0.08366433692247016\n",
      "65     \t [1.03627548 1.15490274]. \t  -0.6579971934135324 \t -0.08366433692247016\n",
      "66     \t [0.87566447 0.70759688]. \t  -0.3658213753617867 \t -0.08366433692247016\n",
      "67     \t [0.83471013 0.69885666]. \t  \u001b[92m-0.02776834513628367\u001b[0m \t -0.02776834513628367\n",
      "68     \t [0.67353261 0.44016426]. \t  -0.12475714222414286 \t -0.02776834513628367\n",
      "69     \t [0.76061353 0.53530826]. \t  -0.24414327418091844 \t -0.02776834513628367\n",
      "70     \t [1.41892437 2.048     ]. \t  -0.2955850105210626 \t -0.02776834513628367\n",
      "71     \t [1.27197921 1.60919228]. \t  -0.0816093921303423 \t -0.02776834513628367\n",
      "72     \t [-0.0268032   0.01802105]. \t  -1.0842629628632152 \t -0.02776834513628367\n",
      "73     \t [1.22168497 1.54051032]. \t  -0.2795071582526161 \t -0.02776834513628367\n",
      "74     \t [1.09253587 1.20403041]. \t  \u001b[92m-0.019370125788263658\u001b[0m \t -0.019370125788263658\n",
      "75     \t [0.70504307 0.47961626]. \t  -0.11751784385071976 \t -0.019370125788263658\n",
      "76     \t [0.6473476  0.45583552]. \t  -0.2596155807629816 \t -0.019370125788263658\n",
      "77     \t [1.42962709 2.04799952]. \t  -0.18631492035784988 \t -0.019370125788263658\n",
      "78     \t [1.37377413 1.89313345]. \t  -0.1431622927718415 \t -0.019370125788263658\n",
      "79     \t [0.78645921 0.56636414]. \t  -0.3176030838292383 \t -0.019370125788263658\n",
      "80     \t [0.73424884 0.49366994]. \t  -0.2772068311208342 \t -0.019370125788263658\n",
      "81     \t [0.88994122 0.81939083]. \t  -0.08716398916796109 \t -0.019370125788263658\n",
      "82     \t [1.19048012 1.4545514 ]. \t  -0.175474964145656 \t -0.019370125788263658\n",
      "83     \t [0.6808651  0.45347551]. \t  -0.1120516664808847 \t -0.019370125788263658\n",
      "84     \t [1.30838312 1.73012857]. \t  -0.12845086838152225 \t -0.019370125788263658\n",
      "85     \t [0.86797006 0.75583555]. \t  \u001b[92m-0.018038797704000523\u001b[0m \t -0.018038797704000523\n",
      "86     \t [0.99871062 0.96539182]. \t  -0.10260069559168525 \t -0.018038797704000523\n",
      "87     \t [1.40806074 1.97849841]. \t  -0.1682247465398864 \t -0.018038797704000523\n",
      "88     \t [1.36977101 1.8941557 ]. \t  -0.16871103233109008 \t -0.018038797704000523\n",
      "89     \t [1.10878763 1.27723889]. \t  -0.2405949181303676 \t -0.018038797704000523\n",
      "90     \t [0.83262689 0.7144665 ]. \t  -0.07295333258468545 \t -0.018038797704000523\n",
      "91     \t [0.9044936  0.81941656]. \t  \u001b[92m-0.009292526873179576\u001b[0m \t -0.009292526873179576\n",
      "92     \t [1.30353387 1.69597647]. \t  -0.09317228480742419 \t -0.009292526873179576\n",
      "93     \t [1.39147962 1.92682742]. \t  -0.16206994111479692 \t -0.009292526873179576\n",
      "94     \t [0.87384855 0.82167321]. \t  -0.3530329768807167 \t -0.009292526873179576\n",
      "95     \t [0.68768966 0.44129977]. \t  -0.19750305593711903 \t -0.009292526873179576\n",
      "96     \t [0.86296786 0.72034016]. \t  -0.07818391057667193 \t -0.009292526873179576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97     \t [0.82495365 0.70901699]. \t  -0.11168656040627233 \t -0.009292526873179576\n",
      "98     \t [1.43505385 2.048     ]. \t  -0.2022212951797177 \t -0.009292526873179576\n",
      "99     \t [0.9214578  0.84295389]. \t  -0.009927282261999253 \t -0.009292526873179576\n",
      "100    \t [1.08452176 1.25161554]. \t  -0.576083655393098 \t -0.009292526873179576\n"
     ]
    }
   ],
   "source": [
    "### 6(t). Bayesian optimization runs (x20): STP DF1 run number = 20\n",
    "\n",
    "np.random.seed(run_num_20)\n",
    "surrogate_stp_df1_20 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_20 = GPGO(surrogate_stp_df1_20, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_20.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.268579130858429, -4.678544763875652)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(t). Training Regret Minimisation: run number = 20\n",
    "\n",
    "gp_output_20 = np.append(np.max(gpgo_gp_20.GP.y[0:n_init]),gpgo_gp_20.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_20 = np.append(np.max(gpgo_stp_df1_20.GP.y[0:n_init]),gpgo_stp_df1_20.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_20 = np.log(y_global_orig - gp_output_20)\n",
    "regret_stp_df1_20 = np.log(y_global_orig - stp_df1_output_20)\n",
    "\n",
    "train_regret_gp_20 = min_max_array(regret_gp_20)\n",
    "train_regret_stp_df1_20 = min_max_array(regret_stp_df1_20)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 20\n",
    "min_train_regret_gp_20 = min(train_regret_gp_20)\n",
    "min_train_regret_stp_df1_20 = min(train_regret_stp_df1_20)\n",
    "\n",
    "min_train_regret_gp_20, min_train_regret_stp_df1_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Run 19</th>\n",
       "      <td>-3.014804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 18</th>\n",
       "      <td>-3.572974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 12</th>\n",
       "      <td>-3.711866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 17</th>\n",
       "      <td>-3.749529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 14</th>\n",
       "      <td>-3.825188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 11</th>\n",
       "      <td>-4.034060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 20</th>\n",
       "      <td>-4.268579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 13</th>\n",
       "      <td>-4.811180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 8</th>\n",
       "      <td>-4.885139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 6</th>\n",
       "      <td>-4.957978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 3</th>\n",
       "      <td>-5.020849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 5</th>\n",
       "      <td>-5.173298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 9</th>\n",
       "      <td>-5.426294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 2</th>\n",
       "      <td>-5.774243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 4</th>\n",
       "      <td>-5.808657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 10</th>\n",
       "      <td>-6.184398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 16</th>\n",
       "      <td>-6.729627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 7</th>\n",
       "      <td>-7.140646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 1</th>\n",
       "      <td>-7.921689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 15</th>\n",
       "      <td>-8.878073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GP\n",
       "Run 19 -3.014804\n",
       "Run 18 -3.572974\n",
       "Run 12 -3.711866\n",
       "Run 17 -3.749529\n",
       "Run 14 -3.825188\n",
       "Run 11 -4.034060\n",
       "Run 20 -4.268579\n",
       "Run 13 -4.811180\n",
       "Run 8  -4.885139\n",
       "Run 6  -4.957978\n",
       "Run 3  -5.020849\n",
       "Run 5  -5.173298\n",
       "Run 9  -5.426294\n",
       "Run 2  -5.774243\n",
       "Run 4  -5.808657\n",
       "Run 10 -6.184398\n",
       "Run 16 -6.729627\n",
       "Run 7  -7.140646\n",
       "Run 1  -7.921689\n",
       "Run 15 -8.878073"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7(a). Sort GP results:\n",
    "\n",
    "gp_regret = [min_train_regret_gp_1,\n",
    "                 min_train_regret_gp_2,\n",
    "                 min_train_regret_gp_3,\n",
    "                 min_train_regret_gp_4,\n",
    "                 min_train_regret_gp_5,\n",
    "                 min_train_regret_gp_6,\n",
    "                 min_train_regret_gp_7,\n",
    "                 min_train_regret_gp_8,\n",
    "                 min_train_regret_gp_9,\n",
    "                 min_train_regret_gp_10,\n",
    "                 min_train_regret_gp_11,\n",
    "                 min_train_regret_gp_12,\n",
    "                 min_train_regret_gp_13,\n",
    "                 min_train_regret_gp_14,\n",
    "                 min_train_regret_gp_15,\n",
    "                 min_train_regret_gp_16,\n",
    "                 min_train_regret_gp_17,\n",
    "                 min_train_regret_gp_18,\n",
    "                 min_train_regret_gp_19,\n",
    "                 min_train_regret_gp_20]\n",
    "\n",
    "fields = [\"Run 1\",\"Run 2\",\"Run 3\",\"Run 4\",\"Run 5\",\"Run 6\",\"Run 7\",\"Run 8\",\"Run 9\",\"Run 10\",\n",
    "          \"Run 11\",\"Run 12\",\"Run 13\",\"Run 14\",\"Run 15\",\"Run 16\",\"Run 17\",\"Run 18\",\"Run 19\",\"Run 20\"]\n",
    "\n",
    "IndexTitle = [\"GP\"]\n",
    "\n",
    "gp_results = pd.DataFrame(gp_regret, fields, IndexTitle).sort_values(by=[\"GP\"], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp = gp_results[4:5]\n",
    "median_gp = gp_results[9:10]\n",
    "upper_gp = gp_results[14:15]\n",
    "best_gp = gp_results[19:20]\n",
    "\n",
    "gp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              GP\n",
       " Run 14 -3.825188,              GP\n",
       " Run 6 -4.957978,              GP\n",
       " Run 4 -5.808657)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7(b). Training regret minimization - GP:\n",
    "lower_gp, median_gp, upper_gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STP DF 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Run 6</th>\n",
       "      <td>-4.016836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 3</th>\n",
       "      <td>-4.531908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 20</th>\n",
       "      <td>-4.678545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 19</th>\n",
       "      <td>-4.757480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 11</th>\n",
       "      <td>-4.871495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 16</th>\n",
       "      <td>-4.900112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 8</th>\n",
       "      <td>-4.937377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 9</th>\n",
       "      <td>-4.969756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 15</th>\n",
       "      <td>-5.105432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 12</th>\n",
       "      <td>-5.460182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 5</th>\n",
       "      <td>-5.844037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 1</th>\n",
       "      <td>-5.935391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 14</th>\n",
       "      <td>-6.029286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 4</th>\n",
       "      <td>-6.497165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 17</th>\n",
       "      <td>-6.658817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 7</th>\n",
       "      <td>-7.140646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 2</th>\n",
       "      <td>-7.474929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 13</th>\n",
       "      <td>-7.738322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 18</th>\n",
       "      <td>-7.856445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 10</th>\n",
       "      <td>-8.739369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STP DF 1\n",
       "Run 6  -4.016836\n",
       "Run 3  -4.531908\n",
       "Run 20 -4.678545\n",
       "Run 19 -4.757480\n",
       "Run 11 -4.871495\n",
       "Run 16 -4.900112\n",
       "Run 8  -4.937377\n",
       "Run 9  -4.969756\n",
       "Run 15 -5.105432\n",
       "Run 12 -5.460182\n",
       "Run 5  -5.844037\n",
       "Run 1  -5.935391\n",
       "Run 14 -6.029286\n",
       "Run 4  -6.497165\n",
       "Run 17 -6.658817\n",
       "Run 7  -7.140646\n",
       "Run 2  -7.474929\n",
       "Run 13 -7.738322\n",
       "Run 18 -7.856445\n",
       "Run 10 -8.739369"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7(c). Sort STP DF1 results:\n",
    "\n",
    "stp_df1_regret = [min_train_regret_stp_df1_1,\n",
    "                  min_train_regret_stp_df1_2,\n",
    "                  min_train_regret_stp_df1_3,\n",
    "                  min_train_regret_stp_df1_4,\n",
    "                  min_train_regret_stp_df1_5,\n",
    "                  min_train_regret_stp_df1_6,\n",
    "                  min_train_regret_stp_df1_7,\n",
    "                  min_train_regret_stp_df1_8,\n",
    "                  min_train_regret_stp_df1_9,\n",
    "                  min_train_regret_stp_df1_10,\n",
    "                  min_train_regret_stp_df1_11,\n",
    "                  min_train_regret_stp_df1_12,\n",
    "                  min_train_regret_stp_df1_13,\n",
    "                  min_train_regret_stp_df1_14,\n",
    "                  min_train_regret_stp_df1_15,\n",
    "                  min_train_regret_stp_df1_16,\n",
    "                  min_train_regret_stp_df1_17,\n",
    "                  min_train_regret_stp_df1_18,\n",
    "                  min_train_regret_stp_df1_19,\n",
    "                  min_train_regret_stp_df1_20]\n",
    "\n",
    "fields = [\"Run 1\",\"Run 2\",\"Run 3\",\"Run 4\",\"Run 5\",\"Run 6\",\"Run 7\",\"Run 8\",\"Run 9\",\"Run 10\",\n",
    "          \"Run 11\",\"Run 12\",\"Run 13\",\"Run 14\",\"Run 15\",\"Run 16\",\"Run 17\",\"Run 18\",\"Run 19\",\"Run 20\"]\n",
    "\n",
    "IndexTitle = [\"STP DF 1\"]\n",
    "\n",
    "stp_df1_results = pd.DataFrame(stp_df1_regret, fields, IndexTitle).sort_values(by=[\"STP DF 1\"], ascending=False)\n",
    "\n",
    "### training regret minimization IQR - STP DF1:\n",
    "lower_stp_df1 = stp_df1_results[4:5]\n",
    "median_stp_df1 = stp_df1_results[9:10]\n",
    "upper_stp_df1 = stp_df1_results[14:15]\n",
    "best_stp_df1 = stp_df1_results[19:20]\n",
    "\n",
    "stp_df1_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        STP DF 1\n",
       " Run 11 -4.871495,         STP DF 1\n",
       " Run 12 -5.460182,         STP DF 1\n",
       " Run 17 -6.658817)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7(d). Sort STP DF 1 results:\n",
    "\n",
    "### Training regret minimization - STP DF1:\n",
    "lower_stp_df1, median_stp_df1, upper_stp_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              GP\n",
       " Run 14 -3.825188,              GP\n",
       " Run 4 -5.808657,         STP DF 1\n",
       " Run 11 -4.871495,         STP DF 1\n",
       " Run 17 -6.658817)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 8(a). IQR inputs:\n",
    "\n",
    "lower_gp, upper_gp, lower_stp_df1, upper_stp_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 8(b). Regret minimisation plot: GP v STP DF 1\n",
    "\n",
    "title = obj_func\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(train_regret_gp_6, label = 'GP ERM Regret: Median', marker = 'D', color = 'Red')\n",
    "plt.plot(train_regret_stp_df1_12, label = 'STP ERM Regret: Median ' r'($\\nu$' ' = {})'.format(df1), marker = '*', color = 'Blue')\n",
    "\n",
    "plt.title(title, weight = 'bold')\n",
    "plt.xlabel('(post-initialization) iteration $\\it{k}$', weight = 'bold') # x-axis label\n",
    "plt.ylabel('ln(Regret)', weight = 'bold') # y-axis label\n",
    "plt.legend(loc=0) # add plot legend\n",
    "\n",
    "plt.show() #visualise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 8(c). Regret minimisation plot: IQR GP v STP DF 1\n",
    "\n",
    "title = obj_func\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(train_regret_gp_6, marker = 'D', color = 'Red')\n",
    "plt.plot(train_regret_stp_df1_12, marker = '*', color = 'Blue')\n",
    "\n",
    "xstar = np.arange(0, 101, step=1)\n",
    "plt.fill_between(xstar, train_regret_gp_14, train_regret_gp_4, facecolor = 'Red', alpha=0.4, label='GP ERM Regret: IQR')\n",
    "plt.fill_between(xstar, train_regret_stp_df1_11, train_regret_stp_df1_17, facecolor = 'Blue', alpha=0.4, label='STP ERM Regret: IQR ' r'($\\nu$' ' = {})'.format(df1))\n",
    "\n",
    "plt.title(title, weight = 'bold')\n",
    "plt.xlabel('(post-initialization) iteration $\\it{k}$', weight = 'bold') # x-axis label\n",
    "plt.ylabel('ln(Regret)', weight = 'bold') # y-axis label\n",
    "plt.legend(loc=0) # add plot legend\n",
    "\n",
    "plt.show() #visualise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.465863922875987,\n",
       " 2.8293117007883186,\n",
       " 2.038736147173563,\n",
       " 4.465863922875987,\n",
       " 2.8293117007883186,\n",
       " 2.038736147173563)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration1 :\n",
    "\n",
    "slice1 = 0\n",
    "\n",
    "gp1 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp1 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp1_results = pd.DataFrame(gp1).sort_values(by=[0], ascending=False)\n",
    "stp1_results = pd.DataFrame(stp1).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp1 = np.asarray(gp1_results[4:5][0])[0]\n",
    "median_gp1 = np.asarray(gp1_results[9:10][0])[0]\n",
    "upper_gp1 = np.asarray(gp1_results[14:15][0])[0]\n",
    "\n",
    "lower_stp1 = np.asarray(stp1_results[4:5][0])[0]\n",
    "median_stp1 = np.asarray(stp1_results[9:10][0])[0]\n",
    "upper_stp1 = np.asarray(stp1_results[14:15][0])[0]\n",
    "\n",
    "lower_gp1, median_gp1, upper_gp1, lower_stp1, median_stp1, upper_stp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5625916257926228,\n",
       " -0.026971405705059574,\n",
       " -1.000871878711436,\n",
       " 2.14947779733742,\n",
       " 1.329082918870567,\n",
       " 1.0017029551408791)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration11 :\n",
    "\n",
    "slice11 = 10\n",
    "\n",
    "gp11 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp11 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp11_results = pd.DataFrame(gp11).sort_values(by=[0], ascending=False)\n",
    "stp11_results = pd.DataFrame(stp11).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp11 = np.asarray(gp11_results[4:5][0])[0]\n",
    "median_gp11 = np.asarray(gp11_results[9:10][0])[0]\n",
    "upper_gp11 = np.asarray(gp11_results[14:15][0])[0]\n",
    "\n",
    "lower_stp11 = np.asarray(stp11_results[4:5][0])[0]\n",
    "median_stp11 = np.asarray(stp11_results[9:10][0])[0]\n",
    "upper_stp11 = np.asarray(stp11_results[14:15][0])[0]\n",
    "\n",
    "lower_gp11, median_gp11, upper_gp11, lower_stp11, median_stp11, upper_stp11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.208363177769124,\n",
       " -1.274475222696904,\n",
       " -2.052180654175121,\n",
       " 0.6216108281338706,\n",
       " -0.5175952818556977,\n",
       " -2.1904454410872676)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration21 :\n",
    "\n",
    "slice21 = 20\n",
    "\n",
    "gp21 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp21 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp21_results = pd.DataFrame(gp21).sort_values(by=[0], ascending=False)\n",
    "stp21_results = pd.DataFrame(stp21).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp21 = np.asarray(gp21_results[4:5][0])[0]\n",
    "median_gp21 = np.asarray(gp21_results[9:10][0])[0]\n",
    "upper_gp21 = np.asarray(gp21_results[14:15][0])[0]\n",
    "\n",
    "lower_stp21 = np.asarray(stp21_results[4:5][0])[0]\n",
    "median_stp21 = np.asarray(stp21_results[9:10][0])[0]\n",
    "upper_stp21 = np.asarray(stp21_results[14:15][0])[0]\n",
    "\n",
    "lower_gp21, median_gp21, upper_gp21, lower_stp21, median_stp21, upper_stp21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3487992463193132,\n",
       " -2.2817150034838853,\n",
       " -3.2052202609509837,\n",
       " -0.5175952818556977,\n",
       " -1.7566873445784115,\n",
       " -2.738923020326601)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration31 :\n",
    "\n",
    "slice31 = 30\n",
    "\n",
    "gp31 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp31 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp31_results = pd.DataFrame(gp31).sort_values(by=[0], ascending=False)\n",
    "stp31_results = pd.DataFrame(stp31).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp31 = np.asarray(gp31_results[4:5][0])[0]\n",
    "median_gp31 = np.asarray(gp31_results[9:10][0])[0]\n",
    "upper_gp31 = np.asarray(gp31_results[14:15][0])[0]\n",
    "\n",
    "lower_stp31 = np.asarray(stp31_results[4:5][0])[0]\n",
    "median_stp31 = np.asarray(stp31_results[9:10][0])[0]\n",
    "upper_stp31 = np.asarray(stp31_results[14:15][0])[0]\n",
    "\n",
    "lower_gp31, median_gp31, upper_gp31, lower_stp31, median_stp31, upper_stp31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.043216882553417,\n",
       " -2.576818470829016,\n",
       " -3.2052202609509837,\n",
       " -1.4852585956582012,\n",
       " -2.2399794545981377,\n",
       " -3.046315615391803)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration41 :\n",
    "\n",
    "slice41 = 40\n",
    "\n",
    "gp41 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp41 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp41_results = pd.DataFrame(gp41).sort_values(by=[0], ascending=False)\n",
    "stp41_results = pd.DataFrame(stp41).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp41 = np.asarray(gp41_results[4:5][0])[0]\n",
    "median_gp41 = np.asarray(gp41_results[9:10][0])[0]\n",
    "upper_gp41 = np.asarray(gp41_results[14:15][0])[0]\n",
    "\n",
    "lower_stp41 = np.asarray(stp41_results[4:5][0])[0]\n",
    "median_stp41 = np.asarray(stp41_results[9:10][0])[0]\n",
    "upper_stp41 = np.asarray(stp41_results[14:15][0])[0]\n",
    "\n",
    "lower_gp41, median_gp41, upper_gp41, lower_stp41, median_stp41, upper_stp41\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.548486389313155,\n",
       " -3.387839435485708,\n",
       " -4.811180114806883,\n",
       " -3.0999172719175387,\n",
       " -3.6510894827713627,\n",
       " -4.201581819953229)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration51 :\n",
    "\n",
    "slice51 = 50\n",
    "\n",
    "gp51 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp51 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp51_results = pd.DataFrame(gp51).sort_values(by=[0], ascending=False)\n",
    "stp51_results = pd.DataFrame(stp51).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp51 = np.asarray(gp51_results[4:5][0])[0]\n",
    "median_gp51 = np.asarray(gp51_results[9:10][0])[0]\n",
    "upper_gp51 = np.asarray(gp51_results[14:15][0])[0]\n",
    "\n",
    "lower_stp51 = np.asarray(stp51_results[4:5][0])[0]\n",
    "median_stp51 = np.asarray(stp51_results[9:10][0])[0]\n",
    "upper_stp51 = np.asarray(stp51_results[14:15][0])[0]\n",
    "\n",
    "lower_gp51, median_gp51, upper_gp51, lower_stp51, median_stp51, upper_stp51\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.8569412381127535,\n",
       " -3.5729738225166305,\n",
       " -4.811180114806883,\n",
       " -3.6510894827713627,\n",
       " -4.557464367596583,\n",
       " -5.571695061435701)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration61 :\n",
    "\n",
    "slice61 = 60\n",
    "\n",
    "gp61 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp61 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp61_results = pd.DataFrame(gp61).sort_values(by=[0], ascending=False)\n",
    "stp61_results = pd.DataFrame(stp61).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp61 = np.asarray(gp61_results[4:5][0])[0]\n",
    "median_gp61 = np.asarray(gp61_results[9:10][0])[0]\n",
    "upper_gp61 = np.asarray(gp61_results[14:15][0])[0]\n",
    "\n",
    "lower_stp61 = np.asarray(stp61_results[4:5][0])[0]\n",
    "median_stp61 = np.asarray(stp61_results[9:10][0])[0]\n",
    "upper_stp61 = np.asarray(stp61_results[14:15][0])[0]\n",
    "\n",
    "lower_gp61, median_gp61, upper_gp61, lower_stp61, median_stp61, upper_stp61\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.1162744483056444,\n",
       " -3.5729738225166305,\n",
       " -5.426294075349022,\n",
       " -4.273469106263236,\n",
       " -4.725440108525788,\n",
       " -6.029286036209675)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration71 :\n",
    "\n",
    "slice71 = 70\n",
    "\n",
    "gp71 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp71 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp71_results = pd.DataFrame(gp71).sort_values(by=[0], ascending=False)\n",
    "stp71_results = pd.DataFrame(stp71).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp71 = np.asarray(gp71_results[4:5][0])[0]\n",
    "median_gp71 = np.asarray(gp71_results[9:10][0])[0]\n",
    "upper_gp71 = np.asarray(gp71_results[14:15][0])[0]\n",
    "\n",
    "lower_stp71 = np.asarray(stp71_results[4:5][0])[0]\n",
    "median_stp71 = np.asarray(stp71_results[9:10][0])[0]\n",
    "upper_stp71 = np.asarray(stp71_results[14:15][0])[0]\n",
    "\n",
    "lower_gp71, median_gp71, upper_gp71, lower_stp71, median_stp71, upper_stp71\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.5271283016889377,\n",
       " -4.811180114806883,\n",
       " -5.774243280230393,\n",
       " -4.612434374652544,\n",
       " -5.235169480342767,\n",
       " -6.25090236822877)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration81 :\n",
    "\n",
    "slice81 = 80\n",
    "\n",
    "gp81 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp81 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp81_results = pd.DataFrame(gp81).sort_values(by=[0], ascending=False)\n",
    "stp81_results = pd.DataFrame(stp81).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp81 = np.asarray(gp81_results[4:5][0])[0]\n",
    "median_gp81 = np.asarray(gp81_results[9:10][0])[0]\n",
    "upper_gp81 = np.asarray(gp81_results[14:15][0])[0]\n",
    "\n",
    "lower_stp81 = np.asarray(stp81_results[4:5][0])[0]\n",
    "median_stp81 = np.asarray(stp81_results[9:10][0])[0]\n",
    "upper_stp81 = np.asarray(stp81_results[14:15][0])[0]\n",
    "\n",
    "lower_gp81, median_gp81, upper_gp81, lower_stp81, median_stp81, upper_stp81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.711865895026006,\n",
       " -4.885139440616033,\n",
       " -5.8086569761712905,\n",
       " -4.871495191540244,\n",
       " -5.460181814912429,\n",
       " -6.658817289219496)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration91 :\n",
    "\n",
    "slice1 = 90\n",
    "\n",
    "gp91 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp91 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp91_results = pd.DataFrame(gp91).sort_values(by=[0], ascending=False)\n",
    "stp91_results = pd.DataFrame(stp91).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp91 = np.asarray(gp91_results[4:5][0])[0]\n",
    "median_gp91 = np.asarray(gp91_results[9:10][0])[0]\n",
    "upper_gp91 = np.asarray(gp91_results[14:15][0])[0]\n",
    "\n",
    "lower_stp91 = np.asarray(stp91_results[4:5][0])[0]\n",
    "median_stp91 = np.asarray(stp91_results[9:10][0])[0]\n",
    "upper_stp91 = np.asarray(stp91_results[14:15][0])[0]\n",
    "\n",
    "lower_gp91, median_gp91, upper_gp91, lower_stp91, median_stp91, upper_stp91\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.8251876066440342,\n",
       " -4.957978184518829,\n",
       " -5.8086569761712905,\n",
       " -4.871495191540244,\n",
       " -5.460181814912429,\n",
       " -6.658817289219496)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration101 :\n",
    "\n",
    "slice1 = 100\n",
    "\n",
    "gp101 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp101 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp101_results = pd.DataFrame(gp101).sort_values(by=[0], ascending=False)\n",
    "stp101_results = pd.DataFrame(stp101).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp101 = np.asarray(gp101_results[4:5][0])[0]\n",
    "median_gp101 = np.asarray(gp101_results[9:10][0])[0]\n",
    "upper_gp101 = np.asarray(gp101_results[14:15][0])[0]\n",
    "\n",
    "lower_stp101 = np.asarray(stp101_results[4:5][0])[0]\n",
    "median_stp101 = np.asarray(stp101_results[9:10][0])[0]\n",
    "upper_stp101 = np.asarray(stp101_results[14:15][0])[0]\n",
    "\n",
    "lower_gp101, median_gp101, upper_gp101, lower_stp101, median_stp101, upper_stp101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration2 :\n",
    "\n",
    "slice1 = 1\n",
    "\n",
    "gp2 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp2 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp2_results = pd.DataFrame(gp2).sort_values(by=[0], ascending=False)\n",
    "stp2_results = pd.DataFrame(stp2).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp2 = np.asarray(gp2_results[4:5][0])[0]\n",
    "median_gp2 = np.asarray(gp2_results[9:10][0])[0]\n",
    "upper_gp2 = np.asarray(gp2_results[14:15][0])[0]\n",
    "\n",
    "lower_stp2 = np.asarray(stp2_results[4:5][0])[0]\n",
    "median_stp2 = np.asarray(stp2_results[9:10][0])[0]\n",
    "upper_stp2 = np.asarray(stp2_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration12 :\n",
    "\n",
    "slice11 = 11\n",
    "\n",
    "gp12 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp12 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp12_results = pd.DataFrame(gp12).sort_values(by=[0], ascending=False)\n",
    "stp12_results = pd.DataFrame(stp12).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp12 = np.asarray(gp12_results[4:5][0])[0]\n",
    "median_gp12 = np.asarray(gp12_results[9:10][0])[0]\n",
    "upper_gp12 = np.asarray(gp12_results[14:15][0])[0]\n",
    "\n",
    "lower_stp12 = np.asarray(stp12_results[4:5][0])[0]\n",
    "median_stp12 = np.asarray(stp12_results[9:10][0])[0]\n",
    "upper_stp12 = np.asarray(stp12_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration22 :\n",
    "\n",
    "slice21 = 21\n",
    "\n",
    "gp22 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp22 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp22_results = pd.DataFrame(gp22).sort_values(by=[0], ascending=False)\n",
    "stp22_results = pd.DataFrame(stp22).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp22 = np.asarray(gp22_results[4:5][0])[0]\n",
    "median_gp22 = np.asarray(gp22_results[9:10][0])[0]\n",
    "upper_gp22 = np.asarray(gp22_results[14:15][0])[0]\n",
    "\n",
    "lower_stp22 = np.asarray(stp22_results[4:5][0])[0]\n",
    "median_stp22 = np.asarray(stp22_results[9:10][0])[0]\n",
    "upper_stp22 = np.asarray(stp22_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration32 :\n",
    "\n",
    "slice31 = 31\n",
    "\n",
    "gp32 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp32 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp32_results = pd.DataFrame(gp32).sort_values(by=[0], ascending=False)\n",
    "stp32_results = pd.DataFrame(stp32).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp32 = np.asarray(gp32_results[4:5][0])[0]\n",
    "median_gp32 = np.asarray(gp32_results[9:10][0])[0]\n",
    "upper_gp32 = np.asarray(gp32_results[14:15][0])[0]\n",
    "\n",
    "lower_stp32 = np.asarray(stp32_results[4:5][0])[0]\n",
    "median_stp32 = np.asarray(stp32_results[9:10][0])[0]\n",
    "upper_stp32 = np.asarray(stp32_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration42 :\n",
    "\n",
    "slice41 = 41\n",
    "\n",
    "gp42 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp42 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp42_results = pd.DataFrame(gp42).sort_values(by=[0], ascending=False)\n",
    "stp42_results = pd.DataFrame(stp42).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp42 = np.asarray(gp42_results[4:5][0])[0]\n",
    "median_gp42 = np.asarray(gp42_results[9:10][0])[0]\n",
    "upper_gp42 = np.asarray(gp42_results[14:15][0])[0]\n",
    "\n",
    "lower_stp42 = np.asarray(stp42_results[4:5][0])[0]\n",
    "median_stp42 = np.asarray(stp42_results[9:10][0])[0]\n",
    "upper_stp42 = np.asarray(stp42_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration52 :\n",
    "\n",
    "slice51 = 51\n",
    "\n",
    "gp52 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp52 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp52_results = pd.DataFrame(gp52).sort_values(by=[0], ascending=False)\n",
    "stp52_results = pd.DataFrame(stp52).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp52 = np.asarray(gp52_results[4:5][0])[0]\n",
    "median_gp52 = np.asarray(gp52_results[9:10][0])[0]\n",
    "upper_gp52 = np.asarray(gp52_results[14:15][0])[0]\n",
    "\n",
    "lower_stp52 = np.asarray(stp52_results[4:5][0])[0]\n",
    "median_stp52 = np.asarray(stp52_results[9:10][0])[0]\n",
    "upper_stp52 = np.asarray(stp52_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration62 :\n",
    "\n",
    "slice61 = 61\n",
    "\n",
    "gp62 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp62 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp62_results = pd.DataFrame(gp62).sort_values(by=[0], ascending=False)\n",
    "stp62_results = pd.DataFrame(stp62).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp62 = np.asarray(gp62_results[4:5][0])[0]\n",
    "median_gp62 = np.asarray(gp62_results[9:10][0])[0]\n",
    "upper_gp62 = np.asarray(gp62_results[14:15][0])[0]\n",
    "\n",
    "lower_stp62 = np.asarray(stp62_results[4:5][0])[0]\n",
    "median_stp62 = np.asarray(stp62_results[9:10][0])[0]\n",
    "upper_stp62 = np.asarray(stp62_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration72 :\n",
    "\n",
    "slice71 = 71\n",
    "\n",
    "gp72 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp72 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp72_results = pd.DataFrame(gp72).sort_values(by=[0], ascending=False)\n",
    "stp72_results = pd.DataFrame(stp72).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp72 = np.asarray(gp72_results[4:5][0])[0]\n",
    "median_gp72 = np.asarray(gp72_results[9:10][0])[0]\n",
    "upper_gp72 = np.asarray(gp72_results[14:15][0])[0]\n",
    "\n",
    "lower_stp72 = np.asarray(stp72_results[4:5][0])[0]\n",
    "median_stp72 = np.asarray(stp72_results[9:10][0])[0]\n",
    "upper_stp72 = np.asarray(stp72_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration82 :\n",
    "\n",
    "slice81 = 81\n",
    "\n",
    "gp82 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp82 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp82_results = pd.DataFrame(gp82).sort_values(by=[0], ascending=False)\n",
    "stp82_results = pd.DataFrame(stp82).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp82 = np.asarray(gp82_results[4:5][0])[0]\n",
    "median_gp82 = np.asarray(gp82_results[9:10][0])[0]\n",
    "upper_gp82 = np.asarray(gp82_results[14:15][0])[0]\n",
    "\n",
    "lower_stp82 = np.asarray(stp82_results[4:5][0])[0]\n",
    "median_stp82 = np.asarray(stp82_results[9:10][0])[0]\n",
    "upper_stp82 = np.asarray(stp82_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration92 :\n",
    "\n",
    "slice1 = 91\n",
    "\n",
    "gp92 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp92 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp92_results = pd.DataFrame(gp92).sort_values(by=[0], ascending=False)\n",
    "stp92_results = pd.DataFrame(stp92).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp92 = np.asarray(gp92_results[4:5][0])[0]\n",
    "median_gp92 = np.asarray(gp92_results[9:10][0])[0]\n",
    "upper_gp92 = np.asarray(gp92_results[14:15][0])[0]\n",
    "\n",
    "lower_stp92 = np.asarray(stp92_results[4:5][0])[0]\n",
    "median_stp92 = np.asarray(stp92_results[9:10][0])[0]\n",
    "upper_stp92 = np.asarray(stp92_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration3 :\n",
    "\n",
    "slice1 = 2\n",
    "\n",
    "gp3 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp3 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp3_results = pd.DataFrame(gp3).sort_values(by=[0], ascending=False)\n",
    "stp3_results = pd.DataFrame(stp3).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp3 = np.asarray(gp3_results[4:5][0])[0]\n",
    "median_gp3 = np.asarray(gp3_results[9:10][0])[0]\n",
    "upper_gp3 = np.asarray(gp3_results[14:15][0])[0]\n",
    "\n",
    "lower_stp3 = np.asarray(stp3_results[4:5][0])[0]\n",
    "median_stp3 = np.asarray(stp3_results[9:10][0])[0]\n",
    "upper_stp3 = np.asarray(stp3_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration13 :\n",
    "\n",
    "slice11 = 12\n",
    "\n",
    "gp13 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp13 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp13_results = pd.DataFrame(gp12).sort_values(by=[0], ascending=False)\n",
    "stp13_results = pd.DataFrame(stp12).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp13 = np.asarray(gp13_results[4:5][0])[0]\n",
    "median_gp13 = np.asarray(gp13_results[9:10][0])[0]\n",
    "upper_gp13 = np.asarray(gp13_results[14:15][0])[0]\n",
    "\n",
    "lower_stp13 = np.asarray(stp13_results[4:5][0])[0]\n",
    "median_stp13 = np.asarray(stp13_results[9:10][0])[0]\n",
    "upper_stp13 = np.asarray(stp13_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration23 :\n",
    "\n",
    "slice21 = 22\n",
    "\n",
    "gp23 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp23 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp23_results = pd.DataFrame(gp23).sort_values(by=[0], ascending=False)\n",
    "stp23_results = pd.DataFrame(stp23).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp23 = np.asarray(gp23_results[4:5][0])[0]\n",
    "median_gp23 = np.asarray(gp23_results[9:10][0])[0]\n",
    "upper_gp23 = np.asarray(gp23_results[14:15][0])[0]\n",
    "\n",
    "lower_stp23 = np.asarray(stp23_results[4:5][0])[0]\n",
    "median_stp23 = np.asarray(stp23_results[9:10][0])[0]\n",
    "upper_stp23 = np.asarray(stp23_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration33 :\n",
    "\n",
    "slice31 = 32\n",
    "\n",
    "gp33 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp33 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp33_results = pd.DataFrame(gp33).sort_values(by=[0], ascending=False)\n",
    "stp33_results = pd.DataFrame(stp33).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp33 = np.asarray(gp33_results[4:5][0])[0]\n",
    "median_gp33 = np.asarray(gp33_results[9:10][0])[0]\n",
    "upper_gp33 = np.asarray(gp33_results[14:15][0])[0]\n",
    "\n",
    "lower_stp33 = np.asarray(stp33_results[4:5][0])[0]\n",
    "median_stp33 = np.asarray(stp33_results[9:10][0])[0]\n",
    "upper_stp33 = np.asarray(stp33_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration43 :\n",
    "\n",
    "slice41 = 42\n",
    "\n",
    "gp43 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp43 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp43_results = pd.DataFrame(gp43).sort_values(by=[0], ascending=False)\n",
    "stp43_results = pd.DataFrame(stp43).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp43 = np.asarray(gp43_results[4:5][0])[0]\n",
    "median_gp43 = np.asarray(gp43_results[9:10][0])[0]\n",
    "upper_gp43 = np.asarray(gp43_results[14:15][0])[0]\n",
    "\n",
    "lower_stp43 = np.asarray(stp43_results[4:5][0])[0]\n",
    "median_stp43 = np.asarray(stp43_results[9:10][0])[0]\n",
    "upper_stp43 = np.asarray(stp43_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration53 :\n",
    "\n",
    "slice51 = 52\n",
    "\n",
    "gp53 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp53 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp53_results = pd.DataFrame(gp53).sort_values(by=[0], ascending=False)\n",
    "stp53_results = pd.DataFrame(stp53).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp53 = np.asarray(gp53_results[4:5][0])[0]\n",
    "median_gp53 = np.asarray(gp53_results[9:10][0])[0]\n",
    "upper_gp53 = np.asarray(gp53_results[14:15][0])[0]\n",
    "\n",
    "lower_stp53 = np.asarray(stp53_results[4:5][0])[0]\n",
    "median_stp53 = np.asarray(stp53_results[9:10][0])[0]\n",
    "upper_stp53 = np.asarray(stp53_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration63 :\n",
    "\n",
    "slice61 = 62\n",
    "\n",
    "gp63 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp63 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp63_results = pd.DataFrame(gp63).sort_values(by=[0], ascending=False)\n",
    "stp63_results = pd.DataFrame(stp63).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp63 = np.asarray(gp63_results[4:5][0])[0]\n",
    "median_gp63 = np.asarray(gp63_results[9:10][0])[0]\n",
    "upper_gp63 = np.asarray(gp63_results[14:15][0])[0]\n",
    "\n",
    "lower_stp63 = np.asarray(stp63_results[4:5][0])[0]\n",
    "median_stp63 = np.asarray(stp63_results[9:10][0])[0]\n",
    "upper_stp63 = np.asarray(stp63_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration73 :\n",
    "\n",
    "slice71 = 72\n",
    "\n",
    "gp73 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp73 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp73_results = pd.DataFrame(gp73).sort_values(by=[0], ascending=False)\n",
    "stp73_results = pd.DataFrame(stp73).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp73 = np.asarray(gp73_results[4:5][0])[0]\n",
    "median_gp73 = np.asarray(gp73_results[9:10][0])[0]\n",
    "upper_gp73 = np.asarray(gp73_results[14:15][0])[0]\n",
    "\n",
    "lower_stp73 = np.asarray(stp73_results[4:5][0])[0]\n",
    "median_stp73 = np.asarray(stp73_results[9:10][0])[0]\n",
    "upper_stp73 = np.asarray(stp73_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration83 :\n",
    "\n",
    "slice81 = 82\n",
    "\n",
    "gp83 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp83 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp83_results = pd.DataFrame(gp83).sort_values(by=[0], ascending=False)\n",
    "stp83_results = pd.DataFrame(stp83).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp83 = np.asarray(gp83_results[4:5][0])[0]\n",
    "median_gp83 = np.asarray(gp83_results[9:10][0])[0]\n",
    "upper_gp83 = np.asarray(gp83_results[14:15][0])[0]\n",
    "\n",
    "lower_stp83 = np.asarray(stp83_results[4:5][0])[0]\n",
    "median_stp83 = np.asarray(stp83_results[9:10][0])[0]\n",
    "upper_stp83 = np.asarray(stp83_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration93 :\n",
    "\n",
    "slice1 = 92\n",
    "\n",
    "gp93 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp93 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp93_results = pd.DataFrame(gp93).sort_values(by=[0], ascending=False)\n",
    "stp93_results = pd.DataFrame(stp93).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp93 = np.asarray(gp93_results[4:5][0])[0]\n",
    "median_gp93 = np.asarray(gp93_results[9:10][0])[0]\n",
    "upper_gp93 = np.asarray(gp93_results[14:15][0])[0]\n",
    "\n",
    "lower_stp93 = np.asarray(stp93_results[4:5][0])[0]\n",
    "median_stp93 = np.asarray(stp93_results[9:10][0])[0]\n",
    "upper_stp93 = np.asarray(stp93_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration4 :\n",
    "\n",
    "slice1 = 3\n",
    "\n",
    "gp4 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp4 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp4_results = pd.DataFrame(gp4).sort_values(by=[0], ascending=False)\n",
    "stp4_results = pd.DataFrame(stp4).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp4 = np.asarray(gp4_results[4:5][0])[0]\n",
    "median_gp4 = np.asarray(gp4_results[9:10][0])[0]\n",
    "upper_gp4 = np.asarray(gp4_results[14:15][0])[0]\n",
    "\n",
    "lower_stp4 = np.asarray(stp4_results[4:5][0])[0]\n",
    "median_stp4 = np.asarray(stp4_results[9:10][0])[0]\n",
    "upper_stp4 = np.asarray(stp4_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration14 :\n",
    "\n",
    "slice11 = 13\n",
    "\n",
    "gp14 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp14 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp14_results = pd.DataFrame(gp14).sort_values(by=[0], ascending=False)\n",
    "stp14_results = pd.DataFrame(stp14).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp14 = np.asarray(gp14_results[4:5][0])[0]\n",
    "median_gp14 = np.asarray(gp14_results[9:10][0])[0]\n",
    "upper_gp14 = np.asarray(gp14_results[14:15][0])[0]\n",
    "\n",
    "lower_stp14 = np.asarray(stp14_results[4:5][0])[0]\n",
    "median_stp14 = np.asarray(stp14_results[9:10][0])[0]\n",
    "upper_stp14 = np.asarray(stp14_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration24 :\n",
    "\n",
    "slice21 = 23\n",
    "\n",
    "gp24 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp24 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp24_results = pd.DataFrame(gp24).sort_values(by=[0], ascending=False)\n",
    "stp24_results = pd.DataFrame(stp24).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp24 = np.asarray(gp24_results[4:5][0])[0]\n",
    "median_gp24 = np.asarray(gp24_results[9:10][0])[0]\n",
    "upper_gp24 = np.asarray(gp24_results[14:15][0])[0]\n",
    "\n",
    "lower_stp24 = np.asarray(stp24_results[4:5][0])[0]\n",
    "median_stp24 = np.asarray(stp24_results[9:10][0])[0]\n",
    "upper_stp24 = np.asarray(stp24_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration34 :\n",
    "\n",
    "slice31 = 33\n",
    "\n",
    "gp34 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp34 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp34_results = pd.DataFrame(gp34).sort_values(by=[0], ascending=False)\n",
    "stp34_results = pd.DataFrame(stp34).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp34 = np.asarray(gp34_results[4:5][0])[0]\n",
    "median_gp34 = np.asarray(gp34_results[9:10][0])[0]\n",
    "upper_gp34 = np.asarray(gp34_results[14:15][0])[0]\n",
    "\n",
    "lower_stp34 = np.asarray(stp34_results[4:5][0])[0]\n",
    "median_stp34 = np.asarray(stp34_results[9:10][0])[0]\n",
    "upper_stp34 = np.asarray(stp34_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration44 :\n",
    "\n",
    "slice41 = 43\n",
    "\n",
    "gp44 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp44 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp44_results = pd.DataFrame(gp44).sort_values(by=[0], ascending=False)\n",
    "stp44_results = pd.DataFrame(stp44).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp44 = np.asarray(gp44_results[4:5][0])[0]\n",
    "median_gp44 = np.asarray(gp44_results[9:10][0])[0]\n",
    "upper_gp44 = np.asarray(gp44_results[14:15][0])[0]\n",
    "\n",
    "lower_stp44 = np.asarray(stp44_results[4:5][0])[0]\n",
    "median_stp44 = np.asarray(stp44_results[9:10][0])[0]\n",
    "upper_stp44 = np.asarray(stp44_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration54 :\n",
    "\n",
    "slice51 = 53\n",
    "\n",
    "gp54 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp54 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp54_results = pd.DataFrame(gp54).sort_values(by=[0], ascending=False)\n",
    "stp54_results = pd.DataFrame(stp54).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp54 = np.asarray(gp54_results[4:5][0])[0]\n",
    "median_gp54 = np.asarray(gp54_results[9:10][0])[0]\n",
    "upper_gp54 = np.asarray(gp54_results[14:15][0])[0]\n",
    "\n",
    "lower_stp54 = np.asarray(stp54_results[4:5][0])[0]\n",
    "median_stp54 = np.asarray(stp54_results[9:10][0])[0]\n",
    "upper_stp54 = np.asarray(stp54_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration64 :\n",
    "\n",
    "slice61 = 63\n",
    "\n",
    "gp64 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp64 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp64_results = pd.DataFrame(gp64).sort_values(by=[0], ascending=False)\n",
    "stp64_results = pd.DataFrame(stp64).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp64 = np.asarray(gp64_results[4:5][0])[0]\n",
    "median_gp64 = np.asarray(gp64_results[9:10][0])[0]\n",
    "upper_gp64 = np.asarray(gp64_results[14:15][0])[0]\n",
    "\n",
    "lower_stp64 = np.asarray(stp64_results[4:5][0])[0]\n",
    "median_stp64 = np.asarray(stp64_results[9:10][0])[0]\n",
    "upper_stp64 = np.asarray(stp64_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration74 :\n",
    "\n",
    "slice71 = 73\n",
    "\n",
    "gp74 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp74 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp74_results = pd.DataFrame(gp74).sort_values(by=[0], ascending=False)\n",
    "stp74_results = pd.DataFrame(stp74).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp74 = np.asarray(gp74_results[4:5][0])[0]\n",
    "median_gp74 = np.asarray(gp74_results[9:10][0])[0]\n",
    "upper_gp74 = np.asarray(gp74_results[14:15][0])[0]\n",
    "\n",
    "lower_stp74 = np.asarray(stp74_results[4:5][0])[0]\n",
    "median_stp74 = np.asarray(stp74_results[9:10][0])[0]\n",
    "upper_stp74 = np.asarray(stp74_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration84 :\n",
    "\n",
    "slice81 = 83\n",
    "\n",
    "gp84 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp84 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp84_results = pd.DataFrame(gp84).sort_values(by=[0], ascending=False)\n",
    "stp84_results = pd.DataFrame(stp84).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp84 = np.asarray(gp84_results[4:5][0])[0]\n",
    "median_gp84 = np.asarray(gp84_results[9:10][0])[0]\n",
    "upper_gp84 = np.asarray(gp84_results[14:15][0])[0]\n",
    "\n",
    "lower_stp84 = np.asarray(stp84_results[4:5][0])[0]\n",
    "median_stp84 = np.asarray(stp84_results[9:10][0])[0]\n",
    "upper_stp84 = np.asarray(stp84_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration94 :\n",
    "\n",
    "slice1 = 93\n",
    "\n",
    "gp94 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp94 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp94_results = pd.DataFrame(gp94).sort_values(by=[0], ascending=False)\n",
    "stp94_results = pd.DataFrame(stp94).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp94 = np.asarray(gp94_results[4:5][0])[0]\n",
    "median_gp94 = np.asarray(gp94_results[9:10][0])[0]\n",
    "upper_gp94 = np.asarray(gp94_results[14:15][0])[0]\n",
    "\n",
    "lower_stp94 = np.asarray(stp94_results[4:5][0])[0]\n",
    "median_stp94 = np.asarray(stp94_results[9:10][0])[0]\n",
    "upper_stp94 = np.asarray(stp94_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration5 :\n",
    "\n",
    "slice1 = 4\n",
    "\n",
    "gp5 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp5 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp5_results = pd.DataFrame(gp5).sort_values(by=[0], ascending=False)\n",
    "stp5_results = pd.DataFrame(stp5).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp5 = np.asarray(gp5_results[4:5][0])[0]\n",
    "median_gp5 = np.asarray(gp5_results[9:10][0])[0]\n",
    "upper_gp5 = np.asarray(gp5_results[14:15][0])[0]\n",
    "\n",
    "lower_stp5 = np.asarray(stp5_results[4:5][0])[0]\n",
    "median_stp5 = np.asarray(stp5_results[9:10][0])[0]\n",
    "upper_stp5 = np.asarray(stp5_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration15 :\n",
    "\n",
    "slice11 = 14\n",
    "\n",
    "gp15 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp15 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp15_results = pd.DataFrame(gp15).sort_values(by=[0], ascending=False)\n",
    "stp15_results = pd.DataFrame(stp15).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp15 = np.asarray(gp15_results[4:5][0])[0]\n",
    "median_gp15 = np.asarray(gp15_results[9:10][0])[0]\n",
    "upper_gp15 = np.asarray(gp15_results[14:15][0])[0]\n",
    "\n",
    "lower_stp15 = np.asarray(stp15_results[4:5][0])[0]\n",
    "median_stp15 = np.asarray(stp15_results[9:10][0])[0]\n",
    "upper_stp15 = np.asarray(stp15_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration25 :\n",
    "\n",
    "slice21 = 24\n",
    "\n",
    "gp25 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp25 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp25_results = pd.DataFrame(gp25).sort_values(by=[0], ascending=False)\n",
    "stp25_results = pd.DataFrame(stp25).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp25 = np.asarray(gp25_results[4:5][0])[0]\n",
    "median_gp25 = np.asarray(gp25_results[9:10][0])[0]\n",
    "upper_gp25 = np.asarray(gp25_results[14:15][0])[0]\n",
    "\n",
    "lower_stp25 = np.asarray(stp25_results[4:5][0])[0]\n",
    "median_stp25 = np.asarray(stp25_results[9:10][0])[0]\n",
    "upper_stp25= np.asarray(stp25_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration35 :\n",
    "\n",
    "slice31 = 34\n",
    "\n",
    "gp35 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp35 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp35_results = pd.DataFrame(gp35).sort_values(by=[0], ascending=False)\n",
    "stp35_results = pd.DataFrame(stp35).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp35 = np.asarray(gp35_results[4:5][0])[0]\n",
    "median_gp35 = np.asarray(gp35_results[9:10][0])[0]\n",
    "upper_gp35 = np.asarray(gp35_results[14:15][0])[0]\n",
    "\n",
    "lower_stp35 = np.asarray(stp35_results[4:5][0])[0]\n",
    "median_stp35 = np.asarray(stp35_results[9:10][0])[0]\n",
    "upper_stp35 = np.asarray(stp35_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration45 :\n",
    "\n",
    "slice41 = 44\n",
    "\n",
    "gp45 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp45 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp45_results = pd.DataFrame(gp45).sort_values(by=[0], ascending=False)\n",
    "stp45_results = pd.DataFrame(stp45).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp45 = np.asarray(gp45_results[4:5][0])[0]\n",
    "median_gp45 = np.asarray(gp45_results[9:10][0])[0]\n",
    "upper_gp45 = np.asarray(gp45_results[14:15][0])[0]\n",
    "\n",
    "lower_stp45 = np.asarray(stp45_results[4:5][0])[0]\n",
    "median_stp45 = np.asarray(stp45_results[9:10][0])[0]\n",
    "upper_stp45 = np.asarray(stp45_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration55 :\n",
    "\n",
    "slice51 = 54\n",
    "\n",
    "gp55 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp55 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp55_results = pd.DataFrame(gp55).sort_values(by=[0], ascending=False)\n",
    "stp55_results = pd.DataFrame(stp55).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp55 = np.asarray(gp55_results[4:5][0])[0]\n",
    "median_gp55 = np.asarray(gp55_results[9:10][0])[0]\n",
    "upper_gp55 = np.asarray(gp55_results[14:15][0])[0]\n",
    "\n",
    "lower_stp55 = np.asarray(stp55_results[4:5][0])[0]\n",
    "median_stp55 = np.asarray(stp55_results[9:10][0])[0]\n",
    "upper_stp55 = np.asarray(stp55_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration65 :\n",
    "\n",
    "slice61 = 64\n",
    "\n",
    "gp65 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp65 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp65_results = pd.DataFrame(gp65).sort_values(by=[0], ascending=False)\n",
    "stp65_results = pd.DataFrame(stp65).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp65 = np.asarray(gp65_results[4:5][0])[0]\n",
    "median_gp65 = np.asarray(gp65_results[9:10][0])[0]\n",
    "upper_gp65 = np.asarray(gp65_results[14:15][0])[0]\n",
    "\n",
    "lower_stp65 = np.asarray(stp65_results[4:5][0])[0]\n",
    "median_stp65 = np.asarray(stp65_results[9:10][0])[0]\n",
    "upper_stp65 = np.asarray(stp65_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration75 :\n",
    "\n",
    "slice71 = 74\n",
    "\n",
    "gp75 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp75 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp75_results = pd.DataFrame(gp75).sort_values(by=[0], ascending=False)\n",
    "stp75_results = pd.DataFrame(stp75).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp75 = np.asarray(gp75_results[4:5][0])[0]\n",
    "median_gp75 = np.asarray(gp75_results[9:10][0])[0]\n",
    "upper_gp75 = np.asarray(gp75_results[14:15][0])[0]\n",
    "\n",
    "lower_stp75 = np.asarray(stp75_results[4:5][0])[0]\n",
    "median_stp75 = np.asarray(stp75_results[9:10][0])[0]\n",
    "upper_stp75 = np.asarray(stp75_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration85 :\n",
    "\n",
    "slice81 = 84\n",
    "\n",
    "gp85 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp85 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp85_results = pd.DataFrame(gp85).sort_values(by=[0], ascending=False)\n",
    "stp85_results = pd.DataFrame(stp85).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp85 = np.asarray(gp85_results[4:5][0])[0]\n",
    "median_gp85 = np.asarray(gp85_results[9:10][0])[0]\n",
    "upper_gp85 = np.asarray(gp85_results[14:15][0])[0]\n",
    "\n",
    "lower_stp85 = np.asarray(stp85_results[4:5][0])[0]\n",
    "median_stp85 = np.asarray(stp85_results[9:10][0])[0]\n",
    "upper_stp85 = np.asarray(stp85_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration95 :\n",
    "\n",
    "slice1 = 94\n",
    "\n",
    "gp95 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp95 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp95_results = pd.DataFrame(gp95).sort_values(by=[0], ascending=False)\n",
    "stp95_results = pd.DataFrame(stp95).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp95 = np.asarray(gp95_results[4:5][0])[0]\n",
    "median_gp95 = np.asarray(gp95_results[9:10][0])[0]\n",
    "upper_gp95 = np.asarray(gp95_results[14:15][0])[0]\n",
    "\n",
    "lower_stp95 = np.asarray(stp95_results[4:5][0])[0]\n",
    "median_stp95 = np.asarray(stp95_results[9:10][0])[0]\n",
    "upper_stp95 = np.asarray(stp95_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration6 :\n",
    "\n",
    "slice1 = 5\n",
    "\n",
    "gp6 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp6 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp6_results = pd.DataFrame(gp6).sort_values(by=[0], ascending=False)\n",
    "stp6_results = pd.DataFrame(stp6).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp6 = np.asarray(gp6_results[4:5][0])[0]\n",
    "median_gp6 = np.asarray(gp6_results[9:10][0])[0]\n",
    "upper_gp6 = np.asarray(gp6_results[14:15][0])[0]\n",
    "\n",
    "lower_stp6 = np.asarray(stp6_results[4:5][0])[0]\n",
    "median_stp6 = np.asarray(stp6_results[9:10][0])[0]\n",
    "upper_stp6 = np.asarray(stp6_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration16 :\n",
    "\n",
    "slice11 = 15\n",
    "\n",
    "gp16 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp16 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp16_results = pd.DataFrame(gp16).sort_values(by=[0], ascending=False)\n",
    "stp16_results = pd.DataFrame(stp16).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp16 = np.asarray(gp16_results[4:5][0])[0]\n",
    "median_gp16 = np.asarray(gp16_results[9:10][0])[0]\n",
    "upper_gp16 = np.asarray(gp16_results[14:15][0])[0]\n",
    "\n",
    "lower_stp16 = np.asarray(stp16_results[4:5][0])[0]\n",
    "median_stp16 = np.asarray(stp16_results[9:10][0])[0]\n",
    "upper_stp16 = np.asarray(stp16_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration26 :\n",
    "\n",
    "slice21 = 25\n",
    "\n",
    "gp26 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp26 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp26_results = pd.DataFrame(gp26).sort_values(by=[0], ascending=False)\n",
    "stp26_results = pd.DataFrame(stp26).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp26 = np.asarray(gp26_results[4:5][0])[0]\n",
    "median_gp26 = np.asarray(gp26_results[9:10][0])[0]\n",
    "upper_gp26 = np.asarray(gp26_results[14:15][0])[0]\n",
    "\n",
    "lower_stp26 = np.asarray(stp26_results[4:5][0])[0]\n",
    "median_stp26 = np.asarray(stp26_results[9:10][0])[0]\n",
    "upper_stp26 = np.asarray(stp26_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration36 :\n",
    "\n",
    "slice31 = 35\n",
    "\n",
    "gp36 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp36 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp36_results = pd.DataFrame(gp36).sort_values(by=[0], ascending=False)\n",
    "stp36_results = pd.DataFrame(stp36).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp36 = np.asarray(gp36_results[4:5][0])[0]\n",
    "median_gp36 = np.asarray(gp36_results[9:10][0])[0]\n",
    "upper_gp36 = np.asarray(gp36_results[14:15][0])[0]\n",
    "\n",
    "lower_stp36 = np.asarray(stp36_results[4:5][0])[0]\n",
    "median_stp36 = np.asarray(stp36_results[9:10][0])[0]\n",
    "upper_stp36 = np.asarray(stp36_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration46 :\n",
    "\n",
    "slice41 = 45\n",
    "\n",
    "gp46 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp46 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp46_results = pd.DataFrame(gp46).sort_values(by=[0], ascending=False)\n",
    "stp46_results = pd.DataFrame(stp46).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp46 = np.asarray(gp46_results[4:5][0])[0]\n",
    "median_gp46 = np.asarray(gp46_results[9:10][0])[0]\n",
    "upper_gp46 = np.asarray(gp46_results[14:15][0])[0]\n",
    "\n",
    "lower_stp46 = np.asarray(stp46_results[4:5][0])[0]\n",
    "median_stp46 = np.asarray(stp46_results[9:10][0])[0]\n",
    "upper_stp46 = np.asarray(stp46_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration56 :\n",
    "\n",
    "slice51 = 55\n",
    "\n",
    "gp56 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp56 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp56_results = pd.DataFrame(gp56).sort_values(by=[0], ascending=False)\n",
    "stp56_results = pd.DataFrame(stp56).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp56 = np.asarray(gp56_results[4:5][0])[0]\n",
    "median_gp56 = np.asarray(gp56_results[9:10][0])[0]\n",
    "upper_gp56 = np.asarray(gp56_results[14:15][0])[0]\n",
    "\n",
    "lower_stp56 = np.asarray(stp56_results[4:5][0])[0]\n",
    "median_stp56 = np.asarray(stp56_results[9:10][0])[0]\n",
    "upper_stp56 = np.asarray(stp56_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration66 :\n",
    "\n",
    "slice61 = 65\n",
    "\n",
    "gp66 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp66 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp66_results = pd.DataFrame(gp66).sort_values(by=[0], ascending=False)\n",
    "stp66_results = pd.DataFrame(stp66).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp66 = np.asarray(gp66_results[4:5][0])[0]\n",
    "median_gp66 = np.asarray(gp66_results[9:10][0])[0]\n",
    "upper_gp66 = np.asarray(gp66_results[14:15][0])[0]\n",
    "\n",
    "lower_stp66 = np.asarray(stp66_results[4:5][0])[0]\n",
    "median_stp66 = np.asarray(stp66_results[9:10][0])[0]\n",
    "upper_stp66 = np.asarray(stp66_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration76 :\n",
    "\n",
    "slice71 = 75\n",
    "\n",
    "gp76 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp76 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp76_results = pd.DataFrame(gp76).sort_values(by=[0], ascending=False)\n",
    "stp76_results = pd.DataFrame(stp76).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp76 = np.asarray(gp76_results[4:5][0])[0]\n",
    "median_gp76 = np.asarray(gp76_results[9:10][0])[0]\n",
    "upper_gp76 = np.asarray(gp76_results[14:15][0])[0]\n",
    "\n",
    "lower_stp76 = np.asarray(stp76_results[4:5][0])[0]\n",
    "median_stp76 = np.asarray(stp76_results[9:10][0])[0]\n",
    "upper_stp76 = np.asarray(stp76_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration86 :\n",
    "\n",
    "slice81 = 85\n",
    "\n",
    "gp86 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp86 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp86_results = pd.DataFrame(gp86).sort_values(by=[0], ascending=False)\n",
    "stp86_results = pd.DataFrame(stp86).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp86 = np.asarray(gp86_results[4:5][0])[0]\n",
    "median_gp86 = np.asarray(gp86_results[9:10][0])[0]\n",
    "upper_gp86 = np.asarray(gp86_results[14:15][0])[0]\n",
    "\n",
    "lower_stp86 = np.asarray(stp86_results[4:5][0])[0]\n",
    "median_stp86 = np.asarray(stp86_results[9:10][0])[0]\n",
    "upper_stp86 = np.asarray(stp86_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration96 :\n",
    "\n",
    "slice1 = 95\n",
    "\n",
    "gp96 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp96 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp96_results = pd.DataFrame(gp96).sort_values(by=[0], ascending=False)\n",
    "stp96_results = pd.DataFrame(stp96).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp96 = np.asarray(gp96_results[4:5][0])[0]\n",
    "median_gp96 = np.asarray(gp96_results[9:10][0])[0]\n",
    "upper_gp96 = np.asarray(gp96_results[14:15][0])[0]\n",
    "\n",
    "lower_stp96 = np.asarray(stp96_results[4:5][0])[0]\n",
    "median_stp96 = np.asarray(stp96_results[9:10][0])[0]\n",
    "upper_stp96 = np.asarray(stp96_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration7 :\n",
    "\n",
    "slice1 = 6\n",
    "\n",
    "gp7 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp7 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp7_results = pd.DataFrame(gp7).sort_values(by=[0], ascending=False)\n",
    "stp7_results = pd.DataFrame(stp7).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp7 = np.asarray(gp7_results[4:5][0])[0]\n",
    "median_gp7 = np.asarray(gp7_results[9:10][0])[0]\n",
    "upper_gp7 = np.asarray(gp7_results[14:15][0])[0]\n",
    "\n",
    "lower_stp7 = np.asarray(stp7_results[4:5][0])[0]\n",
    "median_stp7 = np.asarray(stp7_results[9:10][0])[0]\n",
    "upper_stp7 = np.asarray(stp7_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration17 :\n",
    "\n",
    "slice11 = 16\n",
    "\n",
    "gp17 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp17 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp17_results = pd.DataFrame(gp17).sort_values(by=[0], ascending=False)\n",
    "stp17_results = pd.DataFrame(stp17).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp17 = np.asarray(gp17_results[4:5][0])[0]\n",
    "median_gp17 = np.asarray(gp17_results[9:10][0])[0]\n",
    "upper_gp17 = np.asarray(gp17_results[14:15][0])[0]\n",
    "\n",
    "lower_stp17 = np.asarray(stp17_results[4:5][0])[0]\n",
    "median_stp17 = np.asarray(stp17_results[9:10][0])[0]\n",
    "upper_stp17 = np.asarray(stp17_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration27 :\n",
    "\n",
    "slice21 = 26\n",
    "\n",
    "gp27 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp27 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp27_results = pd.DataFrame(gp27).sort_values(by=[0], ascending=False)\n",
    "stp27_results = pd.DataFrame(stp27).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp27 = np.asarray(gp27_results[4:5][0])[0]\n",
    "median_gp27 = np.asarray(gp27_results[9:10][0])[0]\n",
    "upper_gp27 = np.asarray(gp27_results[14:15][0])[0]\n",
    "\n",
    "lower_stp27 = np.asarray(stp27_results[4:5][0])[0]\n",
    "median_stp27 = np.asarray(stp27_results[9:10][0])[0]\n",
    "upper_stp27 = np.asarray(stp27_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration37 :\n",
    "\n",
    "slice31 = 36\n",
    "\n",
    "gp37 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp37 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp37_results = pd.DataFrame(gp37).sort_values(by=[0], ascending=False)\n",
    "stp37_results = pd.DataFrame(stp37).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp37 = np.asarray(gp37_results[4:5][0])[0]\n",
    "median_gp37 = np.asarray(gp37_results[9:10][0])[0]\n",
    "upper_gp37 = np.asarray(gp37_results[14:15][0])[0]\n",
    "\n",
    "lower_stp37 = np.asarray(stp37_results[4:5][0])[0]\n",
    "median_stp37 = np.asarray(stp37_results[9:10][0])[0]\n",
    "upper_stp37 = np.asarray(stp37_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration47 :\n",
    "\n",
    "slice41 = 46\n",
    "\n",
    "gp47 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp47 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp47_results = pd.DataFrame(gp47).sort_values(by=[0], ascending=False)\n",
    "stp47_results = pd.DataFrame(stp47).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp47 = np.asarray(gp47_results[4:5][0])[0]\n",
    "median_gp47 = np.asarray(gp47_results[9:10][0])[0]\n",
    "upper_gp47 = np.asarray(gp47_results[14:15][0])[0]\n",
    "\n",
    "lower_stp47 = np.asarray(stp47_results[4:5][0])[0]\n",
    "median_stp47 = np.asarray(stp47_results[9:10][0])[0]\n",
    "upper_stp47 = np.asarray(stp47_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration57 :\n",
    "\n",
    "slice51 = 56\n",
    "\n",
    "gp57 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp57 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp57_results = pd.DataFrame(gp57).sort_values(by=[0], ascending=False)\n",
    "stp57_results = pd.DataFrame(stp57).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp57 = np.asarray(gp57_results[4:5][0])[0]\n",
    "median_gp57 = np.asarray(gp57_results[9:10][0])[0]\n",
    "upper_gp57 = np.asarray(gp57_results[14:15][0])[0]\n",
    "\n",
    "lower_stp57 = np.asarray(stp57_results[4:5][0])[0]\n",
    "median_stp57 = np.asarray(stp57_results[9:10][0])[0]\n",
    "upper_stp57 = np.asarray(stp57_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration67 :\n",
    "\n",
    "slice61 = 66\n",
    "\n",
    "gp67 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp67 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp67_results = pd.DataFrame(gp67).sort_values(by=[0], ascending=False)\n",
    "stp67_results = pd.DataFrame(stp67).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp67 = np.asarray(gp67_results[4:5][0])[0]\n",
    "median_gp67 = np.asarray(gp67_results[9:10][0])[0]\n",
    "upper_gp67 = np.asarray(gp67_results[14:15][0])[0]\n",
    "\n",
    "lower_stp67 = np.asarray(stp67_results[4:5][0])[0]\n",
    "median_stp67 = np.asarray(stp67_results[9:10][0])[0]\n",
    "upper_stp67 = np.asarray(stp67_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration77 :\n",
    "\n",
    "slice71 = 76\n",
    "\n",
    "gp77 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp77 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp77_results = pd.DataFrame(gp77).sort_values(by=[0], ascending=False)\n",
    "stp77_results = pd.DataFrame(stp77).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp77 = np.asarray(gp77_results[4:5][0])[0]\n",
    "median_gp77 = np.asarray(gp77_results[9:10][0])[0]\n",
    "upper_gp77 = np.asarray(gp77_results[14:15][0])[0]\n",
    "\n",
    "lower_stp77 = np.asarray(stp77_results[4:5][0])[0]\n",
    "median_stp77 = np.asarray(stp77_results[9:10][0])[0]\n",
    "upper_stp77 = np.asarray(stp77_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration87 :\n",
    "\n",
    "slice81 = 86\n",
    "\n",
    "gp87 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp87 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp87_results = pd.DataFrame(gp87).sort_values(by=[0], ascending=False)\n",
    "stp87_results = pd.DataFrame(stp87).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp87 = np.asarray(gp87_results[4:5][0])[0]\n",
    "median_gp87 = np.asarray(gp87_results[9:10][0])[0]\n",
    "upper_gp87 = np.asarray(gp87_results[14:15][0])[0]\n",
    "\n",
    "lower_stp87 = np.asarray(stp87_results[4:5][0])[0]\n",
    "median_stp87 = np.asarray(stp87_results[9:10][0])[0]\n",
    "upper_stp87 = np.asarray(stp87_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration97 :\n",
    "\n",
    "slice1 = 96\n",
    "\n",
    "gp97 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp97 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp97_results = pd.DataFrame(gp97).sort_values(by=[0], ascending=False)\n",
    "stp97_results = pd.DataFrame(stp97).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp97 = np.asarray(gp97_results[4:5][0])[0]\n",
    "median_gp97 = np.asarray(gp97_results[9:10][0])[0]\n",
    "upper_gp97 = np.asarray(gp97_results[14:15][0])[0]\n",
    "\n",
    "lower_stp97 = np.asarray(stp97_results[4:5][0])[0]\n",
    "median_stp97 = np.asarray(stp97_results[9:10][0])[0]\n",
    "upper_stp97 = np.asarray(stp97_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration8 :\n",
    "\n",
    "slice1 = 7\n",
    "\n",
    "gp8 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp8 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp8_results = pd.DataFrame(gp8).sort_values(by=[0], ascending=False)\n",
    "stp8_results = pd.DataFrame(stp8).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp8 = np.asarray(gp8_results[4:5][0])[0]\n",
    "median_gp8 = np.asarray(gp8_results[9:10][0])[0]\n",
    "upper_gp8 = np.asarray(gp8_results[14:15][0])[0]\n",
    "\n",
    "lower_stp8 = np.asarray(stp8_results[4:5][0])[0]\n",
    "median_stp8 = np.asarray(stp8_results[9:10][0])[0]\n",
    "upper_stp8 = np.asarray(stp8_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration18 :\n",
    "\n",
    "slice11 = 17\n",
    "\n",
    "gp18 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp18 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp18_results = pd.DataFrame(gp18).sort_values(by=[0], ascending=False)\n",
    "stp18_results = pd.DataFrame(stp18).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp18 = np.asarray(gp18_results[4:5][0])[0]\n",
    "median_gp18 = np.asarray(gp18_results[9:10][0])[0]\n",
    "upper_gp18 = np.asarray(gp18_results[14:15][0])[0]\n",
    "\n",
    "lower_stp18 = np.asarray(stp18_results[4:5][0])[0]\n",
    "median_stp18 = np.asarray(stp18_results[9:10][0])[0]\n",
    "upper_stp18 = np.asarray(stp18_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration28 :\n",
    "\n",
    "slice21 = 27\n",
    "\n",
    "gp28 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp28 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp28_results = pd.DataFrame(gp28).sort_values(by=[0], ascending=False)\n",
    "stp28_results = pd.DataFrame(stp28).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp28 = np.asarray(gp28_results[4:5][0])[0]\n",
    "median_gp28 = np.asarray(gp28_results[9:10][0])[0]\n",
    "upper_gp28 = np.asarray(gp28_results[14:15][0])[0]\n",
    "\n",
    "lower_stp28 = np.asarray(stp28_results[4:5][0])[0]\n",
    "median_stp28 = np.asarray(stp28_results[9:10][0])[0]\n",
    "upper_stp28 = np.asarray(stp28_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration38 :\n",
    "\n",
    "slice31 = 37\n",
    "\n",
    "gp38 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp38 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp38_results = pd.DataFrame(gp38).sort_values(by=[0], ascending=False)\n",
    "stp38_results = pd.DataFrame(stp38).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp38 = np.asarray(gp38_results[4:5][0])[0]\n",
    "median_gp38 = np.asarray(gp38_results[9:10][0])[0]\n",
    "upper_gp38 = np.asarray(gp38_results[14:15][0])[0]\n",
    "\n",
    "lower_stp38 = np.asarray(stp38_results[4:5][0])[0]\n",
    "median_stp38 = np.asarray(stp38_results[9:10][0])[0]\n",
    "upper_stp38 = np.asarray(stp38_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration48 :\n",
    "\n",
    "slice41 = 47\n",
    "\n",
    "gp48 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp48 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp48_results = pd.DataFrame(gp48).sort_values(by=[0], ascending=False)\n",
    "stp48_results = pd.DataFrame(stp48).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp48 = np.asarray(gp48_results[4:5][0])[0]\n",
    "median_gp48 = np.asarray(gp48_results[9:10][0])[0]\n",
    "upper_gp48 = np.asarray(gp48_results[14:15][0])[0]\n",
    "\n",
    "lower_stp48 = np.asarray(stp48_results[4:5][0])[0]\n",
    "median_stp48 = np.asarray(stp48_results[9:10][0])[0]\n",
    "upper_stp48 = np.asarray(stp48_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration58 :\n",
    "\n",
    "slice51 = 57\n",
    "\n",
    "gp58 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp58 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp58_results = pd.DataFrame(gp58).sort_values(by=[0], ascending=False)\n",
    "stp58_results = pd.DataFrame(stp58).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp58 = np.asarray(gp58_results[4:5][0])[0]\n",
    "median_gp58 = np.asarray(gp58_results[9:10][0])[0]\n",
    "upper_gp58 = np.asarray(gp58_results[14:15][0])[0]\n",
    "\n",
    "lower_stp58 = np.asarray(stp58_results[4:5][0])[0]\n",
    "median_stp58 = np.asarray(stp58_results[9:10][0])[0]\n",
    "upper_stp58 = np.asarray(stp58_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration68 :\n",
    "\n",
    "slice61 = 67\n",
    "\n",
    "gp68 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp68 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp68_results = pd.DataFrame(gp68).sort_values(by=[0], ascending=False)\n",
    "stp68_results = pd.DataFrame(stp68).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp68 = np.asarray(gp68_results[4:5][0])[0]\n",
    "median_gp68 = np.asarray(gp68_results[9:10][0])[0]\n",
    "upper_gp68 = np.asarray(gp68_results[14:15][0])[0]\n",
    "\n",
    "lower_stp68 = np.asarray(stp68_results[4:5][0])[0]\n",
    "median_stp68 = np.asarray(stp68_results[9:10][0])[0]\n",
    "upper_stp68 = np.asarray(stp68_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration78 :\n",
    "\n",
    "slice71 = 77\n",
    "\n",
    "gp78 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp78 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp78_results = pd.DataFrame(gp78).sort_values(by=[0], ascending=False)\n",
    "stp78_results = pd.DataFrame(stp78).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp78 = np.asarray(gp78_results[4:5][0])[0]\n",
    "median_gp78 = np.asarray(gp78_results[9:10][0])[0]\n",
    "upper_gp78 = np.asarray(gp78_results[14:15][0])[0]\n",
    "\n",
    "lower_stp78 = np.asarray(stp78_results[4:5][0])[0]\n",
    "median_stp78 = np.asarray(stp78_results[9:10][0])[0]\n",
    "upper_stp78 = np.asarray(stp78_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration88 :\n",
    "\n",
    "slice81 = 87\n",
    "\n",
    "gp88 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp88 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp88_results = pd.DataFrame(gp88).sort_values(by=[0], ascending=False)\n",
    "stp88_results = pd.DataFrame(stp88).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp88 = np.asarray(gp88_results[4:5][0])[0]\n",
    "median_gp88 = np.asarray(gp88_results[9:10][0])[0]\n",
    "upper_gp88 = np.asarray(gp88_results[14:15][0])[0]\n",
    "\n",
    "lower_stp88 = np.asarray(stp88_results[4:5][0])[0]\n",
    "median_stp88 = np.asarray(stp88_results[9:10][0])[0]\n",
    "upper_stp88 = np.asarray(stp88_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration98 :\n",
    "\n",
    "slice1 = 97\n",
    "\n",
    "gp98 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp98 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp98_results = pd.DataFrame(gp98).sort_values(by=[0], ascending=False)\n",
    "stp98_results = pd.DataFrame(stp98).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp98 = np.asarray(gp98_results[4:5][0])[0]\n",
    "median_gp98 = np.asarray(gp98_results[9:10][0])[0]\n",
    "upper_gp98 = np.asarray(gp98_results[14:15][0])[0]\n",
    "\n",
    "lower_stp98 = np.asarray(stp98_results[4:5][0])[0]\n",
    "median_stp98 = np.asarray(stp98_results[9:10][0])[0]\n",
    "upper_stp98 = np.asarray(stp98_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration9 :\n",
    "\n",
    "slice1 = 8\n",
    "\n",
    "gp9 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp9 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp9_results = pd.DataFrame(gp9).sort_values(by=[0], ascending=False)\n",
    "stp9_results = pd.DataFrame(stp9).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp9 = np.asarray(gp9_results[4:5][0])[0]\n",
    "median_gp9 = np.asarray(gp9_results[9:10][0])[0]\n",
    "upper_gp9 = np.asarray(gp9_results[14:15][0])[0]\n",
    "\n",
    "lower_stp9 = np.asarray(stp9_results[4:5][0])[0]\n",
    "median_stp9 = np.asarray(stp9_results[9:10][0])[0]\n",
    "upper_stp9 = np.asarray(stp9_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration19 :\n",
    "\n",
    "slice11 = 18\n",
    "\n",
    "gp19 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp19 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp19_results = pd.DataFrame(gp19).sort_values(by=[0], ascending=False)\n",
    "stp19_results = pd.DataFrame(stp19).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp19 = np.asarray(gp19_results[4:5][0])[0]\n",
    "median_gp19 = np.asarray(gp19_results[9:10][0])[0]\n",
    "upper_gp19 = np.asarray(gp19_results[14:15][0])[0]\n",
    "\n",
    "lower_stp19 = np.asarray(stp19_results[4:5][0])[0]\n",
    "median_stp19 = np.asarray(stp19_results[9:10][0])[0]\n",
    "upper_stp19 = np.asarray(stp19_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration29 :\n",
    "\n",
    "slice21 = 28\n",
    "\n",
    "gp29 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp29 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp29_results = pd.DataFrame(gp29).sort_values(by=[0], ascending=False)\n",
    "stp29_results = pd.DataFrame(stp29).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp29 = np.asarray(gp29_results[4:5][0])[0]\n",
    "median_gp29 = np.asarray(gp29_results[9:10][0])[0]\n",
    "upper_gp29 = np.asarray(gp29_results[14:15][0])[0]\n",
    "\n",
    "lower_stp29 = np.asarray(stp29_results[4:5][0])[0]\n",
    "median_stp29 = np.asarray(stp29_results[9:10][0])[0]\n",
    "upper_stp29 = np.asarray(stp29_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration39 :\n",
    "\n",
    "slice31 = 38\n",
    "\n",
    "gp39 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp39 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp39_results = pd.DataFrame(gp39).sort_values(by=[0], ascending=False)\n",
    "stp39_results = pd.DataFrame(stp39).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp39 = np.asarray(gp39_results[4:5][0])[0]\n",
    "median_gp39 = np.asarray(gp39_results[9:10][0])[0]\n",
    "upper_gp39 = np.asarray(gp39_results[14:15][0])[0]\n",
    "\n",
    "lower_stp39 = np.asarray(stp39_results[4:5][0])[0]\n",
    "median_stp39 = np.asarray(stp39_results[9:10][0])[0]\n",
    "upper_stp39 = np.asarray(stp39_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration49 :\n",
    "\n",
    "slice41 = 48\n",
    "\n",
    "gp49 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp49 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp49_results = pd.DataFrame(gp49).sort_values(by=[0], ascending=False)\n",
    "stp49_results = pd.DataFrame(stp49).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp49 = np.asarray(gp49_results[4:5][0])[0]\n",
    "median_gp49 = np.asarray(gp49_results[9:10][0])[0]\n",
    "upper_gp49 = np.asarray(gp49_results[14:15][0])[0]\n",
    "\n",
    "lower_stp49 = np.asarray(stp49_results[4:5][0])[0]\n",
    "median_stp49 = np.asarray(stp49_results[9:10][0])[0]\n",
    "upper_stp49 = np.asarray(stp49_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration59 :\n",
    "\n",
    "slice51 = 58\n",
    "\n",
    "gp59 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp59 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp59_results = pd.DataFrame(gp59).sort_values(by=[0], ascending=False)\n",
    "stp59_results = pd.DataFrame(stp59).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp59 = np.asarray(gp59_results[4:5][0])[0]\n",
    "median_gp59 = np.asarray(gp59_results[9:10][0])[0]\n",
    "upper_gp59 = np.asarray(gp59_results[14:15][0])[0]\n",
    "\n",
    "lower_stp59 = np.asarray(stp59_results[4:5][0])[0]\n",
    "median_stp59 = np.asarray(stp59_results[9:10][0])[0]\n",
    "upper_stp59 = np.asarray(stp59_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration69 :\n",
    "\n",
    "slice61 = 68\n",
    "\n",
    "gp69 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp69 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp69_results = pd.DataFrame(gp69).sort_values(by=[0], ascending=False)\n",
    "stp69_results = pd.DataFrame(stp69).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp69 = np.asarray(gp69_results[4:5][0])[0]\n",
    "median_gp69 = np.asarray(gp69_results[9:10][0])[0]\n",
    "upper_gp69 = np.asarray(gp69_results[14:15][0])[0]\n",
    "\n",
    "lower_stp69 = np.asarray(stp69_results[4:5][0])[0]\n",
    "median_stp69 = np.asarray(stp69_results[9:10][0])[0]\n",
    "upper_stp69 = np.asarray(stp69_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration79 :\n",
    "\n",
    "slice71 = 78\n",
    "\n",
    "gp79 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp79 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp79_results = pd.DataFrame(gp79).sort_values(by=[0], ascending=False)\n",
    "stp79_results = pd.DataFrame(stp79).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp79 = np.asarray(gp79_results[4:5][0])[0]\n",
    "median_gp79 = np.asarray(gp79_results[9:10][0])[0]\n",
    "upper_gp79 = np.asarray(gp79_results[14:15][0])[0]\n",
    "\n",
    "lower_stp79 = np.asarray(stp79_results[4:5][0])[0]\n",
    "median_stp79 = np.asarray(stp79_results[9:10][0])[0]\n",
    "upper_stp79 = np.asarray(stp79_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration89 :\n",
    "\n",
    "slice81 = 88\n",
    "\n",
    "gp89 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp89 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp89_results = pd.DataFrame(gp89).sort_values(by=[0], ascending=False)\n",
    "stp89_results = pd.DataFrame(stp89).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp89 = np.asarray(gp89_results[4:5][0])[0]\n",
    "median_gp89 = np.asarray(gp89_results[9:10][0])[0]\n",
    "upper_gp89 = np.asarray(gp89_results[14:15][0])[0]\n",
    "\n",
    "lower_stp89 = np.asarray(stp89_results[4:5][0])[0]\n",
    "median_stp89 = np.asarray(stp89_results[9:10][0])[0]\n",
    "upper_stp89 = np.asarray(stp89_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.8251876066440342, -4.871495191540244)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration99 :\n",
    "\n",
    "slice1 = 98\n",
    "\n",
    "gp99 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp99 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp99_results = pd.DataFrame(gp99).sort_values(by=[0], ascending=False)\n",
    "stp99_results = pd.DataFrame(stp99).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp99 = np.asarray(gp99_results[4:5][0])[0]\n",
    "median_gp99 = np.asarray(gp99_results[9:10][0])[0]\n",
    "upper_gp99 = np.asarray(gp99_results[14:15][0])[0]\n",
    "\n",
    "lower_stp99 = np.asarray(stp99_results[4:5][0])[0]\n",
    "median_stp99 = np.asarray(stp99_results[9:10][0])[0]\n",
    "upper_stp99 = np.asarray(stp99_results[14:15][0])[0]\n",
    "\n",
    "lower_gp99, lower_stp99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration10 :\n",
    "\n",
    "slice1 = 9\n",
    "\n",
    "gp10 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp10 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp10_results = pd.DataFrame(gp10).sort_values(by=[0], ascending=False)\n",
    "stp10_results = pd.DataFrame(stp10).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp10 = np.asarray(gp10_results[4:5][0])[0]\n",
    "median_gp10 = np.asarray(gp10_results[9:10][0])[0]\n",
    "upper_gp10 = np.asarray(gp10_results[14:15][0])[0]\n",
    "\n",
    "lower_stp10 = np.asarray(stp10_results[4:5][0])[0]\n",
    "median_stp10 = np.asarray(stp10_results[9:10][0])[0]\n",
    "upper_stp10 = np.asarray(stp10_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration20 :\n",
    "\n",
    "slice1 = 19\n",
    "\n",
    "gp20 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp20 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp20_results = pd.DataFrame(gp20).sort_values(by=[0], ascending=False)\n",
    "stp20_results = pd.DataFrame(stp20).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp20 = np.asarray(gp20_results[4:5][0])[0]\n",
    "median_gp20 = np.asarray(gp20_results[9:10][0])[0]\n",
    "upper_gp20 = np.asarray(gp20_results[14:15][0])[0]\n",
    "\n",
    "lower_stp20 = np.asarray(stp20_results[4:5][0])[0]\n",
    "median_stp20 = np.asarray(stp20_results[9:10][0])[0]\n",
    "upper_stp20 = np.asarray(stp20_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration30 :\n",
    "\n",
    "slice1 = 29\n",
    "\n",
    "gp30 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp30 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp30_results = pd.DataFrame(gp30).sort_values(by=[0], ascending=False)\n",
    "stp30_results = pd.DataFrame(stp30).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp30 = np.asarray(gp30_results[4:5][0])[0]\n",
    "median_gp30 = np.asarray(gp30_results[9:10][0])[0]\n",
    "upper_gp30 = np.asarray(gp30_results[14:15][0])[0]\n",
    "\n",
    "lower_stp30 = np.asarray(stp30_results[4:5][0])[0]\n",
    "median_stp30 = np.asarray(stp30_results[9:10][0])[0]\n",
    "upper_stp30 = np.asarray(stp30_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration40 :\n",
    "\n",
    "slice1 = 39\n",
    "\n",
    "gp40 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp40 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp40_results = pd.DataFrame(gp40).sort_values(by=[0], ascending=False)\n",
    "stp40_results = pd.DataFrame(stp40).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp40 = np.asarray(gp40_results[4:5][0])[0]\n",
    "median_gp40 = np.asarray(gp40_results[9:10][0])[0]\n",
    "upper_gp40 = np.asarray(gp40_results[14:15][0])[0]\n",
    "\n",
    "lower_stp40 = np.asarray(stp40_results[4:5][0])[0]\n",
    "median_stp40 = np.asarray(stp40_results[9:10][0])[0]\n",
    "upper_stp40 = np.asarray(stp40_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration50 :\n",
    "\n",
    "slice1 = 49\n",
    "\n",
    "gp50 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp50 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp50_results = pd.DataFrame(gp50).sort_values(by=[0], ascending=False)\n",
    "stp50_results = pd.DataFrame(stp50).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp50 = np.asarray(gp50_results[4:5][0])[0]\n",
    "median_gp50 = np.asarray(gp50_results[9:10][0])[0]\n",
    "upper_gp50 = np.asarray(gp50_results[14:15][0])[0]\n",
    "\n",
    "lower_stp50 = np.asarray(stp50_results[4:5][0])[0]\n",
    "median_stp50 = np.asarray(stp50_results[9:10][0])[0]\n",
    "upper_stp50 = np.asarray(stp50_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration60 :\n",
    "\n",
    "slice1 = 59\n",
    "\n",
    "gp60 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp60 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp60_results = pd.DataFrame(gp60).sort_values(by=[0], ascending=False)\n",
    "stp60_results = pd.DataFrame(stp60).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp60 = np.asarray(gp60_results[4:5][0])[0]\n",
    "median_gp60 = np.asarray(gp60_results[9:10][0])[0]\n",
    "upper_gp60 = np.asarray(gp60_results[14:15][0])[0]\n",
    "\n",
    "lower_stp60 = np.asarray(stp60_results[4:5][0])[0]\n",
    "median_stp60 = np.asarray(stp60_results[9:10][0])[0]\n",
    "upper_stp60 = np.asarray(stp60_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration70 :\n",
    "\n",
    "slice1 = 69\n",
    "\n",
    "gp70 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp70 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp70_results = pd.DataFrame(gp70).sort_values(by=[0], ascending=False)\n",
    "stp70_results = pd.DataFrame(stp70).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp70 = np.asarray(gp70_results[4:5][0])[0]\n",
    "median_gp70 = np.asarray(gp70_results[9:10][0])[0]\n",
    "upper_gp70 = np.asarray(gp70_results[14:15][0])[0]\n",
    "\n",
    "lower_stp70 = np.asarray(stp70_results[4:5][0])[0]\n",
    "median_stp70 = np.asarray(stp70_results[9:10][0])[0]\n",
    "upper_stp70 = np.asarray(stp70_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration80 :\n",
    "\n",
    "slice1 = 79\n",
    "\n",
    "gp80 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp80 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp80_results = pd.DataFrame(gp80).sort_values(by=[0], ascending=False)\n",
    "stp80_results = pd.DataFrame(stp80).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp80 = np.asarray(gp80_results[4:5][0])[0]\n",
    "median_gp80 = np.asarray(gp80_results[9:10][0])[0]\n",
    "upper_gp80 = np.asarray(gp80_results[14:15][0])[0]\n",
    "\n",
    "lower_stp80 = np.asarray(stp80_results[4:5][0])[0]\n",
    "median_stp80 = np.asarray(stp80_results[9:10][0])[0]\n",
    "upper_stp80 = np.asarray(stp80_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration90 :\n",
    "\n",
    "slice1 = 89\n",
    "\n",
    "gp90 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp90 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp90_results = pd.DataFrame(gp90).sort_values(by=[0], ascending=False)\n",
    "stp90_results = pd.DataFrame(stp90).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp90 = np.asarray(gp90_results[4:5][0])[0]\n",
    "median_gp90 = np.asarray(gp90_results[9:10][0])[0]\n",
    "upper_gp90 = np.asarray(gp90_results[14:15][0])[0]\n",
    "\n",
    "lower_stp90 = np.asarray(stp90_results[4:5][0])[0]\n",
    "median_stp90 = np.asarray(stp90_results[9:10][0])[0]\n",
    "upper_stp90 = np.asarray(stp90_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration100 :\n",
    "\n",
    "slice1 = 99\n",
    "\n",
    "gp100 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp100 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp100_results = pd.DataFrame(gp100).sort_values(by=[0], ascending=False)\n",
    "stp100_results = pd.DataFrame(stp100).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp100 = np.asarray(gp100_results[4:5][0])[0]\n",
    "median_gp100 = np.asarray(gp100_results[9:10][0])[0]\n",
    "upper_gp100 = np.asarray(gp100_results[14:15][0])[0]\n",
    "\n",
    "lower_stp100 = np.asarray(stp100_results[4:5][0])[0]\n",
    "median_stp100 = np.asarray(stp100_results[9:10][0])[0]\n",
    "upper_stp100 = np.asarray(stp100_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9(a). Summarize Arrays: GPs\n",
    "\n",
    "lower_gp = [lower_gp1,\n",
    "            lower_gp2,\n",
    "            lower_gp3,\n",
    "            lower_gp4,\n",
    "            lower_gp5,\n",
    "            lower_gp6,\n",
    "            lower_gp7,\n",
    "            lower_gp8,\n",
    "            lower_gp9,\n",
    "            lower_gp10,\n",
    "            lower_gp11,\n",
    "            lower_gp12,\n",
    "            lower_gp13,\n",
    "            lower_gp14,\n",
    "            lower_gp15,\n",
    "            lower_gp16,\n",
    "            lower_gp17,\n",
    "            lower_gp18,\n",
    "            lower_gp19,\n",
    "            lower_gp20,\n",
    "            lower_gp21,\n",
    "            lower_gp22,\n",
    "            lower_gp23,\n",
    "            lower_gp24,\n",
    "            lower_gp25,\n",
    "            lower_gp26,\n",
    "            lower_gp27,\n",
    "            lower_gp28,\n",
    "            lower_gp29,\n",
    "            lower_gp30,\n",
    "            lower_gp31,\n",
    "            lower_gp32,\n",
    "            lower_gp33,\n",
    "            lower_gp34,\n",
    "            lower_gp35,\n",
    "            lower_gp36,\n",
    "            lower_gp37,\n",
    "            lower_gp38,\n",
    "            lower_gp39,\n",
    "            lower_gp40,\n",
    "            lower_gp41,\n",
    "            lower_gp42,\n",
    "            lower_gp43,\n",
    "            lower_gp44,\n",
    "            lower_gp45,\n",
    "            lower_gp46,\n",
    "            lower_gp47,\n",
    "            lower_gp48,\n",
    "            lower_gp49,\n",
    "            lower_gp50,\n",
    "            lower_gp51,\n",
    "            lower_gp52,\n",
    "            lower_gp53,\n",
    "            lower_gp54,\n",
    "            lower_gp55,\n",
    "            lower_gp56,\n",
    "            lower_gp57,\n",
    "            lower_gp58,\n",
    "            lower_gp59,\n",
    "            lower_gp60,\n",
    "            lower_gp61,\n",
    "            lower_gp62,\n",
    "            lower_gp63,\n",
    "            lower_gp64,\n",
    "            lower_gp65,\n",
    "            lower_gp66,\n",
    "            lower_gp67,\n",
    "            lower_gp68,\n",
    "            lower_gp69,\n",
    "            lower_gp70,\n",
    "            lower_gp71,\n",
    "            lower_gp72,\n",
    "            lower_gp73,\n",
    "            lower_gp74,\n",
    "            lower_gp75,\n",
    "            lower_gp76,\n",
    "            lower_gp77,\n",
    "            lower_gp78,\n",
    "            lower_gp79,\n",
    "            lower_gp80,\n",
    "            lower_gp81,\n",
    "            lower_gp82,\n",
    "            lower_gp83,\n",
    "            lower_gp84,\n",
    "            lower_gp85,\n",
    "            lower_gp86,\n",
    "            lower_gp87,\n",
    "            lower_gp88,\n",
    "            lower_gp89,\n",
    "            lower_gp90,\n",
    "            lower_gp91,\n",
    "            lower_gp92,\n",
    "            lower_gp93,\n",
    "            lower_gp94,\n",
    "            lower_gp95,\n",
    "            lower_gp96,\n",
    "            lower_gp97,\n",
    "            lower_gp98,\n",
    "            lower_gp99,\n",
    "            lower_gp100,\n",
    "            lower_gp101]\n",
    "\n",
    "median_gp = [median_gp1,\n",
    "            median_gp2,\n",
    "            median_gp3,\n",
    "            median_gp4,\n",
    "            median_gp5,\n",
    "            median_gp6,\n",
    "            median_gp7,\n",
    "            median_gp8,\n",
    "            median_gp9,\n",
    "            median_gp10,\n",
    "            median_gp11,\n",
    "            median_gp12,\n",
    "            median_gp13,\n",
    "            median_gp14,\n",
    "            median_gp15,\n",
    "            median_gp16,\n",
    "            median_gp17,\n",
    "            median_gp18,\n",
    "            median_gp19,\n",
    "            median_gp20,\n",
    "            median_gp21,\n",
    "            median_gp22,\n",
    "            median_gp23,\n",
    "            median_gp24,\n",
    "            median_gp25,\n",
    "            median_gp26,\n",
    "            median_gp27,\n",
    "            median_gp28,\n",
    "            median_gp29,\n",
    "            median_gp30,\n",
    "            median_gp31,\n",
    "            median_gp32,\n",
    "            median_gp33,\n",
    "            median_gp34,\n",
    "            median_gp35,\n",
    "            median_gp36,\n",
    "            median_gp37,\n",
    "            median_gp38,\n",
    "            median_gp39,\n",
    "            median_gp40,\n",
    "            median_gp41,\n",
    "            median_gp42,\n",
    "            median_gp43,\n",
    "            median_gp44,\n",
    "            median_gp45,\n",
    "            median_gp46,\n",
    "            median_gp47,\n",
    "            median_gp48,\n",
    "            median_gp49,\n",
    "            median_gp50,\n",
    "            median_gp51,\n",
    "            median_gp52,\n",
    "            median_gp53,\n",
    "            median_gp54,\n",
    "            median_gp55,\n",
    "            median_gp56,\n",
    "            median_gp57,\n",
    "            median_gp58,\n",
    "            median_gp59,\n",
    "            median_gp60,\n",
    "            median_gp61,\n",
    "            median_gp62,\n",
    "            median_gp63,\n",
    "            median_gp64,\n",
    "            median_gp65,\n",
    "            median_gp66,\n",
    "            median_gp67,\n",
    "            median_gp68,\n",
    "            median_gp69,\n",
    "            median_gp70,\n",
    "            median_gp71,\n",
    "            median_gp72,\n",
    "            median_gp73,\n",
    "            median_gp74,\n",
    "            median_gp75,\n",
    "            median_gp76,\n",
    "            median_gp77,\n",
    "            median_gp78,\n",
    "            median_gp79,\n",
    "            median_gp80,\n",
    "            median_gp81,\n",
    "            median_gp82,\n",
    "            median_gp83,\n",
    "            median_gp84,\n",
    "            median_gp85,\n",
    "            median_gp86,\n",
    "            median_gp87,\n",
    "            median_gp88,\n",
    "            median_gp89,\n",
    "            median_gp90,\n",
    "            median_gp91,\n",
    "            median_gp92,\n",
    "            median_gp93,\n",
    "            median_gp94,\n",
    "            median_gp95,\n",
    "            median_gp96,\n",
    "            median_gp97,\n",
    "            median_gp98,\n",
    "            median_gp99,\n",
    "            median_gp100,\n",
    "            median_gp101]\n",
    "\n",
    "upper_gp = [upper_gp1,\n",
    "            upper_gp2,\n",
    "            upper_gp3,\n",
    "            upper_gp4,\n",
    "            upper_gp5,\n",
    "            upper_gp6,\n",
    "            upper_gp7,\n",
    "            upper_gp8,\n",
    "            upper_gp9,\n",
    "            upper_gp10,\n",
    "            upper_gp11,\n",
    "            upper_gp12,\n",
    "            upper_gp13,\n",
    "            upper_gp14,\n",
    "            upper_gp15,\n",
    "            upper_gp16,\n",
    "            upper_gp17,\n",
    "            upper_gp18,\n",
    "            upper_gp19,\n",
    "            upper_gp20,\n",
    "            upper_gp21,\n",
    "            upper_gp22,\n",
    "            upper_gp23,\n",
    "            upper_gp24,\n",
    "            upper_gp25,\n",
    "            upper_gp26,\n",
    "            upper_gp27,\n",
    "            upper_gp28,\n",
    "            upper_gp29,\n",
    "            upper_gp30,\n",
    "            upper_gp31,\n",
    "            upper_gp32,\n",
    "            upper_gp33,\n",
    "            upper_gp34,\n",
    "            upper_gp35,\n",
    "            upper_gp36,\n",
    "            upper_gp37,\n",
    "            upper_gp38,\n",
    "            upper_gp39,\n",
    "            upper_gp40,\n",
    "            upper_gp41,\n",
    "            upper_gp42,\n",
    "            upper_gp43,\n",
    "            upper_gp44,\n",
    "            upper_gp45,\n",
    "            upper_gp46,\n",
    "            upper_gp47,\n",
    "            upper_gp48,\n",
    "            upper_gp49,\n",
    "            upper_gp50,\n",
    "            upper_gp51,\n",
    "            upper_gp52,\n",
    "            upper_gp53,\n",
    "            upper_gp54,\n",
    "            upper_gp55,\n",
    "            upper_gp56,\n",
    "            upper_gp57,\n",
    "            upper_gp58,\n",
    "            upper_gp59,\n",
    "            upper_gp60,\n",
    "            upper_gp61,\n",
    "            upper_gp62,\n",
    "            upper_gp63,\n",
    "            upper_gp64,\n",
    "            upper_gp65,\n",
    "            upper_gp66,\n",
    "            upper_gp67,\n",
    "            upper_gp68,\n",
    "            upper_gp69,\n",
    "            upper_gp70,\n",
    "            upper_gp71,\n",
    "            upper_gp72,\n",
    "            upper_gp73,\n",
    "            upper_gp74,\n",
    "            upper_gp75,\n",
    "            upper_gp76,\n",
    "            upper_gp77,\n",
    "            upper_gp78,\n",
    "            upper_gp79,\n",
    "            upper_gp80,\n",
    "            upper_gp81,\n",
    "            upper_gp82,\n",
    "            upper_gp83,\n",
    "            upper_gp84,\n",
    "            upper_gp85,\n",
    "            upper_gp86,\n",
    "            upper_gp87,\n",
    "            upper_gp88,\n",
    "            upper_gp89,\n",
    "            upper_gp90,\n",
    "            upper_gp91,\n",
    "            upper_gp92,\n",
    "            upper_gp93,\n",
    "            upper_gp94,\n",
    "            upper_gp95,\n",
    "            upper_gp96,\n",
    "            upper_gp97,\n",
    "            upper_gp98,\n",
    "            upper_gp99,\n",
    "            upper_gp100,\n",
    "            upper_gp101]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9(a). Summarize Arrays: STPs\n",
    "\n",
    "lower_stp = [lower_stp1,\n",
    "            lower_stp2,\n",
    "            lower_stp3,\n",
    "            lower_stp4,\n",
    "            lower_stp5,\n",
    "            lower_stp6,\n",
    "            lower_stp7,\n",
    "            lower_stp8,\n",
    "            lower_stp9,\n",
    "            lower_stp10,\n",
    "            lower_stp11,\n",
    "            lower_stp12,\n",
    "            lower_stp13,\n",
    "            lower_stp14,\n",
    "            lower_stp15,\n",
    "            lower_stp16,\n",
    "            lower_stp17,\n",
    "            lower_stp18,\n",
    "            lower_stp19,\n",
    "            lower_stp20,\n",
    "            lower_stp21,\n",
    "            lower_stp22,\n",
    "            lower_stp23,\n",
    "            lower_stp24,\n",
    "            lower_stp25,\n",
    "            lower_stp26,\n",
    "            lower_stp27,\n",
    "            lower_stp28,\n",
    "            lower_stp29,\n",
    "            lower_stp30,\n",
    "            lower_stp31,\n",
    "            lower_stp32,\n",
    "            lower_stp33,\n",
    "            lower_stp34,\n",
    "            lower_stp35,\n",
    "            lower_stp36,\n",
    "            lower_stp37,\n",
    "            lower_stp38,\n",
    "            lower_stp39,\n",
    "            lower_stp40,\n",
    "            lower_stp41,\n",
    "            lower_stp42,\n",
    "            lower_stp43,\n",
    "            lower_stp44,\n",
    "            lower_stp45,\n",
    "            lower_stp46,\n",
    "            lower_stp47,\n",
    "            lower_stp48,\n",
    "            lower_stp49,\n",
    "            lower_stp50,\n",
    "            lower_stp51,\n",
    "            lower_stp52,\n",
    "            lower_stp53,\n",
    "            lower_stp54,\n",
    "            lower_stp55,\n",
    "            lower_stp56,\n",
    "            lower_stp57,\n",
    "            lower_stp58,\n",
    "            lower_stp59,\n",
    "            lower_stp60,\n",
    "            lower_stp61,\n",
    "            lower_stp62,\n",
    "            lower_stp63,\n",
    "            lower_stp64,\n",
    "            lower_stp65,\n",
    "            lower_stp66,\n",
    "            lower_stp67,\n",
    "            lower_stp68,\n",
    "            lower_stp69,\n",
    "            lower_stp70,\n",
    "            lower_stp71,\n",
    "            lower_stp72,\n",
    "            lower_stp73,\n",
    "            lower_stp74,\n",
    "            lower_stp75,\n",
    "            lower_stp76,\n",
    "            lower_stp77,\n",
    "            lower_stp78,\n",
    "            lower_stp79,\n",
    "            lower_stp80,\n",
    "            lower_stp81,\n",
    "            lower_stp82,\n",
    "            lower_stp83,\n",
    "            lower_stp84,\n",
    "            lower_stp85,\n",
    "            lower_stp86,\n",
    "            lower_stp87,\n",
    "            lower_stp88,\n",
    "            lower_stp89,\n",
    "            lower_stp90,\n",
    "            lower_stp91,\n",
    "            lower_stp92,\n",
    "            lower_stp93,\n",
    "            lower_stp94,\n",
    "            lower_stp95,\n",
    "            lower_stp96,\n",
    "            lower_stp97,\n",
    "            lower_stp98,\n",
    "            lower_stp99,\n",
    "            lower_stp100,\n",
    "            lower_stp101]\n",
    "\n",
    "median_stp = [median_stp1,\n",
    "            median_stp2,\n",
    "            median_stp3,\n",
    "            median_stp4,\n",
    "            median_stp5,\n",
    "            median_stp6,\n",
    "            median_stp7,\n",
    "            median_stp8,\n",
    "            median_stp9,\n",
    "            median_stp10,\n",
    "            median_stp11,\n",
    "            median_stp12,\n",
    "            median_stp13,\n",
    "            median_stp14,\n",
    "            median_stp15,\n",
    "            median_stp16,\n",
    "            median_stp17,\n",
    "            median_stp18,\n",
    "            median_stp19,\n",
    "            median_stp20,\n",
    "            median_stp21,\n",
    "            median_stp22,\n",
    "            median_stp23,\n",
    "            median_stp24,\n",
    "            median_stp25,\n",
    "            median_stp26,\n",
    "            median_stp27,\n",
    "            median_stp28,\n",
    "            median_stp29,\n",
    "            median_stp30,\n",
    "            median_stp31,\n",
    "            median_stp32,\n",
    "            median_stp33,\n",
    "            median_stp34,\n",
    "            median_stp35,\n",
    "            median_stp36,\n",
    "            median_stp37,\n",
    "            median_stp38,\n",
    "            median_stp39,\n",
    "            median_stp40,\n",
    "            median_stp41,\n",
    "            median_stp42,\n",
    "            median_stp43,\n",
    "            median_stp44,\n",
    "            median_stp45,\n",
    "            median_stp46,\n",
    "            median_stp47,\n",
    "            median_stp48,\n",
    "            median_stp49,\n",
    "            median_stp50,\n",
    "            median_stp51,\n",
    "            median_stp52,\n",
    "            median_stp53,\n",
    "            median_stp54,\n",
    "            median_stp55,\n",
    "            median_stp56,\n",
    "            median_stp57,\n",
    "            median_stp58,\n",
    "            median_stp59,\n",
    "            median_stp60,\n",
    "            median_stp61,\n",
    "            median_stp62,\n",
    "            median_stp63,\n",
    "            median_stp64,\n",
    "            median_stp65,\n",
    "            median_stp66,\n",
    "            median_stp67,\n",
    "            median_stp68,\n",
    "            median_stp69,\n",
    "            median_stp70,\n",
    "            median_stp71,\n",
    "            median_stp72,\n",
    "            median_stp73,\n",
    "            median_stp74,\n",
    "            median_stp75,\n",
    "            median_stp76,\n",
    "            median_stp77,\n",
    "            median_stp78,\n",
    "            median_stp79,\n",
    "            median_stp80,\n",
    "            median_stp81,\n",
    "            median_stp82,\n",
    "            median_stp83,\n",
    "            median_stp84,\n",
    "            median_stp85,\n",
    "            median_stp86,\n",
    "            median_stp87,\n",
    "            median_stp88,\n",
    "            median_stp89,\n",
    "            median_stp90,\n",
    "            median_stp91,\n",
    "            median_stp92,\n",
    "            median_stp93,\n",
    "            median_stp94,\n",
    "            median_stp95,\n",
    "            median_stp96,\n",
    "            median_stp97,\n",
    "            median_stp98,\n",
    "            median_stp99,\n",
    "            median_stp100,\n",
    "            median_stp101]\n",
    "\n",
    "upper_stp = [upper_stp1,\n",
    "            upper_stp2,\n",
    "            upper_stp3,\n",
    "            upper_stp4,\n",
    "            upper_stp5,\n",
    "            upper_stp6,\n",
    "            upper_stp7,\n",
    "            upper_stp8,\n",
    "            upper_stp9,\n",
    "            upper_stp10,\n",
    "            upper_stp11,\n",
    "            upper_stp12,\n",
    "            upper_stp13,\n",
    "            upper_stp14,\n",
    "            upper_stp15,\n",
    "            upper_stp16,\n",
    "            upper_stp17,\n",
    "            upper_stp18,\n",
    "            upper_stp19,\n",
    "            upper_stp20,\n",
    "            upper_stp21,\n",
    "            upper_stp22,\n",
    "            upper_stp23,\n",
    "            upper_stp24,\n",
    "            upper_stp25,\n",
    "            upper_stp26,\n",
    "            upper_stp27,\n",
    "            upper_stp28,\n",
    "            upper_stp29,\n",
    "            upper_stp30,\n",
    "            upper_stp31,\n",
    "            upper_stp32,\n",
    "            upper_stp33,\n",
    "            upper_stp34,\n",
    "            upper_stp35,\n",
    "            upper_stp36,\n",
    "            upper_stp37,\n",
    "            upper_stp38,\n",
    "            upper_stp39,\n",
    "            upper_stp40,\n",
    "            upper_stp41,\n",
    "            upper_stp42,\n",
    "            upper_stp43,\n",
    "            upper_stp44,\n",
    "            upper_stp45,\n",
    "            upper_stp46,\n",
    "            upper_stp47,\n",
    "            upper_stp48,\n",
    "            upper_stp49,\n",
    "            upper_stp50,\n",
    "            upper_stp51,\n",
    "            upper_stp52,\n",
    "            upper_stp53,\n",
    "            upper_stp54,\n",
    "            upper_stp55,\n",
    "            upper_stp56,\n",
    "            upper_stp57,\n",
    "            upper_stp58,\n",
    "            upper_stp59,\n",
    "            upper_stp60,\n",
    "            upper_stp61,\n",
    "            upper_stp62,\n",
    "            upper_stp63,\n",
    "            upper_stp64,\n",
    "            upper_stp65,\n",
    "            upper_stp66,\n",
    "            upper_stp67,\n",
    "            upper_stp68,\n",
    "            upper_stp69,\n",
    "            upper_stp70,\n",
    "            upper_stp71,\n",
    "            upper_stp72,\n",
    "            upper_stp73,\n",
    "            upper_stp74,\n",
    "            upper_stp75,\n",
    "            upper_stp76,\n",
    "            upper_stp77,\n",
    "            upper_stp78,\n",
    "            upper_stp79,\n",
    "            upper_stp80,\n",
    "            upper_stp81,\n",
    "            upper_stp82,\n",
    "            upper_stp83,\n",
    "            upper_stp84,\n",
    "            upper_stp85,\n",
    "            upper_stp86,\n",
    "            upper_stp87,\n",
    "            upper_stp88,\n",
    "            upper_stp89,\n",
    "            upper_stp90,\n",
    "            upper_stp91,\n",
    "            upper_stp92,\n",
    "            upper_stp93,\n",
    "            upper_stp94,\n",
    "            upper_stp95,\n",
    "            upper_stp96,\n",
    "            upper_stp97,\n",
    "            upper_stp98,\n",
    "            upper_stp99,\n",
    "            upper_stp100,\n",
    "            upper_stp101]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEaCAYAAAAYOoCaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXhU5dn48e8zk0z2fSUbCVtYAgQIi7IIsooLoNal1o23r/V1q9bW8ra/1lbbt65d1ba2tpYK7mtxQwEVEAQCBAIBAiGBbGTfM0lm8vz+OJOQZWYySSaZJPN8rmsuM+ecOedJ1HPPeZb7FlJKFEVRFPejc3UDFEVRFNdQAUBRFMVNqQCgKIriplQAUBRFcVMqACiKorgpFQAURVHclAoAiuJEQoiXhRBSCPELd7iuMrypAKAMK0KIXMuNTgohzEKIIiHEJiFElKvbpijDjYerG6AofbQFOA+sA76N9mXmZpe2qI+EEJ5SyhZXt0NxP+oJQBmuXpJS3gNssLyfDiCE8BNCPC2EOCOEqBNCHBZC3Nr2ISHETCHETiFEjWV/phDifzrsv0YIsc+yP08I8awQwteyb7HlySNXCPETIUSJ5fUjK+0LE0J8IIRoEEIcEEKkdrhG2xPMg0KIs8BJy/ZEIcSblqeaSiHEDiHE3A6f8xVC/FIIcUII0SiEyBdC/Le1P44Q4hnLNfYLIYL7/mdWRjIVAJRhSwhhAGZZ3h6x/POfwA8BM/AGMB7YKIRoezr4I7AA2Aq8ClS2nUMIsRJ4H0gC3gXygR8Az3e59GjgO8AuIAJ4Uggxvssx9wDNwGHL+bcIIby7HPN/wFfAViGEH7AduB44Zfl5MbBdCDHWcvzfgJ8DkZa2HwQmWPm7PAo8DBwAlkspq7oeoygASCnVS72GzQvIBWSX15dAONqNsW3baMvx37e8/9ry/hvL+/VACuAJ6C37PrTs2wr8HnjB8r4V8EW7IUvABERbPpNn2Xa95f3LlvfvWt57Ahcs2660bGtr4/oOv9cNlm1nAJ1l27uWbf9n+f3aPjejw+c8u1z3pOWf+4FgV//7Uq+h/VJPAMpwtQV4z/LzHCAZSLS8b5RS5ll+PmH552jLP3+A9rTwd+AoUAE8YNnX9vnlaIGjrWtIAGM6XLtYSlls+bnt27V/l/ZlAUitbz/Hsi2uyzG7O/zcdu2TUspWK21PsvzcJKU81PYh2X3soO2JYLNU3/yVHqgAoAxXL0kp16F1+Xijde3kWvb5CCESLD8nW/7ZFhAOSCmnAyFo3+g9gSeEEB4dPv99KaVoewFjpZSZHa5t6vCzrXS6k0Ab4OVi8MjvckxTh5/brj1BCCGstP2s5WevLuMJXSdyvAvUAs8IIa6z0TZFAdQsIGX4+yVwKzATmAG8hdaP/pkQYjda1wrAc5Z//kcIoUfragkCvIBytDGD54HVaH36lwCNwDQgjIvfwB11jRDiLSAGrWuqEK1f35YP0W70Y4EdQogytBlOjcA/pJRlQojNaDOetgkh3kMLYqeBRzqc5wjwF8v5NgkhKqWU9q6ruDH1BKAMa5aunn9b3m5A69v/HWAAbkTrfrlTSrnZcswXaDflW4Ar0frKb5Saj9BuuhlogeBatP7/P/ShaS+gBZdUtMHaq6WUjXZ+j3rgcuBtYCKwDG1sY6mU8rTlsP8GHgfKLO2fA2RbOddW4C7L9d8TQszqeoyiAAgpVUEYRVEUd6SeABRFUdyUCgCKoihuSgUARVEUN6UCgKIoipsaVtNAw8PDZWJioquboSiKMqykp6eXSSkjum4fVgEgMTGRAwcOuLoZiqIow4oQIs/adtUFpCiK4qZUAFAURXFTKgAoiqK4qWE1BqAoA6GlpYX8/HyMRqOrm6Io/eLt7U1cXByenp4OHa8CgOL28vPzCQgIIDExkYuJOBVleJFSUl5eTn5+PklJjuUuVF1AitszGo2EhYWpm78yrAkhCAsL69WTrAoAigLq5q+MCL3971gFAEVRFDflNmMAdVUm/IPd5tdV+uPFF517vrvu6vGQCxcu8NBDD7F3715CQkIwGAw88sgjrFu3ji+++II1a9aQlJREU1MTN910E48++minz+fm5jJp0iSSk5Pbt/3gBz/gtttuIzExkYCAAIQQhISEsHHjRkaP1ipkCiG45ZZbeOWVVwAwmUyMGjWKuXPnsmXLlk7X6NgOo9HIVVddxTPPPNPfv06PXn75ZVasWEFMTEyPxx04cIDnntNq/7z44ov89re/BcDf359nnnmGxYsXA7B48WKKiorw9vbGYDDwt7/9jdTUVFunHrHc5gngxCGbtTgUxaWklKxdu5ZFixaRk5NDeno6r732Gvn5FytILly4kMOHD3PgwAFeeeUVDh482O08Y8eO5fDhw+2v2267rX3fjh07OHLkCIsXL+ZXv/pV+3Y/Pz8yMzNpbNT+//jss8+IjY212da2dhw6dIgtW7awe/dum8f2htlstrnv5ZdfprCwsFfn27JlC3/961/ZtWsXJ06c4MUXX+Q73/kOBQUF7cds2rSJjIwM7rnnHn70ox/1ue3DmdsEgLzsZhoaXN0KRelu+/btGAwG7r777vZto0eP5v777+92rJ+fH7NmzeL06dPd9jnikksu6XQTBFi9ejUffvghAK+++io333xzj+fx8fEhNTW1/Vz19fWsX7+eOXPmMGPGDN5//30AGhoauOGGG5g8eTLr1q1j7ty57elc/P39efjhh5k+fTp79uwhPT2dyy67jFmzZrFy5UqKiop46623OHDgALfccgupqantgaonTz75JE8//TTh4eEAzJw5kzvvvJPnn3/eob+Ju3CbANBa38ipU65uhaJ0d+zYMWbOnOnQseXl5ezdu5cpU6Z023fmzBlSU1PbXzt37ux2zCeffMLatWs7bbvpppt47bXXMBqNHDlyhLlz5/bYjsrKSrKzs1m0aBEAv/71r7n88svZt28fO3bs4Ec/+hH19fW88MILhISEcPz4cR5//HHS09Pbz1FfX8/cuXPJyMhg7ty53H///bz11lukp6ezfv16fvrTn3L99deTlpbGpk2bOHz4MD4+Pvz85z/ngw8+sNu+Y8eOMWtW50qYaWlpHD9+3KG/ibtwn05xYyMnTsD06aAmfChD2b333suuXbswGAzs378fgJ07dzJjxgx0Oh0bNmywGgDauoCsWbJkCRUVFfj7+/P444932jdt2jRyc3N59dVXWb16td227dy5k+nTp5Odnc2DDz5IdHQ0AFu3buWDDz5oHxMwGo2cO3eOXbt28f3vfx+AlJQUpk2b1n4uvV7PddddB8DJkyfJzMxk+fLlgNYlNGrUKKtteOyxx+y20VG33HILzc3N1NXV2fy7jXQufwIQQuiFEIeEEFt6ProfjEZqasBNn/SUIWzKlCmd+vSff/55tm3bRmlpafu2hQsXcujQIdLT0zt1FTlqx44d5OXlkZqa2m0AGeCaa67hhz/8YY/dPwsXLiQjI4Njx47x0ksvtd84pZS8/fbb7eMP586dY9KkSXbP5e3tjV6vb//8lClT2j9/9OhRtm7d2uvfs83kyZM7PW0ApKenk5aW1v5+06ZN5OTkcPvtt1vtbnMHLg8AwPeBrAG/SqO2OCJr4K+kKL1y+eWXYzQa+fOf/9y+rWEABqw8PDz4/e9/z8aNG6moqOi0b/369Tz66KNMnTrVoXMlJSWxYcMGnnzySQBWrlzJn/70J6SUABw6dAiA+fPn88YbbwBw/Phxjh49avV8ycnJlJaWsmfPHkBLz3Hs2DEAAgICqK2t7dXv+sgjj/DjH/+Y8vJyAA4fPsy7777L9773vU7HCSF4/PHH2bt3LydOnOjVNUYCl3YBCSHigCuBXwM/GNCLmUxgMpGX50FjI/j4DOjVlOHMgWmbziSE4L333uOhhx7iqaeeIiIiAj8/v/abq6PaxgDarF+/ngceeKDTMaNGjeLmm2/m+eef52c/+1n79ri4uG7H9uTuu+/mmWeeITc3l5/97Gc8+OCDTJs2jdbWVpKSktiyZQv33HMPt99+O5MnT2bixIlMmTKFoKCgbucyGAy89dZbPPDAA1RXV2MymXjwwQeZMmUKd9xxB3fffTc+Pj7s2bOH3/zmN6SlpXHNNdfYbNs111xDYWEh8+fPx2QyUVxcTEZGBhER3Wqi4OPjw8MPP8zTTz/NSy+91Ku/wXAn2iK2Sy4uxFvAb4AA4IdSyqvsHZ+Wlib7WhDmzR/soTJuKvj7s3QpjB3bp9MoI1BWVlaP3RVK35jNZlpaWvD29ubMmTMsW7aMkydPYjAYBq0NJpOJO++8k9bWVl555ZURv+rb2n/PQoh0KWVa12Nd9gQghLgKKJFSpgshFts57i7gLoCEhIT+XdRoBH9/yspUAFCUwdDQ0MCSJUtoaWlBSskLL7wwqDd/0Lq+/v3vfw/qNYcLV3YBzQeuEUKsBryBQCHEK1LK73Q8SEr5IvAiaE8A/bpiUxMAZWX9OouiKA4KCAhQZVyHMJcNAksp/1dKGSelTARuArZ3vfk7nSVLngoAiqIoQ2MW0OBp0gJAUxP0clKBoijKiDMkAoCU8oueBoCdwtjU/qN6ClAUxd0NiQAwaJouFkpQAUBRFHfnXgGgxQRmE6ACgKIoinsFAGjvBuqwyl5RFMUtuU8yuDZNRvDzw2iE+nrw83N1g5ShxgX1YAAto+bmzZvR6/XodDr++te/tqcuKC4uRq/Xt69k3bdvHz4+PkydOhWTycSkSZP417/+ha+vb6dz6vX6TukdbrrpJjZs2NC+3WQykZSUxL///W+Cg4OB3hWJ6XgNa+caKFVVVWzevJl77rmnx2P9/f2pq6sDID8/n3vvvZfjx49jNptZvXo1zz77LF5eXr36XRobG1m1ahXbt29vz2fkbG2FfPR6PR4eHhw4cIDm5maWLVvG9u3b8fDo/+3bbZ8AQHUDKUPHnj172LJlCwcPHuTIkSN8/vnnxMfHtydHu/vuu3nooYfa3xsMBnx8fDh8+DCZmZkYDAb+8pe/dDtv2zFtrw0bNnTanpmZSWhoaKc8+b0tEmPvXP0hpaS1tdXqvqqqKl544YVen+/aa69l7dq1ZGdnk52dTWNjI4888kj7MY7+Lv/4xz+49tprB+zm32bHjh3thYBAS5mxdOlSXn/9daec3/0CgBoIVoagoqIiwsPD27+JhoeH91gCsaOFCxe6vEiMtXO98sorzJkzh9TUVL73ve+1V/56/PHHSU5OZsGCBdx8883taaRzc3NJTk7mtttuIyUlhfPnz1s9x4YNG9pzHzlazWv79u14e3tz5513Atq3/d/97nds3Lix/Qmhp79Lm02bNrFmzRoAqquriYqKat83a9YsqqurHWpTX6xdu5ZNmzY55VzuFwA6PAGocQBlqFixYgXnz59nwoQJ3HPPPXz55ZcOf9ZkMvHxxx9bzeTZ2NjYqUhM12+OZrOZbdu2dUus1pciMV3PlZWVxeuvv87u3bs5fPgwer2eTZs2sX//ft5++20yMjL4+OOPu60Uzs7O5p577uHYsWM0NDRYPccTTzzRXv/g6aefBrSgZa90pLUiMYGBgSQmJnYLnrb+LgDNzc3k5OSQmJgIQFBQEA0NDZhM2gST6dOnc+TIkW6fW7hwYad/F22vzz//3Gp7hRCsWLGCWbNm8WKHfsmUlJT2OhH95X5jAEb1BKAMPf7+/qSnp7Nz50527NjBjTfeyBNPPMEdd9xh8zNtN3fQbi7/9V//1e2Yti4NW58tKChg0qRJ7YVY2vSmSIytc23bto309HRmz57dflxkZCQVFRWsWbMGb29vvL29ufrqqzudb/To0cybN8/uOdoqkXX00Ucf2W2nI3r6uwCUlZV1GxeIjo6mqKiI+Ph4Tpw40V4opyNrFdrs2bVrF7GxsZSUlLB8+XImTpzIokWL0Ov1GAwGamtrCQgI6N0v2IX7PQE0XXwCaGhA1QlWhgy9Xs/ixYv55S9/yXPPPcfbb79t9/iO/ft/+tOfepVkre2zeXl5SCmt9nU7WiTG1rmklNx+++3tbTx58iS/+MUvemybX4eZGX09hzXWisTU1NRQXFxMcnKy3d+l6+9r7PBFEiAmJobCwkLeeustwsPDGT9+fLfP9fYJoG3cJTIyknXr1rFv3772fU1NTXh7e/fuD2CF+wWA5maw9EMCbNsGW7dqLzesB6EMESdPniQ7O7v9/eHDhxk9evSAX9fX15c//vGPPPvss+1dGG16WySm67mWLl3KW2+9RUlJCQAVFRXk5eUxf/58/vOf/2A0Gqmrq7M6s6iNrXP0pUjM0qVLaWhoYOPGjYDWzfPwww9z33334dOlQIi9v0tISAhms7lTEIiJieGjjz7iqaee4h//+IfV6+/cubPTgHzba9myZd2Ora+vb//96uvr2bp1KykpKYBWFzo8PBxPT89e/f7WuF8XEGhPAZbpckVFFzfn5WnTQuPjXdQuZUgY5HowANTV1XH//fdTVVWFh4cH48aN69Tv21cdu4kAVq1axRNPPNHpmBkzZjBt2jReffVVbr311vbtfSkS0/Vcv/rVr1ixYgWtra14enry/PPPM2/ePK655hqmTZtGVFQUU6dOtVokBrRv7bbOMX/+fFJSUrjiiit4+umnWb16NX//+99tDp4LIXj33Xe59957efzxxyktLeXGG2/kpz/9qUO/S0crVqxg165d7TfvmJgYNm/ezPbt2wkPD+/V38yaCxcusG7dOkAb4/n2t7/NqlWrAG1m0JVXXtnva4CLC8L0Vr8LwpS0aG+io2HCBKvHGQywdi0M8DRmZQhRBWEGX11dHf7+/jQ0NLBo0SJefPFFZs6cOaht+Prrr7n55pt59913e33tgwcP8rvf/c4ldQauvfZannjiCSbYuIcNi4IwLlVcDGFh2quL5mb49FMtCFhm5CmK4mR33XUXx48fx2g0cvvttw/6zR/g0ksvJS8vr0+fnTlzJkuWLMFsNg/4WoCOmpubWbt2rc2bf2+5ZwAAyM6GwECw0o9WXQ0bN0Jb5bhZs2DGjEFun6KMYJs3b3Z1E/pt/fr1g35Ng8HAbbfd5rTzucUg8P6/Z5D1aR6deruamyH7lM3PSAmtrdrLMv6kKIoyorhFAPjz74w8evwmntsxmfK6Dv06ZeUOrQZTAUBRlJHILQLA3x4r4g88wOmSQH75YRpfZY+6uDMvT/uab0djI1hZKa6MIMNpMoSi2NLb/47dIgDoL7+M+3mON8b/lDHhNWzaN570c5apWg0N6inAzXl7e1NeXq6CgDKsSSkpLy/v1QIx9xgEDgmhKnI8syo/574l1/DMZ9PZuGcCccF1RAUa4dw5iIgAne14WFICY8YMYpuVQRMXF0d+fj6lKjmUMsx5e3sTFxfn8PHuEQCAkriZjD38Dl4YuWthFr/6aCYv7pzMj1cextDYCCUXIHqUzc+re8PI5enpSVJSkquboSiDzi26gABK42bi0dpMZNlxQv2aWD//BAVVfvx152Q+PJrAh++b2LPb9lhAaWmPQwWKoijDits8AZTGpdIqdMRcOERR1AxSYipZMz2X948kklkYqh10EJLJIjSgRVstHBnZ/nmTCaqqIDTURb+AoiiKk7lNADB5+VMWMp6Y4kOkT9O2XZFynpWTzwNwtjyAp7bOIPesJDShSrvjdwgAoI0DqACgKMpI4TZdQABFUTOILM9Cb7qYxU+n014JoXXoda3klvtrO+rqus39VDOBFEUZSdwqABRGzUDf2kJU2bFu+zz1ktjgenLLAy9uvHCh0zFqIFhRlJHErQJAceQ0WoWemOJDVvcnhtWSV+FPa9t08JKSTiO/FRVaz5CiKMpI4FYBoMXTl9LQZGIvpIOVRT+JYbUYWzwoqbEUh2hp0e76FlKqMpKKoowcLhsEFkLEAxuBKEACL0op/zDQ182Lu5Q5GX9n5Zc/Yeech2nwvVi8ITFMq8CTWx5AdFCjtrHkAnQo8LB/v3NqBfj7qwyjiqK4litnAZmAh6WUB4UQAUC6EOIzKeXxgbxoxuRvY9Z7MTvjb3zrw9vZM/M+To1ZBUIwKrABLw8zZ8sDmDfGMuJbUaE9CVjSRhcVda4i1ldCQHJye2EyRVGUQeeyLiApZZGU8qDl51ogC4gdqOt5BWn5MaROz9FJN/DW6n9SGZTE4r1PcPVn9xNaedoyG6iWvPKAix9slVBQ4PT2SAlnzjj9tIqiKA4bEmMAQohEYAbwjZV9dwkhDgghDvQnV8u4ayaD98VU0DWBcXyw/I98OfcRgmvOce3H/838/b9nbFAZ5yv9MZnFxQ+fP6+tAnOyDjXAFUVRBp3LA4AQwh94G3hQSlnTdb+U8kUpZZqUMi0iIqLP1xk72QvdlMmdE74JHSfHXcnrV28ia/waJmV/wHfOPIapVUdxeYfeMSnhxAmtiIwTlZVBZaVTT6koiuIwlwYAIYQn2s1/k5TynYG8lpcXJE4NgHFju+1r9gpg9+wHefPKfxIfqS0SC/nqPTxaGjoc1AwnT1idPdQfp0879XSKoigOc1kAEEII4CUgS0r528G4ZnIyWsbPoCCr+6uDRpN1+X0EejSQ2TSB2OL0zgdUVkFhoVPblJ3t9JiiKIriEFc+AcwHbgUuF0IctrxWD+QF4+Iss24CAmweIwTERzSyj7kkFO7tfkBBvlPv2HV13RYcK4qiDAqXTQOVUu4CRI8HOpEQMGECHM71t3tcYngdHxalcMWZ56grisTPy8QDSzIJ8G4BYxOUl3daG9Bfp05pyUcVRVEGk8sHgQfbhAlAgP0AcOmYC6yO2Mdl8gsmBxVwvsKfrVkdquwUOb8bSNUcVhRlsLldAAgOhpgxPqDX2zwm3N/IzQvy+Rd38HTkM8xOLOXLUzHUGrXFYFRWabWEncRshgMHnHY6RVEUh7hdAABYdJnAI8jP7jENvuGUhYwjvnAvq1PyaDbp+Cyrwzq1QucuDjt1SutZUhRFGSxuGQACA2HOnJ6POx8zl+jSTEb7lJA2upQvTsVSZ7QMm1wocXpq0G+6LYNTFEUZOG4ZAACmzPUnJth+N865mHnopJnYogNcObXtKcAyFmA2O336Tn6+9lIURRkMblMSsisREc5lE3by9sEkTK3aZKTW1s6TkkrCJ9Nk8Ceh8BvOjl5C2uhStp2MJbvEso5ApwN/qU0v6oO4OJg4UVuf4Gfpkdq9GxYuhJiYPv9qiqIoDnHbAEBQEAEBcMelp9o3ZV8IZMfJi3deqfMgP3o28YXfgGxlzfRcGlv0mFvbHpxagWYweNFbJhPs3QtffqnFj/XrtW6p6mrYsgXCwmDaNBg3rs/xRVEUxS73DQBCaHfZ4uL2TeOjajhTGsi5iovTRPPi5jP23A4S83dB/CLuX9KlnKSPD8ya1TnHkIPMZjh7FjZvho8+gtmzL97sy8thxw7IyYElS8Bg6NNvqSiKYpPbjgEAVhdzLRxfjMHjYhnIM6OXUBGUxLz059Gbmrqfo7Gxz2XC9HrtG/6yZVqNAWvZQfPy4J131AwhRVGcz70DgJXson5eJi4Zc3FwV+o8+DrtAQLri5mW9Zr185w716/0EGlpWoqKr76yvr+mBt57D/bsgfr6Pl9GURSlE/ftAgKb6RySo6upNXrS2KL9eYzh4zmbfRkzjm3i1JhV1PtFdf5AQ0O/0kMYDDBvnjYeUFOjTVPtymyGo0fh2DFtNfOll4KHe//bUxSln9z7FhIcrN1FrcznT0vs3K3TFHYFusf2sPjoc3yz7Kfdz1V7FiZ2DwAmk2O1ZBYuhO3btW/5K1faPq61VStN0NICS5f2fF5FURRb3DsACAEzZ15MxFNYaPNu7RUVAlesJPY//+HaG+ZDYmKXI3Lh8vFWK8YXFsLBg/YzScfEwPjxsHMnLF/e85jymTMQEqI1X1EUpS/cewwAIDUVFizQXmlp9o9dtgy8vWHbNuv7T5ywujkmBq66Ctau1W7uy5dbX4m8aBGUlto8TTcHDmiziBRFUfpCBYCOEhMtBQNs8PaG+fO1O6+1Wo6nTmmd9TZERkJSkvaaOrV7ProZM7TL79vneJN37NCmkLa91GwhRVEcpQJARzqdpWyYHUuWaDN+vvyy+z6jEXJzHbqUXg+jRnXe5ukJU6ZAZqbW1+8Ik+liCon8fO3hxMkpihRFGaFUAOhq0iT7+yMitCW6O3daLxKfleXwpWJju2+bOhVqa7X5/31RVaWSyimK4hgVALry94eEBPvHLF2qDRxb66spLNTmcjrAWgCYMkUbmz561KFTWHXsmLY0QVEUxR4VAKyZPNn+/gkTtExu27dbfwrYv9+hEl9hYdqwQkf+/jBmTP8CAMAXX0BFRf/OoSjKyObe00BtiY/X7sS2buJCaE8B//oXPPCAtgAsIQFuuklbxXXmjPaKioLRo8HLSrI4IRD+/sSGhHKm0KdTxreUFHj/fS0xXFBQ334Fo1FLITFtmjZVVC0aUxSlK3VbsEYIuOwy+OQT27N6LrlEy+F87pyWyOfwYS0x3K23XjzmwoUeawbEFgdxJideu+tblgBPnaoFgMxMbdJRX7W2as3KydGCQFKSNtCsKIoCKgDYFhurLcn99FPrQUAImD5dewG88YbWJbR0aa+S+ccF12vTdjIz24NAXJy2nuzo0f4FgDY1NVqX0K5d2kzX6Oi+n2vUKG0BmqIow58KAPbExcGKFVoQ6Gle5urV8PXXWr/Lffc5fAl/bxNBPs1UN6IFgalTEQEBpKRoyw1MJud135hMcPq09uqrSZO0tBWKogx/KgD0JD5eu7l//rnWsW6Lvz9ccYUWAE6e7Hk9QQexIfVUNxq0O/SRI2AwMNUnmF3G8Rx77xTjorWxCF+D+eJQwaRJ2jUHmSpZqSgjR4+zgIQQSUKIHwshtgghMi2vD4UQjwghkgajkS4XEwPr1kFoqP3jlizR+kfeftvxlVxAbMfaxGYzNDYyMeQCHrpWXvhsAj/490x+8O+ZvLcnSqs/0NioBZleXMNZamsdnuWqKMoQZzcACCHeBbKB3wBTgVqgzvLzE0C2EOLtgW7kkBAQAGvWaCO0EyZor64BwWDQjsnL09J6OijMr9dm7b8AACAASURBVPuThbdnK/cuzuSGWae5YdZpYoPrOFbU4Xr19S6b7K+eAhRlZOjpCSAG+B4QLaUcLaW8REo5T0qZAEQDdwNxfb24EGKVEOKkEOK0EGJDX88zaDw9tdk/ixdrr5SU7sfMnasFhzfecDgxT4B3C3pd94Iyk0dVsXRiIUsnFjI9rpyCKj+aTR3+lZ0/75Kv4yoAKMrIYDcASCnnSilfklKWWNlXIqX8u5Rybl8uLITQA88DVwCTgZuFED2swBpirHUJ6XRw++1avqCXX3aom0YICPKxsqCsg6SwWlqlIK9DvWKk1LqCioqg2PKyk4zOWQoLXdL7pCiKkzm0ElgIYRZC3NDh/WohxKl+XnsOcFpKmSOlbAZeA9b085yDy0ruf0BbGHbDDVp20B07HDuVbw8BILwWgJyyLuXCGhu1YsKnLC97RQecpLkZSrp9JVAUZbixOwtICJEAJAICmCyEWGTZdQUwpp/XjgXOd3ifD/TpacJlDAbbK4bnz9dWYb37rvVq70JoK4UTEyEpiRDfcCDA5qUCvFsI928kt8z2MYDWLRQdPeArvgoK+reeQFEU1+tpGuidwM8BCfzM8gItIDie9rIfhBB3AXcBJPSUpM0VQkKsBwAhtFXB//yn9dXAZrMWICx9KfFrvku6/63dj+sgKayW06U95IYwmSD/PCT1Nz7bl58Ps2YN6CUURRlgPQWAfcCfgXuArWgzgiRQCWzq57ULgPgO7+Ms2zqRUr4IvAiQlpbWfaTU1UJCtG/d1gQFwYMP2v5sc7P22ZdfJuT4bpjTQwAIr2F/XiSVDQZC7HUZFRRCTKz1HEROUlKiNd9gGLBLKIoywOwGACnlx8DHQoj9wBdSyj5mqbdqPzDespagALgJ+LYTzz84+pMXwWCAsWMhNRWPbdswzGyg2cN2RbK2cYCzZQGEJNiZYdTaqk1FnTCh723rgZTaU8CYgX3QUBRlADmaDvpD4BkhRKUQYpkQ4k0hhOP5DqyQUpqA+4BP0bqT3pBSHuvPOV3CGYlxpk5FmM2MLbdfCzI+pA69rpWz5YF2jwO0bicbBe6dJTNzQE+vKMoAczQAPA+sAgKBViAXbX1Av0gpP5JSTpBSjpVS/rq/53MJZwSAsWPB25vEoq/tHuapl8SH1PU8EAzaV/RjxwZ0nUBxsVoToCjDmaMBYAXwTIf3xwH3SAPRE0/P/ufk0eth8mSizu3Xbtx2JIXXklcRgNmRefhmMxzL1FYND5D09AE7taIoA8zRZHD1QJTlZz2wDHBsmas7CA11qAKYXVOmYDh4kJCqHCpDxto8LCmslh0nYyms9iM+xIEbe4tJyysdH4c2ecuO0FCtpkEvXLigPQXE9Xk9uKIoruJoAHgN+AHaDKAtls89PVCNGnZCQvqfl8eSViKh8Bv7ASBc69I5WxbgWAAAbbrOmZyej6uv79PA8YEDKgAoynDkaAD4X6AGuMryfgtagjgFnDMOEBxMa2wc8YXfkDHF9mSoCH8jfl4tvLp/HG+m2w4UADMTyrjz0pOOt6GkpE9lw0pK4MQJrcZxVz4+LslarSiKA3oMAJacPa8CG6WUjw18k4YhJ5XI0k1NIfrTrXg219FisH7XFAJum3uK06X2ZwLllQewLzeCG9NO42twMD9Qa6vWp9OHr/NffWV9e0gIfOtbvT6doiiDoMcAIKU0CyEm0nnRltKRs2okTp2K7pNPiCvaz9nRS2welhpfTmq8/SGYM6WBPLU1lWOFocxOLHW8DYWFWjlM0cN4gYMqK9UYgaIMVY52AWUCjwshEoGito1Syt8OQJuGHw8PrV5AbW3/zpOURFNAGIv2PUOLpx/5MXP6fqqwGgK8msnID+tdADAaobICQq305/TR0aMqACjKUOToNNAbgGDgYbTpoM+gBoE7c8ZTgF5P3p2/pM43ilVf/Jhpx1/tcVqoLTodTI2tILMwFHNrL7/NFzg3o+j589qTgKIoQ4ujTwDr0WYAKbaEhzulQldgXCDvr3yey/Y8wbxDf2HO4Rdpm76ZG7+AL+c+YnN8oKvpceV8nRNNdkkQE6N7sSq4shLKyno3GOzlBd7eNncfPQqLFtncrSiKCzgUAKSULw9wO4a/6dMhNxcqKvp1muigRiLDJdsW/IJzZz8lqEZbauvVUsek7A8IqzzN1oWP250q2mbSqEo89WYy8sN6FwAAjh/v3fEREVqhehuys2HOHLsxQlGUQeZoQZgcK6+DQognhRDqf2nQvi2vWtXrhVTWLBhXjE4P2WNWcSD1uxxI/S67Zz/If5b9AQ+TkXWf/g9Ts17Hs8X+OgAvj1YmRleRkR/W154kx1VU2C0TZjb3PqYoijKwHB0DiEQrDJNgeSUCU4AfotYDXOTvDytXaqkd+iHYt5mpsd2fJC5ETuWdK/5GccRULjn4Are8cx2X7v89fvW2y3NNjyunvN6bwirbWUadwmzuMflcVpYqJakoQ4mjYwDPA2HAvWgd0s8BVZafrwceGpDWDUeRkXDllVBdrb2vrYWDB3t9mpkJZWRfCKKhufO/okafMD5a+iwR5VlMOfkOk07/h7ii/bx95T8w67vn/59mCSQZBWHEhjT0/vfpjfJy63WSLerrtQHh0aMHthmKojjG0SeAe4BiKWWTlNIIFAN3oKWJjrL3QbcUHQ3JydorLQ36UMnMUy+5ZKyVSmIWpWGT+OLSn/LJ4icIrs1nRuYrVo8L8mkmMayG9zOS+J/NC/ifzQv49cczqGoYgEou5eU9zlrKGpQ6coqiOMLRAHAE+F8hxDkhRB5aaoiTaHV9B74K+XC3YIG2VqCXxkbUEhXYaPeYglGzOZW0gtRjmwipsp7v5+bZp7liyjlWTs5n2aQCLtT48Mxn0ymvc3LFsObmHtdCnDvX/7x5iqI4h6MB4EbgfcAfrXL5e2gVvI4A3xmYpo0g/v7ak0AfzBtju3+/zZ6Z99Js8GfhN8+A7N7JnhhWx9rUXNam5nLdjLM8uPQo9c0ePP3ZdC7UOHkMv7znJLEnTjj3koqi9I1DAUBKmS+lvFZKGWp5XSelPC+lzJBS2q9iomhSUrS1Ar0UFdjImAj736qbvIPZM/NeosuOsXjPb5iV8RKzMl5ifM6n6M1N3Y4fE17LQ0uP0GLW8fRnqZx1pMCMoxwMAGowWFFcT0gH5gcKIcKAv6DVAfgWWjWwL6WUzw1s8zpLS0uTBw4cGMxLOld9vfUKXU1N8NlnNvvPaxo9eSN9DK32VvRKyeW7H2Ns3g4AhGXdXqNXMFnjr+HYhHU0+nQeoC2u9uFPX6RQ3WjgjktOkja6rG+/V1ez08DH/qyj5cu1xKOKogw8IUS6lLJbN4SjAeAN4ArAF1hu+XmVlHKqsxtqz7APAPZ88QWcOmVz954zkRwtsD3DphspiblwiKkn3iShYA/1vhG8eeU/u60irjV68pevJnO6NIiF44oI8tGeGAz6VqKDGhgV1EC4nxGdo52FoN3Z4+3nDvTx0dIndaXTaWPn48fTu2sqimJTfwNAJfB74OdoAWA08Ccp5aBmeh/RAaC2Fl5/3WbfSEOznlf2ju/TqaNKjnD159/n5Jgr2DnvkW77W8yCzfvG83VOtNXP+3iamJt0gUXji4gNdmAqqb8/zJzZp7a2CQyE1FTtn6AlJw0JUSuJFaUvbAUAVRJyqAgIgIkTbS6X9TWYCfBuodbYu2ItABcip3Fk0k2kHt9MzuglFIya3Wm/p15y+yWnuG3exScQY4ue4hpfCqt9OVEczK7To/jiVCzJUVXceekJQnybbV+wrg4aGsC374vPamqs1xgICYFRo7TiMyEhEByspSGyxkkZrRVlxHL0CeAZLpaENGEpCSml3DCwzetsRD8BgDZG8Npr2qpaK7ZlxXCmh0IwtujNTVz70XfxNBl586qXafH069Xn64wefJ0TzYdHE/AxmHjg8kxiguw8DSQkQGJin9rqLN/5Tr9ikKKMGP3tAvIEfgJcadm0Bfg/KaXJqa3swYgPAAB79mipM604kh/K3pzIPp86suwY12y9j5LwKVQGaovTTB4+VAfEUR0YR1nIeJq8g+2e43yFH3/ckYKpVcc9lx1jfKSVQW3QOvlnz7a+b5AsXtynEseKMuL0KwDYOOGVUsoP+92yXnCLANDQAJs2WZ0RVFztwwcZ/cujMDXrdaZmvdk+S8jQUo+nSVts1uzhw6eLn6AoKtXuOcrqvPjjjqmU13mzLvUsl08sQGetu6VjJ74LjBsHl1/usssrypDRpwBgyfR5LzAG+EZKuVEIsQr4NZAqpexf1rNecosAAPDpp5CX122zySz459fJzs3sKSU+xgpCqvOYv//3BNQX8+llv+42TtBVXZMHG/dOICM/nOSoKu645CShfl3WHMTGwtie01YPFB8frRtIjQUo7q6vAWAT2opfgdb//y6wzrL7XSnl9QPQVpvcJgDk5WlBwIp3DiZSVjcwU2G8jZWs3v5DQqrz2HHpTzgbvwipsz1PQEr4OieK1w+MxdSqw6DvMoNJgMFHz7p1gksuGZAm9+i667QBY0VxZ32dBbQCrb//SbTpn48CB4H1UsojTm+loomP10YvG7oPskYGNg5YADB6h/Dh0t9xxY4fsWzXLzHpvSgNnUD+qDkcnnILUtf5gU8ImD/2AslR1XyZPQqTuftX7TxjNC+/7MH589rNuJ+ZsnutoEAFAEWxpacAEAa8KqX8WgiRjRYAftXfm78Q4mngaqAZOAPcKaXsZcmqEaxtNdShQ912RfgbB/TSTV6B/GfZH0jM30VkWRZRZceYfeQlPE2N7JvxPaufCfc3ct2Ms1b3mT0KeCs9kW3bojh/vJaJsTYGjdsIQUKsmeRJOgyhAdaT6Al6XGncJj8fpk1z6FBFcTs9dQG1AueBarT5/xOBXLR1AVJKOb1PFxViBbBdSmkSQjyJdrIf9/Q5t+kCAm1h2KuvdttcWW/gzfQxg9qUBd88y+TTH7Dt0v/HmaTlfTrHnpxIXt0/jiaTY0tPPPVmJkZXEeLbPZeRABZeBvGzY3o8j14Pt9/ep2SsijJi9GchWLzl1abfGVyklFs7vN2LVlRG6SggQBtELSjotDnYtxlPfSst5sHLk/B12gME1+Rx2TdPUR0YT1nYxF6f45IxJcxNKoEeBrBNrTpOlQRxtCCU40Uh5JZ3zxdhbNFzrKiZX4Sdw3OM/VoLZjMUF0NcXK+brCgjXp+ngTqtAUL8B3hdSmm1ookQ4i7gLoCEhIRZeVZmx4xYZ8/C7t3dNm85GENhhbd2dxukf3/exirWffI99OZmDky7k+wxK61WIBsMWUXB/H77NNZOP8sVV+kh2n5NomkpknmXeanpQIrb6ussoIlSSrvZ220dI4T4HLCWXOanUsr3Lcf8FEgDrpUORCK36gKyY98+OHzY8sZeEKirg6IiKC+D1v4HipCqHBbv+Q0RFado8A7h2IRrOT5hLU1egz/X/89fTiarOITHrt5PsL20FECoXxPX3+QBl12mMswpbqmvAaAV2AV8AOxHq/4lgBi0G/c1wPy+rAcQQtyBllZ6qZTSoWK1KgBocnNh69YeD7uopQVqbQy+njsHNfbrDXQiJaMuHGJ61uskFO6lxcOHE+Ou4sjEb1HvN3jVQUtrvfnFljTSRpdy56Unezw+1K9Jq8cwbVqnqUgJCVqtHhUXlJGsr2MAa4EfAk/RvfdWADstx/S2MauAR4DLHL35KxdFR8OMGT0fl5mp3fvx9IRQG3MhW0xQ0/MNtJ0QFEXPpCh6JiGVZ5ie9TpTTr7DlJPvkJ20nIzJN1MVlOj4+fooIsDIskn5fHIsgdGhtfh7tXQ7ZmJ0FYE+2vaKei+or4WqzE4DAhWFfhQWerN0qfX01IoykjmaCygeWMDFweBzwG4p5fk+XVSI04AXFzOK7pVS3t3T59QTQO9s2wZnzvRwkNkEe7+xmYDOEX71F5h24k0mZv8HD3MT52Pm0ODTvfpZq05PXux8zsfMAdH/r9zGFh2PfzSLsjofq/ujAhp49KoD6O1dSgiIjMAwJp7V3/Ijsu+plhRlyHJ6LiBXUAGgd86c0YJAj06ehAsX+n09L2MVKSffZnzu5+jM3b+RG0wNGFrqqfGPIWvcVdRZuoxadZ6ci5mH2aP3g8rNJh2VDd0/d7o0kI17k/nO3FMsHFfs0LkCQjy4bm4+Bo8uK5rDw+HSS1VqUWXY6m820PnAL4BEtPUAoK0DGNRELyoA9E5zM2zc6ED93eoqyBj4hd06cwuJ53cy5dS7jCrtfL3zo+bwyeLf2E090RtSwlNbp1NR783j1+zvflO3YUJUNYuTi7rvMBhg3jytZoOiDDP9LQjzKhAHNKHVA1CGAYMBYmK01bB2BQZppbaMA7vKuFXvSU7i5eQkXo5fQwkeJu16cUX7mX/gjyzY91t2zv2RU6ZrCgHrUnN59vPp7DgVw8rJPf0RNKcuBBEfWsfYiC4D483NWoWa8+dhyRK1skwZEXrTEfv/pJQ+UsqAtteAtUpxGodqsggBUYM3gweg3jeS6sAEqgMTOJZ8HQdTbmPSmQ+Zkflvp11jQlQ1KTEVfHIsnoZmxyeq7cweRZ3Rxg3+7Fn46CNo6r5CWVGGG0e7gP4IzETLBVTZtl1KeXDgmtad6gLqvYYGeMXqErsujEZtgYGrSMniPf/HhLNbqfWL7mnBMA0+4VQGjaYqKBGjnXUIp+tHcdeR+5kYXERwsOj2dDEpupJ5Y0q6fS4upJ7VU+3McQgOhkWLtHqUOp32uOVjfTBaUVytv11A91n+2XX2+SDndlR6y9cXIiOhpPs9rjNvb5g0qefZQKUlUDkAefuE4Ku5j1DnG4V/g/3GCtmKX0Mpifm78DljvybREiCfCv5ddStFNZ40e/pisqxgbjJ78M3ZSOJC6okLqe/0ufxKP04WB5EcXW39xFVV8MEHnbcZDFqh4sBA6wsLhAB/f22/v//FY/R67XNqMYIyyBwNAP+ysm34TB9yc4mJDgQAgIiIno/R6QYmAKCNERxI/W6vPuNtrMKzxf5Skkm08nLxC0zOfp/wytPt2ysJZhyn2flJPf8Y9RPq/Ed1ekIwHZS0RFXj2bHOQXi47TJjzc3abKq+zKhqG7CJidF+tsfDA8YMbkJAZWSyGwCEEB/Y268MD4mJTuzdCbZfM3iwGb2DMfZQxxigJiCOE+OuJqL8BCHVF1NX33l+K88W3MyeimSuL3m9+wfPSNBZAoDZrK2smzxZW43nTM3N2hLv3FzHjp83T+W5VvqtpyeAq+zsU08Aw0RwMFx1lbPyxhnAqw4qKpxxsm4aWzzYcTJmYHLcCUFp+CRKwye1bxqbJBj1YT0PyeeoWnMHHvruF54cU8mcxFIMteWwYQMcPAirVw9AA3vhm2+0bqP4+J6PVRQbegoA/U79rAwNMT2nznfc9HA47Ni0yr4orvHheGHIgJ2/I71Ocv3MHP70xVR2nIph+aSCbsccLwzhbFkg85L8GZ+UNDQCgJTaKr916yAoyLVtUYYtuwFASulGuZcVh8XGdkhH6nxpo8s4XRJEs2lwBkVTYitJiang7YNjKK72Zc303PYcQm0am/XsOBmDLn4xY7/6J5SWOjZmMpCam7Upqf3pjpo1SxuUVtySWs2i9F50tDYQaRqYNYHenmZmJ5ay+/TgrU347oIsPjyawLYTsRzIi+Ca6blcnlzYbU3avpCVjOWfWrnOFSsGrX021dZqr76qq9P6B1WtBLek5p0pvafXw6hRA3qJSdGVWgrnQeLjaeb6mWd59Kp0xkXW8Eb6OF7cNQljS+f/RWr9R1EaOoGGvQOfOmNQFBVBVparW6G4iHoCUPomLk5LizBAdDpYnFzIuQp/q/tbzDqMLR40NutplX3/9lpW542x5eJylujARu5bnMnnJ2J5+9AYLtT48N35Jwjy0YrOGDzMnI1fxJyMv5NxRDB+og5fQ98zqQ4Je/dqg8kqH7bbUQFA6ZvY2AG/RLh/E+H+A/sU0NSiY39eRKdBZyFg+aQCYoMb+Nuuifzyw4sLKAO8mvnT5fnMyfg7dXuPsrnmOhLD6kgMq0Wv02YQhfg29VilbEgxmeDLL2HVqt51Bel0qutomFPpoJW+e+UVLdfECFBa681nWbHUGT07bS+v8+JIQRhSQnWjgU+OJ/Bf87N4KvNKjF6BbFn+x27nCvRp4VuzctoDwogVEKANIo8frwLBENffVBCK0t3s2VBZ2fNxg0VKrbZBc++/fUcEGFk2sYAPjoymtfXizSzMv4klyYWAVlb5m9xI9p2NJCdhMbOOvszo87vIi1/Q6Vw1jZ5k5IcyM6GcEa22Fr74QpsRNmGC9VQW4eFOnoOsOJMKAErfJSe7ugXdJSVpUyP7MEMpMtDI7NGlfHPWelkwnYDZiaV8nhXL17NvIaFwL0t3/ZJPljxJYfTMTsceOhfO+MgaAry7F8YZcaqqbC811+m0rqUOZTiVoUPNAlJGluhoWL68z4nVpsVVdEsM19HcxBJapY69hQl8vOQpagJiWfnlT4goO97pOHOr4Oszg5tie0hqbYWtW6HYsapsyuBSAUAZeeLjtYRtERHWX3rbSWyFgCXJhfjYmNkTG1xPTFA9+3IjafIK5MOlz9LoHcLqHT8itmh/p2Pzyv3JLbM+i8mtmEzwySdw7py2gM7eq6bG1a11K2oQWHE/ZWXw2Wd2F1DllAbweZb1mU4fZ8bzXkYSv17zDeH+TfjXFbHqi/8luCaP/dO/S8bkb7cPinp7mrl2xln8vVUhPYcIodVfnjLF1S0ZUVRReEXpqKlJy6Vjp17mp8fiyCvv/g2+rM6Ln74/lzXTz7I6RVsL4WFqZNHepxiXt5386DQqgxLbj/cxmBgTXovOU6/NmJk4seeUz+5u4kRYsEDVSHASFQAUpSspYedOOHHC6u76Jg/eODCGFnP3m9BTW6dT1+TJw8syCGrLGyQlKSffYkbmK+haO3/j1+skHuYmrTvE0xPGjdOq9Qxno0YNbBqJ4GDw87N/jBBat15srFbW1E73njtTAUBRrJFSWwR16pTV3ccLg9l1unuytf25Efx99yR0opXpceXMTizF20MbNwjyabY6kJwWW0R8+SECTh3EcPaEzZlKuuEwpd5k0vrsv/1tuOwyV7dGo9drwbWNTqflrNLrHQtSMTFajQX/kTduowKAotgipTafPTvb6q7MwhDMrdpTwOmSQCrqtZKSxTU+7DodzZ6cKOqaOnfp3Lf4KFNj+7ZGwtvTTKhfE6F+TXjoWnv+gAPGRNQ4d1W1lPCHP8CZM/Dzn7s+M6qz6HTa01lysjajbIQscFMBQFHsaW2FggLrVXMqKyEjA4xGq08ELWZBfqU/rRJAsHHvBEytgkevTMfg4ZwbuDMkR1czO7HEebmLKirgsce07peHHx55/fXe3pCQAKGhPR8bGen8KnFOpAKAovRHczMcPUpDRjav7ErUtplasNz1OzlZHMRvt01ndUoea6YPrZIanvpWh7KsLhxf7Fg21j174OWX4frrtfUX7mzKFJgzp3M31BChUkEoSn8YDDBrFr6zZhEVZqn7np2tpVPuIjm6mrmJF9h6PJ65SSVEBzYOfnttaDHruFDj0+NxOaUBjgWAefO02gjvvw+XXDIi+88dduyYttZhyhTnPw2Fhw/IE4ZLA4AQ4mHgGSBCSlnmyrYoiqOSkiwBwM4snutn5nCkIIxX94/jwcuPDruu5JyyQNISHfhfUgi4+mqti2zfPm0BnjurrdXSaztbauqABACXddoJIeKBFcA5V7VBUfoiqa1Stp0AEOjTwtrUs5woDuGbXOu5hYayqgYDlfUOrlWIj9f6ynfvtj6GogxZrhy1+R3wCKD+i1GGlYAA7YkcP/vz+BeNKyIprIY308dQ1zT8elvPlveiQMyCBdqiuryhNeah2OeSACCEWAMUSCkzHDj2LiHEASHEgdLS0kFonaL0LCkJMHiBp+0bu04Ht849RUOzB28dHDN4jXOSnNJeFIufPVsb/Ny9e+AapDjdgAUAIcTnQohMK681wE+AnztyHinli1LKNCllWsRImWusDHsXu4Hsr1SNDWlg5eR89uREk1UcPPANc6KKei+qGx2c0eLrCzNnauMAfajHoLjGgAUAKeUyKWVK1xeQAyQBGUKIXCAOOCiEGLqTaBWli+Bgy/RwB9I5rE45R2RAI5u+GU9JrffAN86Jzpb14ilg/nwwGuHgwYFrkOJUg94xKaU8CrSPilmCQJqaBaQMN9dfD81jm6n/IofKBi+yioMpqOz+RGDwaOU7c0/xx+1T+dkHc5gyqoKF44vaC817e5iJCR6apTVzSgNIjXewstmECdqK4B07wMcy1dTfH8aOHbgGKv0y/EamFGUIMUSFYPBrJsSvmTERtVQ1GPj6TBT5XQJBclQ1/7d2H19lR7Pz9Cj+8lXndMc3z85m8YTuawpcrazOm/S8cIfrG0dOXUnM9lfghRfat2Xd/QeawmOJDGgcsoHOXbk8AEgpE13dBkXps5CQTm+DfZtZklzI6wfG0mzq3MMa5NPM1dPOsTrlPKdLA9uzjG49Hs+7h5OYGV9GoM/QKyGZnhfu8LEiaj0hq5cgZCtezXVcte0havdkcjglFT8vEzemncFDryb+DRUjLHmHogwyHx8tZ0zHTQYzsxNtz1jT6yTJUdWkxFSSElPJt+dk02LW8fah4TdTqCup01MRMo7y0AkURs+kJGwSifk7AS29dmahA3l1lEGjAoCi9Fdw99k9k0dVEu5vdOjj0YGNrJiUz96zUWSX9GLQdRjIjVtAZPkJ/BpKADh0Lgxji8rZP1SoAKAo/WUlW6QQMH/cBYdPcUXKOUJ9jWzeN56CSl8Kqhx/de1qGkrOxi8EYPR5bX1Ai1nHwXOOdykpA8vlYwCKMux1GQdoExXYyKRRVWQV9Tz/38ujZz789AAAEQBJREFUlRvTzvDnr6bw2Efdkjb28FkzKTEVzIgvI8pG4rnIgAa8PQc/NXV10GgqAxNIzN/J8eR1ABwvCiYlpmJIjne4GxUAFKW/bAQAgEvGXKC4xodKSxEZe1Ljy3lkxWGqGh2vF2xuFWRfCOJQfjjp52wvlAzyaeKWOdlMj6tw+NzOkhu/kOnHX8OrqYYmr0BaWwVvH0zCU9+7gBTg3UKQTzNBPs3ts5I8dK1MjK4acaUIBosKAIrSX3YCgIdesnxSAe8cSsJk7jkl6NiIml5ffk5iKTfPPs3Z8gDqmrqv3G026fn4WDwvfJnCnMQSlk3MRyecOxMnyLeZQG/r3+hz4xcy49gmEgq+JnvMKkDrCrJWa9mehmYPq6msz5QGsnxyAd6eTip040ZUAFCU/mqbCWS0Pugb7NvMwnFF7DgZM2BN0OlgbEStzf0z4sv4+Fg8H2UmsG8AspMa9GY2rDpErJV5/qWhE6nziSAxf1d7AHCmompf3j88mlUp5wlS3Uq9ogKAojhDSIjV4jBtxkfVUFDlx6kLQYPYqIs89JKrp51jTmIJRdX28xf1VqsUbN4/jn98PZENKw/h2XWevxDkxS8g+cyHLN35qFOvjdCRH53G6cRlvH1wDD6eprZLkhpfxsToaudeb4RRAUBRnGHlSjDb74KY0wA5b+oxmQaqERIqq7TaxnV1Vo+ICjQSFejY9NTe8NC18vyXKXyQkch1M892239i7JVElR4ltKr7vv7wNDUyNm87cw/9hRPjrqI8+OJaioLjYPRrYmJ0Fd6GAR4ADwqC8eOHXV1kFQAUxRkMPQ/c+vrA1FlaBcUBExWlvaqroaGXaRdyc6Glb10o0+IqWDSukM+y4kiJrSA5qvM37/LQ8byz+qU+ndsuKRlVkkHKybeYlvUaOjn4M53a1AbGcnrKGs6NXYxZ7/hAviMmCDMpM03g4dxbtioKryiDqLkZXn0VmhwotzvoTp2C4uI+f7zJpONXH82kxazj0SvT8TEM7qCst7ESr2brTz4DLbziJFNOvkN02bGBu8jHH8Oqvo2hqKLwijIEGAwwY8bAlI3tt/CwfgUAL49W1l96kic/TeWdw0ncMue0ExvXM6N3CEZv2zOyBlJ1YDxnEpcRXn6SUSUZOLvQYex4PxKSk516TlABQFEG3ZQpcPQo1Ne7uiVdBIeAXt/jWIY9SeG1XD6xgG0n4pg9upQJUe41CFsWlkxZmPNv1PqlYSS0VyFynuE1YqEoI4BeD1dcAStWaK/UVFe3yEKns5rWorfWTM8lzM/IK9+Mp8WBtQ+K66gnAEVxgdDQi/fa2FjIzGQAZwf1QngY9LP2tpdHK7fOPcXvt0/jvcNJLEkudFLjBk+Ib5PDNRCGMxUAFMXFPD21GsPZ2a5uCRASCjoBrf27+U0aVcUlY4r5/EQcn5+Ic1LjBk98SB2PrDiMwcN1s4oGgwoAijIETJgwRAKAh4c2FlDR/5xBt8zJZsqoSkytw6unuabRk3cPJ7F5/zjuuOSUq5szoFQAUJQhICYG/PyGyMBweJhTAoCnXtotjDOUNZn0fJg5mvGR1cwf63ha7+FGBQBFGQKE0BaSHj7s6pYAoWEgTsMwWiPkbFdNzeN0aSCv7h9HuL+RUF/XLtwoKPGkoQF8fZ17XrUQTFGGiMpKePNNV7fCotWBvu/CQsjJGfi2uEhNoye/+ngm1Y09p/IeDP1YB6YWginKUBcSAhER/Z6E4xyO5LSJjYXyci3txAgU6NPChpWHOemiBH4djZ7sz9Spzh9MVwFAUYaQmTPh3DnHj29pgdODu+D2IiG00euDB/u1eGwoC/Vr4pIxJa5uBqnzzcTGqgCgKCPa6NHaqzeqq1341ODjo81hdVkUUvpDBQBFGeZSU+Gzz1zYgJgYkK0D+xRgNmt5ilqGwmq5kUMFAEUZ5hITITgYqqpc2IgB6J7oJi4ezp+HwoJ+L1RTNCoAKMowJwRMnw5ffunqlgwwT08YM0YbfG5p1ra1Smhs1Arg1NWN2LEIvL0H5LQuCwBCiPuBe/9/e/cebNd4h3H8+zhIGpmUCFqXSJC01EiRVqhrXOoSdFpTDEUZMcYMSqvKdMq0WqpV1Wm1GdS1SlOTarQ6JYIWcR+NS4iiiLugFHH59Y/33cm2s/fZ+5yzd1bOXs9nZk32uuz3st6T9VuXvd4X+AC4LiJOKqosZoPduHFw993LyYtknTZkSJoqRoxIg+B0sw07k2whAUDSTsC+wISIeFdS+0epNiuRFVaAzTaD228vuiQ2mBR1BXA0cGZEvAsQEcX/zspskNt0UxjImCELFsCddxb8LMGWqaICwHhgO0lnAO8A34yIu+ptKGkqMBVg9OjRy66EZoOM1NLQxA2NGQOjR8O8eX1/wXfhwr4PQWzF61gAkHQD8Ik6q07N+Y4EJgGfA66WtEHU6ZciIqYB0yB1BdGp8ppZupW08cZp6otXX4UZM5aTMQ2sZR0LABGxS6N1ko4GrskH/DslfQiMApaHl+DNrI9GjoRtt4XZs4suifVFUR11zwB2ApA0HlgZeLmgsphZG4wf3/crBytWUc8ALgIukjQXWAQcWu/2j5kNLttsk3qRXrSoc3m88056YG0DV0gAiIhFwMFF5G1mndPTA9tv3/l8Zs1y90PtMLjGajMzA3bYAdb020MD5gBgZoNOTw/sthsMH150SQY3BwAzG5SGDYMpU2DLLVOHpCu6Z7M+8y4zs0FrxIgUACCNYtnKSJatuP/+NM5Nt3MAMLOusMIKrY1k2YqJE1Pno3PmtCe95ZUDgJlZHRMmpK417qrbSc2y1anbWw4AZmYN9KdbjMHED4HNzErKAcDMrKQcAMzMSsoBwMyspBwAzMxKygHAzKykHADMzErKAcDMrKQcAMzMSkqDaSAuSS8BT/Xz66Mo37CTrnM5uM7lMJA6rx8Ra9QuHFQBYCAk3R0RE4sux7LkOpeD61wOnaizbwGZmZWUA4CZWUmVKQBMK7oABXCdy8F1Loe217k0zwDMzOyjynQFYGZmVRwAzMxKqhQBQNLukuZJmi/p5KLL026S1pN0k6SHJD0o6bi8fKSkv0t6LP+7WtFlbTdJPZLukzQzz4+VNCe39VWSVi66jO0kaVVJ0yU9IulhSVt3eztL+kb+u54r6UpJQ7utnSVdJOlFSXOrltVtVyXn5bo/IGmL/ubb9QFAUg/wS2APYBPgQEmbFFuqtnsfODEiNgEmAcfkOp4M3BgR44Ab83y3OQ54uGr+LOBnEbERsBA4opBSdc7Pgesj4tPABFLdu7adJa0DHAtMjIhNgR7gALqvnS8Gdq9Z1qhd9wDG5WkqcH5/M+36AAB8HpgfEf+OiEXA74F9Cy5TW0XEcxFxb/78X9JBYR1SPS/Jm10CfKmYEnaGpHWBvYAL8ryAycD0vElX1VnSx4HtgQsBImJRRLxGl7czaezyj0laERgGPEeXtXNE3AK8WrO4UbvuC1wayR3AqpI+2Z98yxAA1gGerpp/Ji/rSpLGAJsDc4C1IuK5vOp5YK2CitUp5wInAR/m+dWB1yLi/TzfbW09FngJ+G2+7XWBpFXo4naOiGeBnwD/IR34XwfuobvbuaJRu7btmFaGAFAakoYDfwSOj4g3qtdF+r1v1/zmV9IU4MWIuKfosixDKwJbAOdHxObAW9Tc7unCdl6NdMY7FlgbWIWlb5V0vU61axkCwLPAelXz6+ZlXUXSSqSD/xURcU1e/ELl0jD/+2JR5euALwD7SHqSdFtvMun++Kr5VgF0X1s/AzwTEXPy/HRSQOjmdt4FeCIiXoqI94BrSG3fze1c0ahd23ZMK0MAuAsYl381sDLpAdK1BZeprfK97wuBhyPinKpV1wKH5s+HAn9a1mXrlIj4TkSsGxFjSG06KyIOAm4C9subdVudnweelvSpvGhn4CG6uJ1Jt34mSRqW/84rde7adq7SqF2vBQ7JvwaaBLxedauobyKi6ydgT+BR4HHg1KLL04H6bUu6PHwAuD9Pe5Luid8IPAbcAIwsuqwdqv+OwMz8eQPgTmA+8AdgSNHla3NdPwvcndt6BrBat7czcDrwCDAXuAwY0m3tDFxJesbxHulK74hG7QqI9MvGx4F/kX4h1a983RWEmVlJleEWkJmZ1eEAYGZWUg4AZmYl5QBgZlZSDgBmZiXlAGBmVlIOAGZmJeUAUFK5T/UFks7qQNrDJJ0m6bBethkjKSr9+DdJb/G29dJuNa2adFrOv0Fa/S5HC2mvLultScc3WN/r/miXTtaxTl47S7qsnWlac34RrKQkHUHqRnlcRMxvc9qjSL1W3hwROzbYZhVgb+DZiLi1SXqLtyV1df2RtFtNK/eU+gRwHbB/q/k3SGupOvalTi2kfznpDe+xUfOftNn+6GM+K8aSXjVr13W0jjV5nQAQH+3KxDqt6FegPRUzkV4xfyh/HkPqSuIfpIPja+RX7vP6I0mvo79Fev1+27x8zZzOm8AbpC6o1wCezOlVptPq5F/Jc2bV59uAv+a0fseSE5TqbZdKu2b9GsB9uUxvArcCn+klz0oXEofVpBt5Wd30mpWjqp5L7btm9c3f2z9vs3WTfVd3XwOHA/NyvrcBW9R89zZS9wIvDKSO9epXJ5+6dayp0yXATqRuHi4GfthoW0/tm3wLqITyKGmTSB3lVZsEzAZmAQcDR0maDEwjnQmeAIwGrpW0OnAQqRfOnwInkvog6gFOyek9DBwITM+3E0blaXiDom0F3EI6cB1IOljWWirtmvUfknqMPA44kzRq1rmN9kWVm3N6hwAvA4tI/aw0Sq9ZOWi070h9vDSrb6VttmtS7nr7ekdS54BPAj/I+f1Z0tCq721N6lf/u/2tY5O/jYpW2hRgM1Jvl38DboiIUyJHBuugoiOQp2U/kQaWCOBHeX5Mnr81z2+Y568hDcYRwK553Rl5fi9gCkuuHM4EJudtRuXls6vyPI0lZ5IX0+AKIG97cp7/Wk35ZjZIu3r92sA/SQe1Sn7P19lu8eeafXNRXn5Qnq+bXrNy5PlG++6Y3uqblw3Ny35Vp/2a7Y+zq8paPW1R9d17q7bvVx17qd9ezdq0pj4rkQZ6eYA6VzyeOjf5CqDc1GC+djksGYxi8VlZRMwkXTVcTzqzu1HSLtXbVLkU2DVPP25QnsqQeJV70j29lKORY4FtSGewu5F6Vhza6zcySacCXwe+FxFXNEmvL2enS+27rLf61muD3tKu50SW7PMvkp5/VCyo+jzQOjaqH7TWphuTrnjeBz5oMU9rAweAcnoZeJt05ldtkqRvseQAPRv4S/58uqSjSN3ULgTukLQf6SrgaeDBvN3apPu9HwIbSTpI0vqRxmS+IU8PDaDsS6XdYLvVSOPnrttKopL2Br5Pup/9qKQDJI3tJb1WytFw37VQpErbPNVku3rluC6vO5B0W2Yr4LyIWNgkrb7WcSD1qzaB9KzgANJwl10zpOXyzgGghCLiA+B2YGLNqttIfevvDFwB/CYiZgFTSQ98zyGdHe4TEa8A/wO+Avwa+CpwFTA90shNZwOrApfT/D52X8reLO1fkM4m9yeNkzq3xaS3JJ11jyP1zX4lsEOj9FqpY6N9B7zSQnkqbXNLbxvVK0dEzCZdyQwn9Rs/ldS2jfSrjk3+NvpiAjA3Ih4Fvg1cnUe4sw7zz0BLStLhpAeF40iX3k8A10XElEILZkDvPwM1axdfAZTXFaQRiI4suiD2UZJGAl8GzvXB3zrJVwBmZiXlKwAzs5JyADAzKykHADOzknIAMDMrKQcAM7OScgAwMyspBwAzs5L6P3wm8WajqilwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 10. Visualise!\n",
    "\n",
    "title = obj_func\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(median_gp, color = 'Red')\n",
    "plt.plot(median_stp, color = 'Blue')\n",
    "\n",
    "xstar = np.arange(0, 101, step=1)\n",
    "plt.fill_between(xstar, lower_gp, upper_gp, facecolor = 'Red', alpha=0.4, label='GP ERM Regret: IQR')\n",
    "plt.fill_between(xstar, lower_stp, upper_stp, facecolor = 'Blue', alpha=0.4, label='STP ERM Regret: IQR ' r'($\\nu$' ' = {})'.format(df1))\n",
    "\n",
    "plt.title(title, weight = 'bold')\n",
    "plt.xlabel('(post-initialization) iteration $\\it{k}$', weight = 'bold') # x-axis label\n",
    "plt.ylabel('ln(Regret)', weight = 'bold') # y-axis label\n",
    "plt.legend(loc=0) # add plot legend\n",
    "\n",
    "plt.show() #visualise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
