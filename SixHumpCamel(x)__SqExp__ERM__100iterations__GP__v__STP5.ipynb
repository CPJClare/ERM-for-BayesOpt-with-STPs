{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Import modules:\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.latex.preamble']=[r'\\usepackage{amsmath}']\n",
    "plt.rcParams['text.latex.preamble'] = [r'\\boldmath']\n",
    "from matplotlib.pyplot import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=False)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from numpy.linalg import slogdet\n",
    "from scipy.linalg import inv\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gamma\n",
    "from scipy.stats import norm, t\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from pyGPGO.logger import EventLogger\n",
    "from pyGPGO.GPGO import GPGO\n",
    "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
    "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
    "from pyGPGO.surrogates.tStudentProcess import logpdf\n",
    "from pyGPGO.acquisition import Acquisition\n",
    "from pyGPGO.covfunc import squaredExponential, matern32, matern52\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. User-defined - inputs:\n",
    "\n",
    "### Objective Function:\n",
    "obj_func = 'SixHumpCamel' # 2-D;\n",
    "\n",
    "### Data inputs:\n",
    "n_test = 50\n",
    "\n",
    "### Student-t parameter input:\n",
    "df1 = 5 # Degree(s)-of-freedom (DF)\n",
    "\n",
    "### Acquisition / Utility function - MLE/Type II:\n",
    "util_gp = 'RegretMinimized' # Gaussian MLE\n",
    "util_stp = 'tRegretMinimized' # Student-t MLE\n",
    "\n",
    "#util_gp = 'ExpectedImprovement' # Gaussian MLE\n",
    "#util_stp = 'tExpectedImprovement' # Student-t MLE\n",
    "\n",
    "### Probabilistic / Surrogate / Stochastic model - MLE/Type II: \n",
    "#surrogate_model_gp = 'Gaussian Process'\n",
    "surrogate_model_stp = 'Student-t Process'\n",
    "\n",
    "### Covariance Function:\n",
    "cov_func = squaredExponential()\n",
    "#cov_func = matern32()\n",
    "#cov_func = matern52()\n",
    "\n",
    "n_init = 5  # Number of iterations used to initialise Bayesian optimisation; minimum 2\n",
    "\n",
    "### MLE / Type II Empirical Bayes:\n",
    "optimize = False # MLE Boolean\n",
    "usegrads = False # MLE Boolean (pyGPGO not programmed for Student-t MLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. Objective Function - 6-Humped Camel(x) 2-D:\n",
    "\n",
    "if obj_func == 'SixHumpCamel':\n",
    "    \n",
    "    # True y bounds:\n",
    "    y_lb = -1.0316\n",
    "    operator = -1 # targets global minimum \n",
    "    y_global_orig = y_lb * operator # targets global minimum\n",
    "            \n",
    "# Constraints:\n",
    "    lb_x1 = -3\n",
    "    ub_x1 = +3\n",
    "    \n",
    "    lb_x2 = -2\n",
    "    ub_x2 = +2\n",
    "    \n",
    "# Input array dimension(s):\n",
    "    dim = 2\n",
    "\n",
    "# 2-D inputs' parameter bounds:\n",
    "    param = {'x1_training': ('cont', [lb_x1, ub_x1]),\n",
    "             'x2_training': ('cont', [lb_x2, ub_x2])}\n",
    "    \n",
    "    max_iter = (10 * dim)*0 + 100  # iterations of Bayesian optimisation\n",
    "    \n",
    "# Test data:\n",
    "    x1_test = np.linspace(lb_x1, ub_x1, n_test)\n",
    "    x2_test = np.linspace(lb_x2, ub_x2, n_test)\n",
    "    Xstar_d = np.column_stack((x1_test, x2_test))\n",
    "    \n",
    "    def f_syn_polarity(x1_training, x2_training):\n",
    "        return operator * ((4 - 2.1 * x1_training ** 2 + 1 / 3 * x1_training ** 4) * x1_training ** 2 +\n",
    "                (x1_training * x2_training) + (-4 + 4 * x2_training ** 2) * x2_training ** 2)\n",
    "    \n",
    "    \n",
    "    def f_syn_transform_polarity(x1_training, x2_training):\n",
    "            return operator * (np.sqrt(2 * (y_global_orig - f_syn_polarity(x1_training, x2_training))))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4a. Add new acquisition functions: add CBM & ERM (Nyugen and Osborne, 2019) method .\n",
    "\n",
    "### Inherits from class Acquisition()\n",
    "\n",
    "class Acquisition_new(Acquisition):    \n",
    "    def __init__(self, mode, eps=1e-06, **params):\n",
    "        \"\"\"\n",
    "        Acquisition function class.\n",
    "        Parameters\n",
    "        ----------\n",
    "        mode: str\n",
    "            Defines the behaviour of the acquisition strategy.\n",
    "        eps: float\n",
    "            Small floating value to avoid `np.sqrt` or zero-division warnings.\n",
    "        params: float\n",
    "            Extra parameters needed for certain acquisition functions, e.g. UCB needs\n",
    "            to be supplied with `beta`.\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.eps = eps\n",
    "\n",
    "        mode_dict = {\n",
    "            'ExpectedImprovement': self.ExpectedImprovement,\n",
    "            'tExpectedImprovement': self.tExpectedImprovement,\n",
    "            'RegretMinimized': self.RegretMinimized,\n",
    "            'tRegretMinimized': self.tRegretMinimized\n",
    "        }\n",
    "\n",
    "        self.f = mode_dict[mode]\n",
    "   \n",
    "    def ExpectedImprovement(self, tau, mean, std):\n",
    "        \"\"\"\n",
    "        Expected Improvement acquisition function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tau: float\n",
    "            Best observed function evaluation.\n",
    "        mean: float\n",
    "            Point mean of the posterior process.\n",
    "        std: float\n",
    "            Point std of the posterior process.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Expected improvement.\n",
    "        \"\"\"\n",
    "        z = (mean - tau - self.eps) / (std + self.eps)\n",
    "        return (mean - tau) * norm.cdf(z) + std * norm.pdf(z)[0]\n",
    "\n",
    "\n",
    "    def RegretMinimized(self, tau, mean, std):\n",
    "        \"\"\"\n",
    "        Regret Minimized acquisition function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tau: float\n",
    "            Best observed function evaluation.\n",
    "        mean: float\n",
    "            Point mean of the posterior process.\n",
    "        std: float\n",
    "            Point std of the posterior process.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Expected improvement.\n",
    "        \"\"\"\n",
    "        \n",
    "        z = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
    "        return z * (std + self.eps) * norm.cdf(z) + std * norm.pdf(z)[0]\n",
    "    \n",
    "    \n",
    "    def tExpectedImprovement(self, tau, mean, std, nu=3.0):\n",
    "        \"\"\"\n",
    "        Expected Improvement acquisition function. Only to be used with `tStudentProcess` surrogate.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tau: float\n",
    "            Best observed function evaluation.\n",
    "        mean: float\n",
    "            Point mean of the posterior process.\n",
    "        std: float\n",
    "            Point std of the posterior process.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Expected improvement.\n",
    "        \"\"\"\n",
    "        gamma = (mean - tau - self.eps) / (std + self.eps)\n",
    "        return gamma * std * t.cdf(gamma, df=nu) + std * (1 + (gamma ** 2 - 1)/(nu - 1)) * t.pdf(gamma, df=nu)\n",
    "    \n",
    "    \n",
    "    def tRegretMinimized(self, tau, mean, std, nu=3.0):\n",
    "        \"\"\"\n",
    "        Regret Minimized acquisition function. Only to be used with `tStudentProcess` surrogate.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tau: float\n",
    "            Best observed function evaluation.\n",
    "        mean: float\n",
    "            Point mean of the posterior process.\n",
    "        std: float\n",
    "            Point std of the posterior process.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Expected improvement.\n",
    "        \"\"\"\n",
    "        \n",
    "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
    "        return gamma * (std + self.eps) * t.cdf(gamma, df=nu) + std * (nu + gamma ** 2)/(nu - 1) * t.pdf(gamma, df=nu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4b. Re-define tStudentProcess class with non-zero prior mean function:\n",
    "\n",
    "### [Nyugen and Osborne, 2019] \"Knowing The What But Not The Where in Bayesian Optimization\"\n",
    "\n",
    "### Inherits from class tStudentProcess()\n",
    "\n",
    "class tStudentProcess_prior(tStudentProcess):\n",
    "    def __init__(self, covfunc, nu, optimize=False, mprior=0):\n",
    "        \"\"\"\n",
    "        t-Student Process regressor class.\n",
    "        This class DOES NOT support gradients in ML estimation yet.\n",
    "        Parameters\n",
    "        ----------\n",
    "        covfunc: instance from a class of covfunc module\n",
    "            An instance from a class from the `covfunc` module.\n",
    "        nu: float\n",
    "            (>2.0) Degrees of freedom\n",
    "        Attributes\n",
    "        ----------\n",
    "        covfunc: object\n",
    "            Internal covariance function.\n",
    "        nu: float\n",
    "            Degrees of freedom.\n",
    "        optimize: bool\n",
    "            Whether to optimize covariance function hyperparameters.\n",
    "        \"\"\"\n",
    "        self.covfunc = covfunc\n",
    "        self.nu = nu\n",
    "        self.optimize = optimize\n",
    "        self.mprior = mprior\n",
    "        \n",
    "    def logpdf(x, nu, Sigma):\n",
    "        \"\"\"\n",
    "        Marginal log-likelihood of a Student-t Process\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: array-like\n",
    "            Point to be evaluated\n",
    "        df: float\n",
    "            Degrees of freedom (>2.0)\n",
    "        mu: array-like\n",
    "            Mean of the process.\n",
    "        Sigma: array-like\n",
    "            Covariance matrix of the process.\n",
    "        Returns\n",
    "        -------\n",
    "        logp: float\n",
    "            log-likelihood \n",
    "        \"\"\"\n",
    "        d = len(x)\n",
    "        x = np.atleast_2d(x)\n",
    "        xm = x - self.mprior\n",
    "        V = nu * Sigma\n",
    "        V_inv = np.linalg.inv(V)\n",
    "        _, logdet = slogdet(np.pi * V)\n",
    "\n",
    "        logz = -gamma(nu / 2.0 + d / 2.0) + gamma(nu / 2.0) + 0.5 * logdet\n",
    "        logp = -0.5 * (nu + d) * np.log(1 + np.sum(np.dot(xm, V_inv) * xm, axis=1))\n",
    "\n",
    "        logp = logp - logz\n",
    "\n",
    "        return logp[0]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits a t-Student Process regressor\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray, shape=(nsamples, nfeatures)\n",
    "            Training instances to fit the GP.\n",
    "        y: np.ndarray, shape=(nsamples,)\n",
    "            Corresponding continuous target values to `X`.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n1 = X.shape[0]\n",
    "\n",
    "        if self.optimize:\n",
    "            self.optHyp(param_key=self.covfunc.parameters, param_bounds=self.covfunc.bounds)\n",
    "\n",
    "        self.K11 = self.covfunc.K(self.X, self.X)\n",
    "        self.beta1 = np.dot(np.dot(self.y.T, inv(self.K11)), self.y)\n",
    "        self.logp = logpdf(self.y, self.nu, mu=self.mprior, Sigma=self.K11)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5a. Cumulative Regret Calculator:\n",
    "\n",
    "def min_max_array(x):\n",
    "    new_list = []\n",
    "    for i, num in enumerate(x):\n",
    "            new_list.append(np.min(x[0:i+1]))\n",
    "    return new_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5b. Set-seeds:\n",
    "\n",
    "run_num_1 = 111\n",
    "run_num_2 = 222\n",
    "run_num_3 = 333\n",
    "run_num_4 = 444\n",
    "run_num_5 = 555\n",
    "run_num_6 = 666\n",
    "run_num_7 = 777\n",
    "run_num_8 = 888\n",
    "run_num_9 = 999\n",
    "run_num_10 = 1000\n",
    "run_num_11 = 1111\n",
    "run_num_12 = 1222\n",
    "run_num_13 = 1333\n",
    "run_num_14 = 1444\n",
    "run_num_15 = 1555\n",
    "run_num_16 = 1666\n",
    "run_num_17 = 1777\n",
    "run_num_18 = 1888\n",
    "run_num_19 = 1999\n",
    "run_num_20 = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.67302105 -1.32372098]. \t  -5.793449752432556 \t -0.8736935954900025\n",
      "init   \t [-0.38364588  1.07704989]. \t  -0.8736935954900025 \t -0.8736935954900025\n",
      "init   \t [-1.22804817 -1.40334817]. \t  -11.759316761133794 \t -0.8736935954900025\n",
      "init   \t [-2.86513005 -0.31910203]. \t  -76.26436708944966 \t -0.8736935954900025\n",
      "init   \t [-1.56790715 -0.64937523]. \t  -2.1371114994016214 \t -0.8736935954900025\n",
      "1      \t [-0.93715312 -0.14094362]. \t  -2.1732366761917628 \t -0.8736935954900025\n",
      "2      \t [-0.07304748  1.91440922]. \t  -38.94939625574387 \t -0.8736935954900025\n",
      "3      \t [-0.78050992  0.72945562]. \t  \u001b[92m-0.16756927340884753\u001b[0m \t -0.16756927340884753\n",
      "4      \t [0.30116652 0.52574141]. \t  \u001b[92m0.2959059661444615\u001b[0m \t 0.2959059661444615\n",
      "5      \t [-0.24800952  0.70022954]. \t  \u001b[92m0.9351214113150093\u001b[0m \t 0.9351214113150093\n",
      "6      \t [1.56094666 0.14143972]. \t  -2.2430796288735633 \t 0.9351214113150093\n",
      "7      \t [ 1.98277342 -2.        ]. \t  -47.55707204445898 \t 0.9351214113150093\n",
      "8      \t [3. 2.]. \t  -162.89999999999998 \t 0.9351214113150093\n",
      "9      \t [ 1.04581589 -0.12582474]. \t  -2.1050141276707985 \t 0.9351214113150093\n",
      "10     \t [-0.3312858   0.80795689]. \t  0.7601331855509057 \t 0.9351214113150093\n",
      "11     \t [-1.48211103  1.64684444]. \t  -18.319352436582857 \t 0.9351214113150093\n",
      "12     \t [0.20276286 0.02790145]. \t  -0.16347056748485342 \t 0.9351214113150093\n",
      "13     \t [ 1.86388429 -0.23019458]. \t  -1.8976200882948167 \t 0.9351214113150093\n",
      "14     \t [ 0.26096036 -1.76606431]. \t  -26.238185894466334 \t 0.9351214113150093\n",
      "15     \t [ 0.99354472 -0.93019942]. \t  -0.8323521358113928 \t 0.9351214113150093\n",
      "16     \t [-0.00436231  0.50492679]. \t  0.7619306048970829 \t 0.9351214113150093\n",
      "17     \t [ 0.61503117 -0.7163713 ]. \t  0.20927523803612547 \t 0.9351214113150093\n",
      "18     \t [-2.06825954 -1.82702401]. \t  -39.77174015579872 \t 0.9351214113150093\n",
      "19     \t [ 2.79836475 -0.36511083]. \t  -61.13109513906215 \t 0.9351214113150093\n",
      "20     \t [ 0.08953225 -0.45794159]. \t  0.6719992467043938 \t 0.9351214113150093\n",
      "21     \t [ 1.55365751 -0.32440368]. \t  -1.226962645103788 \t 0.9351214113150093\n",
      "22     \t [-0.03246911  0.71572602]. \t  \u001b[92m1.0184227511114694\u001b[0m \t 1.0184227511114694\n",
      "23     \t [-1.0331679  -0.80591207]. \t  -2.2044185478435976 \t 1.0184227511114694\n",
      "24     \t [-0.22125    -0.31741033]. \t  0.10135530706690432 \t 1.0184227511114694\n",
      "25     \t [-0.06623427  0.6913335 ]. \t  \u001b[92m1.0263362251134789\u001b[0m \t 1.0263362251134789\n",
      "26     \t [-0.12064446  0.3855229 ]. \t  0.4948853256820529 \t 1.0263362251134789\n",
      "27     \t [ 1.69944873 -0.45869842]. \t  -0.6219762540829291 \t 1.0263362251134789\n",
      "28     \t [-0.06057763  0.75063218]. \t  1.0147182520433624 \t 1.0263362251134789\n",
      "29     \t [-1.58777894  0.64712721]. \t  -0.07714900223152943 \t 1.0263362251134789\n",
      "30     \t [-1.30880562  0.71542016]. \t  -0.42957053211949625 \t 1.0263362251134789\n",
      "31     \t [-2.85455508  1.61243532]. \t  -85.54204862515923 \t 1.0263362251134789\n",
      "32     \t [-1.76511934 -0.15155532]. \t  -2.3365582004902055 \t 1.0263362251134789\n",
      "33     \t [-1.7508726   0.38394134]. \t  -0.9552273236159621 \t 1.0263362251134789\n",
      "34     \t [-0.1198851  -0.78435006]. \t  0.7958223749138317 \t 1.0263362251134789\n",
      "35     \t [ 0.13028843 -0.7177014 ]. \t  1.0252999067571194 \t 1.0263362251134789\n",
      "36     \t [-1.80852718  0.38025444]. \t  -1.0984653743738888 \t 1.0263362251134789\n",
      "37     \t [-1.78809222  1.4077139 ]. \t  -7.4806184141338425 \t 1.0263362251134789\n",
      "38     \t [-0.39087178 -0.64675075]. \t  0.1572014174845049 \t 1.0263362251134789\n",
      "39     \t [ 0.07674227 -0.69113972]. \t  \u001b[92m1.0275611168370586\u001b[0m \t 1.0275611168370586\n",
      "40     \t [-2.25205148  1.19447344]. \t  -9.501171268168793 \t 1.0275611168370586\n",
      "41     \t [-1.81306824  0.89573056]. \t  -0.038629271114050456 \t 1.0275611168370586\n",
      "42     \t [0.11986892 1.20162661]. \t  -2.7649172983455013 \t 1.0275611168370586\n",
      "43     \t [-0.18441338  0.78811711]. \t  0.9530333021585169 \t 1.0275611168370586\n",
      "44     \t [-1.52807232  1.13158191]. \t  -1.8414164933370722 \t 1.0275611168370586\n",
      "45     \t [1.08878427 1.92103978]. \t  -44.1520376928909 \t 1.0275611168370586\n",
      "46     \t [ 0.07610358 -0.6937152 ]. \t  \u001b[92m1.0282899350140302\u001b[0m \t 1.0282899350140302\n",
      "47     \t [-1.77367045  1.64443934]. \t  -17.6955156113525 \t 1.0282899350140302\n",
      "48     \t [-1.95465509  0.67202311]. \t  -0.9144651821575858 \t 1.0282899350140302\n",
      "49     \t [-0.33830206 -1.5749701 ]. \t  -15.65361112403584 \t 1.0282899350140302\n",
      "50     \t [0.96700511 1.6088807 ]. \t  -20.1797643715767 \t 1.0282899350140302\n",
      "51     \t [-0.63320781  1.30818715]. \t  -5.328849189545264 \t 1.0282899350140302\n",
      "52     \t [1.78943477 1.05874623]. \t  -4.657173885277427 \t 1.0282899350140302\n",
      "53     \t [ 0.24251203 -0.5235617 ]. \t  0.6948246801657919 \t 1.0282899350140302\n",
      "54     \t [1.5095283  0.74482543]. \t  -2.2909762346483764 \t 1.0282899350140302\n",
      "55     \t [-0.76016924 -1.6482706 ]. \t  -21.584220412392074 \t 1.0282899350140302\n",
      "56     \t [-1.39263147  1.44762328]. \t  -9.458376248624448 \t 1.0282899350140302\n",
      "57     \t [-0.02252971  0.75824675]. \t  0.9925903742455113 \t 1.0282899350140302\n",
      "58     \t [1.17939302 0.48776517]. \t  -2.247908063207417 \t 1.0282899350140302\n",
      "59     \t [0.59966949 1.15925269]. \t  -3.7259669311157895 \t 1.0282899350140302\n",
      "60     \t [1.4978104  1.68247342]. \t  -25.417164401686623 \t 1.0282899350140302\n",
      "61     \t [-0.79823274 -0.23445295]. \t  -1.7617083174416392 \t 1.0282899350140302\n",
      "62     \t [0.38030497 1.23549112]. \t  -4.219773213399278 \t 1.0282899350140302\n",
      "63     \t [-1.6531405   1.26525901]. \t  -3.8071160185632826 \t 1.0282899350140302\n",
      "64     \t [-1.47517746  1.13816911]. \t  -2.0467536045476122 \t 1.0282899350140302\n",
      "65     \t [ 0.04446127 -0.78391692]. \t  0.9744903444205099 \t 1.0282899350140302\n",
      "66     \t [-0.08423858 -0.23792483]. \t  0.16529356485900776 \t 1.0282899350140302\n",
      "67     \t [ 2.14377368 -1.45496872]. \t  -12.72342743307032 \t 1.0282899350140302\n",
      "68     \t [ 0.16023755 -0.76028763]. \t  0.9961418762046389 \t 1.0282899350140302\n",
      "69     \t [-0.08627193  0.75742197]. \t  1.0139693537690022 \t 1.0282899350140302\n",
      "70     \t [-2.27538876 -1.35300516]. \t  -19.839781473580203 \t 1.0282899350140302\n",
      "71     \t [1.86722164 0.27060845]. \t  -2.7798413326718903 \t 1.0282899350140302\n",
      "72     \t [-0.12988261  0.68633578]. \t  1.0189102949372086 \t 1.0282899350140302\n",
      "73     \t [0.71379781 1.66023714]. \t  -22.087172660864255 \t 1.0282899350140302\n",
      "74     \t [-0.4026587  -1.88690108]. \t  -37.81861699002644 \t 1.0282899350140302\n",
      "75     \t [-0.36505783  0.38931278]. \t  0.15993082202549325 \t 1.0282899350140302\n",
      "76     \t [-0.76437006 -0.06979844]. \t  -1.720627974182256 \t 1.0282899350140302\n",
      "77     \t [ 0.31622755 -0.56341955]. \t  0.6655256602171276 \t 1.0282899350140302\n",
      "78     \t [1.50877989 1.95950441]. \t  -48.725209640449066 \t 1.0282899350140302\n",
      "79     \t [-0.63462875 -0.18815498]. \t  -1.2749621822997672 \t 1.0282899350140302\n",
      "80     \t [-0.75974962 -1.7818196 ]. \t  -30.64699317939762 \t 1.0282899350140302\n",
      "81     \t [ 0.97444179 -0.22800717]. \t  -1.7708006741633173 \t 1.0282899350140302\n",
      "82     \t [1.32274211 0.57888504]. \t  -2.2297831175980805 \t 1.0282899350140302\n",
      "83     \t [ 1.09004211 -1.94185986]. \t  -42.02348857257047 \t 1.0282899350140302\n",
      "84     \t [1.74306568 1.61403765]. \t  -21.65610178465473 \t 1.0282899350140302\n",
      "85     \t [-2.6672884   0.65360609]. \t  -39.47632188643165 \t 1.0282899350140302\n",
      "86     \t [ 1.08795635 -1.7951684 ]. \t  -29.043000392860524 \t 1.0282899350140302\n",
      "87     \t [-0.58486961  1.27081664]. \t  -4.365318131187895 \t 1.0282899350140302\n",
      "88     \t [-1.58461732  0.13930054]. \t  -1.7837788225475826 \t 1.0282899350140302\n",
      "89     \t [1.29854219 0.70445066]. \t  -2.2868519260290716 \t 1.0282899350140302\n",
      "90     \t [-0.05184226  0.73552753]. \t  1.0206718490187514 \t 1.0282899350140302\n",
      "91     \t [-0.04926054  0.75311248]. \t  1.009352932694486 \t 1.0282899350140302\n",
      "92     \t [ 2.15048771 -0.66737539]. \t  -4.13124619636116 \t 1.0282899350140302\n",
      "93     \t [-0.17662727  0.73279209]. \t  1.0012046919843132 \t 1.0282899350140302\n",
      "94     \t [ 0.11333463 -0.70660871]. \t  \u001b[92m1.0290480670839535\u001b[0m \t 1.0290480670839535\n",
      "95     \t [ 2.42228947 -1.65386767]. \t  -33.486234540202446 \t 1.0290480670839535\n",
      "96     \t [-2.42244289 -1.42115387]. \t  -30.19710499829729 \t 1.0290480670839535\n",
      "97     \t [-0.31163253  1.16961094]. \t  -2.018095017814412 \t 1.0290480670839535\n",
      "98     \t [ 2.52120677 -0.8352527 ]. \t  -23.23708434097477 \t 1.0290480670839535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [ 1.73673603 -0.96623492]. \t  -0.1807152065744506 \t 1.0290480670839535\n",
      "100    \t [-0.09590284  0.63470091]. \t  0.9865013931367435 \t 1.0290480670839535\n"
     ]
    }
   ],
   "source": [
    "### 6(a). Bayesian optimization runs (x20): GP run number = 1\n",
    "\n",
    "np.random.seed(run_num_1)\n",
    "surrogate_gp_1 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_1 = GPGO(surrogate_gp_1, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_1.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.67302105 -1.32372098]. \t  -5.793449752432556 \t -0.8736935954900025\n",
      "init   \t [-0.38364588  1.07704989]. \t  -0.8736935954900025 \t -0.8736935954900025\n",
      "init   \t [-1.22804817 -1.40334817]. \t  -11.759316761133794 \t -0.8736935954900025\n",
      "init   \t [-2.86513005 -0.31910203]. \t  -76.26436708944966 \t -0.8736935954900025\n",
      "init   \t [-1.56790715 -0.64937523]. \t  -2.1371114994016214 \t -0.8736935954900025\n",
      "1      \t [-0.76667074 -0.12653939]. \t  -1.7272889036171455 \t -0.8736935954900025\n",
      "2      \t [1.45153661 2.        ]. \t  -53.126220337543344 \t -0.8736935954900025\n",
      "3      \t [ 2.84441619 -2.        ]. \t  -113.74682161429033 \t -0.8736935954900025\n",
      "4      \t [-1.64233813  2.        ]. \t  -46.76746445556631 \t -0.8736935954900025\n",
      "5      \t [3.         0.59730211]. \t  -109.7739658735874 \t -0.8736935954900025\n",
      "6      \t [0.68619279 0.15367271]. \t  -1.4658686514072254 \t -0.8736935954900025\n",
      "7      \t [-3. -2.]. \t  -162.89999999999998 \t -0.8736935954900025\n",
      "8      \t [-3.  2.]. \t  -150.89999999999998 \t -0.8736935954900025\n",
      "9      \t [-0.26825681  2.        ]. \t  -47.740582636100854 \t -0.8736935954900025\n",
      "10     \t [-0.05049905 -2.        ]. \t  -48.11118507247364 \t -0.8736935954900025\n",
      "11     \t [-1.37551104  0.68398888]. \t  \u001b[92m-0.37157173341130934\u001b[0m \t -0.37157173341130934\n",
      "12     \t [ 1.39900414 -0.682707  ]. \t  \u001b[92m-0.3330623782629937\u001b[0m \t -0.3330623782629937\n",
      "13     \t [3. 2.]. \t  -162.89999999999998 \t -0.3330623782629937\n",
      "14     \t [ 1.2940139 -2.       ]. \t  -47.78675466552409 \t -0.3330623782629937\n",
      "15     \t [ 0.70561704 -0.60947272]. \t  \u001b[92m-0.14817359113881456\u001b[0m \t -0.14817359113881456\n",
      "16     \t [0.67255106 1.07468483]. \t  -2.849097716784072 \t -0.14817359113881456\n",
      "17     \t [1.4619552  0.45626404]. \t  -2.2183995163420978 \t -0.14817359113881456\n",
      "18     \t [-0.85752577  0.63921389]. \t  -0.42366929679415877 \t -0.14817359113881456\n",
      "19     \t [-0.87123639 -0.85449259]. \t  -1.9284068497537081 \t -0.14817359113881456\n",
      "20     \t [-1.45965002 -0.00992077]. \t  -2.227559679503151 \t -0.14817359113881456\n",
      "21     \t [ 3.         -0.64153977]. \t  -106.00665784564033 \t -0.14817359113881456\n",
      "22     \t [0.0261249  0.65327928]. \t  \u001b[92m0.9587557921398103\u001b[0m \t 0.9587557921398103\n",
      "23     \t [ 1.300708   -0.12713583]. \t  -2.141703905625089 \t 0.9587557921398103\n",
      "24     \t [ 1.05556552 -0.93041958]. \t  -0.8636247563731757 \t 0.9587557921398103\n",
      "25     \t [-0.03454665 -0.6245939 ]. \t  0.9253548548970485 \t 0.9587557921398103\n",
      "26     \t [-1.07237226  1.21971259]. \t  -3.923909273186009 \t 0.9587557921398103\n",
      "27     \t [-3.          0.69043464]. \t  -105.8308676318439 \t 0.9587557921398103\n",
      "28     \t [1.01255748 0.69805852]. \t  -1.9603252385806318 \t 0.9587557921398103\n",
      "29     \t [ 0.09096853 -0.19485188]. \t  0.13087088883547465 \t 0.9587557921398103\n",
      "30     \t [ 1.92337978 -0.14675661]. \t  -2.5674587191199247 \t 0.9587557921398103\n",
      "31     \t [-1.20715281 -0.56960613]. \t  -2.2118860619115854 \t 0.9587557921398103\n",
      "32     \t [-1.83164652 -2.        ]. \t  -54.033545785033404 \t 0.9587557921398103\n",
      "33     \t [1.8409683  1.18438409]. \t  -6.851972773368396 \t 0.9587557921398103\n",
      "34     \t [1.45889578 1.05838416]. \t  -4.2969234229958335 \t 0.9587557921398103\n",
      "35     \t [0.32746272 0.78839377]. \t  0.277527361963697 \t 0.9587557921398103\n",
      "36     \t [-1.99087815  0.27316052]. \t  -2.799316483911238 \t 0.9587557921398103\n",
      "37     \t [-1.90749131  1.16761085]. \t  -2.5631718516992956 \t 0.9587557921398103\n",
      "38     \t [-1.6886979   0.92607155]. \t  -0.00706682082461535 \t 0.9587557921398103\n",
      "39     \t [ 2.03140494 -1.24418125]. \t  -5.035275317682892 \t 0.9587557921398103\n",
      "40     \t [ 1.86670943 -0.80878932]. \t  -0.12839574588893754 \t 0.9587557921398103\n",
      "41     \t [ 0.33439839 -0.92293146]. \t  0.39207052108044693 \t 0.9587557921398103\n",
      "42     \t [-1.05591275 -2.        ]. \t  -52.42309126433312 \t 0.9587557921398103\n",
      "43     \t [ 1.67848418 -1.09971733]. \t  -1.2219411757985874 \t 0.9587557921398103\n",
      "44     \t [1.98861079 0.68033713]. \t  -3.9502998023489626 \t 0.9587557921398103\n",
      "45     \t [-2.21039299 -1.21024463]. \t  -13.688303630541077 \t 0.9587557921398103\n",
      "46     \t [-1.69586594 -1.10447129]. \t  -5.0094061455394785 \t 0.9587557921398103\n",
      "47     \t [0.56103499 2.        ]. \t  -50.18345041890951 \t 0.9587557921398103\n",
      "48     \t [-2.0308219  -0.42643456]. \t  -4.431758766980743 \t 0.9587557921398103\n",
      "49     \t [-1.93565538  0.78467877]. \t  -0.5741013686007587 \t 0.9587557921398103\n",
      "50     \t [ 2.08952385 -2.        ]. \t  -48.99686396547049 \t 0.9587557921398103\n",
      "51     \t [-3.        -1.1297533]. \t  -113.70009078522722 \t 0.9587557921398103\n",
      "52     \t [-0.24741234 -1.26650808]. \t  -4.426050091753001 \t 0.9587557921398103\n",
      "53     \t [-2.27946214  2.        ]. \t  -54.28917810164523 \t 0.9587557921398103\n",
      "54     \t [2.208522 2.      ]. \t  -60.64712307519011 \t 0.9587557921398103\n",
      "55     \t [-0.60131968  0.86773145]. \t  0.07829581741496594 \t 0.9587557921398103\n",
      "56     \t [ 3.         -1.35874425]. \t  -111.07263360789347 \t 0.9587557921398103\n",
      "57     \t [0.07606131 0.40485644]. \t  0.4943056625302104 \t 0.9587557921398103\n",
      "58     \t [2.73393488 1.31115708]. \t  -60.29728978447892 \t 0.9587557921398103\n",
      "59     \t [-0.23957973 -0.70581062]. \t  0.6081504636388984 \t 0.9587557921398103\n",
      "60     \t [ 0.05268559 -0.73497227]. \t  \u001b[92m1.0211764414028348\u001b[0m \t 1.0211764414028348\n",
      "61     \t [-0.06870753  0.76680065]. \t  1.0028846483284366 \t 1.0211764414028348\n",
      "62     \t [ 0.07696477 -0.72943701]. \t  \u001b[92m1.0284041819347676\u001b[0m \t 1.0284041819347676\n",
      "63     \t [-3.          1.40077598]. \t  -112.2494754956662 \t 1.0284041819347676\n",
      "64     \t [-0.04666932  0.73967337]. \t  1.0169379783174368 \t 1.0284041819347676\n",
      "65     \t [ 0.0444578  -0.78391375]. \t  0.9744932767068606 \t 1.0284041819347676\n",
      "66     \t [-0.07503344  0.7359706 ]. \t  1.0258290441189557 \t 1.0284041819347676\n",
      "67     \t [ 0.09322535 -0.69629181]. \t  \u001b[92m1.0293851328595218\u001b[0m \t 1.0293851328595218\n",
      "68     \t [ 0.0773286  -0.69200826]. \t  1.0278832092439727 \t 1.0293851328595218\n",
      "69     \t [-0.08627193  0.75742197]. \t  1.0139693537690022 \t 1.0293851328595218\n",
      "70     \t [-0.09506286  0.76552062]. \t  1.007197029918921 \t 1.0293851328595218\n",
      "71     \t [ 2.42421909 -0.03136828]. \t  -18.555765528491964 \t 1.0293851328595218\n",
      "72     \t [ 0.1308309  -0.77802034]. \t  0.9895702515003255 \t 1.0293851328595218\n",
      "73     \t [ 0.05054086 -0.72498992]. \t  1.0238142307167426 \t 1.0293851328595218\n",
      "74     \t [-0.04585079  0.7163638 ]. \t  1.023751402435263 \t 1.0293851328595218\n",
      "75     \t [ 0.02053472 -0.82304244]. \t  0.8893332051066418 \t 1.0293851328595218\n",
      "76     \t [-0.90370647  2.        ]. \t  -48.240250643458346 \t 1.0293851328595218\n",
      "77     \t [ 0.60654682 -2.        ]. \t  -47.99086650104962 \t 1.0293851328595218\n",
      "78     \t [ 0.00374586 -0.77007873]. \t  0.9682166702974663 \t 1.0293851328595218\n",
      "79     \t [-0.02278315 -0.67180219]. \t  0.9731388309055103 \t 1.0293851328595218\n",
      "80     \t [-0.00804054 -0.66608844]. \t  0.9816951372215906 \t 1.0293851328595218\n",
      "81     \t [ 0.03848734 -0.70340332]. \t  1.0210424752708998 \t 1.0293851328595218\n",
      "82     \t [-0.11220792  0.61880207]. \t  0.9645696117550295 \t 1.0293851328595218\n",
      "83     \t [ 0.073043   -0.73149534]. \t  1.0272252715331738 \t 1.0293851328595218\n",
      "84     \t [ 0.04840215 -0.71725654]. \t  1.0245211947581085 \t 1.0293851328595218\n",
      "85     \t [ 0.10847513 -0.77429305]. \t  0.9975896748209372 \t 1.0293851328595218\n",
      "86     \t [-0.01288422  0.75027127]. \t  0.993173551051188 \t 1.0293851328595218\n",
      "87     \t [-0.02599541 -0.73076262]. \t  0.9736736314463348 \t 1.0293851328595218\n",
      "88     \t [ 0.12418916 -0.75196267]. \t  1.0150584307285981 \t 1.0293851328595218\n",
      "89     \t [-0.05871376  0.66208214]. \t  1.0099075200185168 \t 1.0293851328595218\n",
      "90     \t [-0.05183108  0.73554032]. \t  1.0206627361240346 \t 1.0293851328595218\n",
      "91     \t [-0.03406119  0.74302049]. \t  1.009821249449783 \t 1.0293851328595218\n",
      "92     \t [-0.11063897  0.76371479]. \t  1.0081176520977948 \t 1.0293851328595218\n",
      "93     \t [-0.08329725  0.730201  ]. \t  1.028763761468263 \t 1.0293851328595218\n",
      "94     \t [ 0.04549002 -0.67940956]. \t  1.0167389223825383 \t 1.0293851328595218\n",
      "95     \t [ 0.0490083 -0.6602346]. \t  1.006331581298134 \t 1.0293851328595218\n",
      "96     \t [-0.04850598  0.71760523]. \t  1.024513566167876 \t 1.0293851328595218\n",
      "97     \t [ 0.05126836 -0.69268344]. \t  1.023382978652164 \t 1.0293851328595218\n",
      "98     \t [ 0.01775433 -0.6893312 ]. \t  1.0085133306579361 \t 1.0293851328595218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-1.71592082  0.62291892]. \t  -0.061751538610774426 \t 1.0293851328595218\n",
      "100    \t [ 0.06767501 -0.73411557]. \t  1.0253448360858308 \t 1.0293851328595218\n"
     ]
    }
   ],
   "source": [
    "### 6(a). Bayesian optimization runs (x20): STP DF1 run number = 1\n",
    "\n",
    "np.random.seed(run_num_1)\n",
    "surrogate_stp_df1_1 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_1 = GPGO(surrogate_stp_df1_1, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_1.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.970904200660691, -6.112562859009409)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(a). Training Regret Minimisation: run number = 1\n",
    "\n",
    "gp_output_1 = np.append(np.max(gpgo_gp_1.GP.y[0:n_init]),gpgo_gp_1.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_1 = np.append(np.max(gpgo_stp_df1_1.GP.y[0:n_init]),gpgo_stp_df1_1.GP.y[n_init:(n_init+max_iter)]) \n",
    "\n",
    "regret_gp_1 = np.log(y_global_orig - gp_output_1)\n",
    "regret_stp_df1_1 = np.log(y_global_orig - stp_df1_output_1)\n",
    "\n",
    "train_regret_gp_1 = min_max_array(regret_gp_1)\n",
    "train_regret_stp_df1_1 = min_max_array(regret_stp_df1_1)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 1\n",
    "min_train_regret_gp_1 = min(train_regret_gp_1)\n",
    "min_train_regret_stp_df1_1 = min(train_regret_stp_df1_1)\n",
    "\n",
    "min_train_regret_gp_1, min_train_regret_stp_df1_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.15617056 0.74126874]. \t  0.7781301729194089 \t 0.7781301729194089\n",
      "init   \t [2.01404513 0.61506104]. \t  -4.217845205490776 \t 0.7781301729194089\n",
      "init   \t [-2.77786827 -1.27937735]. \t  -66.70574763186394 \t 0.7781301729194089\n",
      "init   \t [ 1.56341651 -1.10278153]. \t  -1.4256953951254026 \t 0.7781301729194089\n",
      "init   \t [ 1.41081044 -0.85003815]. \t  -0.26940046897857206 \t 0.7781301729194089\n",
      "1      \t [ 0.56383471 -0.39136015]. \t  -0.33063048644256754 \t 0.7781301729194089\n",
      "2      \t [-0.24205132  1.44181377]. \t  -8.848998873131606 \t 0.7781301729194089\n",
      "3      \t [0.61129222 0.40285122]. \t  -0.9213257082859216 \t 0.7781301729194089\n",
      "4      \t [-0.2565      0.27641199]. \t  0.09899018145728539 \t 0.7781301729194089\n",
      "5      \t [0.08211468 0.4901557 ]. \t  0.6630002916895797 \t 0.7781301729194089\n",
      "6      \t [ 0.46359621 -1.21307217]. \t  -2.979209389096109 \t 0.7781301729194089\n",
      "7      \t [0.70581202 1.21135767]. \t  -5.111072403703613 \t 0.7781301729194089\n",
      "8      \t [ 3.        -0.0370283]. \t  -108.78343822652434 \t 0.7781301729194089\n",
      "9      \t [1.94182245 1.33544674]. \t  -11.277240165847203 \t 0.7781301729194089\n",
      "10     \t [1.50356455 0.52667624]. \t  -2.1516102673590067 \t 0.7781301729194089\n",
      "11     \t [ 1.30049365 -1.52942428]. \t  -12.91153215610838 \t 0.7781301729194089\n",
      "12     \t [-0.3918166  -0.98358315]. \t  -0.8251624637803489 \t 0.7781301729194089\n",
      "13     \t [ 0.04706298 -0.75176074]. \t  \u001b[92m1.0095556307393636\u001b[0m \t 1.0095556307393636\n",
      "14     \t [-3.  2.]. \t  -150.89999999999998 \t 1.0095556307393636\n",
      "15     \t [-0.82833519  0.06645535]. \t  -1.7909446739864472 \t 1.0095556307393636\n",
      "16     \t [-0.16568097 -1.1116269 ]. \t  -1.4575032410240014 \t 1.0095556307393636\n",
      "17     \t [-0.410831   -0.37157372]. \t  -0.29354351556392305 \t 1.0095556307393636\n",
      "18     \t [-1.31042014 -1.89815764]. \t  -42.36613039308655 \t 1.0095556307393636\n",
      "19     \t [ 0.5511748 -0.7814205]. \t  0.35104374959697404 \t 1.0095556307393636\n",
      "20     \t [-0.4642924   0.79322523]. \t  0.533488153549316 \t 1.0095556307393636\n",
      "21     \t [-0.01419134 -0.70744655]. \t  0.9891539729138166 \t 1.0095556307393636\n",
      "22     \t [-0.16394992  0.73164271]. \t  1.0089605983052428 \t 1.0095556307393636\n",
      "23     \t [-0.31784894  0.627808  ]. \t  0.7717036325754397 \t 1.0095556307393636\n",
      "24     \t [2.92870584 1.42104975]. \t  -102.55291478197968 \t 1.0095556307393636\n",
      "25     \t [ 0.16769665 -0.60895988]. \t  0.9245479038321162 \t 1.0095556307393636\n",
      "26     \t [1.66264729 0.80935209]. \t  -2.4931874038608326 \t 1.0095556307393636\n",
      "27     \t [ 0.19307961 -0.81083546]. \t  0.9111708923375285 \t 1.0095556307393636\n",
      "28     \t [ 2.33122835 -1.79608663]. \t  -37.75447513258511 \t 1.0095556307393636\n",
      "29     \t [0.67900452 0.57956868]. \t  -0.9317157737674769 \t 1.0095556307393636\n",
      "30     \t [1.5611328  1.96518087]. \t  -49.3789061914903 \t 1.0095556307393636\n",
      "31     \t [-1.95159551 -0.06685501]. \t  -3.3011098916928883 \t 1.0095556307393636\n",
      "32     \t [ 0.0896501  -0.63740862]. \t  0.9900042159999627 \t 1.0095556307393636\n",
      "33     \t [-1.54798483  0.04495786]. \t  -2.035539351991666 \t 1.0095556307393636\n",
      "34     \t [ 1.69981025 -0.61511776]. \t  -0.07990063685245608 \t 1.0095556307393636\n",
      "35     \t [ 0.08077616 -0.63453261]. \t  0.9873228734178396 \t 1.0095556307393636\n",
      "36     \t [-2.7566764  -1.11706374]. \t  -59.72378784659972 \t 1.0095556307393636\n",
      "37     \t [ 1.49701669 -1.03769654]. \t  -0.9465104085391738 \t 1.0095556307393636\n",
      "38     \t [ 1.29957815 -0.01474977]. \t  -2.351352604389876 \t 1.0095556307393636\n",
      "39     \t [ 2.19430042 -1.68588507]. \t  -25.027914324850613 \t 1.0095556307393636\n",
      "40     \t [-1.61509285 -0.27580507]. \t  -2.2256619016840173 \t 1.0095556307393636\n",
      "41     \t [-1.92632927 -1.35378228]. \t  -11.67108878520584 \t 1.0095556307393636\n",
      "42     \t [-2.54791715  1.47025082]. \t  -34.96119596572066 \t 1.0095556307393636\n",
      "43     \t [-2.27725249  0.78320767]. \t  -8.023925961221936 \t 1.0095556307393636\n",
      "44     \t [-1.74305029  1.54481998]. \t  -12.6589818904698 \t 1.0095556307393636\n",
      "45     \t [-2.20217645  0.66640904]. \t  -5.572744454772032 \t 1.0095556307393636\n",
      "46     \t [-1.40054564 -1.08208378]. \t  -4.597851892497702 \t 1.0095556307393636\n",
      "47     \t [-1.87198934  0.93670201]. \t  -0.38968548635673395 \t 1.0095556307393636\n",
      "48     \t [ 1.56350329 -1.87013195]. \t  -34.111885062807815 \t 1.0095556307393636\n",
      "49     \t [ 1.73243745 -0.12743981]. \t  -1.8158473784831632 \t 1.0095556307393636\n",
      "50     \t [ 2.07230635 -0.97543184]. \t  -2.6427275888023205 \t 1.0095556307393636\n",
      "51     \t [-2.92550119 -0.70888169]. \t  -90.45370031998272 \t 1.0095556307393636\n",
      "52     \t [1.72219732 1.23360492]. \t  -7.3880725338748165 \t 1.0095556307393636\n",
      "53     \t [-2.07541311 -0.92203595]. \t  -6.309992623714273 \t 1.0095556307393636\n",
      "54     \t [-2.9383799  -0.97578448]. \t  -95.22098825158577 \t 1.0095556307393636\n",
      "55     \t [-1.95089392  1.04710549]. \t  -1.5616984874097086 \t 1.0095556307393636\n",
      "56     \t [-0.44776395 -1.00250311]. \t  -1.1892775677108178 \t 1.0095556307393636\n",
      "57     \t [ 0.236967   -0.69731283]. \t  0.9464326123301798 \t 1.0095556307393636\n",
      "58     \t [-0.08877841  0.69310645]. \t  \u001b[92m1.0285995727662216\u001b[0m \t 1.0285995727662216\n",
      "59     \t [-0.37331384 -1.05506252]. \t  -1.4152838188919095 \t 1.0285995727662216\n",
      "60     \t [-0.94148847 -0.7546573 ]. \t  -1.8575961736846787 \t 1.0285995727662216\n",
      "61     \t [0.59142988 1.79803946]. \t  -31.0958702273855 \t 1.0285995727662216\n",
      "62     \t [-0.12174498  0.70046153]. \t  1.0261006099093888 \t 1.0285995727662216\n",
      "63     \t [ 2.89013087 -0.53133963]. \t  -78.80806220864298 \t 1.0285995727662216\n",
      "64     \t [1.524553   1.32491691]. \t  -9.46188349119478 \t 1.0285995727662216\n",
      "65     \t [0.10566418 1.67998182]. \t  -20.7949447313331 \t 1.0285995727662216\n",
      "66     \t [-1.04418171  0.56428438]. \t  -0.8395330116647326 \t 1.0285995727662216\n",
      "67     \t [ 1.75026044 -0.18230824]. \t  -1.6814550788327474 \t 1.0285995727662216\n",
      "68     \t [-0.05296498  0.70591274]. \t  1.0261726297219385 \t 1.0285995727662216\n",
      "69     \t [-1.25990162 -1.62938146]. \t  -22.01823593934722 \t 1.0285995727662216\n",
      "70     \t [ 1.69749518 -1.6957663 ]. \t  -20.760471460768066 \t 1.0285995727662216\n",
      "71     \t [ 2.91759117 -0.31480317]. \t  -86.20903748208403 \t 1.0285995727662216\n",
      "72     \t [ 0.07190123 -0.71174982]. \t  \u001b[92m1.0303790239044615\u001b[0m \t 1.0303790239044615\n",
      "73     \t [-0.5817364  -1.86657849]. \t  -36.83171491814548 \t 1.0303790239044615\n",
      "74     \t [2.60971046 1.50385723]. \t  -50.47413797374169 \t 1.0303790239044615\n",
      "75     \t [2.58944374 1.92212658]. \t  -77.69211359087149 \t 1.0303790239044615\n",
      "76     \t [ 1.63204691 -0.83465671]. \t  0.15291013439198853 \t 1.0303790239044615\n",
      "77     \t [-0.17359621  0.71271916]. \t  1.004826783148679 \t 1.0303790239044615\n",
      "78     \t [1.82032211 1.85204921]. \t  -39.037150453700534 \t 1.0303790239044615\n",
      "79     \t [-0.301905   -1.45897657]. \t  -10.397381560403357 \t 1.0303790239044615\n",
      "80     \t [1.11452154 1.93158376]. \t  -45.277933391715315 \t 1.0303790239044615\n",
      "81     \t [2.12732176 1.43833398]. \t  -17.892370637036024 \t 1.0303790239044615\n",
      "82     \t [0.8195282  0.24303845]. \t  -1.8170817439179738 \t 1.0303790239044615\n",
      "83     \t [-0.02965059  0.73211444]. \t  1.0130110521907103 \t 1.0303790239044615\n",
      "84     \t [ 0.18207268 -0.68513762]. \t  0.9906965339657506 \t 1.0303790239044615\n",
      "85     \t [ 2.41727888 -0.4484793 ]. \t  -16.447652115634284 \t 1.0303790239044615\n",
      "86     \t [-0.07156843 -0.93834421]. \t  0.3333209511628788 \t 1.0303790239044615\n",
      "87     \t [-1.38871864 -0.09601683]. \t  -2.3914219909740546 \t 1.0303790239044615\n",
      "88     \t [ 1.51416536 -0.0691353 ]. \t  -2.025669756552551 \t 1.0303790239044615\n",
      "89     \t [-1.86487046 -0.93586692]. \t  -3.843170539101475 \t 1.0303790239044615\n",
      "90     \t [ 0.13504201 -0.7390204 ]. \t  1.019030070572997 \t 1.0303790239044615\n",
      "91     \t [-1.83485986 -1.46265137]. \t  -14.817772481595286 \t 1.0303790239044615\n",
      "92     \t [-1.42822044 -1.58005664]. \t  -19.45258357496585 \t 1.0303790239044615\n",
      "93     \t [2.63742298 0.99266169]. \t  -40.96482359582472 \t 1.0303790239044615\n",
      "94     \t [-0.03610285  0.0613045 ]. \t  0.011979642999683208 \t 1.0303790239044615\n",
      "95     \t [0.03434764 0.82605753]. \t  0.8338739653322376 \t 1.0303790239044615\n",
      "96     \t [ 0.06692497 -0.70716994]. \t  1.0294535871807644 \t 1.0303790239044615\n",
      "97     \t [-1.04640007  0.80841444]. \t  -0.5480291953375088 \t 1.0303790239044615\n",
      "98     \t [-1.70523519  0.16673078]. \t  -1.6780954101792132 \t 1.0303790239044615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-1.67652682 -1.69857111]. \t  -26.65761816792822 \t 1.0303790239044615\n",
      "100    \t [-2.60451112  0.10492464]. \t  -34.232925648259844 \t 1.0303790239044615\n"
     ]
    }
   ],
   "source": [
    "### 6(b). Bayesian optimization runs (x20): GP run number = 2\n",
    "\n",
    "np.random.seed(run_num_2)\n",
    "surrogate_gp_2 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_2 = GPGO(surrogate_gp_2, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_2.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.15617056 0.74126874]. \t  0.7781301729194089 \t 0.7781301729194089\n",
      "init   \t [2.01404513 0.61506104]. \t  -4.217845205490776 \t 0.7781301729194089\n",
      "init   \t [-2.77786827 -1.27937735]. \t  -66.70574763186394 \t 0.7781301729194089\n",
      "init   \t [ 1.56341651 -1.10278153]. \t  -1.4256953951254026 \t 0.7781301729194089\n",
      "init   \t [ 1.41081044 -0.85003815]. \t  -0.26940046897857206 \t 0.7781301729194089\n",
      "1      \t [-1.75707272  2.        ]. \t  -46.627858066407576 \t 0.7781301729194089\n",
      "2      \t [ 0.03279058 -2.        ]. \t  -47.93871729250405 \t 0.7781301729194089\n",
      "3      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.7781301729194089\n",
      "4      \t [3. 2.]. \t  -162.89999999999998 \t 0.7781301729194089\n",
      "5      \t [0.52646518 2.        ]. \t  -50.00736647749386 \t 0.7781301729194089\n",
      "6      \t [-1.06413312  0.07411321]. \t  -2.220016634429899 \t 0.7781301729194089\n",
      "7      \t [-3.          0.80586084]. \t  -105.57171290025683 \t 0.7781301729194089\n",
      "8      \t [ 2.71511689 -0.13294738]. \t  -48.4735159427264 \t 0.7781301729194089\n",
      "9      \t [1.18586881 0.54669983]. \t  -2.2092520463460033 \t 0.7781301729194089\n",
      "10     \t [-0.20901273 -0.24091846]. \t  -0.0024288103999922928 \t 0.7781301729194089\n",
      "11     \t [-1.51586384 -2.        ]. \t  -53.17919329343124 \t 0.7781301729194089\n",
      "12     \t [ 1.20450492 -2.        ]. \t  -47.99195843859425 \t 0.7781301729194089\n",
      "13     \t [-0.59013873  0.62342776]. \t  0.16589350619944576 \t 0.7781301729194089\n",
      "14     \t [-0.91396079 -0.83382218]. \t  -1.9848601081894155 \t 0.7781301729194089\n",
      "15     \t [-3.  2.]. \t  -150.89999999999998 \t 0.7781301729194089\n",
      "16     \t [-0.72555288  2.        ]. \t  -48.121267649781046 \t 0.7781301729194089\n",
      "17     \t [ 1.80501122 -0.17340272]. \t  -1.8392416939910152 \t 0.7781301729194089\n",
      "18     \t [1.4159189  1.28605442]. \t  -8.411955384903319 \t 0.7781301729194089\n",
      "19     \t [-0.47933528  0.12542217]. \t  -0.6901794896559583 \t 0.7781301729194089\n",
      "20     \t [-2.01239958 -0.31878467]. \t  -4.173621005235307 \t 0.7781301729194089\n",
      "21     \t [-1.63388683  0.74264425]. \t  0.1487129034109439 \t 0.7781301729194089\n",
      "22     \t [-1.76129749  0.20892407]. \t  -1.615664194966075 \t 0.7781301729194089\n",
      "23     \t [-1.25008327  0.98276255]. \t  -1.0340137436480368 \t 0.7781301729194089\n",
      "24     \t [-1.56461231 -0.68096923]. \t  -2.168082750045789 \t 0.7781301729194089\n",
      "25     \t [ 0.08475977 -1.0363972 ]. \t  -0.2592350263648063 \t 0.7781301729194089\n",
      "26     \t [1.58110514 0.69969239]. \t  -2.190082395806093 \t 0.7781301729194089\n",
      "27     \t [0.25597403 0.30267642]. \t  0.0022341680624093363 \t 0.7781301729194089\n",
      "28     \t [-0.26732614 -0.83212721]. \t  0.3541746490319325 \t 0.7781301729194089\n",
      "29     \t [1.60215908 2.        ]. \t  -53.27281391474904 \t 0.7781301729194089\n",
      "30     \t [0.84161084 0.95947019]. \t  -2.413176450080603 \t 0.7781301729194089\n",
      "31     \t [-3. -2.]. \t  -162.89999999999998 \t 0.7781301729194089\n",
      "32     \t [-3.         -0.41998128]. \t  -109.57885239020786 \t 0.7781301729194089\n",
      "33     \t [ 0.94716213 -1.19945724]. \t  -3.5275523835814724 \t 0.7781301729194089\n",
      "34     \t [3.         0.74842146]. \t  -110.15972910472401 \t 0.7781301729194089\n",
      "35     \t [ 0.6067307  -0.61511285]. \t  0.10948850195573823 \t 0.7781301729194089\n",
      "36     \t [ 2.07439594 -0.79027141]. \t  -2.309863696658869 \t 0.7781301729194089\n",
      "37     \t [-1.9651235  -1.11095672]. \t  -6.665772196805973 \t 0.7781301729194089\n",
      "38     \t [-0.83493389 -1.53909577]. \t  -16.135782325728652 \t 0.7781301729194089\n",
      "39     \t [-0.33473902  1.15924409]. \t  -1.8825695612699418 \t 0.7781301729194089\n",
      "40     \t [ 3.         -1.01668387]. \t  -105.98906101607912 \t 0.7781301729194089\n",
      "41     \t [ 1.80001899 -0.7430513 ]. \t  0.07412946967621259 \t 0.7781301729194089\n",
      "42     \t [ 2.06273228 -2.        ]. \t  -48.55236951360465 \t 0.7781301729194089\n",
      "43     \t [-2.0010897   1.20263923]. \t  -3.9229784274104817 \t 0.7781301729194089\n",
      "44     \t [-0.34516125  0.83017322]. \t  0.6960733220050789 \t 0.7781301729194089\n",
      "45     \t [-2.03105342  0.72502584]. \t  -1.6943969397957739 \t 0.7781301729194089\n",
      "46     \t [ 0.91082266 -0.1054373 ]. \t  -1.923413378220589 \t 0.7781301729194089\n",
      "47     \t [2.09715407 1.33452543]. \t  -13.691304896325196 \t 0.7781301729194089\n",
      "48     \t [0.53780551 0.59744906]. \t  -0.3924952503193573 \t 0.7781301729194089\n",
      "49     \t [ 0.18044266 -0.76520718]. \t  \u001b[92m0.9807828099219816\u001b[0m \t 0.9807828099219816\n",
      "50     \t [-1.75228778  0.99722734]. \t  -0.3633395061330937 \t 0.9807828099219816\n",
      "51     \t [ 2.13663955 -1.31580764]. \t  -8.46275899180517 \t 0.9807828099219816\n",
      "52     \t [ 0.46460126 -0.89509256]. \t  0.2840735197262673 \t 0.9807828099219816\n",
      "53     \t [-2.27237678 -2.        ]. \t  -63.10016175075059 \t 0.9807828099219816\n",
      "54     \t [2.24544576 2.        ]. \t  -61.99891835309036 \t 0.9807828099219816\n",
      "55     \t [-2.33292232  2.        ]. \t  -56.63782725867692 \t 0.9807828099219816\n",
      "56     \t [-0.67089302 -2.        ]. \t  -50.74713636423541 \t 0.9807828099219816\n",
      "57     \t [-2.12662772 -0.80140186]. \t  -6.757059902827509 \t 0.9807828099219816\n",
      "58     \t [-0.05776389  0.58801998]. \t  0.9254923676541879 \t 0.9807828099219816\n",
      "59     \t [-0.08839711  2.        ]. \t  -47.85433391664648 \t 0.9807828099219816\n",
      "60     \t [ 0.11863496 -0.72965827]. \t  \u001b[92m1.0264816636820115\u001b[0m \t 1.0264816636820115\n",
      "61     \t [0.3547475  1.32231054]. \t  -6.17493646322724 \t 1.0264816636820115\n",
      "62     \t [ 0.13401164 -0.71957475]. \t  1.0240046695454013 \t 1.0264816636820115\n",
      "63     \t [ 0.12642468 -0.70680759]. \t  1.0259595203427017 \t 1.0264816636820115\n",
      "64     \t [-2.46981647  0.20811312]. \t  -21.239488638703218 \t 1.0264816636820115\n",
      "65     \t [1.63644864 0.24377069]. \t  -2.2287361075206586 \t 1.0264816636820115\n",
      "66     \t [-0.04710754  0.72360868]. \t  1.0229916446660954 \t 1.0264816636820115\n",
      "67     \t [-0.04019078  0.81111427]. \t  0.9264059280699563 \t 1.0264816636820115\n",
      "68     \t [ 0.09026519 -0.67303941]. \t  1.0194572916543376 \t 1.0264816636820115\n",
      "69     \t [ 0.16921248 -0.70870591]. \t  1.0070837706095432 \t 1.0264816636820115\n",
      "70     \t [-0.1097607   0.72903057]. \t  \u001b[92m1.0281681059160501\u001b[0m \t 1.0281681059160501\n",
      "71     \t [-0.03138265  0.59445264]. \t  0.9287212495155321 \t 1.0281681059160501\n",
      "72     \t [ 0.03684858 -0.73385042]. \t  1.015673720009039 \t 1.0281681059160501\n",
      "73     \t [-0.11003448  0.73897773]. \t  1.0246934910613614 \t 1.0281681059160501\n",
      "74     \t [-0.03654024  0.60959161]. \t  0.9509933588419779 \t 1.0281681059160501\n",
      "75     \t [ 0.09188242 -0.73946508]. \t  1.025559615920094 \t 1.0281681059160501\n",
      "76     \t [-0.01039728 -0.6849364 ]. \t  0.9886362535477318 \t 1.0281681059160501\n",
      "77     \t [ 0.05574207 -0.76500522]. \t  1.0011758787406755 \t 1.0281681059160501\n",
      "78     \t [-0.00477593  0.73218264]. \t  0.9981952513018716 \t 1.0281681059160501\n",
      "79     \t [ 0.10453945 -0.61324786]. \t  0.9592133091613497 \t 1.0281681059160501\n",
      "80     \t [ 0.08351254 -0.72494575]. \t  \u001b[92m1.0301362548025494\u001b[0m \t 1.0301362548025494\n",
      "81     \t [3.         1.43363721]. \t  -121.87693878241097 \t 1.0301362548025494\n",
      "82     \t [ 0.06651826 -0.73601716]. \t  1.0243382959055358 \t 1.0301362548025494\n",
      "83     \t [ 0.04074839 -0.72890529]. \t  1.0191462879183821 \t 1.0301362548025494\n",
      "84     \t [ 0.18207268 -0.68513762]. \t  0.9906965339657506 \t 1.0301362548025494\n",
      "85     \t [-0.0562505   0.64773539]. \t  0.9979183363107521 \t 1.0301362548025494\n",
      "86     \t [ 0.11883725 -0.70975378]. \t  1.0282176405991796 \t 1.0301362548025494\n",
      "87     \t [0.04829439 0.80856736]. \t  0.8570381613962845 \t 1.0301362548025494\n",
      "88     \t [-0.06364798  0.79763223]. \t  0.9603773804858682 \t 1.0301362548025494\n",
      "89     \t [ 0.13825554 -0.70351782]. \t  1.0214692780428234 \t 1.0301362548025494\n",
      "90     \t [ 0.11638416 -0.72728233]. \t  1.0274975210824098 \t 1.0301362548025494\n",
      "91     \t [ 0.0007921  -0.77838449]. \t  0.9557697077064653 \t 1.0301362548025494\n",
      "92     \t [ 0.04811929 -0.75559476]. \t  1.006987534140376 \t 1.0301362548025494\n",
      "93     \t [ 0.06132053 -0.72393586]. \t  1.0270609868410197 \t 1.0301362548025494\n",
      "94     \t [ 0.05830223 -0.72243774]. \t  1.0266260865149672 \t 1.0301362548025494\n",
      "95     \t [ 0.11708762 -0.72532817]. \t  1.0277577046310182 \t 1.0301362548025494\n",
      "96     \t [ 0.0650113  -0.73287038]. \t  1.025271125782791 \t 1.0301362548025494\n",
      "97     \t [ 0.1868739  -0.68039183]. \t  0.9845110493464603 \t 1.0301362548025494\n",
      "98     \t [-0.10057514  0.7402916 ]. \t  1.024979863436671 \t 1.0301362548025494\n",
      "99     \t [-1.37993129 -1.12781485]. \t  -5.243807054797328 \t 1.0301362548025494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [ 0.12552168 -0.69703519]. \t  1.0241902861661667 \t 1.0301362548025494\n"
     ]
    }
   ],
   "source": [
    "### 6(b). Bayesian optimization runs (x20): STP DF1 run number = 2\n",
    "\n",
    "np.random.seed(run_num_2)\n",
    "surrogate_stp_df1_2 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_2 = GPGO(surrogate_stp_df1_2, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_2.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.708104661818667, -6.526756924047907)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(b). Training Regret Minimisation: run number = 2\n",
    "\n",
    "gp_output_2 = np.append(np.max(gpgo_gp_2.GP.y[0:n_init]),gpgo_gp_2.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_2 = np.append(np.max(gpgo_stp_df1_2.GP.y[0:n_init]),gpgo_stp_df1_2.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_2 = np.log(y_global_orig - gp_output_2)\n",
    "regret_stp_df1_2 = np.log(y_global_orig - stp_df1_output_2)\n",
    "\n",
    "train_regret_gp_2 = min_max_array(regret_gp_2)\n",
    "train_regret_stp_df1_2 = min_max_array(regret_stp_df1_2)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 2\n",
    "min_train_regret_gp_2 = min(train_regret_gp_2)\n",
    "min_train_regret_stp_df1_2 = min(train_regret_stp_df1_2)\n",
    "\n",
    "min_train_regret_gp_2, min_train_regret_stp_df1_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.25974652 0.91580291]. \t  0.042849973588555135 \t 0.042849973588555135\n",
      "init   \t [-2.89871132 -0.67864479]. \t  -84.06473188459181 \t 0.042849973588555135\n",
      "init   \t [-0.78766905 -1.80678534]. \t  -32.74535306061013 \t 0.042849973588555135\n",
      "init   \t [-2.37281887 -1.61024994]. \t  -35.78610684100105 \t 0.042849973588555135\n",
      "init   \t [-1.52758011  1.49395742]. \t  -10.850400550671884 \t 0.042849973588555135\n",
      "1      \t [1.11748476 1.10886849]. \t  -4.737752701566043 \t 0.042849973588555135\n",
      "2      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.042849973588555135\n",
      "3      \t [0.08042381 2.        ]. \t  -48.186631822714794 \t 0.042849973588555135\n",
      "4      \t [0.36826057 0.25461379]. \t  -0.3559345587383371 \t 0.042849973588555135\n",
      "5      \t [0.10161228 0.59409912]. \t  \u001b[92m0.8120651377920329\u001b[0m \t 0.8120651377920329\n",
      "6      \t [0.62041596 0.62355213]. \t  -0.6838450677796934 \t 0.8120651377920329\n",
      "7      \t [3. 2.]. \t  -162.89999999999998 \t 0.8120651377920329\n",
      "8      \t [ 0.28618415 -0.46417935]. \t  0.4952921985967601 \t 0.8120651377920329\n",
      "9      \t [0.34998376 0.74217696]. \t  0.2708569094876849 \t 0.8120651377920329\n",
      "10     \t [ 0.66063991 -0.40995003]. \t  -0.5433851653359106 \t 0.8120651377920329\n",
      "11     \t [-0.41709548  0.31632586]. \t  -0.14193630175640182 \t 0.8120651377920329\n",
      "12     \t [-0.24896223  0.67697029]. \t  \u001b[92m0.9216403529035876\u001b[0m \t 0.9216403529035876\n",
      "13     \t [-0.1196342   0.59471589]. \t  \u001b[92m0.9286981968495891\u001b[0m \t 0.9286981968495891\n",
      "14     \t [ 0.21544595 -0.31406423]. \t  0.24211608085976982 \t 0.9286981968495891\n",
      "15     \t [-2.65466573  1.80819205]. \t  -65.44108306153325 \t 0.9286981968495891\n",
      "16     \t [ 0.63812017 -0.94801757]. \t  -0.3341114576211052 \t 0.9286981968495891\n",
      "17     \t [1.83306435 0.20437376]. \t  -2.5908732941928836 \t 0.9286981968495891\n",
      "18     \t [-1.17745041  0.8180113 ]. \t  -0.5487162899707689 \t 0.9286981968495891\n",
      "19     \t [ 0.48276901 -1.53159259]. \t  -12.710560919810714 \t 0.9286981968495891\n",
      "20     \t [-1.06873641  1.02407737]. \t  -1.435776907115092 \t 0.9286981968495891\n",
      "21     \t [1.5469497  0.59805769]. \t  -2.1204303490380543 \t 0.9286981968495891\n",
      "22     \t [-0.06906955  0.70254559]. \t  \u001b[92m1.0293244897685945\u001b[0m \t 1.0293244897685945\n",
      "23     \t [-1.07815827 -0.01631208]. \t  -2.352204699680916 \t 1.0293244897685945\n",
      "24     \t [-0.90095208  0.57201312]. \t  -0.6455678781763219 \t 1.0293244897685945\n",
      "25     \t [-0.8582692  -0.86404897]. \t  -1.925036640490983 \t 1.0293244897685945\n",
      "26     \t [-0.46496991 -0.34853932]. \t  -0.5051709620598137 \t 1.0293244897685945\n",
      "27     \t [2.7895833  0.20975687]. \t  -61.454119356843776 \t 1.0293244897685945\n",
      "28     \t [ 0.83429953 -1.37228595]. \t  -7.386923401379969 \t 1.0293244897685945\n",
      "29     \t [ 1.73457938 -1.05218488]. \t  -0.7527251681838807 \t 1.0293244897685945\n",
      "30     \t [ 1.62948839 -0.65543838]. \t  -0.007206662105023631 \t 1.0293244897685945\n",
      "31     \t [ 1.28946937 -0.90352644]. \t  -0.6126760063270106 \t 1.0293244897685945\n",
      "32     \t [-0.32296614  0.2558504 ]. \t  -0.0674298547377837 \t 1.0293244897685945\n",
      "33     \t [-1.89296402  0.03106542]. \t  -2.643049439731432 \t 1.0293244897685945\n",
      "34     \t [-1.81408805  0.44711906]. \t  -0.8498313184975825 \t 1.0293244897685945\n",
      "35     \t [-2.26905791 -0.54487007]. \t  -10.822176910628237 \t 1.0293244897685945\n",
      "36     \t [-1.74461607 -0.8870138 ]. \t  -2.995719989493998 \t 1.0293244897685945\n",
      "37     \t [-0.45068343  0.14720182]. \t  -0.5774811430179914 \t 1.0293244897685945\n",
      "38     \t [-0.08345159 -0.93070578]. \t  0.35812760400839705 \t 1.0293244897685945\n",
      "39     \t [0.38345148 1.73663402]. \t  -25.528679573250752 \t 1.0293244897685945\n",
      "40     \t [-0.14365402  0.70748318]. \t  1.0199771445516268 \t 1.0293244897685945\n",
      "41     \t [ 1.80777065 -0.90510638]. \t  -0.04966565639380627 \t 1.0293244897685945\n",
      "42     \t [-2.36661568  1.99752834]. \t  -58.08932144691153 \t 1.0293244897685945\n",
      "43     \t [-2.81680137 -1.708311  ]. \t  -93.23949648703939 \t 1.0293244897685945\n",
      "44     \t [2.05000294 0.69534697]. \t  -4.888612802231361 \t 1.0293244897685945\n",
      "45     \t [-0.63980247  0.98409127]. \t  -0.5564698635011434 \t 1.0293244897685945\n",
      "46     \t [-1.37743418  1.11555856]. \t  -1.9866608336625062 \t 1.0293244897685945\n",
      "47     \t [ 1.78186322 -0.11591214]. \t  -1.9398161838052181 \t 1.0293244897685945\n",
      "48     \t [ 0.43542462 -0.11600601]. \t  -0.5815462461263493 \t 1.0293244897685945\n",
      "49     \t [ 2.46416153 -1.85884667]. \t  -50.842309287576064 \t 1.0293244897685945\n",
      "50     \t [ 2.67279388 -0.70913826]. \t  -40.03466062626089 \t 1.0293244897685945\n",
      "51     \t [-2.15800094 -1.80620183]. \t  -40.17062996573483 \t 1.0293244897685945\n",
      "52     \t [ 0.69115759 -1.9061174 ]. \t  -38.42035509368671 \t 1.0293244897685945\n",
      "53     \t [-0.10812379  0.71996279]. \t  \u001b[92m1.0300222068623754\u001b[0m \t 1.0300222068623754\n",
      "54     \t [ 1.02241558 -1.07731014]. \t  -1.9114662975295453 \t 1.0300222068623754\n",
      "55     \t [-2.38332488 -1.76061378]. \t  -46.28652512200055 \t 1.0300222068623754\n",
      "56     \t [-0.00236914  0.69389437]. \t  1.000250913066333 \t 1.0300222068623754\n",
      "57     \t [-0.5668816  -1.78824151]. \t  -30.206002760348323 \t 1.0300222068623754\n",
      "58     \t [-1.06446494  0.08773771]. \t  -2.1971562760660217 \t 1.0300222068623754\n",
      "59     \t [-2.26556095 -0.95396124]. \t  -12.114491384163998 \t 1.0300222068623754\n",
      "60     \t [-1.47502806 -0.35299855]. \t  -2.279463908584124 \t 1.0300222068623754\n",
      "61     \t [1.25626489 0.18472996]. \t  -2.492807294312283 \t 1.0300222068623754\n",
      "62     \t [ 2.18012376 -0.78471517]. \t  -4.705011434960945 \t 1.0300222068623754\n",
      "63     \t [ 1.82610625 -1.51752518]. \t  -11.577541274068981 \t 1.0300222068623754\n",
      "64     \t [-1.35548859 -1.68935402]. \t  -25.78124845560896 \t 1.0300222068623754\n",
      "65     \t [ 2.50720323 -1.00174394]. \t  -22.4632030266179 \t 1.0300222068623754\n",
      "66     \t [ 0.01528795 -0.57102775]. \t  0.8867922385616059 \t 1.0300222068623754\n",
      "67     \t [ 2.29752098 -1.37076015]. \t  -15.084822956916042 \t 1.0300222068623754\n",
      "68     \t [ 2.34225633 -0.86360055]. \t  -10.998628154312264 \t 1.0300222068623754\n",
      "69     \t [-0.17279228  0.75020184]. \t  0.9962868093337808 \t 1.0300222068623754\n",
      "70     \t [-1.19817013  0.50292723]. \t  -1.042213416163615 \t 1.0300222068623754\n",
      "71     \t [-0.64052834  1.95787855]. \t  -43.49981047759713 \t 1.0300222068623754\n",
      "72     \t [ 0.44314535 -0.57215019]. \t  0.4272709875453162 \t 1.0300222068623754\n",
      "73     \t [ 0.03709622 -1.0023055 ]. \t  0.013130725561925356 \t 1.0300222068623754\n",
      "74     \t [2.48494631 0.29670569]. \t  -23.526706807973945 \t 1.0300222068623754\n",
      "75     \t [-0.8216957  -0.85579181]. \t  -1.7652026097357918 \t 1.0300222068623754\n",
      "76     \t [1.8522685  1.34997391]. \t  -10.961928513625626 \t 1.0300222068623754\n",
      "77     \t [-0.08528453  0.72843732]. \t  1.0293910328417102 \t 1.0300222068623754\n",
      "78     \t [ 0.23200289 -1.46304543]. \t  -9.634824928540265 \t 1.0300222068623754\n",
      "79     \t [2.49076964 1.58327047]. \t  -42.634907357182456 \t 1.0300222068623754\n",
      "80     \t [-2.49406929 -0.31739781]. \t  -24.28387361652167 \t 1.0300222068623754\n",
      "81     \t [-0.06451274 -0.26527993]. \t  0.22795892910852192 \t 1.0300222068623754\n",
      "82     \t [0.69604704 1.75963322]. \t  -28.670985647312914 \t 1.0300222068623754\n",
      "83     \t [1.53530019 1.11049994]. \t  -4.9815767648882705 \t 1.0300222068623754\n",
      "84     \t [ 2.98798386 -1.63085072]. \t  -118.32325625125732 \t 1.0300222068623754\n",
      "85     \t [-0.04598575  0.68520233]. \t  1.0193397196770728 \t 1.0300222068623754\n",
      "86     \t [ 2.97377987 -1.16633219]. \t  -100.16717346308262 \t 1.0300222068623754\n",
      "87     \t [-1.23545255  1.94361728]. \t  -41.968934275806475 \t 1.0300222068623754\n",
      "88     \t [1.560101   1.69105501]. \t  -26.01183619764965 \t 1.0300222068623754\n",
      "89     \t [-2.21357808 -1.68689707]. \t  -33.13664126450066 \t 1.0300222068623754\n",
      "90     \t [ 0.11800979 -0.72324757]. \t  1.0279193826575512 \t 1.0300222068623754\n",
      "91     \t [-1.39475519  0.50918974]. \t  -0.8097772995625216 \t 1.0300222068623754\n",
      "92     \t [-0.11326699  0.64556235]. \t  0.994426448309496 \t 1.0300222068623754\n",
      "93     \t [ 1.99004449 -0.42675056]. \t  -2.164145341935961 \t 1.0300222068623754\n",
      "94     \t [2.61665642 1.36181689]. \t  -45.836206267808166 \t 1.0300222068623754\n",
      "95     \t [ 0.11281143 -0.71930244]. \t  1.0293688107810248 \t 1.0300222068623754\n",
      "96     \t [-2.06797231 -0.02200776]. \t  -4.814054885282196 \t 1.0300222068623754\n",
      "97     \t [1.76369653 1.75046868]. \t  -30.542278878593123 \t 1.0300222068623754\n",
      "98     \t [-0.1327515   0.69787046]. \t  1.0221282865022314 \t 1.0300222068623754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [1.1394925  1.41044161]. \t  -11.862761340100338 \t 1.0300222068623754\n",
      "100    \t [-2.8142179  -1.96423183]. \t  -115.1842979606987 \t 1.0300222068623754\n"
     ]
    }
   ],
   "source": [
    "### 6(c). Bayesian optimization runs (x20): GP run number = 3\n",
    "\n",
    "np.random.seed(run_num_3)\n",
    "surrogate_gp_3 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_3 = GPGO(surrogate_gp_3, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_3.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.25974652 0.91580291]. \t  0.042849973588555135 \t 0.042849973588555135\n",
      "init   \t [-2.89871132 -0.67864479]. \t  -84.06473188459181 \t 0.042849973588555135\n",
      "init   \t [-0.78766905 -1.80678534]. \t  -32.74535306061013 \t 0.042849973588555135\n",
      "init   \t [-2.37281887 -1.61024994]. \t  -35.78610684100105 \t 0.042849973588555135\n",
      "init   \t [-1.52758011  1.49395742]. \t  -10.850400550671884 \t 0.042849973588555135\n",
      "1      \t [2.6356981  1.45408066]. \t  -51.45107200599952 \t 0.042849973588555135\n",
      "2      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.042849973588555135\n",
      "3      \t [-3.  2.]. \t  -150.89999999999998 \t 0.042849973588555135\n",
      "4      \t [-0.39841409  2.        ]. \t  -47.786527669629564 \t 0.042849973588555135\n",
      "5      \t [-0.87638507  0.29763474]. \t  -1.4006356748774984 \t 0.042849973588555135\n",
      "6      \t [ 0.88784638 -0.27970043]. \t  -1.4746952795092014 \t 0.042849973588555135\n",
      "7      \t [ 0.75888595 -2.        ]. \t  -48.15302330342396 \t 0.042849973588555135\n",
      "8      \t [1.31352649 0.63280044]. \t  -2.232928836037554 \t 0.042849973588555135\n",
      "9      \t [3.         0.02383834]. \t  -108.96924323675576 \t 0.042849973588555135\n",
      "10     \t [1.34862351 2.        ]. \t  -53.03113204289326 \t 0.042849973588555135\n",
      "11     \t [0.40306564 0.25145436]. \t  -0.4602770414295746 \t 0.042849973588555135\n",
      "12     \t [-1.0264601   0.94260434]. \t  -0.9093107321280982 \t 0.042849973588555135\n",
      "13     \t [-1.73602396  0.48487245]. \t  -0.5446185359426289 \t 0.042849973588555135\n",
      "14     \t [-3. -2.]. \t  -162.89999999999998 \t 0.042849973588555135\n",
      "15     \t [-1.64389151 -1.03365933]. \t  -4.043657129575801 \t 0.042849973588555135\n",
      "16     \t [-1.64805631 -2.        ]. \t  -53.34746485259552 \t 0.042849973588555135\n",
      "17     \t [-6.76388075e-04 -9.67733439e-01]. \t  \u001b[92m0.2371866408776261\u001b[0m \t 0.2371866408776261\n",
      "18     \t [3. 2.]. \t  -162.89999999999998 \t 0.2371866408776261\n",
      "19     \t [1.99550619 0.95431163]. \t  -5.255555612887737 \t 0.2371866408776261\n",
      "20     \t [ 1.60970454 -1.1089532 ]. \t  -1.4093338777644029 \t 0.2371866408776261\n",
      "21     \t [ 1.002522   -1.03013007]. \t  -1.4642554432263053 \t 0.2371866408776261\n",
      "22     \t [ 1.53583634 -0.56550584]. \t  -0.38704049776563076 \t 0.2371866408776261\n",
      "23     \t [-3.          0.67678131]. \t  -105.87670100756655 \t 0.2371866408776261\n",
      "24     \t [-0.60405003 -0.717674  ]. \t  -0.6305329683540627 \t 0.2371866408776261\n",
      "25     \t [-1.48010015  0.81461917]. \t  -0.09041078099200028 \t 0.2371866408776261\n",
      "26     \t [-1.56825729 -0.18629627]. \t  -2.2522650766233894 \t 0.2371866408776261\n",
      "27     \t [1.29662739 1.16358926]. \t  -5.7988086655033735 \t 0.2371866408776261\n",
      "28     \t [-0.14962746 -0.37433554]. \t  \u001b[92m0.33745044301164073\u001b[0m \t 0.33745044301164073\n",
      "29     \t [ 1.33021443 -0.81613003]. \t  -0.3741670409022192 \t 0.33745044301164073\n",
      "30     \t [ 1.72043585 -2.        ]. \t  -46.644513855656015 \t 0.33745044301164073\n",
      "31     \t [-1.33162364  2.        ]. \t  -47.68510031457693 \t 0.33745044301164073\n",
      "32     \t [-0.27277697  0.78190679]. \t  \u001b[92m0.8775258315914825\u001b[0m \t 0.8775258315914825\n",
      "33     \t [-2.07437501 -0.8472325 ]. \t  -5.834014269639022 \t 0.8775258315914825\n",
      "34     \t [0.54164005 2.        ]. \t  -50.08444922899484 \t 0.8775258315914825\n",
      "35     \t [ 2.31813248 -0.8958763 ]. \t  -9.868539711819741 \t 0.8775258315914825\n",
      "36     \t [ 1.8726468  -0.81998244]. \t  -0.16059081498347427 \t 0.8775258315914825\n",
      "37     \t [1.92513831 1.3622025 ]. \t  -11.921619357210774 \t 0.8775258315914825\n",
      "38     \t [-0.61697482 -0.20559719]. \t  -1.2016411268479847 \t 0.8775258315914825\n",
      "39     \t [-2.12547703  1.12564752]. \t  -4.906314353592505 \t 0.8775258315914825\n",
      "40     \t [-1.8235716   0.93991909]. \t  -0.21107562803019064 \t 0.8775258315914825\n",
      "41     \t [-0.33230177  1.17367838]. \t  -2.1066967660695206 \t 0.8775258315914825\n",
      "42     \t [-2.12805456  2.        ]. \t  -49.74896082303007 \t 0.8775258315914825\n",
      "43     \t [ 0.24082505 -0.72074661]. \t  \u001b[92m0.9470683810596394\u001b[0m \t 0.9470683810596394\n",
      "44     \t [-0.11949394 -2.        ]. \t  -48.29567590689754 \t 0.9470683810596394\n",
      "45     \t [-0.137433   -0.70788056]. \t  0.8279046593288872 \t 0.9470683810596394\n",
      "46     \t [ 3.         -0.97136853]. \t  -105.77286503562583 \t 0.9470683810596394\n",
      "47     \t [ 2.08944536 -1.23039062]. \t  -5.715185208237878 \t 0.9470683810596394\n",
      "48     \t [1.93034383 0.10719124]. \t  -3.154312800029324 \t 0.9470683810596394\n",
      "49     \t [0.02041554 0.52932284]. \t  0.7942481295572794 \t 0.9470683810596394\n",
      "50     \t [3.        0.9741112]. \t  -111.62835193736122 \t 0.9470683810596394\n",
      "51     \t [0.73634504 0.79210888]. \t  -1.2528061662204597 \t 0.9470683810596394\n",
      "52     \t [-2.26891638 -0.10402274]. \t  -10.608309164141476 \t 0.9470683810596394\n",
      "53     \t [2.23713425 2.        ]. \t  -61.67915831686358 \t 0.9470683810596394\n",
      "54     \t [-1.84320947 -1.37237712]. \t  -11.607011570557233 \t 0.9470683810596394\n",
      "55     \t [0.61620122 1.3473632 ]. \t  -7.985521047974267 \t 0.9470683810596394\n",
      "56     \t [-3.         -1.37256103]. \t  -119.6786630589783 \t 0.9470683810596394\n",
      "57     \t [-0.63387581 -1.16976579]. \t  -4.047415317178599 \t 0.9470683810596394\n",
      "58     \t [1.51276901 0.08660932]. \t  -2.2521990792459894 \t 0.9470683810596394\n",
      "59     \t [ 2.34810488 -2.        ]. \t  -57.3893543437847 \t 0.9470683810596394\n",
      "60     \t [ 0.10504965 -0.73592536]. \t  \u001b[92m1.0265046494347259\u001b[0m \t 1.0265046494347259\n",
      "61     \t [ 2.00558295 -0.40509918]. \t  -2.4446895521481764 \t 1.0265046494347259\n",
      "62     \t [-0.16500486  0.22855025]. \t  0.12838225941640674 \t 1.0265046494347259\n",
      "63     \t [ 0.09948177 -0.66089783]. \t  1.0103820832956278 \t 1.0265046494347259\n",
      "64     \t [-3.         1.3675139]. \t  -111.30609138335778 \t 1.0265046494347259\n",
      "65     \t [-0.07793403  0.74313415]. \t  1.0227784143304475 \t 1.0265046494347259\n",
      "66     \t [ 0.10695336 -0.73125108]. \t  \u001b[92m1.0279037880688777\u001b[0m \t 1.0279037880688777\n",
      "67     \t [ 0.08080613 -0.67117154]. \t  1.0183933006966475 \t 1.0279037880688777\n",
      "68     \t [-2.2299335   0.63428058]. \t  -6.573432013214362 \t 1.0279037880688777\n",
      "69     \t [ 0.0432777  -0.71547348]. \t  1.022912913806211 \t 1.0279037880688777\n",
      "70     \t [-0.07121388  0.71158501]. \t  \u001b[92m1.030281575278263\u001b[0m \t 1.030281575278263\n",
      "71     \t [-0.07667021  0.74921426]. \t  1.0189600710030144 \t 1.030281575278263\n",
      "72     \t [ 0.09768513 -0.66936931]. \t  1.0166158033903483 \t 1.030281575278263\n",
      "73     \t [-0.06448275  0.76606593]. \t  1.002625659258225 \t 1.030281575278263\n",
      "74     \t [-0.13039525  0.77151283]. \t  0.9969188266612697 \t 1.030281575278263\n",
      "75     \t [ 0.20406719 -0.3960939 ]. \t  0.4469769460141152 \t 1.030281575278263\n",
      "76     \t [2.42674774 0.54046423]. \t  -19.290712005151807 \t 1.030281575278263\n",
      "77     \t [-0.08618106  0.76630933]. \t  1.0060120723023318 \t 1.030281575278263\n",
      "78     \t [ 0.12597064 -0.63822033]. \t  0.9830956035874299 \t 1.030281575278263\n",
      "79     \t [ 0.10969161 -0.75919139]. \t  1.0121209087537124 \t 1.030281575278263\n",
      "80     \t [ 0.00925406 -0.67066591]. \t  0.9957807820608136 \t 1.030281575278263\n",
      "81     \t [ 0.130841  -0.7576359]. \t  1.0093549529535142 \t 1.030281575278263\n",
      "82     \t [ 0.10613698 -0.61077882]. \t  0.9555675700781453 \t 1.030281575278263\n",
      "83     \t [ 0.12107689 -0.66977523]. \t  1.0123377897699921 \t 1.030281575278263\n",
      "84     \t [-0.13410777  0.65161398]. \t  0.9933840720688998 \t 1.030281575278263\n",
      "85     \t [-0.04598169  0.68520392]. \t  1.0193390330202738 \t 1.030281575278263\n",
      "86     \t [ 0.05228721 -0.71810174]. \t  1.0256452075677072 \t 1.030281575278263\n",
      "87     \t [-0.0632351   0.68184038]. \t  1.0222288184509538 \t 1.030281575278263\n",
      "88     \t [-0.1036481   0.77978216]. \t  0.9913851350758438 \t 1.030281575278263\n",
      "89     \t [-0.13387986  0.77928448]. \t  0.987268272938262 \t 1.030281575278263\n",
      "90     \t [ 0.03755005 -0.68613141]. \t  1.0167123208440974 \t 1.030281575278263\n",
      "91     \t [-0.01076908 -0.70126091]. \t  0.9917130606692772 \t 1.030281575278263\n",
      "92     \t [-0.11326694  0.6455623 ]. \t  0.9944264181247446 \t 1.030281575278263\n",
      "93     \t [-0.05615223  0.735416  ]. \t  1.0220332817110687 \t 1.030281575278263\n",
      "94     \t [-1.8501569  -0.47287712]. \t  -2.6360295197813635 \t 1.030281575278263\n",
      "95     \t [ 0.12337615 -0.6765213 ]. \t  1.0159017219058433 \t 1.030281575278263\n",
      "96     \t [-1.30920215 -1.42785463]. \t  -12.705674905222535 \t 1.030281575278263\n",
      "97     \t [ 0.20787102 -0.82361639]. \t  0.8750323662014162 \t 1.030281575278263\n",
      "98     \t [-0.13275204  0.69786995]. \t  1.0221279579718592 \t 1.030281575278263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-0.19698371  0.79106653]. \t  0.9404705401316356 \t 1.030281575278263\n",
      "100    \t [-0.08481882  0.77024177]. \t  1.0018636818716766 \t 1.030281575278263\n"
     ]
    }
   ],
   "source": [
    "### 6(c). Bayesian optimization runs (x20): STP DF1 run number = 3\n",
    "\n",
    "np.random.seed(run_num_3)\n",
    "surrogate_stp_df1_3 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_3 = GPGO(surrogate_stp_df1_3, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_3.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.451728156644326, -6.6313176476673314)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(c). Training Regret Minimisation: run number = 3\n",
    "\n",
    "gp_output_3 = np.append(np.max(gpgo_gp_3.GP.y[0:n_init]),gpgo_gp_3.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_3 = np.append(np.max(gpgo_stp_df1_3.GP.y[0:n_init]),gpgo_stp_df1_3.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_3 = np.log(y_global_orig - gp_output_3)\n",
    "regret_stp_df1_3 = np.log(y_global_orig - stp_df1_output_3)\n",
    "\n",
    "train_regret_gp_3 = min_max_array(regret_gp_3)\n",
    "train_regret_stp_df1_3 = min_max_array(regret_stp_df1_3)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 3\n",
    "min_train_regret_gp_3 = min(train_regret_gp_3)\n",
    "min_train_regret_stp_df1_3 = min(train_regret_stp_df1_3)\n",
    "\n",
    "min_train_regret_gp_3, min_train_regret_stp_df1_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [2.03616628 1.28517986]. \t  -11.164343885550666 \t -1.5094648555070385\n",
      "init   \t [0.85324299 0.66889047]. \t  -1.5094648555070385 \t -1.5094648555070385\n",
      "init   \t [-2.76516057 -1.73731045]. \t  -85.9872978949554 \t -1.5094648555070385\n",
      "init   \t [-1.34099616 -0.73455799]. \t  -2.3318567753236477 \t -1.5094648555070385\n",
      "init   \t [-1.83844553 -1.21162847]. \t  -7.376051913381579 \t -1.5094648555070385\n",
      "1      \t [-1.01437892 -1.75256639]. \t  -29.483578197738566 \t -1.5094648555070385\n",
      "2      \t [-1.91438987 -0.42850762]. \t  -3.082520813936117 \t -1.5094648555070385\n",
      "3      \t [ 3. -2.]. \t  -150.90000000000003 \t -1.5094648555070385\n",
      "4      \t [-0.05640395  2.        ]. \t  -47.8998964816582 \t -1.5094648555070385\n",
      "5      \t [1.00244668 0.20551427]. \t  -2.281434645361688 \t -1.5094648555070385\n",
      "6      \t [-2.96701333  1.47701968]. \t  -105.80292056646262 \t -1.5094648555070385\n",
      "7      \t [-1.69152228 -0.76906945]. \t  -2.3952991781490383 \t -1.5094648555070385\n",
      "8      \t [-0.37581569  0.09326533]. \t  \u001b[92m-0.45445642606740266\u001b[0m \t -0.45445642606740266\n",
      "9      \t [-1.12120765 -0.00457079]. \t  -2.3770109070262926 \t -0.45445642606740266\n",
      "10     \t [-0.05116604 -0.07685488]. \t  \u001b[92m0.00909730817858418\u001b[0m \t 0.00909730817858418\n",
      "11     \t [0.13620185 0.23751596]. \t  \u001b[92m0.10709191246407179\u001b[0m \t 0.10709191246407179\n",
      "12     \t [2.90089528 1.58797867]. \t  -103.54551315512943 \t 0.10709191246407179\n",
      "13     \t [1.5238049  1.05219356]. \t  -4.2163079149571185 \t 0.10709191246407179\n",
      "14     \t [-0.64070024 -0.29532758]. \t  -1.1819495636764243 \t 0.10709191246407179\n",
      "15     \t [ 0.35644758 -0.03360426]. \t  -0.45851296913255374 \t 0.10709191246407179\n",
      "16     \t [1.56922006 1.92106752]. \t  -44.825015921670634 \t 0.10709191246407179\n",
      "17     \t [2.2289841  0.59820475]. \t  -9.330734784046534 \t 0.10709191246407179\n",
      "18     \t [-1.06612122  0.70212874]. \t  -0.5745874498456677 \t 0.10709191246407179\n",
      "19     \t [0.59968305 0.33681097]. \t  -0.9820857720893055 \t 0.10709191246407179\n",
      "20     \t [ 0.61162347 -0.85555771]. \t  0.08810996954121186 \t 0.10709191246407179\n",
      "21     \t [-0.06688063  0.79188944]. \t  \u001b[92m0.9705056459578632\u001b[0m \t 0.9705056459578632\n",
      "22     \t [ 1.23470571 -0.85777865]. \t  -0.5616924861630658 \t 0.9705056459578632\n",
      "23     \t [ 0.96275538 -0.60166994]. \t  -0.6657507490357036 \t 0.9705056459578632\n",
      "24     \t [ 1.03773944 -1.41537765]. \t  -8.859278906746724 \t 0.9705056459578632\n",
      "25     \t [1.71515633 0.59658587]. \t  -2.18597156118879 \t 0.9705056459578632\n",
      "26     \t [-0.29716498  0.61722234]. \t  0.7896564533571521 \t 0.9705056459578632\n",
      "27     \t [ 1.76825846 -0.48851696]. \t  -0.5752235587867599 \t 0.9705056459578632\n",
      "28     \t [ 0.12112497 -0.68158134]. \t  \u001b[92m1.0192965228924795\u001b[0m \t 1.0192965228924795\n",
      "29     \t [ 0.20460349 -0.61970452]. \t  0.9092063684468745 \t 1.0192965228924795\n",
      "30     \t [-2.79086856 -0.21948544]. \t  -61.69526754144576 \t 1.0192965228924795\n",
      "31     \t [-1.68171016  0.10517426]. \t  -1.8355176611791315 \t 1.0192965228924795\n",
      "32     \t [-1.30307549  1.18672325]. \t  -3.12289688899998 \t 1.0192965228924795\n",
      "33     \t [ 0.23317622 -0.84945214]. \t  0.7903707510127012 \t 1.0192965228924795\n",
      "34     \t [-0.02325013 -0.56856418]. \t  0.8596784265581336 \t 1.0192965228924795\n",
      "35     \t [0.02151287 0.69157959]. \t  0.9813847466228548 \t 1.0192965228924795\n",
      "36     \t [-0.50383496  0.98811789]. \t  -0.2954197517958001 \t 1.0192965228924795\n",
      "37     \t [-2.33313211  0.64413321]. \t  -10.840325346586532 \t 1.0192965228924795\n",
      "38     \t [ 0.08925651 -0.67917935]. \t  \u001b[92m1.0228918623095424\u001b[0m \t 1.0228918623095424\n",
      "39     \t [ 0.17652761 -0.72445466]. \t  1.002800402176357 \t 1.0228918623095424\n",
      "40     \t [0.18489196 0.77016641]. \t  0.6885906675508231 \t 1.0228918623095424\n",
      "41     \t [-0.37402625 -0.93030868]. \t  -0.401642068037274 \t 1.0228918623095424\n",
      "42     \t [1.74432768 0.36192449]. \t  -2.2947272832239722 \t 1.0228918623095424\n",
      "43     \t [-0.00170113 -0.65256742]. \t  0.9768820080365259 \t 1.0228918623095424\n",
      "44     \t [-0.00075889 -0.4882414 ]. \t  0.7258463677604814 \t 1.0228918623095424\n",
      "45     \t [-2.01313241  1.69248607]. \t  -21.863720800237815 \t 1.0228918623095424\n",
      "46     \t [-0.34952555 -1.65696159]. \t  -20.20655931026264 \t 1.0228918623095424\n",
      "47     \t [0.19945342 0.8981783 ]. \t  0.288711967883419 \t 1.0228918623095424\n",
      "48     \t [-0.12224617  0.73296553]. \t  \u001b[92m1.0247467842373679\u001b[0m \t 1.0247467842373679\n",
      "49     \t [-1.72158534  0.80701522]. \t  0.2111083670045243 \t 1.0247467842373679\n",
      "50     \t [-2.80745569 -0.78639926]. \t  -65.54659070114327 \t 1.0247467842373679\n",
      "51     \t [2.64482093 0.05739439]. \t  -39.45595239398992 \t 1.0247467842373679\n",
      "52     \t [2.88321692 0.50180912]. \t  -80.31301853059882 \t 1.0247467842373679\n",
      "53     \t [2.75631719 0.8736854 ]. \t  -57.033858950697564 \t 1.0247467842373679\n",
      "54     \t [ 1.94759015 -1.44321963]. \t  -9.360926545341943 \t 1.0247467842373679\n",
      "55     \t [ 1.15616927 -1.00246659]. \t  -1.2515516194025211 \t 1.0247467842373679\n",
      "56     \t [-1.6016663  -0.88536188]. \t  -2.809173142980251 \t 1.0247467842373679\n",
      "57     \t [0.00372818 1.07337042]. \t  -0.7051205099094748 \t 1.0247467842373679\n",
      "58     \t [-1.66448557 -0.56728501]. \t  -2.1228155949450414 \t 1.0247467842373679\n",
      "59     \t [-2.79303402  0.44502954]. \t  -59.775048507785044 \t 1.0247467842373679\n",
      "60     \t [ 2.48071995 -0.68503503]. \t  -20.07684884118497 \t 1.0247467842373679\n",
      "61     \t [ 0.15628587 -0.67105499]. \t  0.998548834118897 \t 1.0247467842373679\n",
      "62     \t [ 1.53081709 -1.67480463]. \t  -19.81874943512973 \t 1.0247467842373679\n",
      "63     \t [-1.00928588 -0.90835668]. \t  -2.587461425158197 \t 1.0247467842373679\n",
      "64     \t [ 1.73293054 -0.90303612]. \t  0.06557521846813807 \t 1.0247467842373679\n",
      "65     \t [0.21002109 0.56319727]. \t  0.5756621194672236 \t 1.0247467842373679\n",
      "66     \t [-1.10009728 -0.35363513]. \t  -2.3073517237133614 \t 1.0247467842373679\n",
      "67     \t [ 1.12482493 -1.58099808]. \t  -15.588889124059172 \t 1.0247467842373679\n",
      "68     \t [0.16930928 0.90281358]. \t  0.3371181676665549 \t 1.0247467842373679\n",
      "69     \t [-2.91393861 -0.96208655]. \t  -89.14848637067882 \t 1.0247467842373679\n",
      "70     \t [-0.03498823  0.69033745]. \t  1.0170634816410133 \t 1.0247467842373679\n",
      "71     \t [-0.88618045  0.86335414]. \t  -0.4833480521606608 \t 1.0247467842373679\n",
      "72     \t [0.19842418 0.9788918 ]. \t  -0.1883852766947534 \t 1.0247467842373679\n",
      "73     \t [-0.42996539 -0.08880044]. \t  -0.6767031144041831 \t 1.0247467842373679\n",
      "74     \t [-1.23406737 -1.61124739]. \t  -20.961775855228854 \t 1.0247467842373679\n",
      "75     \t [ 2.35794808 -0.98124886]. \t  -12.156894774937614 \t 1.0247467842373679\n",
      "76     \t [0.4971928 0.406593 ]. \t  -0.5157145329080287 \t 1.0247467842373679\n",
      "77     \t [2.10915116 1.65383641]. \t  -28.053107444365978 \t 1.0247467842373679\n",
      "78     \t [-0.11734432  0.72929147]. \t  \u001b[92m1.0268349729106456\u001b[0m \t 1.0268349729106456\n",
      "79     \t [ 0.6369389  -1.68238681]. \t  -20.95134466822598 \t 1.0268349729106456\n",
      "80     \t [-2.40525527 -1.66380939]. \t  -40.98022631262636 \t 1.0268349729106456\n",
      "81     \t [1.12943309 0.75342911]. \t  -2.246502150436677 \t 1.0268349729106456\n",
      "82     \t [-2.75694262  1.45525316]. \t  -60.907760328896764 \t 1.0268349729106456\n",
      "83     \t [-1.95619532  0.94174824]. \t  -0.9905924109691995 \t 1.0268349729106456\n",
      "84     \t [2.16973958 1.86296958]. \t  -45.40950165469089 \t 1.0268349729106456\n",
      "85     \t [2.62045572 0.94140433]. \t  -38.43933928147885 \t 1.0268349729106456\n",
      "86     \t [-0.06376867  0.71042198]. \t  \u001b[92m1.0289832579552192\u001b[0m \t 1.0289832579552192\n",
      "87     \t [-2.92248883  1.13975918]. \t  -86.87723689891227 \t 1.0289832579552192\n",
      "88     \t [ 2.93258401 -0.95958499]. \t  -87.99895438247323 \t 1.0289832579552192\n",
      "89     \t [ 0.06064473 -0.72268054]. \t  1.0271607152919477 \t 1.0289832579552192\n",
      "90     \t [ 1.84648262 -0.49219817]. \t  -0.7944946539199708 \t 1.0289832579552192\n",
      "91     \t [2.99130591 1.36234056]. \t  -116.88989274527349 \t 1.0289832579552192\n",
      "92     \t [ 1.61357124 -0.5160565 ]. \t  -0.44783734847806367 \t 1.0289832579552192\n",
      "93     \t [1.63628062 1.15385615]. \t  -5.706261461664688 \t 1.0289832579552192\n",
      "94     \t [0.02448335 0.35365705]. \t  0.42666421846708025 \t 1.0289832579552192\n",
      "95     \t [-0.38776684 -0.49921305]. \t  -0.00026002408885739126 \t 1.0289832579552192\n",
      "96     \t [ 1.98787556 -0.08699199]. \t  -3.380044472638614 \t 1.0289832579552192\n",
      "97     \t [1.16087083 0.00538577]. \t  -2.3986441238140785 \t 1.0289832579552192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98     \t [-1.79473501  1.46034985]. \t  -9.276890587165429 \t 1.0289832579552192\n",
      "99     \t [-0.38490882  1.11186483]. \t  -1.287859305303532 \t 1.0289832579552192\n",
      "100    \t [ 1.88937607 -0.95511048]. \t  -0.5568805346409538 \t 1.0289832579552192\n"
     ]
    }
   ],
   "source": [
    "### 6(d). Bayesian optimization runs (x20): GP run number = 4\n",
    "\n",
    "np.random.seed(run_num_4)\n",
    "surrogate_gp_4 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_4 = GPGO(surrogate_gp_4, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_4.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [2.03616628 1.28517986]. \t  -11.164343885550666 \t -1.5094648555070385\n",
      "init   \t [0.85324299 0.66889047]. \t  -1.5094648555070385 \t -1.5094648555070385\n",
      "init   \t [-2.76516057 -1.73731045]. \t  -85.9872978949554 \t -1.5094648555070385\n",
      "init   \t [-1.34099616 -0.73455799]. \t  -2.3318567753236477 \t -1.5094648555070385\n",
      "init   \t [-1.83844553 -1.21162847]. \t  -7.376051913381579 \t -1.5094648555070385\n",
      "1      \t [-0.71911805 -2.        ]. \t  -50.991266037415386 \t -1.5094648555070385\n",
      "2      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.5094648555070385\n",
      "3      \t [-3.  2.]. \t  -150.89999999999998 \t -1.5094648555070385\n",
      "4      \t [-0.05694129  2.        ]. \t  -47.899064599684586 \t -1.5094648555070385\n",
      "5      \t [3. 2.]. \t  -162.89999999999998 \t -1.5094648555070385\n",
      "6      \t [1.98719811 0.14525788]. \t  -3.7809371957384714 \t -1.5094648555070385\n",
      "7      \t [-2.41621682 -0.09401108]. \t  -18.29685250931465 \t -1.5094648555070385\n",
      "8      \t [ 0.83763525 -1.06233497]. \t  -1.5783397402037211 \t -1.5094648555070385\n",
      "9      \t [1.22698584 2.        ]. \t  -52.85367890723118 \t -1.5094648555070385\n",
      "10     \t [-0.95225897  0.76559959]. \t  \u001b[92m-0.4495789282443202\u001b[0m \t -0.4495789282443202\n",
      "11     \t [ 0.05440255 -0.15579213]. \t  \u001b[92m0.09138371073840501\u001b[0m \t 0.09138371073840501\n",
      "12     \t [ 0.94574827 -2.        ]. \t  -48.244739287363146 \t 0.09138371073840501\n",
      "13     \t [1.64975543 0.74507509]. \t  -2.292553080085205 \t 0.09138371073840501\n",
      "14     \t [3.         0.22167321]. \t  -109.37812215062067 \t 0.09138371073840501\n",
      "15     \t [ 1.28420983 -0.41131511]. \t  -1.289844050971283 \t 0.09138371073840501\n",
      "16     \t [-0.09318801  0.76085836]. \t  \u001b[92m1.0114207290430075\u001b[0m \t 1.0114207290430075\n",
      "17     \t [-1.28474413  2.        ]. \t  -47.81051884137104 \t 1.0114207290430075\n",
      "18     \t [-1.60673571  0.13445397]. \t  -1.7787417005041175 \t 1.0114207290430075\n",
      "19     \t [ 1.92805476 -0.8413274 ]. \t  -0.5238697097704474 \t 1.0114207290430075\n",
      "20     \t [-1.86257945  0.87740339]. \t  -0.1772621487138084 \t 1.0114207290430075\n",
      "21     \t [-0.04547077 -1.01231891]. \t  -0.15590866178327922 \t 1.0114207290430075\n",
      "22     \t [-3.          0.53445086]. \t  -106.48045214550396 \t 1.0114207290430075\n",
      "23     \t [-1.46540404  0.90582201]. \t  -0.2901182372003236 \t 1.0114207290430075\n",
      "24     \t [ 1.85535129 -0.46316772]. \t  -0.9485147772936985 \t 1.0114207290430075\n",
      "25     \t [ 1.51870859 -1.13463111]. \t  -1.9010230084527064 \t 1.0114207290430075\n",
      "26     \t [0.51935137 0.22875321]. \t  -0.8531092020296545 \t 1.0114207290430075\n",
      "27     \t [ 0.36213158 -0.6575789 ]. \t  0.7306623549357396 \t 1.0114207290430075\n",
      "28     \t [-2.03557914 -0.70309059]. \t  -4.6642789646890455 \t 1.0114207290430075\n",
      "29     \t [-0.63961017  0.22692843]. \t  -0.9672394544828801 \t 1.0114207290430075\n",
      "30     \t [-1.79870973  0.55801621]. \t  -0.38693952050154257 \t 1.0114207290430075\n",
      "31     \t [-1.77649715 -2.        ]. \t  -53.738521382122826 \t 1.0114207290430075\n",
      "32     \t [-3.        -0.7830904]. \t  -110.30055583149966 \t 1.0114207290430075\n",
      "33     \t [2.15120104 0.78947983]. \t  -7.33194294211087 \t 1.0114207290430075\n",
      "34     \t [-0.64856279  1.24619131]. \t  -3.9627259140274402 \t 1.0114207290430075\n",
      "35     \t [-0.37366975 -0.58273534]. \t  0.16083019695345624 \t 1.0114207290430075\n",
      "36     \t [-1.89764566 -0.17764405]. \t  -2.952809627916171 \t 1.0114207290430075\n",
      "37     \t [0.28291261 1.14013967]. \t  -2.1889138600197136 \t 1.0114207290430075\n",
      "38     \t [ 0.13077661 -2.        ]. \t  -47.80624429691443 \t 1.0114207290430075\n",
      "39     \t [ 3.         -0.94397124]. \t  -105.6798658662706 \t 1.0114207290430075\n",
      "40     \t [-2.08157727  2.        ]. \t  -48.85861142945549 \t 1.0114207290430075\n",
      "41     \t [ 1.61685185 -0.79908853]. \t  0.15473669694237135 \t 1.0114207290430075\n",
      "42     \t [1.50807113 0.15364572]. \t  -2.2958200631396437 \t 1.0114207290430075\n",
      "43     \t [ 2.00983366 -2.        ]. \t  -47.84282094617079 \t 1.0114207290430075\n",
      "44     \t [-0.81596213 -1.16151633]. \t  -4.662436633038235 \t 1.0114207290430075\n",
      "45     \t [2.01693387 2.        ]. \t  -55.99376850232518 \t 1.0114207290430075\n",
      "46     \t [-0.24456538  0.96888164]. \t  0.23520567501890435 \t 1.0114207290430075\n",
      "47     \t [0.29527588 0.77517997]. \t  0.3973729059946196 \t 1.0114207290430075\n",
      "48     \t [1.21624791 1.22948552]. \t  -6.989753687253592 \t 1.0114207290430075\n",
      "49     \t [-1.73749741  1.33674963]. \t  -5.409725544998772 \t 1.0114207290430075\n",
      "50     \t [3.         1.16922714]. \t  -114.41507636239994 \t 1.0114207290430075\n",
      "51     \t [-0.03863366 -0.74020463]. \t  0.9562588750790463 \t 1.0114207290430075\n",
      "52     \t [-3. -2.]. \t  -162.89999999999998 \t 1.0114207290430075\n",
      "53     \t [ 2.11804264 -1.39542328]. \t  -10.198178682875383 \t 1.0114207290430075\n",
      "54     \t [-0.28327697  0.65184314]. \t  0.8544589216164407 \t 1.0114207290430075\n",
      "55     \t [-2.33774525 -2.        ]. \t  -66.2233014902437 \t 1.0114207290430075\n",
      "56     \t [ 0.27013738 -0.85495425]. \t  0.7367660949970594 \t 1.0114207290430075\n",
      "57     \t [-0.52131726 -0.84285609]. \t  -0.5551508846168072 \t 1.0114207290430075\n",
      "58     \t [-2.61456128  1.37383896]. \t  -38.79962763667182 \t 1.0114207290430075\n",
      "59     \t [-2.23965449  0.63626875]. \t  -6.907034390764325 \t 1.0114207290430075\n",
      "60     \t [-0.06737749  0.69742342]. \t  \u001b[92m1.0281350801871596\u001b[0m \t 1.0281350801871596\n",
      "61     \t [ 0.09998354 -0.71435529]. \t  \u001b[92m1.0312218198590875\u001b[0m \t 1.0312218198590875\n",
      "62     \t [ 0.55863483 -1.48414533]. \t  -10.821386062563276 \t 1.0312218198590875\n",
      "63     \t [ 0.12806623 -0.71952773]. \t  1.0258507641404906 \t 1.0312218198590875\n",
      "64     \t [-0.99612107 -0.34052582]. \t  -2.156231464594371 \t 1.0312218198590875\n",
      "65     \t [ 0.07611201 -0.70173158]. \t  1.0300790690067103 \t 1.0312218198590875\n",
      "66     \t [-0.09042858  0.72264749]. \t  1.0308041094249607 \t 1.0312218198590875\n",
      "67     \t [ 0.0939704  -0.73846177]. \t  1.0260176165439168 \t 1.0312218198590875\n",
      "68     \t [ 0.13203355 -0.75219549]. \t  1.0129025068201316 \t 1.0312218198590875\n",
      "69     \t [0.63062941 2.        ]. \t  -50.54086289102082 \t 1.0312218198590875\n",
      "70     \t [-0.03498866  0.69033706]. \t  1.017063541664455 \t 1.0312218198590875\n",
      "71     \t [-0.12493325  0.72413323]. \t  1.0261700041899358 \t 1.0312218198590875\n",
      "72     \t [-0.0137868  -0.66163864]. \t  0.9746254569839595 \t 1.0312218198590875\n",
      "73     \t [-0.13913401  0.70665743]. \t  1.0216699163395822 \t 1.0312218198590875\n",
      "74     \t [-0.053354   0.7483607]. \t  1.0141374436123518 \t 1.0312218198590875\n",
      "75     \t [ 0.10972693 -0.73021065]. \t  1.0278566366708224 \t 1.0312218198590875\n",
      "76     \t [-0.09105106  0.73477445]. \t  1.0275189898758779 \t 1.0312218198590875\n",
      "77     \t [ 0.10677458 -0.66219296]. \t  1.010245354007995 \t 1.0312218198590875\n",
      "78     \t [-0.11734252  0.7292899 ]. \t  1.026835723138695 \t 1.0312218198590875\n",
      "79     \t [ 0.11485333 -0.69267118]. \t  1.0255218647888862 \t 1.0312218198590875\n",
      "80     \t [-0.03385816  0.63695486]. \t  0.9814220893347341 \t 1.0312218198590875\n",
      "81     \t [ 0.05127156 -0.74758601]. \t  1.0139596178004124 \t 1.0312218198590875\n",
      "82     \t [-0.00378444  0.63785021]. \t  0.9676510834681233 \t 1.0312218198590875\n",
      "83     \t [ 0.0313303  -0.64430031]. \t  0.9874453000009638 \t 1.0312218198590875\n",
      "84     \t [-0.10129909  0.73669358]. \t  1.0265020191908845 \t 1.0312218198590875\n",
      "85     \t [ 0.10676053 -0.72363725]. \t  1.0296995162962599 \t 1.0312218198590875\n",
      "86     \t [-0.06423286  0.75763863]. \t  1.010283935766164 \t 1.0312218198590875\n",
      "87     \t [-0.20016174  0.66720097]. \t  0.9646077012854822 \t 1.0312218198590875\n",
      "88     \t [-0.01115712  0.73388829]. \t  1.0017328102431013 \t 1.0312218198590875\n",
      "89     \t [ 0.11055509 -0.7516988 ]. \t  1.0176009457371957 \t 1.0312218198590875\n",
      "90     \t [-0.08677223  0.74447331]. \t  1.0228327110301016 \t 1.0312218198590875\n",
      "91     \t [-0.11039555  0.69082699]. \t  1.0257550999205511 \t 1.0312218198590875\n",
      "92     \t [ 0.11155793 -0.71378827]. \t  1.0298121434394258 \t 1.0312218198590875\n",
      "93     \t [-3.         1.2354956]. \t  -108.40790657320527 \t 1.0312218198590875\n",
      "94     \t [-0.05289869  0.60644675]. \t  0.9509725974867822 \t 1.0312218198590875\n",
      "95     \t [ 0.14753511 -0.78394631]. \t  0.9770778775040876 \t 1.0312218198590875\n",
      "96     \t [ 0.14128403 -0.73006087]. \t  1.0197822605235374 \t 1.0312218198590875\n",
      "97     \t [-0.12187146  0.71721333]. \t  1.027630535767056 \t 1.0312218198590875\n",
      "98     \t [-0.1224826   0.78430553]. \t  0.9835029093278913 \t 1.0312218198590875\n",
      "99     \t [-0.18916916  0.74196352]. \t  0.9896856580212028 \t 1.0312218198590875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [ 2.51153332 -0.39065023]. \t  -23.836237642539036 \t 1.0312218198590875\n"
     ]
    }
   ],
   "source": [
    "### 6(d). Bayesian optimization runs (x20): STP DF1 run number = 4\n",
    "\n",
    "np.random.seed(run_num_4)\n",
    "surrogate_stp_df1_4 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_4 = GPGO(surrogate_stp_df1_4, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_4.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.945825229348202, -7.880139912603991)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(d). Training Regret Minimisation: run number = 4\n",
    "\n",
    "gp_output_4 = np.append(np.max(gpgo_gp_4.GP.y[0:n_init]),gpgo_gp_4.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_4 = np.append(np.max(gpgo_stp_df1_4.GP.y[0:n_init]),gpgo_stp_df1_4.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_4 = np.log(y_global_orig - gp_output_4)\n",
    "regret_stp_df1_4 = np.log(y_global_orig - stp_df1_output_4)\n",
    "\n",
    "train_regret_gp_4 = min_max_array(regret_gp_4)\n",
    "train_regret_stp_df1_4 = min_max_array(regret_stp_df1_4)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 4\n",
    "min_train_regret_gp_4 = min(train_regret_gp_4)\n",
    "min_train_regret_stp_df1_4 = min(train_regret_stp_df1_4)\n",
    "\n",
    "min_train_regret_gp_4, min_train_regret_stp_df1_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 1.30700452 -1.80857947]. \t  -29.715623403121764 \t -1.2909749409376214\n",
      "init   \t [2.66683187 0.74552016]. \t  -43.13890609652096 \t -1.2909749409376214\n",
      "init   \t [ 0.48724401 -1.42928554]. \t  -8.66094886750837 \t -1.2909749409376214\n",
      "init   \t [ 2.67551509 -0.64003765]. \t  -40.61558623177809 \t -1.2909749409376214\n",
      "init   \t [ 0.72261275 -0.18816142]. \t  -1.2909749409376214 \t -1.2909749409376214\n",
      "1      \t [-0.16782244 -0.35804631]. \t  \u001b[92m0.2759632467048023\u001b[0m \t 0.2759632467048023\n",
      "2      \t [ 0.28827789 -0.03531325]. \t  -0.30294274153183787 \t 0.2759632467048023\n",
      "3      \t [-0.63591921 -1.24656754]. \t  -5.531991045001889 \t 0.2759632467048023\n",
      "4      \t [ 0.23040078 -0.5160962 ]. \t  \u001b[92m0.694079343327121\u001b[0m \t 0.694079343327121\n",
      "5      \t [-1.61636028  0.47947856]. \t  -0.5775343033995384 \t 0.694079343327121\n",
      "6      \t [-3.  2.]. \t  -150.89999999999998 \t 0.694079343327121\n",
      "7      \t [-1.34281409  0.05053619]. \t  -2.260938882705192 \t 0.694079343327121\n",
      "8      \t [-0.98462965  0.7606248 ]. \t  -0.48364346533198 \t 0.694079343327121\n",
      "9      \t [-3. -2.]. \t  -162.89999999999998 \t 0.694079343327121\n",
      "10     \t [-1.28720061  0.47018164]. \t  -1.084663029044207 \t 0.694079343327121\n",
      "11     \t [-0.29589251  1.7239602 ]. \t  -23.26813178981328 \t 0.694079343327121\n",
      "12     \t [-2.04307274  0.05104321]. \t  -4.235303356409633 \t 0.694079343327121\n",
      "13     \t [-0.07740373 -0.64596244]. \t  \u001b[92m0.8987313707052562\u001b[0m \t 0.8987313707052562\n",
      "14     \t [-0.40342861 -0.64712248]. \t  0.11570879725249927 \t 0.8987313707052562\n",
      "15     \t [-1.28717047  1.13896843]. \t  -2.4550694727945888 \t 0.8987313707052562\n",
      "16     \t [ 0.07568373 -0.43755821]. \t  0.6294780917548202 \t 0.8987313707052562\n",
      "17     \t [1.90279039 1.92937591]. \t  -46.98356597112498 \t 0.8987313707052562\n",
      "18     \t [0.22771183 0.75252194]. \t  0.6092538698087508 \t 0.8987313707052562\n",
      "19     \t [0.03847171 0.6041857 ]. \t  0.8979838415186637 \t 0.8987313707052562\n",
      "20     \t [0.37552861 0.68198468]. \t  0.21576524003204245 \t 0.8987313707052562\n",
      "21     \t [-0.17773472 -1.9018163 ]. \t  -38.32268567373163 \t 0.8987313707052562\n",
      "22     \t [ 0.18358827 -0.73181429]. \t  \u001b[92m0.9968509311507776\u001b[0m \t 0.9968509311507776\n",
      "23     \t [ 0.79210997 -0.71733686]. \t  -0.19800361017004764 \t 0.9968509311507776\n",
      "24     \t [-0.51750936 -0.01875652]. \t  -0.935343477208658 \t 0.9968509311507776\n",
      "25     \t [-1.27608716 -1.32386625]. \t  -9.35000854434377 \t 0.9968509311507776\n",
      "26     \t [-0.11684902  0.40573029]. \t  0.543258210345545 \t 0.9968509311507776\n",
      "27     \t [ 0.55069311 -0.67123329]. \t  0.3306491082594829 \t 0.9968509311507776\n",
      "28     \t [-0.00977864 -0.69123362]. \t  0.9908875445464782 \t 0.9968509311507776\n",
      "29     \t [ 0.0155928  -0.64249935]. \t  0.978634361617618 \t 0.9968509311507776\n",
      "30     \t [-2.7241422  -0.41643443]. \t  -50.82196231964552 \t 0.9968509311507776\n",
      "31     \t [1.70950088 1.00624541]. \t  -3.8451466805073395 \t 0.9968509311507776\n",
      "32     \t [1.50640507 0.44708704]. \t  -2.191987076818366 \t 0.9968509311507776\n",
      "33     \t [-0.1875891   0.60014685]. \t  0.8962055281473047 \t 0.9968509311507776\n",
      "34     \t [1.65198483 0.24728489]. \t  -2.2299307785257825 \t 0.9968509311507776\n",
      "35     \t [ 1.54083595 -0.66916362]. \t  -0.10029457223992277 \t 0.9968509311507776\n",
      "36     \t [ 1.61699654 -0.49423764]. \t  -0.5228360424355437 \t 0.9968509311507776\n",
      "37     \t [-2.04224103 -1.93361781]. \t  -49.24701427648493 \t 0.9968509311507776\n",
      "38     \t [ 2.71224441 -0.05891139]. \t  -48.30470448687388 \t 0.9968509311507776\n",
      "39     \t [-0.6944794  -1.04774345]. \t  -2.635046768210992 \t 0.9968509311507776\n",
      "40     \t [-2.14119131 -0.824598  ]. \t  -7.215733723622844 \t 0.9968509311507776\n",
      "41     \t [-1.780582   -0.59573991]. \t  -2.3409677580427375 \t 0.9968509311507776\n",
      "42     \t [-0.50402368  1.30174321]. \t  -4.937647991315182 \t 0.9968509311507776\n",
      "43     \t [1.42139576 1.81987357]. \t  -35.47326432486534 \t 0.9968509311507776\n",
      "44     \t [-0.12200248  0.63519557]. \t  0.98115164557155 \t 0.9968509311507776\n",
      "45     \t [2.47122922 1.21097669]. \t  -27.757066660408153 \t 0.9968509311507776\n",
      "46     \t [ 1.29610648 -0.11278099]. \t  -2.1771219976996234 \t 0.9968509311507776\n",
      "47     \t [ 0.09116882 -0.80928412]. \t  0.9446527619766192 \t 0.9968509311507776\n",
      "48     \t [ 0.01943319 -0.74956409]. \t  \u001b[92m0.9977562520995141\u001b[0m \t 0.9977562520995141\n",
      "49     \t [-0.84400632 -1.02673432]. \t  -2.9993049754826346 \t 0.9977562520995141\n",
      "50     \t [ 2.67914306 -0.77762321]. \t  -40.74686373815095 \t 0.9977562520995141\n",
      "51     \t [-0.00185858  0.93593815]. \t  0.43628119035727525 \t 0.9977562520995141\n",
      "52     \t [-1.66593394 -0.47257708]. \t  -2.1452503803120537 \t 0.9977562520995141\n",
      "53     \t [ 0.11533815 -0.71611225]. \t  \u001b[92m1.0290972750260183\u001b[0m \t 1.0290972750260183\n",
      "54     \t [-2.59399904 -0.76656349]. \t  -34.406582746525906 \t 1.0290972750260183\n",
      "55     \t [0.00680851 0.714298  ]. \t  0.9945333475648062 \t 1.0290972750260183\n",
      "56     \t [-0.26675798  0.53222129]. \t  0.6799429142465181 \t 1.0290972750260183\n",
      "57     \t [ 1.33801094 -0.18709245]. \t  -1.9576387844277967 \t 1.0290972750260183\n",
      "58     \t [-2.37585096 -0.45721659]. \t  -16.043439296909142 \t 1.0290972750260183\n",
      "59     \t [-0.67812809  0.95890384]. \t  -0.4814108279156957 \t 1.0290972750260183\n",
      "60     \t [-2.80566985 -0.59445182]. \t  -64.70613626171676 \t 1.0290972750260183\n",
      "61     \t [-0.08246693  0.71745819]. \t  \u001b[92m1.0311906095003536\u001b[0m \t 1.0311906095003536\n",
      "62     \t [-0.02734115  0.6871819 ]. \t  1.0127122158646973 \t 1.0311906095003536\n",
      "63     \t [ 1.63960638 -0.47712694]. \t  -0.5670634910038107 \t 1.0311906095003536\n",
      "64     \t [-2.49424664 -0.40764977]. \t  -24.331817846842075 \t 1.0311906095003536\n",
      "65     \t [0.02301062 0.74385232]. \t  0.9693956249758159 \t 1.0311906095003536\n",
      "66     \t [-1.82744038  1.28831314]. \t  -4.378392686697042 \t 1.0311906095003536\n",
      "67     \t [-2.0941049   0.75876126]. \t  -2.701315390765436 \t 1.0311906095003536\n",
      "68     \t [ 0.87262256 -1.71571853]. \t  -23.36470929858738 \t 1.0311906095003536\n",
      "69     \t [-0.65919706  1.3088912 ]. \t  -5.393542664990062 \t 1.0311906095003536\n",
      "70     \t [0.38974308 0.91672767]. \t  -0.38106124128598085 \t 1.0311906095003536\n",
      "71     \t [-0.67298818  0.7790493 ]. \t  0.06671777220205122 \t 1.0311906095003536\n",
      "72     \t [-0.20588452  0.76856842]. \t  0.9595263632158271 \t 1.0311906095003536\n",
      "73     \t [0.03181964 0.70002414]. \t  0.9732803754242381 \t 1.0311906095003536\n",
      "74     \t [-1.72757454 -1.0770474 ]. \t  -4.697263982960653 \t 1.0311906095003536\n",
      "75     \t [-2.35529044  1.76608572]. \t  -36.74766835835851 \t 1.0311906095003536\n",
      "76     \t [ 2.45434674 -1.61626332]. \t  -33.635217017360695 \t 1.0311906095003536\n",
      "77     \t [ 1.84653451 -1.64789114]. \t  -18.02953273113684 \t 1.0311906095003536\n",
      "78     \t [-0.12152682 -0.18625475]. \t  0.05269646521279531 \t 1.0311906095003536\n",
      "79     \t [0.7618131 1.1153637]. \t  -3.743337774674676 \t 1.0311906095003536\n",
      "80     \t [ 0.02588482 -0.65728257]. \t  0.9958495730157942 \t 1.0311906095003536\n",
      "81     \t [-0.39080191  0.44850852]. \t  0.2549474405130896 \t 1.0311906095003536\n",
      "82     \t [ 0.01349769 -0.7762851 ]. \t  0.967627098432556 \t 1.0311906095003536\n",
      "83     \t [0.90946527 0.65068695]. \t  -1.6756907263840228 \t 1.0311906095003536\n",
      "84     \t [-0.7687743  0.9439631]. \t  -0.5853811946649725 \t 1.0311906095003536\n",
      "85     \t [-2.12858809  0.1741086 ]. \t  -5.529361344566155 \t 1.0311906095003536\n",
      "86     \t [ 0.00734785 -0.71280647]. \t  1.0047596493275042 \t 1.0311906095003536\n",
      "87     \t [0.47699564 0.77466746]. \t  -0.21491440936940753 \t 1.0311906095003536\n",
      "88     \t [2.61794187 0.55709872]. \t  -36.685011110362026 \t 1.0311906095003536\n",
      "89     \t [-0.15606483  0.6545788 ]. \t  0.985508545412127 \t 1.0311906095003536\n",
      "90     \t [1.97187706 0.30881926]. \t  -3.662989994688935 \t 1.0311906095003536\n",
      "91     \t [-0.0166813   0.74231068]. \t  1.000855545014075 \t 1.0311906095003536\n",
      "92     \t [-1.2574415  -0.34520664]. \t  -2.406378503959986 \t 1.0311906095003536\n",
      "93     \t [ 0.35565591 -1.59714384]. \t  -15.729251187426195 \t 1.0311906095003536\n",
      "94     \t [-0.86977455  1.59538879]. \t  -16.31332340689947 \t 1.0311906095003536\n",
      "95     \t [-1.73168946e-01  4.56801440e-05]. \t  -0.11806258179373141 \t 1.0311906095003536\n",
      "96     \t [0.93336216 0.12275105]. \t  -2.166502182551442 \t 1.0311906095003536\n",
      "97     \t [ 2.0490631 -0.3449721]. \t  -3.3203989842649366 \t 1.0311906095003536\n",
      "98     \t [ 1.83907411 -0.82312747]. \t  -0.015239168435058126 \t 1.0311906095003536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [ 0.10927124 -0.68753673]. \t  1.0246863183365063 \t 1.0311906095003536\n",
      "100    \t [1.38594266 1.67170355]. \t  -24.67504857613833 \t 1.0311906095003536\n"
     ]
    }
   ],
   "source": [
    "### 6(e). Bayesian optimization runs (x20): GP run number = 5\n",
    "\n",
    "np.random.seed(run_num_5)\n",
    "surrogate_gp_5 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_5 = GPGO(surrogate_gp_5, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_5.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 1.30700452 -1.80857947]. \t  -29.715623403121764 \t -1.2909749409376214\n",
      "init   \t [2.66683187 0.74552016]. \t  -43.13890609652096 \t -1.2909749409376214\n",
      "init   \t [ 0.48724401 -1.42928554]. \t  -8.66094886750837 \t -1.2909749409376214\n",
      "init   \t [ 2.67551509 -0.64003765]. \t  -40.61558623177809 \t -1.2909749409376214\n",
      "init   \t [ 0.72261275 -0.18816142]. \t  -1.2909749409376214 \t -1.2909749409376214\n",
      "1      \t [-0.74590162 -0.38257315]. \t  -1.4184368941479326 \t -1.2909749409376214\n",
      "2      \t [-3.  2.]. \t  -150.89999999999998 \t -1.2909749409376214\n",
      "3      \t [-3. -2.]. \t  -162.89999999999998 \t -1.2909749409376214\n",
      "4      \t [0.27758786 2.        ]. \t  -48.85107959232823 \t -1.2909749409376214\n",
      "5      \t [-0.67360753 -2.        ]. \t  -50.76098210582575 \t -1.2909749409376214\n",
      "6      \t [3. 2.]. \t  -162.89999999999998 \t -1.2909749409376214\n",
      "7      \t [-1.08275442  0.80347732]. \t  \u001b[92m-0.5550487354347609\u001b[0m \t -0.5550487354347609\n",
      "8      \t [-2.10426746  0.03231207]. \t  -5.404659179342852 \t -0.5550487354347609\n",
      "9      \t [ 3. -2.]. \t  -150.89999999999998 \t -0.5550487354347609\n",
      "10     \t [1.72612003 0.10354991]. \t  -2.2284809836387898 \t -0.5550487354347609\n",
      "11     \t [-1.09177115  2.        ]. \t  -48.165185110098996 \t -0.5550487354347609\n",
      "12     \t [-0.08686744  0.54425851]. \t  \u001b[92m0.8511044603277489\u001b[0m \t 0.8511044603277489\n",
      "13     \t [-3.          0.05835428]. \t  -108.7113626535697 \t 0.8511044603277489\n",
      "14     \t [-1.44121975  0.03297007]. \t  -2.1835186234753103 \t 0.8511044603277489\n",
      "15     \t [1.22173713 1.03282685]. \t  -3.9469156915298984 \t 0.8511044603277489\n",
      "16     \t [-0.02324541 -0.5217397 ]. \t  0.778162239103164 \t 0.8511044603277489\n",
      "17     \t [-1.66078833 -0.88985342]. \t  -2.869726904128826 \t 0.8511044603277489\n",
      "18     \t [-1.82324999  0.88890887]. \t  -0.051743469108287754 \t 0.8511044603277489\n",
      "19     \t [0.81008267 0.56426302]. \t  -1.4038107756391653 \t 0.8511044603277489\n",
      "20     \t [ 1.31356648 -0.85845815]. \t  -0.4589888379602083 \t 0.8511044603277489\n",
      "21     \t [-0.90161715 -0.9836807 ]. \t  -2.8045859372528446 \t 0.8511044603277489\n",
      "22     \t [1.36025104 2.        ]. \t  -53.04369541652706 \t 0.8511044603277489\n",
      "23     \t [3.         0.04061863]. \t  -109.0152672861559 \t 0.8511044603277489\n",
      "24     \t [1.86976187 0.87145018]. \t  -3.459114089858023 \t 0.8511044603277489\n",
      "25     \t [ 1.92111376 -0.73110062]. \t  -0.5156657725877156 \t 0.8511044603277489\n",
      "26     \t [-0.13704115  1.14535887]. \t  -1.5538031200983082 \t 0.8511044603277489\n",
      "27     \t [-1.58987326 -0.49913351]. \t  -2.1220165166558846 \t 0.8511044603277489\n",
      "28     \t [-1.77701199  0.51789148]. \t  -0.4814245308120596 \t 0.8511044603277489\n",
      "29     \t [-1.65429969 -2.        ]. \t  -53.3595889585597 \t 0.8511044603277489\n",
      "30     \t [0.43997227 1.05126549]. \t  -1.6254280601421982 \t 0.8511044603277489\n",
      "31     \t [-1.92868865  2.        ]. \t  -47.12124422953678 \t 0.8511044603277489\n",
      "32     \t [ 0.56570378 -0.82942733]. \t  0.25196987996143816 \t 0.8511044603277489\n",
      "33     \t [-2.32506236 -0.74878831]. \t  -13.669814060376423 \t 0.8511044603277489\n",
      "34     \t [-0.19801708 -0.98476627]. \t  -0.23135009152766983 \t 0.8511044603277489\n",
      "35     \t [ 1.47828133 -0.44118424]. \t  -0.9120034273524525 \t 0.8511044603277489\n",
      "36     \t [-1.53273795  1.14773395]. \t  -2.041654199538603 \t 0.8511044603277489\n",
      "37     \t [-0.49213862  0.64690823]. \t  0.44144377543477353 \t 0.8511044603277489\n",
      "38     \t [ 0.53138456 -2.        ]. \t  -47.9067753794832 \t 0.8511044603277489\n",
      "39     \t [ 2.16203885 -1.24436118]. \t  -7.564384024674148 \t 0.8511044603277489\n",
      "40     \t [1.52020512 0.53636934]. \t  -2.138302732474342 \t 0.8511044603277489\n",
      "41     \t [-0.32034263  0.0516815 ]. \t  -0.36151210839083964 \t 0.8511044603277489\n",
      "42     \t [-3.          1.05891327]. \t  -106.26730162533374 \t 0.8511044603277489\n",
      "43     \t [-1.95148649 -0.46472735]. \t  -3.4169646171786425 \t 0.8511044603277489\n",
      "44     \t [-0.706669    1.05583268]. \t  -1.2810419800016248 \t 0.8511044603277489\n",
      "45     \t [ 1.74182131 -1.0132318 ]. \t  -0.45915092618382236 \t 0.8511044603277489\n",
      "46     \t [ 2.06207625 -2.        ]. \t  -48.54224169390051 \t 0.8511044603277489\n",
      "47     \t [-3.         -1.04811848]. \t  -112.4774150788032 \t 0.8511044603277489\n",
      "48     \t [0.21079567 0.08657487]. \t  -0.16211563061099438 \t 0.8511044603277489\n",
      "49     \t [2.14477509 2.        ]. \t  -58.699234887177624 \t 0.8511044603277489\n",
      "50     \t [-2.18760445 -1.44223309]. \t  -19.722671079173885 \t 0.8511044603277489\n",
      "51     \t [-0.10259368  0.82932735]. \t  \u001b[92m0.9021630514583423\u001b[0m \t 0.9021630514583423\n",
      "52     \t [2.1236042  1.36547501]. \t  -15.249502663892226 \t 0.9021630514583423\n",
      "53     \t [ 3.         -1.20811026]. \t  -107.95846360977849 \t 0.9021630514583423\n",
      "54     \t [-2.19498788  1.4433394 ]. \t  -13.662858909432229 \t 0.9021630514583423\n",
      "55     \t [-0.28865967 -0.70208304]. \t  0.47822620588365017 \t 0.9021630514583423\n",
      "56     \t [3.         1.20611769]. \t  -115.16431330116149 \t 0.9021630514583423\n",
      "57     \t [-2.27408859 -2.        ]. \t  -63.173630492958075 \t 0.9021630514583423\n",
      "58     \t [-2.22014757  0.72064008]. \t  -6.015151615753618 \t 0.9021630514583423\n",
      "59     \t [-0.38723717  2.        ]. \t  -47.77923994179417 \t 0.9021630514583423\n",
      "60     \t [ 0.09986181 -0.84974811]. \t  0.8479127320626343 \t 0.9021630514583423\n",
      "61     \t [1.21495985 0.08976159]. \t  -2.4779349812278855 \t 0.9021630514583423\n",
      "62     \t [ 2.20108183 -0.12372298]. \t  -7.660780187656435 \t 0.9021630514583423\n",
      "63     \t [ 0.1167655  -0.62801998]. \t  \u001b[92m0.9745861047311182\u001b[0m \t 0.9745861047311182\n",
      "64     \t [1.69332811 1.49679913]. \t  -15.712647208469768 \t 0.9745861047311182\n",
      "65     \t [-0.02538569  0.73769755]. \t  \u001b[92m1.0083363623990544\u001b[0m \t 1.0083363623990544\n",
      "66     \t [-0.13754115  0.7245349 ]. \t  \u001b[92m1.0222421962932764\u001b[0m \t 1.0222421962932764\n",
      "67     \t [-0.10164016 -2.        ]. \t  -48.244379460735004 \t 1.0222421962932764\n",
      "68     \t [-0.05433331  0.75410894]. \t  1.0103151613557528 \t 1.0222421962932764\n",
      "69     \t [-0.13435429  0.66383109]. \t  1.0035871797326679 \t 1.0222421962932764\n",
      "70     \t [-0.05949263  0.72003875]. \t  \u001b[92m1.027343333046584\u001b[0m \t 1.027343333046584\n",
      "71     \t [ 0.17727052 -0.67354202]. \t  0.9871732366025485 \t 1.027343333046584\n",
      "72     \t [ 0.12883189 -0.74750156]. \t  1.0166781201414923 \t 1.027343333046584\n",
      "73     \t [0.03181964 0.70002414]. \t  0.9732803754242381 \t 1.027343333046584\n",
      "74     \t [-0.226737    0.79525336]. \t  0.9100310095049599 \t 1.027343333046584\n",
      "75     \t [-0.11105326  0.78804055]. \t  0.979930291541849 \t 1.027343333046584\n",
      "76     \t [ 0.1738415  -0.67500521]. \t  0.9904951159515103 \t 1.027343333046584\n",
      "77     \t [-0.06014858  0.73847774]. \t  1.0217481913538238 \t 1.027343333046584\n",
      "78     \t [-0.10930423  0.70704689]. \t  \u001b[92m1.029792714606715\u001b[0m \t 1.029792714606715\n",
      "79     \t [ 0.15966656 -0.61141668]. \t  0.9333333385303161 \t 1.029792714606715\n",
      "80     \t [ 0.08616145 -0.7534214 ]. \t  1.017033561858206 \t 1.029792714606715\n",
      "81     \t [ 0.07056137 -0.69307978]. \t  1.0274980620879626 \t 1.029792714606715\n",
      "82     \t [ 0.03842832 -0.67302181]. \t  1.011109065111694 \t 1.029792714606715\n",
      "83     \t [ 0.08737469 -0.70385779]. \t  \u001b[92m1.0310001959421653\u001b[0m \t 1.0310001959421653\n",
      "84     \t [-1.31115209 -1.52006448]. \t  -16.469810518984353 \t 1.0310001959421653\n",
      "85     \t [-0.06675831  0.68844288]. \t  1.0254606152716044 \t 1.0310001959421653\n",
      "86     \t [ 0.00734946 -0.71280502]. \t  1.0047608213624541 \t 1.0310001959421653\n",
      "87     \t [-0.23270163  0.67617009]. \t  0.9395251302445371 \t 1.0310001959421653\n",
      "88     \t [ 0.06238991 -0.68753232]. \t  1.024375865487581 \t 1.0310001959421653\n",
      "89     \t [ 0.0556135  -0.67054737]. \t  1.0147930900630096 \t 1.0310001959421653\n",
      "90     \t [-0.0503178  -0.58566019]. \t  0.861818111311888 \t 1.0310001959421653\n",
      "91     \t [-0.01668354  0.74230862]. \t  1.0008581189976657 \t 1.0310001959421653\n",
      "92     \t [2.09912409 0.46970181]. \t  -5.667785339086685 \t 1.0310001959421653\n",
      "93     \t [0.00753819 0.75335884]. \t  0.9758419816563839 \t 1.0310001959421653\n",
      "94     \t [ 0.03177148 -0.79047178]. \t  0.9587331522297073 \t 1.0310001959421653\n",
      "95     \t [-0.05257648  0.73956467]. \t  1.0190231733584982 \t 1.0310001959421653\n",
      "96     \t [ 0.11117203 -0.57696143]. \t  0.9033148659989217 \t 1.0310001959421653\n",
      "97     \t [-0.04397262  0.70010714]. \t  1.0226709406256973 \t 1.0310001959421653\n",
      "98     \t [ 0.0441637  -0.71500224]. \t  1.023279109129238 \t 1.0310001959421653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [ 0.10927124 -0.68753673]. \t  1.0246863186819353 \t 1.0310001959421653\n",
      "100    \t [ 0.08724553 -0.74467071]. \t  1.0227475549181473 \t 1.0310001959421653\n"
     ]
    }
   ],
   "source": [
    "### 6(e). Bayesian optimization runs (x20): STP DF1 run number = 5\n",
    "\n",
    "np.random.seed(run_num_5)\n",
    "surrogate_stp_df1_5 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_5 = GPGO(surrogate_stp_df1_3, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_5.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.800841090559586, -7.418907526359189)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(e). Training Regret Minimisation: run number = 5\n",
    "\n",
    "gp_output_5 = np.append(np.max(gpgo_gp_5.GP.y[0:n_init]),gpgo_gp_5.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_5 = np.append(np.max(gpgo_stp_df1_5.GP.y[0:n_init]),gpgo_stp_df1_5.GP.y[n_init:(n_init+max_iter)]) \n",
    "\n",
    "regret_gp_5 = np.log(y_global_orig - gp_output_5)\n",
    "regret_stp_df1_5 = np.log(y_global_orig - stp_df1_output_5)\n",
    "\n",
    "train_regret_gp_5 = min_max_array(regret_gp_5)\n",
    "train_regret_stp_df1_5 = min_max_array(regret_stp_df1_5)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 5\n",
    "min_train_regret_gp_5 = min(train_regret_gp_5)\n",
    "min_train_regret_stp_df1_5 = min(train_regret_stp_df1_5)\n",
    "\n",
    "min_train_regret_gp_5, min_train_regret_stp_df1_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.20262273 1.37674657]. \t  -10.845521978070849 \t -2.7177401691678\n",
      "init   \t [1.05908602 0.91143223]. \t  -2.7177401691678 \t -2.7177401691678\n",
      "init   \t [ 2.70874774 -1.94918721]. \t  -85.22675001483634 \t -2.7177401691678\n",
      "init   \t [-0.51847381 -1.80474882]. \t  -31.272506824586927 \t -2.7177401691678\n",
      "init   \t [-2.40042863  0.03226522]. \t  -17.013156689996258 \t -2.7177401691678\n",
      "1      \t [0.69575333 0.29536087]. \t  \u001b[92m-1.3690037724856636\u001b[0m \t -1.3690037724856636\n",
      "2      \t [1.33070943 0.41832802]. \t  -2.3282610270765596 \t -1.3690037724856636\n",
      "3      \t [0.20346335 0.83465619]. \t  \u001b[92m0.5134775157643949\u001b[0m \t 0.5134775157643949\n",
      "4      \t [-1.15619728  2.        ]. \t  -48.078334635520385 \t 0.5134775157643949\n",
      "5      \t [0.40932328 0.67583694]. \t  0.10308411092064185 \t 0.5134775157643949\n",
      "6      \t [-2.82054201 -1.81251976]. \t  -101.8883363751311 \t 0.5134775157643949\n",
      "7      \t [-0.76970738  0.38845718]. \t  -0.8905090534536666 \t 0.5134775157643949\n",
      "8      \t [-0.23520366  0.54780488]. \t  \u001b[92m0.7540773020511695\u001b[0m \t 0.7540773020511695\n",
      "9      \t [2.89682832 1.2673893 ]. \t  -90.22984486622795 \t 0.7540773020511695\n",
      "10     \t [-2.98713126  0.97188029]. \t  -102.19156573630491 \t 0.7540773020511695\n",
      "11     \t [-0.88346478 -0.01048332]. \t  -2.0100452991019124 \t 0.7540773020511695\n",
      "12     \t [-1.70811899  0.05946744]. \t  -1.9573095774431646 \t 0.7540773020511695\n",
      "13     \t [-1.58860948 -0.39394447]. \t  -2.179035507160263 \t 0.7540773020511695\n",
      "14     \t [ 1.30176543 -0.09445657]. \t  -2.211676540512287 \t 0.7540773020511695\n",
      "15     \t [-0.26667252  0.67480384]. \t  \u001b[92m0.898024176675226\u001b[0m \t 0.898024176675226\n",
      "16     \t [ 0.54734379 -1.52724329]. \t  -12.614714203478517 \t 0.898024176675226\n",
      "17     \t [-1.49142086 -0.15465142]. \t  -2.3129330941696367 \t 0.898024176675226\n",
      "18     \t [-0.32162415 -0.52900063]. \t  0.24431507360043314 \t 0.898024176675226\n",
      "19     \t [-0.45350431 -0.43880714]. \t  -0.313836190517486 \t 0.898024176675226\n",
      "20     \t [ 0.66274509 -0.62269321]. \t  -0.017746280259092306 \t 0.898024176675226\n",
      "21     \t [ 0.64070055 -0.82020702]. \t  0.09497182763692824 \t 0.898024176675226\n",
      "22     \t [ 0.23192441 -0.73114849]. \t  \u001b[92m0.9556568143580049\u001b[0m \t 0.9556568143580049\n",
      "23     \t [-0.02001296 -0.59472489]. \t  0.9008785973085426 \t 0.9556568143580049\n",
      "24     \t [-1.75572404  1.40975399]. \t  -7.513721244684939 \t 0.9556568143580049\n",
      "25     \t [-2.15164962 -0.40164126]. \t  -6.9073925032997225 \t 0.9556568143580049\n",
      "26     \t [ 0.12865249 -0.63884335]. \t  \u001b[92m0.9827895943834928\u001b[0m \t 0.9827895943834928\n",
      "27     \t [-1.70734401  0.84280068]. \t  0.18972070239443928 \t 0.9827895943834928\n",
      "28     \t [ 0.57441028 -1.76840969]. \t  -26.697602255107256 \t 0.9827895943834928\n",
      "29     \t [-0.43356136 -1.68971087]. \t  -22.598920470915925 \t 0.9827895943834928\n",
      "30     \t [0.10669227 0.68989305]. \t  0.8788192663605031 \t 0.9827895943834928\n",
      "31     \t [ 0.24595774 -0.80160778]. \t  0.8814817439534044 \t 0.9827895943834928\n",
      "32     \t [-1.53046032  0.80574517]. \t  0.012692602351299986 \t 0.9827895943834928\n",
      "33     \t [-0.02414037 -0.68256018]. \t  0.9765380186327075 \t 0.9827895943834928\n",
      "34     \t [ 0.18794873 -0.73352661]. \t  \u001b[92m0.9933776075576712\u001b[0m \t 0.9933776075576712\n",
      "35     \t [ 1.83958372 -0.27609175]. \t  -1.6157108349490774 \t 0.9933776075576712\n",
      "36     \t [1.71417117 0.35229199]. \t  -2.24775515610084 \t 0.9933776075576712\n",
      "37     \t [ 0.04674352 -0.69390242]. \t  \u001b[92m1.0223367218030044\u001b[0m \t 1.0223367218030044\n",
      "38     \t [ 0.07198097 -0.73618032]. \t  \u001b[92m1.0252792026485908\u001b[0m \t 1.0252792026485908\n",
      "39     \t [ 2.2841601 -0.0290412]. \t  -10.976530731498567 \t 1.0252792026485908\n",
      "40     \t [-1.21996758 -0.11733461]. \t  -2.4893345279860744 \t 1.0252792026485908\n",
      "41     \t [ 1.97011666 -1.60511617]. \t  -16.463318318847048 \t 1.0252792026485908\n",
      "42     \t [ 1.48914058 -1.070432  ]. \t  -1.2526842695124467 \t 1.0252792026485908\n",
      "43     \t [ 0.15427197 -0.7295534 ]. \t  1.0143755144735203 \t 1.0252792026485908\n",
      "44     \t [-0.07719706  0.7627384 ]. \t  1.0083728815351916 \t 1.0252792026485908\n",
      "45     \t [-0.01124173  0.76757306]. \t  0.9763193594724084 \t 1.0252792026485908\n",
      "46     \t [-0.01974504 -0.79548792]. \t  0.9121894540425468 \t 1.0252792026485908\n",
      "47     \t [-1.74322538  1.53743145]. \t  -12.330264253751967 \t 1.0252792026485908\n",
      "48     \t [-0.5764698 -0.91995  ]. \t  -1.1196299615202854 \t 1.0252792026485908\n",
      "49     \t [ 2.56467542 -0.55376646]. \t  -28.042346832985793 \t 1.0252792026485908\n",
      "50     \t [ 2.22935722 -0.27327316]. \t  -8.043901880346448 \t 1.0252792026485908\n",
      "51     \t [ 0.21957611 -0.66717562]. \t  0.9464395688021583 \t 1.0252792026485908\n",
      "52     \t [1.30709601 0.67695243]. \t  -2.2583221750428932 \t 1.0252792026485908\n",
      "53     \t [ 2.33811508 -0.43404715]. \t  -11.940227211351944 \t 1.0252792026485908\n",
      "54     \t [ 0.10886355 -0.72467013]. \t  \u001b[92m1.0292500239945492\u001b[0m \t 1.0292500239945492\n",
      "55     \t [ 0.13229597 -0.53182522]. \t  0.8123537186185988 \t 1.0292500239945492\n",
      "56     \t [-0.12029127  0.77353751]. \t  0.9969095623356389 \t 1.0292500239945492\n",
      "57     \t [-1.10122884  1.78178444]. \t  -28.012059265256234 \t 1.0292500239945492\n",
      "58     \t [ 1.90373311 -0.93474446]. \t  -0.5606546443827372 \t 1.0292500239945492\n",
      "59     \t [-1.88458785 -0.95027793]. \t  -4.091150089231556 \t 1.0292500239945492\n",
      "60     \t [-0.20128525  0.81714548]. \t  0.8933123204368636 \t 1.0292500239945492\n",
      "61     \t [ 0.06647599 -0.69657275]. \t  1.0277955630149502 \t 1.0292500239945492\n",
      "62     \t [ 1.83498544 -1.94572785]. \t  -41.001741257997296 \t 1.0292500239945492\n",
      "63     \t [-2.73117972  1.58709498]. \t  -62.308715618586035 \t 1.0292500239945492\n",
      "64     \t [-1.33618231  0.43085192]. \t  -1.1642210140311473 \t 1.0292500239945492\n",
      "65     \t [ 2.81190828 -1.95503726]. \t  -102.76239041725614 \t 1.0292500239945492\n",
      "66     \t [-0.43078085  1.1637509 ]. \t  -2.090203736028403 \t 1.0292500239945492\n",
      "67     \t [-2.33321339  0.75484199]. \t  -10.576568715549621 \t 1.0292500239945492\n",
      "68     \t [-0.72073449 -1.91259327]. \t  -41.828555594601966 \t 1.0292500239945492\n",
      "69     \t [-1.91613907  0.48475724]. \t  -1.2275931938204256 \t 1.0292500239945492\n",
      "70     \t [ 1.63525091 -0.63017777]. \t  -0.06553118007485847 \t 1.0292500239945492\n",
      "71     \t [-0.57806229  0.46727255]. \t  -0.16178343250235172 \t 1.0292500239945492\n",
      "72     \t [-0.21811503  0.70156888]. \t  0.9671996668540328 \t 1.0292500239945492\n",
      "73     \t [ 0.14028929 -0.79270209]. \t  0.9673719536584651 \t 1.0292500239945492\n",
      "74     \t [-0.64635761  1.30060825]. \t  -5.167698646282534 \t 1.0292500239945492\n",
      "75     \t [-0.31311781  1.47449706]. \t  -10.12160815934156 \t 1.0292500239945492\n",
      "76     \t [ 1.56267068 -0.30045414]. \t  -1.3011265917114314 \t 1.0292500239945492\n",
      "77     \t [-0.10409551 -0.24981755]. \t  0.16495355653504407 \t 1.0292500239945492\n",
      "78     \t [ 1.23510641 -0.72581222]. \t  -0.5047597015097821 \t 1.0292500239945492\n",
      "79     \t [1.06714394 0.98170458]. \t  -3.2319243426156707 \t 1.0292500239945492\n",
      "80     \t [ 0.77706862 -1.99841755]. \t  -47.99312384864026 \t 1.0292500239945492\n",
      "81     \t [ 0.58369786 -1.18467891]. \t  -2.7057255609170894 \t 1.0292500239945492\n",
      "82     \t [2.66493717 0.64026707]. \t  -42.62787608623487 \t 1.0292500239945492\n",
      "83     \t [-0.07894875  0.67608681]. \t  1.0211621762298095 \t 1.0292500239945492\n",
      "84     \t [-1.01730086  1.06976678]. \t  -1.832664200560971 \t 1.0292500239945492\n",
      "85     \t [-2.20010425 -1.5741657 ]. \t  -26.076024963266562 \t 1.0292500239945492\n",
      "86     \t [-1.70147301  0.49829661]. \t  -0.4731132442858599 \t 1.0292500239945492\n",
      "87     \t [-0.20729207  1.19433655]. \t  -2.3536152703283197 \t 1.0292500239945492\n",
      "88     \t [ 2.80609851 -0.80154273]. \t  -60.86346998213694 \t 1.0292500239945492\n",
      "89     \t [-0.03006842  0.69937601]. \t  1.0169415051736717 \t 1.0292500239945492\n",
      "90     \t [-0.56821184 -1.99377485]. \t  -49.52299736027076 \t 1.0292500239945492\n",
      "91     \t [-0.08796085  0.76941361]. \t  1.0030013714841226 \t 1.0292500239945492\n",
      "92     \t [ 1.22466044 -0.41384969]. \t  -1.3254345013655953 \t 1.0292500239945492\n",
      "93     \t [-0.1686009   0.66933762]. \t  0.9900244725586953 \t 1.0292500239945492\n",
      "94     \t [-2.83260925  1.32959854]. \t  -70.74776549894524 \t 1.0292500239945492\n",
      "95     \t [ 0.08491364 -0.70208631]. \t  \u001b[92m1.0306842394421498\u001b[0m \t 1.0306842394421498\n",
      "96     \t [-0.02779829  0.74893332]. \t  1.00289355781575 \t 1.0306842394421498\n",
      "97     \t [ 2.66997036 -1.48223292]. \t  -49.115478317608634 \t 1.0306842394421498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98     \t [0.87930879 1.97681828]. \t  -49.18232487587935 \t 1.0306842394421498\n",
      "99     \t [-2.49293202 -0.86709067]. \t  -25.176104419734525 \t 1.0306842394421498\n",
      "100    \t [ 1.35437574 -0.68365141]. \t  -0.40700865011380205 \t 1.0306842394421498\n"
     ]
    }
   ],
   "source": [
    "### 6(f). Bayesian optimization runs (x20): GP run number = 6\n",
    "\n",
    "np.random.seed(run_num_6)\n",
    "surrogate_gp_6 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_6 = GPGO(surrogate_gp_6, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_6.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.20262273 1.37674657]. \t  -10.845521978070849 \t -2.7177401691678\n",
      "init   \t [1.05908602 0.91143223]. \t  -2.7177401691678 \t -2.7177401691678\n",
      "init   \t [ 2.70874774 -1.94918721]. \t  -85.22675001483634 \t -2.7177401691678\n",
      "init   \t [-0.51847381 -1.80474882]. \t  -31.272506824586927 \t -2.7177401691678\n",
      "init   \t [-2.40042863  0.03226522]. \t  -17.013156689996258 \t -2.7177401691678\n",
      "1      \t [-1.16413295  2.        ]. \t  -48.065382672726926 \t -2.7177401691678\n",
      "2      \t [-3. -2.]. \t  -162.89999999999998 \t -2.7177401691678\n",
      "3      \t [3.         0.86249827]. \t  -110.72545000209281 \t -2.7177401691678\n",
      "4      \t [-0.22959077  0.03234242]. \t  \u001b[92m-0.19345629300432587\u001b[0m \t -0.19345629300432587\n",
      "5      \t [-3.  2.]. \t  -150.89999999999998 \t -0.19345629300432587\n",
      "6      \t [ 0.92793127 -0.73084547]. \t  -0.42653497748969815 \t -0.19345629300432587\n",
      "7      \t [0.23943197 2.        ]. \t  -48.70133584360849 \t -0.19345629300432587\n",
      "8      \t [ 0.83749179 -2.        ]. \t  -48.212505410066626 \t -0.19345629300432587\n",
      "9      \t [-1.30771163 -0.29825703]. \t  -2.431957435659868 \t -0.19345629300432587\n",
      "10     \t [-1.27828442  0.6053967 ]. \t  -0.68074062025138 \t -0.19345629300432587\n",
      "11     \t [ 0.85808225 -0.02465501]. \t  -1.9161909368749983 \t -0.19345629300432587\n",
      "12     \t [ 1.87628511 -0.49720493]. \t  -0.9216531272099927 \t -0.19345629300432587\n",
      "13     \t [-0.357248    0.81230968]. \t  \u001b[92m0.7109999530154856\u001b[0m \t 0.7109999530154856\n",
      "14     \t [2.37336706 2.        ]. \t  -68.22238930806517 \t 0.7109999530154856\n",
      "15     \t [ 3.         -0.66603247]. \t  -105.91462677134176 \t 0.7109999530154856\n",
      "16     \t [ 1.43433765 -0.44779045]. \t  -0.9599503149003963 \t 0.7109999530154856\n",
      "17     \t [-0.00118973 -0.87343247]. \t  \u001b[92m0.7225226093679963\u001b[0m \t 0.7225226093679963\n",
      "18     \t [0.35970222 0.70461222]. \t  0.26339043592240186 \t 0.7225226093679963\n",
      "19     \t [-1.47607728 -1.27525902]. \t  -8.150310986553563 \t 0.7225226093679963\n",
      "20     \t [ 1.73441434 -1.14997332]. \t  -1.8144289093871486 \t 0.7225226093679963\n",
      "21     \t [-3.         -0.39014436]. \t  -109.55425732363395 \t 0.7225226093679963\n",
      "22     \t [-1.82868157  0.19934977]. \t  -1.840566990636495 \t 0.7225226093679963\n",
      "23     \t [-0.9457323  -0.96033525]. \t  -2.7575836436245806 \t 0.7225226093679963\n",
      "24     \t [-3.          0.69235498]. \t  -105.8246398640194 \t 0.7225226093679963\n",
      "25     \t [-1.81686238 -0.49955884]. \t  -2.469532115593766 \t 0.7225226093679963\n",
      "26     \t [ 0.24171071 -0.46144142]. \t  0.5552997652909047 \t 0.7225226093679963\n",
      "27     \t [-0.73867117  0.59535313]. \t  -0.2564561234955699 \t 0.7225226093679963\n",
      "28     \t [-1.07435419  1.10001204]. \t  -2.166525925292353 \t 0.7225226093679963\n",
      "29     \t [1.7672922  0.47248187]. \t  -2.3050411372513984 \t 0.7225226093679963\n",
      "30     \t [-1.49458558 -2.        ]. \t  -53.16111707511793 \t 0.7225226093679963\n",
      "31     \t [ 0.45853981 -1.08034613]. \t  -1.0362578992468787 \t 0.7225226093679963\n",
      "32     \t [-1.82157816  1.16571117]. \t  -2.156371418273202 \t 0.7225226093679963\n",
      "33     \t [-1.60877932  0.91665881]. \t  -0.05304367159392265 \t 0.7225226093679963\n",
      "34     \t [1.40972389 2.        ]. \t  -53.09116911169279 \t 0.7225226093679963\n",
      "35     \t [1.73266254 1.06600873]. \t  -4.567775754760628 \t 0.7225226093679963\n",
      "36     \t [ 1.79507816 -2.        ]. \t  -46.64690581545489 \t 0.7225226093679963\n",
      "37     \t [-1.92153226  2.        ]. \t  -47.0757792568716 \t 0.7225226093679963\n",
      "38     \t [ 1.52826228 -0.90074973]. \t  -0.1449419413679809 \t 0.7225226093679963\n",
      "39     \t [0.11626855 1.14304561]. \t  -1.7887035550224601 \t 0.7225226093679963\n",
      "40     \t [3. 2.]. \t  -162.89999999999998 \t 0.7225226093679963\n",
      "41     \t [-2.20819887 -1.20735255]. \t  -13.554492511532326 \t 0.7225226093679963\n",
      "42     \t [-0.5682326  -0.49122214]. \t  -0.6306677404596682 \t 0.7225226093679963\n",
      "43     \t [2.27237494 0.1117421 ]. \t  -10.759931745838182 \t 0.7225226093679963\n",
      "44     \t [ 1.8108226  -0.06830301]. \t  -2.146714263269691 \t 0.7225226093679963\n",
      "45     \t [-0.02758232  0.6745177 ]. \t  \u001b[92m1.0074535255001693\u001b[0m \t 1.0074535255001693\n",
      "46     \t [-2.17911447 -2.        ]. \t  -59.691287915136 \t 1.0074535255001693\n",
      "47     \t [-0.06997435 -1.21864316]. \t  -2.986427426770201 \t 1.0074535255001693\n",
      "48     \t [ 0.3843108  -0.76335099]. \t  0.7199595159958804 \t 1.0074535255001693\n",
      "49     \t [-2.0563732   0.75267438]. \t  -2.0383366447957623 \t 1.0074535255001693\n",
      "50     \t [-1.74135162 -0.93701728]. \t  -3.317089443864494 \t 1.0074535255001693\n",
      "51     \t [0.19967795 0.12082265]. \t  -0.12275343298746277 \t 1.0074535255001693\n",
      "52     \t [2.2707471  1.00538079]. \t  -12.815710905660017 \t 1.0074535255001693\n",
      "53     \t [ 3.         -1.45969431]. \t  -114.157744698134 \t 1.0074535255001693\n",
      "54     \t [ 0.10574408 -2.        ]. \t  -47.83297697913395 \t 1.0074535255001693\n",
      "55     \t [-0.43324903  2.        ]. \t  -47.812535867555916 \t 1.0074535255001693\n",
      "56     \t [ 1.84396581 -0.88803315]. \t  -0.12126579184983932 \t 1.0074535255001693\n",
      "57     \t [-0.92947471  0.1660611 ]. \t  -1.8416504987005087 \t 1.0074535255001693\n",
      "58     \t [-3.         -1.24697617]. \t  -116.09260286154907 \t 1.0074535255001693\n",
      "59     \t [-0.0371672   0.76782311]. \t  0.9909377653400955 \t 1.0074535255001693\n",
      "60     \t [-3.         1.3922498]. \t  -111.99876299569306 \t 1.0074535255001693\n",
      "61     \t [0.55052057 1.01585169]. \t  -1.7198296118740672 \t 1.0074535255001693\n",
      "62     \t [ 0.11078786 -0.67199982]. \t  \u001b[92m1.016292839419407\u001b[0m \t 1.016292839419407\n",
      "63     \t [ 0.05995428 -0.73015678]. \t  \u001b[92m1.0250349780620165\u001b[0m \t 1.0250349780620165\n",
      "64     \t [-0.00619698 -0.66171048]. \t  0.9803006440140257 \t 1.0250349780620165\n",
      "65     \t [-0.00236221 -0.65764574]. \t  0.9801980619569308 \t 1.0250349780620165\n",
      "66     \t [ 0.03152435 -0.72059504]. \t  1.017259864538117 \t 1.0250349780620165\n",
      "67     \t [ 0.10229971 -0.69905867]. \t  \u001b[92m1.0293698930303183\u001b[0m \t 1.0293698930303183\n",
      "68     \t [ 3. -2.]. \t  -150.89999999999998 \t 1.0293698930303183\n",
      "69     \t [-0.0708408   0.78542817]. \t  0.9809595106347576 \t 1.0293698930303183\n",
      "70     \t [-0.06653341  0.7610632 ]. \t  1.0078690212905193 \t 1.0293698930303183\n",
      "71     \t [ 2.3472318  -0.93191951]. \t  -11.395194530841042 \t 1.0293698930303183\n",
      "72     \t [ 0.1459902 -0.7238452]. \t  1.0190776811181108 \t 1.0293698930303183\n",
      "73     \t [ 0.09747801 -0.75392814]. \t  1.0169544621161588 \t 1.0293698930303183\n",
      "74     \t [ 0.13443949 -0.6764613 ]. \t  1.0121401612137515 \t 1.0293698930303183\n",
      "75     \t [ 0.12442296 -0.75000111]. \t  1.0162692915042106 \t 1.0293698930303183\n",
      "76     \t [-0.05340374  0.79423733]. \t  0.9625763895929734 \t 1.0293698930303183\n",
      "77     \t [0.00229762 0.75571997]. \t  0.9780144798119653 \t 1.0293698930303183\n",
      "78     \t [2.15380437 1.52354753]. \t  -22.188608859389888 \t 1.0293698930303183\n",
      "79     \t [ 0.14923329 -0.72580295]. \t  1.0173987379070382 \t 1.0293698930303183\n",
      "80     \t [ 0.12625425 -0.72771927]. \t  1.0251505399964547 \t 1.0293698930303183\n",
      "81     \t [-2.41613382  1.61912129]. \t  -31.191249458747627 \t 1.0293698930303183\n",
      "82     \t [-0.11856207  0.6066261 ]. \t  0.9464079752857291 \t 1.0293698930303183\n",
      "83     \t [ 0.08101064 -0.71068199]. \t  \u001b[92m1.0313094844995494\u001b[0m \t 1.0313094844995494\n",
      "84     \t [ 0.13284725 -0.75899725]. \t  1.0077386400206096 \t 1.0313094844995494\n",
      "85     \t [-0.11906297  0.76029864]. \t  1.0098707925518897 \t 1.0313094844995494\n",
      "86     \t [3.         0.15673581]. \t  -109.27435694332617 \t 1.0313094844995494\n",
      "87     \t [-0.09572542  0.72008326]. \t  1.031080976187123 \t 1.0313094844995494\n",
      "88     \t [ 0.05995184 -0.65152063]. \t  1.0018964703085151 \t 1.0313094844995494\n",
      "89     \t [-0.03006168  0.69937   ]. \t  1.0169374948045034 \t 1.0313094844995494\n",
      "90     \t [ 0.13192862 -0.76729619]. \t  1.0007405078581217 \t 1.0313094844995494\n",
      "91     \t [-0.10856966  0.74488852]. \t  1.0219760428186226 \t 1.0313094844995494\n",
      "92     \t [ 0.06405265 -0.60977111]. \t  0.956962194314388 \t 1.0313094844995494\n",
      "93     \t [-0.05377069  0.69117919]. \t  1.023633531731776 \t 1.0313094844995494\n",
      "94     \t [ 0.11859915 -0.74131591]. \t  1.0222504275276796 \t 1.0313094844995494\n",
      "95     \t [ 0.05893687 -0.67429058]. \t  1.0176516433964178 \t 1.0313094844995494\n",
      "96     \t [ 0.06729768 -0.67277052]. \t  1.0182236378018148 \t 1.0313094844995494\n",
      "97     \t [-0.13128912  0.7583142 ]. \t  1.0087090312084797 \t 1.0313094844995494\n",
      "98     \t [0.04153207 0.68156964]. \t  0.9597691484485329 \t 1.0313094844995494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-2.33693808 -0.71422734]. \t  -14.176193950859577 \t 1.0313094844995494\n",
      "100    \t [ 0.04466872 -0.5948565 ]. \t  0.933164347467142 \t 1.0313094844995494\n"
     ]
    }
   ],
   "source": [
    "### 6(f). Bayesian optimization runs (x20): STP DF1 run number = 6\n",
    "\n",
    "np.random.seed(run_num_6)\n",
    "surrogate_stp_df1_6 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_6 = GPGO(surrogate_stp_df1_6, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_6.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.995755627187805, -8.143853625262148)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(f). Training Regret Minimisation: run number = 6\n",
    "\n",
    "gp_output_6 = np.append(np.max(gpgo_gp_6.GP.y[0:n_init]),gpgo_gp_6.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_6 = np.append(np.max(gpgo_stp_df1_6.GP.y[0:n_init]),gpgo_stp_df1_6.GP.y[n_init:(n_init+max_iter)]) \n",
    "\n",
    "regret_gp_6 = np.log(y_global_orig - gp_output_6)\n",
    "regret_stp_df1_6 = np.log(y_global_orig - stp_df1_output_6)\n",
    "\n",
    "train_regret_gp_6 = min_max_array(regret_gp_6)\n",
    "train_regret_stp_df1_6 = min_max_array(regret_stp_df1_6)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 6\n",
    "min_train_regret_gp_6 = min(train_regret_gp_6)\n",
    "min_train_regret_stp_df1_6 = min(train_regret_stp_df1_6)\n",
    "\n",
    "min_train_regret_gp_6, min_train_regret_stp_df1_6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.08401759 -0.79057356]. \t  -5.778591021444629 \t -0.6139922708386365\n",
      "init   \t [-2.62778151 -0.16055863]. \t  -37.56206986588009 \t -0.6139922708386365\n",
      "init   \t [2.01152031 1.70798819]. \t  -29.692842569565112 \t -0.6139922708386365\n",
      "init   \t [1.36193391 1.07398489]. \t  -4.49224583043401 \t -0.6139922708386365\n",
      "init   \t [-1.3847696   0.57611717]. \t  -0.6139922708386365 \t -0.6139922708386365\n",
      "1      \t [-1.33546516 -1.33946176]. \t  -9.833389320646171 \t -0.6139922708386365\n",
      "2      \t [0.28388742 0.69494895]. \t  \u001b[92m0.49264738439852374\u001b[0m \t 0.49264738439852374\n",
      "3      \t [1.34037631 0.15528741]. \t  -2.4550945887683198 \t 0.49264738439852374\n",
      "4      \t [-0.87185042  1.09262019]. \t  -1.946473173185879 \t 0.49264738439852374\n",
      "5      \t [-1.05617976  0.1403836 ]. \t  -2.0860344394876034 \t 0.49264738439852374\n",
      "6      \t [0.72509874 0.89824792]. \t  -1.598956046224313 \t 0.49264738439852374\n",
      "7      \t [-2.46851413 -1.80673451]. \t  -55.844268727300246 \t 0.49264738439852374\n",
      "8      \t [-1.58749496 -0.58897969]. \t  -2.107227558534949 \t 0.49264738439852374\n",
      "9      \t [-0.06021823  0.4263303 ]. \t  \u001b[92m0.6060824258029998\u001b[0m \t 0.6060824258029998\n",
      "10     \t [-0.81834681  0.63697259]. \t  -0.3513396030642323 \t 0.6060824258029998\n",
      "11     \t [1.86938363 0.48547091]. \t  -2.745317403699821 \t 0.6060824258029998\n",
      "12     \t [0.36375857 0.43282206]. \t  -0.04176576799385168 \t 0.6060824258029998\n",
      "13     \t [-1.90154482  2.        ]. \t  -46.962495404220846 \t 0.6060824258029998\n",
      "14     \t [-0.09508776  1.23944548]. \t  -3.2131891034978453 \t 0.6060824258029998\n",
      "15     \t [ 1.9781961  -1.71049415]. \t  -22.623982917258957 \t 0.6060824258029998\n",
      "16     \t [ 0.12032623 -1.86380164]. \t  -34.20612263486066 \t 0.6060824258029998\n",
      "17     \t [ 2.90296293 -0.88025528]. \t  -80.81165676528063 \t 0.6060824258029998\n",
      "18     \t [1.42003423 0.58129848]. \t  -2.1906011694362113 \t 0.6060824258029998\n",
      "19     \t [ 0.77436659 -0.58444295]. \t  -0.36316671490529995 \t 0.6060824258029998\n",
      "20     \t [ 1.31343166 -0.54298105]. \t  -0.8173572114281388 \t 0.6060824258029998\n",
      "21     \t [ 1.01041903 -0.81376985]. \t  -0.53262560331891 \t 0.6060824258029998\n",
      "22     \t [-0.0848125   0.03703862]. \t  -0.02004286362349033 \t 0.6060824258029998\n",
      "23     \t [-1.2298219   0.84431664]. \t  -0.5421808330192731 \t 0.6060824258029998\n",
      "24     \t [2.90542942 0.9071926 ]. \t  -86.68689063945362 \t 0.6060824258029998\n",
      "25     \t [0.17074975 0.20096563]. \t  0.005864325293150258 \t 0.6060824258029998\n",
      "26     \t [-0.187739   -0.56880381]. \t  \u001b[92m0.6302681203753914\u001b[0m \t 0.6302681203753914\n",
      "27     \t [1.39416022 1.9784682 ]. \t  -50.677890879010995 \t 0.6302681203753914\n",
      "28     \t [-0.03130072 -0.72812491]. \t  \u001b[92m0.9696523141581839\u001b[0m \t 0.9696523141581839\n",
      "29     \t [-0.04562359 -0.58870442]. \t  0.8706647307812317 \t 0.9696523141581839\n",
      "30     \t [ 1.71523979 -0.09345485]. \t  -1.884849177923638 \t 0.9696523141581839\n",
      "31     \t [-0.53281432  1.71756302]. \t  -23.069246721273927 \t 0.9696523141581839\n",
      "32     \t [ 2.25589818 -1.79479828]. \t  -34.47555745554888 \t 0.9696523141581839\n",
      "33     \t [-0.36004187  0.78662898]. \t  0.7428213766085785 \t 0.9696523141581839\n",
      "34     \t [-1.87500732  1.5058791 ]. \t  -11.266393258109213 \t 0.9696523141581839\n",
      "35     \t [-2.06343644  1.0548814 ]. \t  -3.015443519141977 \t 0.9696523141581839\n",
      "36     \t [-2.92395011  1.78224008]. \t  -111.44648393053825 \t 0.9696523141581839\n",
      "37     \t [-1.73357352  0.94342778]. \t  -0.07520921053137669 \t 0.9696523141581839\n",
      "38     \t [-2.58195158  1.04187562]. \t  -29.776016537517318 \t 0.9696523141581839\n",
      "39     \t [-2.52711463 -0.53737245]. \t  -27.25506880824635 \t 0.9696523141581839\n",
      "40     \t [0.08151787 0.59227592]. \t  0.836177326986924 \t 0.9696523141581839\n",
      "41     \t [-2.66974222  1.32330721]. \t  -44.25179993477073 \t 0.9696523141581839\n",
      "42     \t [2.12310088 1.84371406]. \t  -42.42829347931966 \t 0.9696523141581839\n",
      "43     \t [1.20102993 1.13867345]. \t  -5.30654927068663 \t 0.9696523141581839\n",
      "44     \t [-1.26688507  0.95187126]. \t  -0.8421450545719095 \t 0.9696523141581839\n",
      "45     \t [-0.14819344 -0.78051211]. \t  0.7497995212476773 \t 0.9696523141581839\n",
      "46     \t [ 2.20702255 -0.10006412]. \t  -7.921342044964864 \t 0.9696523141581839\n",
      "47     \t [ 1.22830956 -0.33254151]. \t  -1.5976329368265905 \t 0.9696523141581839\n",
      "48     \t [ 1.8809176  -1.75878782]. \t  -25.220761712644656 \t 0.9696523141581839\n",
      "49     \t [1.21250649 1.14353358]. \t  -5.39680775060438 \t 0.9696523141581839\n",
      "50     \t [-0.50423155  1.21533856]. \t  -3.0924040456911426 \t 0.9696523141581839\n",
      "51     \t [-1.48759749 -0.07008751]. \t  -2.2648817888920205 \t 0.9696523141581839\n",
      "52     \t [ 0.85477092 -0.22929246]. \t  -1.5362746925688928 \t 0.9696523141581839\n",
      "53     \t [1.87037849 0.33092018]. \t  -2.7929414657368534 \t 0.9696523141581839\n",
      "54     \t [ 2.85999473 -1.45185161]. \t  -79.82478357806254 \t 0.9696523141581839\n",
      "55     \t [ 1.85806924 -0.84590557]. \t  -0.1101598636411667 \t 0.9696523141581839\n",
      "56     \t [ 1.41768042 -0.76215083]. \t  -0.2084062749618627 \t 0.9696523141581839\n",
      "57     \t [-0.68608189  0.05452516]. \t  -1.4030431217535346 \t 0.9696523141581839\n",
      "58     \t [ 0.10777843 -0.72889819]. \t  \u001b[92m1.028460684445148\u001b[0m \t 1.028460684445148\n",
      "59     \t [-0.00860593 -0.78279415]. \t  0.9421017861585248 \t 1.028460684445148\n",
      "60     \t [-0.71228017  1.56528679]. \t  -14.629359817589183 \t 1.028460684445148\n",
      "61     \t [-0.08972386  0.78315247]. \t  0.9868291510041477 \t 1.028460684445148\n",
      "62     \t [2.83701769 0.95688008]. \t  -72.36055116619683 \t 1.028460684445148\n",
      "63     \t [ 2.89550491 -0.68849145]. \t  -79.37229654354084 \t 1.028460684445148\n",
      "64     \t [ 1.12307156 -0.00925813]. \t  -2.362471481871678 \t 1.028460684445148\n",
      "65     \t [-2.31629345  0.35737844]. \t  -11.21801410637446 \t 1.028460684445148\n",
      "66     \t [-2.20651298 -0.45591465]. \t  -8.51287292237533 \t 1.028460684445148\n",
      "67     \t [ 1.90233713 -0.76710649]. \t  -0.34328865900458594 \t 1.028460684445148\n",
      "68     \t [ 0.13684218 -0.73710472]. \t  1.0191904180533808 \t 1.028460684445148\n",
      "69     \t [0.03967151 0.71908542]. \t  0.964015252325956 \t 1.028460684445148\n",
      "70     \t [-2.1289087   0.69118165]. \t  -3.5555779832535146 \t 1.028460684445148\n",
      "71     \t [2.27601261 0.04318991]. \t  -10.795542546218192 \t 1.028460684445148\n",
      "72     \t [ 0.10382921 -0.75539975]. \t  1.0156004830014775 \t 1.028460684445148\n",
      "73     \t [-1.36389509  1.56942999]. \t  -14.594391196357211 \t 1.028460684445148\n",
      "74     \t [-2.07828263 -0.23852778]. \t  -5.24056221098302 \t 1.028460684445148\n",
      "75     \t [-0.91419713 -0.72463519]. \t  -1.7357666953058564 \t 1.028460684445148\n",
      "76     \t [-0.03530569  0.65626515]. \t  0.9989683250865011 \t 1.028460684445148\n",
      "77     \t [-0.15999772  0.65753484]. \t  0.9858726103392562 \t 1.028460684445148\n",
      "78     \t [-0.14352453  0.97269335]. \t  0.26196003421164393 \t 1.028460684445148\n",
      "79     \t [1.68582026 0.37829297]. \t  -2.2051799001338055 \t 1.028460684445148\n",
      "80     \t [ 1.53943768 -1.39690109]. \t  -7.396929103144068 \t 1.028460684445148\n",
      "81     \t [0.29850144 0.75169909]. \t  0.41871435526569234 \t 1.028460684445148\n",
      "82     \t [-2.05853931 -1.20006989]. \t  -9.6113730410618 \t 1.028460684445148\n",
      "83     \t [2.70584702 0.07317875]. \t  -47.71789337336684 \t 1.028460684445148\n",
      "84     \t [ 1.61813427 -1.41849948]. \t  -7.910856169388076 \t 1.028460684445148\n",
      "85     \t [ 0.04472985 -0.76885355]. \t  0.9931731482258748 \t 1.028460684445148\n",
      "86     \t [-1.6924592  -0.31644914]. \t  -2.23660983264908 \t 1.028460684445148\n",
      "87     \t [-0.63113889 -1.01439375]. \t  -2.040767516238305 \t 1.028460684445148\n",
      "88     \t [-0.49715951  0.23486027]. \t  -0.5401806250858956 \t 1.028460684445148\n",
      "89     \t [1.99126132 0.79967047]. \t  -4.294183455666888 \t 1.028460684445148\n",
      "90     \t [-2.83890557  0.13291947]. \t  -69.88361423184833 \t 1.028460684445148\n",
      "91     \t [ 0.11791946 -0.64920987]. \t  0.9966739424163479 \t 1.028460684445148\n",
      "92     \t [ 0.21363143 -0.10393113]. \t  -0.1132682463885391 \t 1.028460684445148\n",
      "93     \t [0.02640109 1.95463056]. \t  -43.15941460461513 \t 1.028460684445148\n",
      "94     \t [ 0.17675447 -0.67155499]. \t  0.9861619164999932 \t 1.028460684445148\n",
      "95     \t [-0.10512433  0.68224647]. \t  1.0230002426460265 \t 1.028460684445148\n",
      "96     \t [ 0.14167691 -0.70925847]. \t  1.0210024037349084 \t 1.028460684445148\n",
      "97     \t [ 0.19176328 -0.71077231]. \t  0.9919225433847412 \t 1.028460684445148\n",
      "98     \t [ 1.68596276 -1.4508121 ]. \t  -8.914251805503532 \t 1.028460684445148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [ 0.08011729 -0.70387242]. \t  \u001b[92m1.0307203581405284\u001b[0m \t 1.0307203581405284\n",
      "100    \t [-0.13987136  0.65554394]. \t  0.9944900394745256 \t 1.0307203581405284\n"
     ]
    }
   ],
   "source": [
    "### 6(g). Bayesian optimization runs (x20): GP run number = 7\n",
    "\n",
    "np.random.seed(run_num_7)\n",
    "surrogate_gp_7 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_7 = GPGO(surrogate_gp_7, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_7.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.08401759 -0.79057356]. \t  -5.778591021444629 \t -0.6139922708386365\n",
      "init   \t [-2.62778151 -0.16055863]. \t  -37.56206986588009 \t -0.6139922708386365\n",
      "init   \t [2.01152031 1.70798819]. \t  -29.692842569565112 \t -0.6139922708386365\n",
      "init   \t [1.36193391 1.07398489]. \t  -4.49224583043401 \t -0.6139922708386365\n",
      "init   \t [-1.3847696   0.57611717]. \t  -0.6139922708386365 \t -0.6139922708386365\n",
      "1      \t [-1.0523031  -1.36736548]. \t  -10.250012355108435 \t -0.6139922708386365\n",
      "2      \t [-0.00964282  0.81457352]. \t  \u001b[92m0.9005146102861314\u001b[0m \t 0.9005146102861314\n",
      "3      \t [ 1.58590121 -0.38367153]. \t  -0.9690501919380823 \t 0.9005146102861314\n",
      "4      \t [-2.6151798 -2.       ]. \t  -88.99336105538234 \t 0.9005146102861314\n",
      "5      \t [-1.24522645 -0.39751571]. \t  -2.3587799728328345 \t 0.9005146102861314\n",
      "6      \t [-1.18764406  2.        ]. \t  -48.024141660342835 \t 0.9005146102861314\n",
      "7      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.9005146102861314\n",
      "8      \t [ 0.47199288 -2.        ]. \t  -47.84658640880924 \t 0.9005146102861314\n",
      "9      \t [3.         0.43395724]. \t  -109.59045218442704 \t 0.9005146102861314\n",
      "10     \t [ 8.07319558e-01 -6.62592818e-04]. \t  -1.8067375122638847 \t 0.9005146102861314\n",
      "11     \t [0.70745732 2.        ]. \t  -50.932647027783666 \t 0.9005146102861314\n",
      "12     \t [-3.  2.]. \t  -150.89999999999998 \t 0.9005146102861314\n",
      "13     \t [-0.74367587  0.70045221]. \t  -0.10572011759545985 \t 0.9005146102861314\n",
      "14     \t [3. 2.]. \t  -162.89999999999998 \t 0.9005146102861314\n",
      "15     \t [ 1.16742972 -1.01801556]. \t  -1.3569651783283871 \t 0.9005146102861314\n",
      "16     \t [ 0.05319393 -0.79263132]. \t  \u001b[92m0.9650545701557166\u001b[0m \t 0.9650545701557166\n",
      "17     \t [-0.09323255  0.09346688]. \t  0.008742323012917948 \t 0.9650545701557166\n",
      "18     \t [ 0.80093405 -0.65062426]. \t  -0.2922095730130858 \t 0.9650545701557166\n",
      "19     \t [-3.         -0.98922473]. \t  -111.78377420604313 \t 0.9650545701557166\n",
      "20     \t [-1.83310253 -0.17586189]. \t  -2.578993282033559 \t 0.9650545701557166\n",
      "21     \t [-1.58305934 -0.92510625]. \t  -3.052763007238463 \t 0.9650545701557166\n",
      "22     \t [-1.45912167 -2.        ]. \t  -53.1323467225874 \t 0.9650545701557166\n",
      "23     \t [-0.51819643 -0.85180341]. \t  -0.5740666796276761 \t 0.9650545701557166\n",
      "24     \t [ 2.30400713 -0.8086861 ]. \t  -9.151559884793004 \t 0.9650545701557166\n",
      "25     \t [ 1.71783082 -0.82719975]. \t  0.2026793879761999 \t 0.9650545701557166\n",
      "26     \t [0.50465785 0.61581174]. \t  -0.2571364925215145 \t 0.9650545701557166\n",
      "27     \t [ 1.59659205 -2.        ]. \t  -46.878876738441086 \t 0.9650545701557166\n",
      "28     \t [1.56502146 2.        ]. \t  -53.227038265862085 \t 0.9650545701557166\n",
      "29     \t [1.82737869 0.7759856 ]. \t  -2.8121281511139276 \t 0.9650545701557166\n",
      "30     \t [-0.29774849  2.        ]. \t  -47.74284685623907 \t 0.9650545701557166\n",
      "31     \t [-0.22770433 -1.31806273]. \t  -5.625466389443138 \t 0.9650545701557166\n",
      "32     \t [-1.40802701  1.16505305]. \t  -2.5733787667562193 \t 0.9650545701557166\n",
      "33     \t [-3.         0.8495651]. \t  -105.54801621458175 \t 0.9650545701557166\n",
      "34     \t [ 3.        -0.7112374]. \t  -105.76642509693356 \t 0.9650545701557166\n",
      "35     \t [ 2.02381093 -0.43152004]. \t  -2.5782048376176085 \t 0.9650545701557166\n",
      "36     \t [ 0.54069461 -1.07266352]. \t  -1.111421506884251 \t 0.9650545701557166\n",
      "37     \t [-1.99506406  1.51655833]. \t  -12.60460470599817 \t 0.9650545701557166\n",
      "38     \t [1.36363565 0.47521566]. \t  -2.2686653058811923 \t 0.9650545701557166\n",
      "39     \t [-0.69058138  0.23529211]. \t  -1.0944717902889245 \t 0.9650545701557166\n",
      "40     \t [-1.81266858  0.97426317]. \t  -0.33664831492143366 \t 0.9650545701557166\n",
      "41     \t [-0.07075134  0.54544505]. \t  0.8546122266219682 \t 0.9650545701557166\n",
      "42     \t [-0.60160444 -2.        ]. \t  -50.391640873173365 \t 0.9650545701557166\n",
      "43     \t [-1.79264423 -0.556505  ]. \t  -2.372203991172317 \t 0.9650545701557166\n",
      "44     \t [ 1.99350425 -1.33453974]. \t  -6.554991161393868 \t 0.9650545701557166\n",
      "45     \t [-1.97927672  2.        ]. \t  -47.523629693928726 \t 0.9650545701557166\n",
      "46     \t [ 0.26695097 -0.4742503 ]. \t  0.5494035965369111 \t 0.9650545701557166\n",
      "47     \t [2.54513756 1.1962915 ]. \t  -33.909352988407875 \t 0.9650545701557166\n",
      "48     \t [-0.49491218  1.07355987]. \t  -1.030529749627618 \t 0.9650545701557166\n",
      "49     \t [-0.25594326 -0.46700626]. \t  0.309480767136022 \t 0.9650545701557166\n",
      "50     \t [-1.94607425 -1.42069432]. \t  -14.121807871538687 \t 0.9650545701557166\n",
      "51     \t [1.85030903 1.15982463]. \t  -6.459768169623119 \t 0.9650545701557166\n",
      "52     \t [1.80114057 0.15623108]. \t  -2.4422657173096534 \t 0.9650545701557166\n",
      "53     \t [-0.376995    0.69131533]. \t  0.7316330161808389 \t 0.9650545701557166\n",
      "54     \t [ 2.28007349 -2.        ]. \t  -54.313554355085685 \t 0.9650545701557166\n",
      "55     \t [0.6211409  1.16045338]. \t  -3.837897974551986 \t 0.9650545701557166\n",
      "56     \t [-3. -2.]. \t  -162.89999999999998 \t 0.9650545701557166\n",
      "57     \t [-2.15490749  0.54546397]. \t  -4.657447105829697 \t 0.9650545701557166\n",
      "58     \t [-0.05563568  0.71379795]. \t  \u001b[92m1.0269898587095674\u001b[0m \t 1.0269898587095674\n",
      "59     \t [ 0.00956615 -0.69001644]. \t  1.0039542667024293 \t 1.0269898587095674\n",
      "60     \t [3.         1.24640943]. \t  -116.07898464092456 \t 1.0269898587095674\n",
      "61     \t [-0.12083983  0.71593489]. \t  \u001b[92m1.0279198367516056\u001b[0m \t 1.0279198367516056\n",
      "62     \t [-0.16482558  0.69299724]. \t  1.0055360366944972 \t 1.0279198367516056\n",
      "63     \t [-2.40316883  1.20302626]. \t  -16.96475044450596 \t 1.0279198367516056\n",
      "64     \t [ 3.         -1.39735373]. \t  -112.14809618801132 \t 1.0279198367516056\n",
      "65     \t [-0.02749477  0.7013684 ]. \t  1.0160000153662954 \t 1.0279198367516056\n",
      "66     \t [2.28264296 0.46336302]. \t  -11.365159369966651 \t 1.0279198367516056\n",
      "67     \t [ 0.14151051 -0.72874175]. \t  1.0200031415993134 \t 1.0279198367516056\n",
      "68     \t [ 0.03738013 -0.67289595]. \t  1.010652408902623 \t 1.0279198367516056\n",
      "69     \t [-0.00650173 -0.73219164]. \t  0.9898562311274334 \t 1.0279198367516056\n",
      "70     \t [-0.14418795  0.7370367 ]. \t  1.0165428974149981 \t 1.0279198367516056\n",
      "71     \t [-0.01266061 -0.63529449]. \t  0.9541431297398015 \t 1.0279198367516056\n",
      "72     \t [-0.11589919  0.72747266]. \t  1.027546701285518 \t 1.0279198367516056\n",
      "73     \t [-0.09284991  0.691768  ]. \t  \u001b[92m1.0280604222780865\u001b[0m \t 1.0280604222780865\n",
      "74     \t [0.07501969 1.4958159 ]. \t  -11.209802398821088 \t 1.0280604222780865\n",
      "75     \t [-0.12961192  0.78967007]. \t  0.9746578230396217 \t 1.0280604222780865\n",
      "76     \t [ 0.00210442 -0.69079549]. \t  0.9993563582267534 \t 1.0280604222780865\n",
      "77     \t [-0.11405309  0.69146872]. \t  1.025272960563238 \t 1.0280604222780865\n",
      "78     \t [-0.1664499   0.73954405]. \t  1.0050716528220085 \t 1.0280604222780865\n",
      "79     \t [ 0.28517434 -0.69043897]. \t  0.8831368081575356 \t 1.0280604222780865\n",
      "80     \t [-0.10574189  0.68471494]. \t  1.0240546023527872 \t 1.0280604222780865\n",
      "81     \t [-0.00172444 -0.71596345]. \t  0.9981180631013484 \t 1.0280604222780865\n",
      "82     \t [-0.10105013  0.70506234]. \t  \u001b[92m1.03058739145254\u001b[0m \t 1.03058739145254\n",
      "83     \t [ 0.05517221 -0.65148909]. \t  1.0009492100737793 \t 1.03058739145254\n",
      "84     \t [ 0.24255795 -0.70702552]. \t  0.9433583951857288 \t 1.03058739145254\n",
      "85     \t [-0.03873627  0.68960111]. \t  1.0183240381645622 \t 1.03058739145254\n",
      "86     \t [-2.56795396 -1.45296792]. \t  -43.75872177628424 \t 1.03058739145254\n",
      "87     \t [-0.21802151  0.76881411]. \t  0.9490147643765046 \t 1.03058739145254\n",
      "88     \t [ 0.16177498 -0.78221838]. \t  0.9732355202540902 \t 1.03058739145254\n",
      "89     \t [-0.09780786  0.7290173 ]. \t  1.0292695090514228 \t 1.03058739145254\n",
      "90     \t [-0.16503365  0.66347492]. \t  0.9877976680313559 \t 1.03058739145254\n",
      "91     \t [ 0.08897295 -0.71729123]. \t  \u001b[92m1.0314444285407813\u001b[0m \t 1.0314444285407813\n",
      "92     \t [ 0.03651761 -0.63769763]. \t  0.9831060686307465 \t 1.0314444285407813\n",
      "93     \t [-3.          0.06298013]. \t  -108.695256544631 \t 1.0314444285407813\n",
      "94     \t [ 0.10227525 -0.69315387]. \t  1.0277540827238332 \t 1.0314444285407813\n",
      "95     \t [-0.10512432  0.68224647]. \t  1.0230002461069079 \t 1.0314444285407813\n",
      "96     \t [ 0.09574328 -0.69316025]. \t  1.0283490326889713 \t 1.0314444285407813\n",
      "97     \t [ 0.09438433 -0.69266418]. \t  1.028274655784549 \t 1.0314444285407813\n",
      "98     \t [-0.07956272  0.73036493]. \t  1.028401937743618 \t 1.0314444285407813\n",
      "99     \t [ 0.05644929 -0.69023804]. \t  1.0240162177876655 \t 1.0314444285407813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [-0.13986608  0.65554586]. \t  0.9944940488528364 \t 1.0314444285407813\n"
     ]
    }
   ],
   "source": [
    "### 6(g). Bayesian optimization runs (x20): STP DF1 run number = 7\n",
    "\n",
    "np.random.seed(run_num_7)\n",
    "surrogate_stp_df1_7 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_7 = GPGO(surrogate_stp_df1_7, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_7.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.035995711203121, -8.76840538708832)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(g). Training Regret Minimisation: run number = 7\n",
    "\n",
    "gp_output_7 = np.append(np.max(gpgo_gp_7.GP.y[0:n_init]),gpgo_gp_7.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_7 = np.append(np.max(gpgo_stp_df1_7.GP.y[0:n_init]),gpgo_stp_df1_7.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_7 = np.log(y_global_orig - gp_output_7)\n",
    "regret_stp_df1_7 = np.log(y_global_orig - stp_df1_output_7)\n",
    "\n",
    "train_regret_gp_7 = min_max_array(regret_gp_7)\n",
    "train_regret_stp_df1_7 = min_max_array(regret_stp_df1_7)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 7\n",
    "min_train_regret_gp_7 = min(train_regret_gp_7)\n",
    "min_train_regret_stp_df1_7 = min(train_regret_stp_df1_7)\n",
    "\n",
    "min_train_regret_gp_7, min_train_regret_stp_df1_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 2.15736364 -1.34172202]. \t  -9.601052537803168 \t -7.666172015731641\n",
      "init   \t [-0.09914425  1.68410906]. \t  -20.703904034081347 \t -7.666172015731641\n",
      "init   \t [-0.42866135 -1.77015963]. \t  -28.16551838713855 \t -7.666172015731641\n",
      "init   \t [2.55004461 0.63040615]. \t  -29.518046516003174 \t -7.666172015731641\n",
      "init   \t [-2.20228297  0.1337957 ]. \t  -7.666172015731641 \t -7.666172015731641\n",
      "1      \t [-3.  2.]. \t  -150.89999999999998 \t -7.666172015731641\n",
      "2      \t [-2.45284122 -0.68408505]. \t  -21.32627431811575 \t -7.666172015731641\n",
      "3      \t [-1.39056244  0.19319009]. \t  \u001b[92m-1.880303088279193\u001b[0m \t -1.880303088279193\n",
      "4      \t [ 1.94663326 -1.97602245]. \t  -44.66089906080664 \t -1.880303088279193\n",
      "5      \t [ 2.75412488 -0.8684851 ]. \t  -51.85570808445839 \t -1.880303088279193\n",
      "6      \t [ 1.38534351 -0.73569436]. \t  \u001b[92m-0.285782363998213\u001b[0m \t -0.285782363998213\n",
      "7      \t [ 1.68050253 -0.96705305]. \t  \u001b[92m-0.18810311592823578\u001b[0m \t -0.18810311592823578\n",
      "8      \t [2.62650131 2.        ]. \t  -90.3412744713344 \t -0.18810311592823578\n",
      "9      \t [0.81346548 0.11789072]. \t  -1.8650190244217064 \t -0.18810311592823578\n",
      "10     \t [ 1.50506836 -0.59414249]. \t  -0.3519637522671861 \t -0.18810311592823578\n",
      "11     \t [-0.11274893 -0.15319419]. \t  \u001b[92m0.023887674250720622\u001b[0m \t 0.023887674250720622\n",
      "12     \t [0.26414565 0.03800548]. \t  -0.2732512441895365 \t 0.023887674250720622\n",
      "13     \t [ 0.30772436 -0.24687957]. \t  -0.055319879352220436 \t 0.023887674250720622\n",
      "14     \t [-1.38597741 -0.2425972 ]. \t  -2.412178921602959 \t 0.023887674250720622\n",
      "15     \t [-2.15440924 -1.95302742]. \t  -53.80228209863965 \t 0.023887674250720622\n",
      "16     \t [-0.92584974  0.04856652]. \t  -2.0413112125239743 \t 0.023887674250720622\n",
      "17     \t [1.08103841 0.95799388]. \t  -3.0722585359705255 \t 0.023887674250720622\n",
      "18     \t [0.34362834 0.57027172]. \t  \u001b[92m0.23824181581544757\u001b[0m \t 0.23824181581544757\n",
      "19     \t [ 0.09254867 -0.82665087]. \t  \u001b[92m0.9079269354929334\u001b[0m \t 0.9079269354929334\n",
      "20     \t [-0.27991639 -0.43021072]. \t  0.18220100143749818 \t 0.9079269354929334\n",
      "21     \t [ 0.06162566 -0.63272845]. \t  \u001b[92m0.984107447681622\u001b[0m \t 0.984107447681622\n",
      "22     \t [0.62548223 0.4399135 ]. \t  -0.9143162834856869 \t 0.984107447681622\n",
      "23     \t [0.61059229 0.86114716]. \t  -0.9759145828769594 \t 0.984107447681622\n",
      "24     \t [ 0.36140749 -0.99469356]. \t  -0.08599704622828556 \t 0.984107447681622\n",
      "25     \t [1.59398489 0.46741023]. \t  -2.1359006278927257 \t 0.984107447681622\n",
      "26     \t [2.3472743  0.95180161]. \t  -15.935014738159248 \t 0.984107447681622\n",
      "27     \t [ 0.27736173 -0.69105466]. \t  0.8942155281777346 \t 0.984107447681622\n",
      "28     \t [-2.83363817 -1.56052925]. \t  -87.68956144444046 \t 0.984107447681622\n",
      "29     \t [2.01315709 0.8520662 ]. \t  -4.82732176070124 \t 0.984107447681622\n",
      "30     \t [-0.84068572  0.71114656]. \t  -0.2980164950386468 \t 0.984107447681622\n",
      "31     \t [-1.28302975  0.92779741]. \t  -0.7112521424035765 \t 0.984107447681622\n",
      "32     \t [ 1.57891864 -0.69599754]. \t  0.012844712538121805 \t 0.984107447681622\n",
      "33     \t [-1.75151176  0.136266  ]. \t  -1.8197915492226608 \t 0.984107447681622\n",
      "34     \t [-2.68858331  1.39211241]. \t  -48.61353853796264 \t 0.984107447681622\n",
      "35     \t [-1.88504805  0.8079451 ]. \t  -0.22383587188148946 \t 0.984107447681622\n",
      "36     \t [-1.98292996 -1.33662339]. \t  -11.795845800026607 \t 0.984107447681622\n",
      "37     \t [-1.70529343 -0.83921737]. \t  -2.668606885578014 \t 0.984107447681622\n",
      "38     \t [0.25944875 0.71903114]. \t  0.5524505756266157 \t 0.984107447681622\n",
      "39     \t [-0.36634618  0.81932711]. \t  0.6829685458083847 \t 0.984107447681622\n",
      "40     \t [-0.08113453  0.65666795]. \t  \u001b[92m1.0081113821796541\u001b[0m \t 1.0081113821796541\n",
      "41     \t [-0.39874869 -1.35290175]. \t  -7.202970955647393 \t 1.0081113821796541\n",
      "42     \t [-0.01439995  0.68472095]. \t  1.0051475131865806 \t 1.0081113821796541\n",
      "43     \t [-1.30542686 -1.23499675]. \t  -7.184102335464931 \t 1.0081113821796541\n",
      "44     \t [ 0.41314613 -0.12590308]. \t  -0.5088154834814345 \t 1.0081113821796541\n",
      "45     \t [ 0.18637766 -0.68447214]. \t  0.9871752788265049 \t 1.0081113821796541\n",
      "46     \t [ 2.73751777 -1.58384817]. \t  -63.12947737221396 \t 1.0081113821796541\n",
      "47     \t [ 2.7816628  -1.52867164]. \t  -67.88545656787642 \t 1.0081113821796541\n",
      "48     \t [-0.90893437 -0.12548341]. \t  -2.1113334283255436 \t 1.0081113821796541\n",
      "49     \t [ 1.95641295 -1.64023836]. \t  -18.218399445018296 \t 1.0081113821796541\n",
      "50     \t [-1.02478042  1.81931929]. \t  -30.989005531238874 \t 1.0081113821796541\n",
      "51     \t [-0.191289    0.65401054]. \t  0.9606425892163124 \t 1.0081113821796541\n",
      "52     \t [-0.07342992  1.56952848]. \t  -14.326323385158375 \t 1.0081113821796541\n",
      "53     \t [-2.03622627 -0.5316377 ]. \t  -4.5144106751069355 \t 1.0081113821796541\n",
      "54     \t [ 0.15720853 -0.77371416]. \t  0.985139697999519 \t 1.0081113821796541\n",
      "55     \t [ 2.3674707  -0.95478848]. \t  -12.558268257669965 \t 1.0081113821796541\n",
      "56     \t [-0.11072492  0.69222741]. \t  \u001b[92m1.0261877342145824\u001b[0m \t 1.0261877342145824\n",
      "57     \t [1.11645763 0.45459149]. \t  -2.2204213620977233 \t 1.0261877342145824\n",
      "58     \t [1.01167788 1.79661852]. \t  -32.833526076679874 \t 1.0261877342145824\n",
      "59     \t [-0.09761605  0.63337487]. \t  0.9848279315019416 \t 1.0261877342145824\n",
      "60     \t [ 0.83547399 -0.15690195]. \t  -1.6551176888592571 \t 1.0261877342145824\n",
      "61     \t [-2.79346345  0.37432644]. \t  -60.20274638578556 \t 1.0261877342145824\n",
      "62     \t [-1.69634194  1.31602787]. \t  -4.902074164919207 \t 1.0261877342145824\n",
      "63     \t [ 1.86914654 -0.47423942]. \t  -0.973261012902824 \t 1.0261877342145824\n",
      "64     \t [1.43918076 0.63131272]. \t  -2.187520017942127 \t 1.0261877342145824\n",
      "65     \t [ 0.03735981 -0.63763802]. \t  0.9833355971500057 \t 1.0261877342145824\n",
      "66     \t [-1.25866562  0.74064306]. \t  -0.46893685124985574 \t 1.0261877342145824\n",
      "67     \t [-0.59539977  0.18432478]. \t  -0.9279127870785949 \t 1.0261877342145824\n",
      "68     \t [1.56089966 1.59365762]. \t  -20.230535168224364 \t 1.0261877342145824\n",
      "69     \t [ 0.58105305 -0.85918046]. \t  0.14834749024527716 \t 1.0261877342145824\n",
      "70     \t [0.01163155 0.73140564]. \t  0.9860642991040677 \t 1.0261877342145824\n",
      "71     \t [-2.72945737  1.85337681]. \t  -79.47251386809741 \t 1.0261877342145824\n",
      "72     \t [ 0.09376014 -0.79321885]. \t  0.9726039494240669 \t 1.0261877342145824\n",
      "73     \t [ 0.03838711 -0.72312861]. \t  1.0197687088584577 \t 1.0261877342145824\n",
      "74     \t [ 1.67659409 -0.4856812 ]. \t  -0.5190294872677508 \t 1.0261877342145824\n",
      "75     \t [ 0.65497601 -0.63708545]. \t  0.026023341259308053 \t 1.0261877342145824\n",
      "76     \t [-2.5557718   0.00609621]. \t  -29.411267762074274 \t 1.0261877342145824\n",
      "77     \t [ 2.89056018 -1.64046402]. \t  -94.71242552040957 \t 1.0261877342145824\n",
      "78     \t [2.944611   0.03060023]. \t  -94.1811788676729 \t 1.0261877342145824\n",
      "79     \t [-0.56975874  0.51309932]. \t  -0.020422117668913664 \t 1.0261877342145824\n",
      "80     \t [-0.12431882 -1.46455016]. \t  -10.06626966420452 \t 1.0261877342145824\n",
      "81     \t [-1.65247482 -1.45342633]. \t  -13.852746299715946 \t 1.0261877342145824\n",
      "82     \t [-0.11732764  0.05489794]. \t  -0.0362061759612077 \t 1.0261877342145824\n",
      "83     \t [ 0.03537613 -0.71714795]. \t  1.0195492316987511 \t 1.0261877342145824\n",
      "84     \t [-0.03842312 -0.65430726]. \t  0.9482906063026056 \t 1.0261877342145824\n",
      "85     \t [ 0.05103009 -0.714971  ]. \t  1.0255827024106312 \t 1.0261877342145824\n",
      "86     \t [-0.08150217  0.71946371]. \t  \u001b[92m1.0309170116011364\u001b[0m \t 1.0309170116011364\n",
      "87     \t [ 0.85014915 -0.33243115]. \t  -1.2440728183198158 \t 1.0309170116011364\n",
      "88     \t [2.69731073 1.96317456]. \t  -95.60763788601668 \t 1.0309170116011364\n",
      "89     \t [ 0.90517295 -1.31583353]. \t  -5.925438803067122 \t 1.0309170116011364\n",
      "90     \t [-1.87296829 -1.37097855]. \t  -11.759959774359984 \t 1.0309170116011364\n",
      "91     \t [ 1.71456785 -1.62276934]. \t  -16.501990466108854 \t 1.0309170116011364\n",
      "92     \t [-0.32033034 -1.21793046]. \t  -3.6467801935435817 \t 1.0309170116011364\n",
      "93     \t [ 0.89958323 -0.44870824]. \t  -0.9915386432992231 \t 1.0309170116011364\n",
      "94     \t [ 0.05507365 -0.69316663]. \t  1.024537974002799 \t 1.0309170116011364\n",
      "95     \t [ 0.21061337 -0.75260463]. \t  0.9675364297314435 \t 1.0309170116011364\n",
      "96     \t [2.79072263 0.77458703]. \t  -62.44174776233982 \t 1.0309170116011364\n",
      "97     \t [0.06285752 1.76844385]. \t  -26.739721181942347 \t 1.0309170116011364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98     \t [ 0.11013293 -0.63027454]. \t  0.9789717496869259 \t 1.0309170116011364\n",
      "99     \t [-0.81967392 -1.65084135]. \t  -22.00119453056065 \t 1.0309170116011364\n",
      "100    \t [-0.07542143  0.71838228]. \t  1.0304623619635795 \t 1.0309170116011364\n"
     ]
    }
   ],
   "source": [
    "### 6(h). Bayesian optimization runs (x20): GP run number = 8\n",
    "\n",
    "np.random.seed(run_num_8)\n",
    "surrogate_gp_8 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_8 = GPGO(surrogate_gp_8, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_8.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 2.15736364 -1.34172202]. \t  -9.601052537803168 \t -7.666172015731641\n",
      "init   \t [-0.09914425  1.68410906]. \t  -20.703904034081347 \t -7.666172015731641\n",
      "init   \t [-0.42866135 -1.77015963]. \t  -28.16551838713855 \t -7.666172015731641\n",
      "init   \t [2.55004461 0.63040615]. \t  -29.518046516003174 \t -7.666172015731641\n",
      "init   \t [-2.20228297  0.1337957 ]. \t  -7.666172015731641 \t -7.666172015731641\n",
      "1      \t [-3.  2.]. \t  -150.89999999999998 \t -7.666172015731641\n",
      "2      \t [-3.       -1.537427]. \t  -126.40551991097128 \t -7.666172015731641\n",
      "3      \t [-0.80863622  0.0850813 ]. \t  \u001b[92m-1.7133123173802882\u001b[0m \t -1.7133123173802882\n",
      "4      \t [3. 2.]. \t  -162.89999999999998 \t -1.7133123173802882\n",
      "5      \t [1.0942692  0.03005864]. \t  -2.3802454876790593 \t -1.7133123173802882\n",
      "6      \t [ 3.         -0.51507007]. \t  -106.57513146993162 \t -1.7133123173802882\n",
      "7      \t [ 1.34202397 -2.        ]. \t  -47.655622661943674 \t -1.7133123173802882\n",
      "8      \t [1.3570817  1.10500068]. \t  -4.905261686208551 \t -1.7133123173802882\n",
      "9      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.7133123173802882\n",
      "10     \t [ 1.644905   -0.77507679]. \t  \u001b[92m0.18259623065823194\u001b[0m \t 0.18259623065823194\n",
      "11     \t [-1.33114318  1.06076271]. \t  -1.5002957231418015 \t 0.18259623065823194\n",
      "12     \t [-1.42793361 -2.        ]. \t  -53.106803841003895 \t 0.18259623065823194\n",
      "13     \t [0.13980165 0.63012159]. \t  \u001b[92m0.7921374802295817\u001b[0m \t 0.7921374802295817\n",
      "14     \t [-1.14473875  2.        ]. \t  -48.09616740838792 \t 0.7921374802295817\n",
      "15     \t [1.72276593 0.36468228]. \t  -2.2551223225653803 \t 0.7921374802295817\n",
      "16     \t [-1.5021558   0.41093497]. \t  -0.984429903506865 \t 0.7921374802295817\n",
      "17     \t [ 0.02465971 -0.56047802]. \t  \u001b[92m0.873207316774831\u001b[0m \t 0.873207316774831\n",
      "18     \t [-3.          0.33835031]. \t  -107.47944889344564 \t 0.873207316774831\n",
      "19     \t [-1.57258851 -0.67062018]. \t  -2.1550763042287837 \t 0.873207316774831\n",
      "20     \t [0.97258088 2.        ]. \t  -52.13195531549357 \t 0.873207316774831\n",
      "21     \t [-0.67516797  1.00326326]. \t  -0.767549193285612 \t 0.873207316774831\n",
      "22     \t [-0.70312777 -0.77980116]. \t  -1.09958537631734 \t 0.873207316774831\n",
      "23     \t [-0.01397423 -0.04057734]. \t  0.005227165543943883 \t 0.873207316774831\n",
      "24     \t [0.98561265 0.71088836]. \t  -1.9103492515498115 \t 0.873207316774831\n",
      "25     \t [-1.79913552 -0.21166377]. \t  -2.4593254607915593 \t 0.873207316774831\n",
      "26     \t [ 1.15185371 -1.06103258]. \t  -1.7332218299845432 \t 0.873207316774831\n",
      "27     \t [-1.92118921  0.84753928]. \t  -0.4784208768186261 \t 0.873207316774831\n",
      "28     \t [ 1.71657225 -1.20166589]. \t  -2.582966448420244 \t 0.873207316774831\n",
      "29     \t [ 0.74108775 -0.65077734]. \t  -0.15975446988704145 \t 0.873207316774831\n",
      "30     \t [ 0.35650559 -1.32800487]. \t  -5.388414600781957 \t 0.873207316774831\n",
      "31     \t [-0.35952871  0.55458117]. \t  0.5685797665813604 \t 0.873207316774831\n",
      "32     \t [ 0.3077797 -2.       ]. \t  -47.74479305769192 \t 0.873207316774831\n",
      "33     \t [1.92637371 0.95447647]. \t  -4.473438752273329 \t 0.873207316774831\n",
      "34     \t [-1.79540861  0.62128578]. \t  -0.17459751828672943 \t 0.873207316774831\n",
      "35     \t [-2.29027398 -0.6672871 ]. \t  -11.849257353208982 \t 0.873207316774831\n",
      "36     \t [-2.01267481  2.        ]. \t  -47.87569401742681 \t 0.873207316774831\n",
      "37     \t [1.89064809 2.        ]. \t  -54.47143455035979 \t 0.873207316774831\n",
      "38     \t [-1.16679688 -1.24934602]. \t  -7.3539937913196916 \t 0.873207316774831\n",
      "39     \t [-2.33615563 -2.        ]. \t  -66.1392227638396 \t 0.873207316774831\n",
      "40     \t [-0.16361626 -0.97488979]. \t  -0.07656740024214201 \t 0.873207316774831\n",
      "41     \t [0.36188824 1.13088476]. \t  -2.3245801328249716 \t 0.873207316774831\n",
      "42     \t [-0.99175511  0.67859858]. \t  -0.5531364088826322 \t 0.873207316774831\n",
      "43     \t [-0.11500229  0.95172478]. \t  0.3982851306513174 \t 0.873207316774831\n",
      "44     \t [ 2.1255214 -2.       ]. \t  -49.69517347509992 \t 0.873207316774831\n",
      "45     \t [-1.91095236 -1.17202888]. \t  -7.128021692382319 \t 0.873207316774831\n",
      "46     \t [ 2.08301527 -0.42581962]. \t  -3.568484146299135 \t 0.873207316774831\n",
      "47     \t [ 1.94338152 -0.87835065]. \t  -0.6977558245233041 \t 0.873207316774831\n",
      "48     \t [ 1.72833594 -0.30743161]. \t  -1.2213358998319186 \t 0.873207316774831\n",
      "49     \t [-1.77483274  1.12428147]. \t  -1.5208229820725445 \t 0.873207316774831\n",
      "50     \t [ 0.31371724 -0.87502925]. \t  0.6185256551219778 \t 0.873207316774831\n",
      "51     \t [-3.         -0.56505563]. \t  -109.7257943982431 \t 0.873207316774831\n",
      "52     \t [-3.          1.25724743]. \t  -108.79965774050449 \t 0.873207316774831\n",
      "53     \t [-0.23558794 -0.55360853]. \t  0.504185477020383 \t 0.873207316774831\n",
      "54     \t [3.         1.18009078]. \t  -114.62731315206842 \t 0.873207316774831\n",
      "55     \t [3.         0.26831645]. \t  -109.4377068575017 \t 0.873207316774831\n",
      "56     \t [-3. -2.]. \t  -162.89999999999998 \t 0.873207316774831\n",
      "57     \t [2.05833635 0.28673962]. \t  -4.890214945343412 \t 0.873207316774831\n",
      "58     \t [-0.11523679  0.71777257]. \t  \u001b[92m1.0290414303390778\u001b[0m \t 1.0290414303390778\n",
      "59     \t [2.29626168 1.52228856]. \t  -27.278620827185993 \t 1.0290414303390778\n",
      "60     \t [-0.04770047  0.68260334]. \t  1.018831690284569 \t 1.0290414303390778\n",
      "61     \t [ 3.         -1.32130714]. \t  -110.1446729509027 \t 1.0290414303390778\n",
      "62     \t [-2.36650854  1.54082672]. \t  -24.490289242679353 \t 1.0290414303390778\n",
      "63     \t [-0.08946962  0.70935652]. \t  \u001b[92m1.031540378189526\u001b[0m \t 1.031540378189526\n",
      "64     \t [-0.06292258  0.6766168 ]. \t  1.019650481832929 \t 1.031540378189526\n",
      "65     \t [-0.06483231  0.78843519]. \t  0.9751647622752238 \t 1.031540378189526\n",
      "66     \t [0.27271908 2.        ]. \t  -48.83146143657469 \t 1.031540378189526\n",
      "67     \t [-0.06064393  0.71128636]. \t  1.0283122637729538 \t 1.031540378189526\n",
      "68     \t [ 0.12968118 -0.76283796]. \t  1.0054045266724776 \t 1.031540378189526\n",
      "69     \t [ 0.05618556 -0.72538239]. \t  1.025408176146995 \t 1.031540378189526\n",
      "70     \t [0.01160292 0.7314177 ]. \t  0.986082826888361 \t 1.031540378189526\n",
      "71     \t [-0.07034772  0.66145916]. \t  1.0111774310639048 \t 1.031540378189526\n",
      "72     \t [-0.04018757  0.71198415]. \t  1.0219666018862525 \t 1.031540378189526\n",
      "73     \t [ 0.07395134 -0.70623118]. \t  1.030408165405238 \t 1.031540378189526\n",
      "74     \t [-1.39645233  1.53134177]. \t  -12.764110797258239 \t 1.031540378189526\n",
      "75     \t [1.74969982 1.50312294]. \t  -16.13972149811559 \t 1.031540378189526\n",
      "76     \t [-0.03160357  0.65498515]. \t  0.9965459735821105 \t 1.031540378189526\n",
      "77     \t [ 0.07890429 -0.73883048]. \t  1.0250582617984498 \t 1.031540378189526\n",
      "78     \t [ 0.0836916  -0.74691863]. \t  1.0211927653167177 \t 1.031540378189526\n",
      "79     \t [ 0.07186371 -0.7390062 ]. \t  1.02399415247881 \t 1.031540378189526\n",
      "80     \t [ 0.02611006 -0.67737117]. \t  1.0081809215746336 \t 1.031540378189526\n",
      "81     \t [ 1.28749354 -0.6727142 ]. \t  -0.5214066183464141 \t 1.031540378189526\n",
      "82     \t [-0.06808268  0.68824674]. \t  1.0255915482670743 \t 1.031540378189526\n",
      "83     \t [ 0.0317979  -0.74825356]. \t  1.0054065287902938 \t 1.031540378189526\n",
      "84     \t [-0.04848996  0.73247017]. \t  1.0207912844625073 \t 1.031540378189526\n",
      "85     \t [-0.04484888  0.72953837]. \t  1.0205276618176118 \t 1.031540378189526\n",
      "86     \t [-0.09264828  0.75360012]. \t  1.0171906746512234 \t 1.031540378189526\n",
      "87     \t [-0.06694365  0.61288889]. \t  0.9612765440987565 \t 1.031540378189526\n",
      "88     \t [ 0.20691728 -0.67824867]. \t  0.9665124879018078 \t 1.031540378189526\n",
      "89     \t [-0.01654079  0.74550147]. \t  0.9987946895634833 \t 1.031540378189526\n",
      "90     \t [-0.02872996  0.66831008]. \t  1.004510449958251 \t 1.031540378189526\n",
      "91     \t [ 0.11527155 -0.68739799]. \t  1.023435819206401 \t 1.031540378189526\n",
      "92     \t [ 0.11485033 -0.73194052]. \t  1.0265573257227893 \t 1.031540378189526\n",
      "93     \t [ 0.22127695 -0.71854602]. \t  0.9670753286943301 \t 1.031540378189526\n",
      "94     \t [-0.06471811  0.68809744]. \t  1.0250017993037301 \t 1.031540378189526\n",
      "95     \t [-0.07301804  0.7048259 ]. \t  1.0301566287828812 \t 1.031540378189526\n",
      "96     \t [-0.10395196  0.68445704]. \t  1.0241977279017225 \t 1.031540378189526\n",
      "97     \t [ 0.22519062 -0.67218947]. \t  0.9446063150236126 \t 1.031540378189526\n",
      "98     \t [-0.09074619  0.74282141]. \t  1.0238847641272095 \t 1.031540378189526\n",
      "99     \t [-1.82896014 -0.78155748]. \t  -2.8374913885084085 \t 1.031540378189526\n",
      "100    \t [-0.06893653  0.7524879 ]. \t  1.0153624009287305 \t 1.031540378189526\n"
     ]
    }
   ],
   "source": [
    "### 6(h). Bayesian optimization runs (x20): STP DF1 run number = 8\n",
    "\n",
    "np.random.seed(run_num_8)\n",
    "surrogate_stp_df1_8 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_8 = GPGO(surrogate_stp_df1_8, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_8.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.28903268409599, -9.72748910328459)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(h). Training Regret Minimisation: run number = 8\n",
    "\n",
    "gp_output_8 = np.append(np.max(gpgo_gp_8.GP.y[0:n_init]),gpgo_gp_8.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_8 = np.append(np.max(gpgo_stp_df1_8.GP.y[0:n_init]),gpgo_stp_df1_8.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_8 = np.log(y_global_orig - gp_output_8)\n",
    "regret_stp_df1_8 = np.log(y_global_orig - stp_df1_output_8)\n",
    "\n",
    "train_regret_gp_8 = min_max_array(regret_gp_8)\n",
    "train_regret_stp_df1_8 = min_max_array(regret_stp_df1_8)\n",
    "\n",
    "# GP, STP df1, STP df2 - training regret minimization: run number = 8\n",
    "min_train_regret_gp_8 = min(train_regret_gp_8)\n",
    "min_train_regret_stp_df1_8 = min(train_regret_stp_df1_8)\n",
    "\n",
    "min_train_regret_gp_8, min_train_regret_stp_df1_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.82056824 0.11008918]. \t  -2.477688900627931 \t -0.41085242186652027\n",
      "init   \t [-2.28533121  0.55872578]. \t  -8.96037673064254 \t -0.41085242186652027\n",
      "init   \t [-2.45444842 -0.67109728]. \t  -21.41922905364948 \t -0.41085242186652027\n",
      "init   \t [-0.43571432  0.21754325]. \t  -0.41085242186652027 \t -0.41085242186652027\n",
      "init   \t [0.76875913 0.78957178]. \t  -1.3672247671728295 \t -0.41085242186652027\n",
      "1      \t [-0.82503116  1.89985858]. \t  -37.96244529973831 \t -0.41085242186652027\n",
      "2      \t [ 0.05988327 -0.3083046 ]. \t  \u001b[92m0.3482128362957119\u001b[0m \t 0.3482128362957119\n",
      "3      \t [-0.18899046 -0.0734608 ]. \t  -0.13261964654453468 \t 0.3482128362957119\n",
      "4      \t [ 0.79900843 -1.25154205]. \t  -4.332968711302838 \t 0.3482128362957119\n",
      "5      \t [ 0.63417552 -0.08139391]. \t  -1.212785822394039 \t 0.3482128362957119\n",
      "6      \t [1.80881775 1.41804896]. \t  -12.977739905057868 \t 0.3482128362957119\n",
      "7      \t [-0.07750909 -1.1171676 ]. \t  -1.3489412060263328 \t 0.3482128362957119\n",
      "8      \t [ 3.        -0.4144033]. \t  -107.08783459639301 \t 0.3482128362957119\n",
      "9      \t [1.43601406 0.42895763]. \t  -2.2569074269685316 \t 0.3482128362957119\n",
      "10     \t [ 1.34166888 -0.32145937]. \t  -1.538052756107229 \t 0.3482128362957119\n",
      "11     \t [0.13771568 0.79407706]. \t  \u001b[92m0.7473518419527957\u001b[0m \t 0.7473518419527957\n",
      "12     \t [0.35538223 0.86739357]. \t  -0.03538287555776132 \t 0.7473518419527957\n",
      "13     \t [0.05821547 0.42093471]. \t  0.5451275884783693 \t 0.7473518419527957\n",
      "14     \t [-0.16483605 -0.61172691]. \t  0.7287326327977135 \t 0.7473518419527957\n",
      "15     \t [-3.          1.24086079]. \t  -108.50161725514074 \t 0.7473518419527957\n",
      "16     \t [-1.74313848  0.27550695]. \t  -1.3559506441196618 \t 0.7473518419527957\n",
      "17     \t [-0.31273497  0.68194088]. \t  \u001b[92m0.836941862697689\u001b[0m \t 0.836941862697689\n",
      "18     \t [-0.07818356  0.65109212]. \t  \u001b[92m1.0033803234665457\u001b[0m \t 1.0033803234665457\n",
      "19     \t [-1.64489162  0.60585369]. \t  -0.1258658085854074 \t 1.0033803234665457\n",
      "20     \t [ 0.34152663 -1.99929895]. \t  -47.67723434030749 \t 1.0033803234665457\n",
      "21     \t [ 0.40626886 -0.7740103 ]. \t  0.6706732135457341 \t 1.0033803234665457\n",
      "22     \t [2.71827246 1.97890367]. \t  -100.43202535871926 \t 1.0033803234665457\n",
      "23     \t [-0.59637423 -1.09673672]. \t  -2.801958294808321 \t 1.0033803234665457\n",
      "24     \t [1.21725254 1.33687673]. \t  -9.655969462941782 \t 1.0033803234665457\n",
      "25     \t [-1.47895783 -1.9008639 ]. \t  -42.77185784862974 \t 1.0033803234665457\n",
      "26     \t [1.93545877 0.68433056]. \t  -3.3661639112610557 \t 1.0033803234665457\n",
      "27     \t [-2.95379071 -0.06511339]. \t  -96.60508662588975 \t 1.0033803234665457\n",
      "28     \t [-1.90096988  0.58950557]. \t  -0.7338371088188491 \t 1.0033803234665457\n",
      "29     \t [-1.97081331 -1.01133688]. \t  -5.473915999176331 \t 1.0033803234665457\n",
      "30     \t [ 0.98038285 -0.87714296]. \t  -0.6308999483167468 \t 1.0033803234665457\n",
      "31     \t [-2.80513597 -1.67743866]. \t  -88.97392578111912 \t 1.0033803234665457\n",
      "32     \t [-1.91173487 -0.5838722 ]. \t  -3.0587028007367794 \t 1.0033803234665457\n",
      "33     \t [ 0.45933743 -0.79541731]. \t  0.5413313961960238 \t 1.0033803234665457\n",
      "34     \t [-0.84293885  0.71218267]. \t  -0.3014053353265329 \t 1.0033803234665457\n",
      "35     \t [ 0.02923165 -0.72297332]. \t  \u001b[92m1.0156578577875435\u001b[0m \t 1.0156578577875435\n",
      "36     \t [0.01813622 0.70041717]. \t  0.9856269852775649 \t 1.0156578577875435\n",
      "37     \t [0.02297013 0.67787738]. \t  0.9757638899495081 \t 1.0156578577875435\n",
      "38     \t [1.47376753 1.67733176]. \t  -25.076657615861073 \t 1.0156578577875435\n",
      "39     \t [-0.13888208  0.63408175]. \t  0.9733193148087405 \t 1.0156578577875435\n",
      "40     \t [ 2.85006428 -1.87021287]. \t  -102.19746025288038 \t 1.0156578577875435\n",
      "41     \t [0.05951879 1.76769598]. \t  -26.67658543390337 \t 1.0156578577875435\n",
      "42     \t [-0.92639988 -0.19607064]. \t  -2.1306206151992577 \t 1.0156578577875435\n",
      "43     \t [ 2.86340944 -0.84650547]. \t  -72.11643989506022 \t 1.0156578577875435\n",
      "44     \t [0.10505238 0.25445861]. \t  0.171606744372016 \t 1.0156578577875435\n",
      "45     \t [ 1.7409211  -0.71477524]. \t  0.13070536085700424 \t 1.0156578577875435\n",
      "46     \t [-0.11518206  0.7469588 ]. \t  \u001b[92m1.0199058417058688\u001b[0m \t 1.0199058417058688\n",
      "47     \t [ 0.12517262 -0.66354732]. \t  1.0066407429828323 \t 1.0199058417058688\n",
      "48     \t [-1.51696617 -1.49601534]. \t  -15.499069278120784 \t 1.0199058417058688\n",
      "49     \t [2.40882514 1.01984948]. \t  -20.249180176248352 \t 1.0199058417058688\n",
      "50     \t [1.95156969 1.22165235]. \t  -8.51202587713247 \t 1.0199058417058688\n",
      "51     \t [1.74936812 0.22234803]. \t  -2.328450528884415 \t 1.0199058417058688\n",
      "52     \t [ 1.15704714 -1.48007282]. \t  -11.111275172619074 \t 1.0199058417058688\n",
      "53     \t [0.07037763 0.74464852]. \t  0.9159512116388642 \t 1.0199058417058688\n",
      "54     \t [2.34805138 1.92134299]. \t  -58.338343521752265 \t 1.0199058417058688\n",
      "55     \t [2.18972401 1.87424811]. \t  -47.05700729180754 \t 1.0199058417058688\n",
      "56     \t [-1.75223719  0.16671226]. \t  -1.7325008517346894 \t 1.0199058417058688\n",
      "57     \t [-1.10280006 -1.80887296]. \t  -34.089469104871895 \t 1.0199058417058688\n",
      "58     \t [-2.31477127 -1.96547864]. \t  -61.21089940842959 \t 1.0199058417058688\n",
      "59     \t [-0.87908806 -0.57824248]. \t  -1.60894321808982 \t 1.0199058417058688\n",
      "60     \t [ 0.10807498 -0.74327704]. \t  \u001b[92m1.0228862891443267\u001b[0m \t 1.0228862891443267\n",
      "61     \t [ 0.45330759 -1.51353407]. \t  -11.87772315277833 \t 1.0228862891443267\n",
      "62     \t [ 2.21177225 -1.38672824]. \t  -12.368365546781789 \t 1.0228862891443267\n",
      "63     \t [-1.60016807  0.51880711]. \t  -0.4527071103932998 \t 1.0228862891443267\n",
      "64     \t [ 1.7706953  -0.94112759]. \t  -0.1001350103129085 \t 1.0228862891443267\n",
      "65     \t [-2.32532831  0.43947172]. \t  -11.281866867613772 \t 1.0228862891443267\n",
      "66     \t [-2.4378167   1.44939194]. \t  -25.28437925020681 \t 1.0228862891443267\n",
      "67     \t [-1.86957817  1.73948472]. \t  -23.82615047426291 \t 1.0228862891443267\n",
      "68     \t [-0.10529823  0.72588939]. \t  \u001b[92m1.029443957041393\u001b[0m \t 1.029443957041393\n",
      "69     \t [1.18023884 0.97088587]. \t  -3.3275938255749096 \t 1.029443957041393\n",
      "70     \t [-5.89723857e-04  6.89891047e-01]. \t  0.9980917779368037 \t 1.029443957041393\n",
      "71     \t [-2.73101456  0.32693115]. \t  -50.039774792866396 \t 1.029443957041393\n",
      "72     \t [-2.0941387  -1.98911825]. \t  -56.225575264699806 \t 1.029443957041393\n",
      "73     \t [-0.86649091 -1.66531128]. \t  -23.074364892146264 \t 1.029443957041393\n",
      "74     \t [-2.81539451  1.51706952]. \t  -73.4786633568564 \t 1.029443957041393\n",
      "75     \t [2.94278206 1.16095138]. \t  -98.92664130016473 \t 1.029443957041393\n",
      "76     \t [ 0.37604725 -0.76118104]. \t  0.7364301853888002 \t 1.029443957041393\n",
      "77     \t [-1.38104727  0.07950375]. \t  -2.167702937794805 \t 1.029443957041393\n",
      "78     \t [ 0.76845665 -1.76819012]. \t  -26.933586070150017 \t 1.029443957041393\n",
      "79     \t [-2.65092802  1.94877611]. \t  -77.41810390142757 \t 1.029443957041393\n",
      "80     \t [-1.92339518  1.88273363]. \t  -35.3933581064062 \t 1.029443957041393\n",
      "81     \t [ 0.68973197 -0.1922867 ]. \t  -1.1884847630915212 \t 1.029443957041393\n",
      "82     \t [-0.08055857  0.69790141]. \t  \u001b[92m1.029682445701965\u001b[0m \t 1.029682445701965\n",
      "83     \t [-0.83952645 -1.06746558]. \t  -3.42466674342256 \t 1.029682445701965\n",
      "84     \t [ 2.13774634 -1.14509473]. \t  -5.420675353374332 \t 1.029682445701965\n",
      "85     \t [2.52329603 0.23780472]. \t  -26.76041031081613 \t 1.029682445701965\n",
      "86     \t [ 2.89752297 -1.38835727]. \t  -85.94947289591074 \t 1.029682445701965\n",
      "87     \t [-2.3413483  -1.08339346]. \t  -17.08507216370622 \t 1.029682445701965\n",
      "88     \t [-2.26447014 -0.27867299]. \t  -10.581882321246896 \t 1.029682445701965\n",
      "89     \t [0.29747379 1.80605252]. \t  -30.38572754421957 \t 1.029682445701965\n",
      "90     \t [-1.6404632  1.0119517]. \t  -0.49091945313591356 \t 1.029682445701965\n",
      "91     \t [-0.13170255 -0.2649038 ]. \t  0.15735784728858754 \t 1.029682445701965\n",
      "92     \t [ 0.11404073 -0.76185614]. \t  1.0093433551795137 \t 1.029682445701965\n",
      "93     \t [0.21237853 0.70634316]. \t  0.6738063709041711 \t 1.029682445701965\n",
      "94     \t [2.52842735 0.55961513]. \t  -27.392559668046072 \t 1.029682445701965\n",
      "95     \t [-0.95965248  1.92489102]. \t  -40.40917899997455 \t 1.029682445701965\n",
      "96     \t [2.73264304 1.00572602]. \t  -54.361473355297704 \t 1.029682445701965\n",
      "97     \t [ 1.13827669 -1.79436461]. \t  -28.92787699636363 \t 1.029682445701965\n",
      "98     \t [ 0.12889872 -0.70207309]. \t  1.0244137232922874 \t 1.029682445701965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [1.37662349 0.82042015]. \t  -2.556393502942637 \t 1.029682445701965\n",
      "100    \t [0.3584519  0.16714052]. \t  -0.4312786933609494 \t 1.029682445701965\n"
     ]
    }
   ],
   "source": [
    "### 6(i). Bayesian optimization runs (x20): GP run number = 9\n",
    "\n",
    "np.random.seed(run_num_9)\n",
    "surrogate_gp_9 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_9 = GPGO(surrogate_gp_9, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_9.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.82056824 0.11008918]. \t  -2.477688900627931 \t -0.41085242186652027\n",
      "init   \t [-2.28533121  0.55872578]. \t  -8.96037673064254 \t -0.41085242186652027\n",
      "init   \t [-2.45444842 -0.67109728]. \t  -21.41922905364948 \t -0.41085242186652027\n",
      "init   \t [-0.43571432  0.21754325]. \t  -0.41085242186652027 \t -0.41085242186652027\n",
      "init   \t [0.76875913 0.78957178]. \t  -1.3672247671728295 \t -0.41085242186652027\n",
      "1      \t [-0.89120868  2.        ]. \t  -48.23685003310006 \t -0.41085242186652027\n",
      "2      \t [ 0.25418522 -1.13180241]. \t  -1.4017749608715506 \t -0.41085242186652027\n",
      "3      \t [ 3. -2.]. \t  -150.89999999999998 \t -0.41085242186652027\n",
      "4      \t [3. 2.]. \t  -162.89999999999998 \t -0.41085242186652027\n",
      "5      \t [-3.  2.]. \t  -150.89999999999998 \t -0.41085242186652027\n",
      "6      \t [-1.0317041 -2.       ]. \t  -52.34379732587441 \t -0.41085242186652027\n",
      "7      \t [-3. -2.]. \t  -162.89999999999998 \t -0.41085242186652027\n",
      "8      \t [-1.52948617 -0.15964769]. \t  -2.277272757432445 \t -0.41085242186652027\n",
      "9      \t [ 0.86771086 -0.2965646 ]. \t  -1.3852976516924786 \t -0.41085242186652027\n",
      "10     \t [ 0.84209783 -2.        ]. \t  -48.215170827730795 \t -0.41085242186652027\n",
      "11     \t [0.70088841 2.        ]. \t  -50.89949642603967 \t -0.41085242186652027\n",
      "12     \t [-3.          0.03034304]. \t  -108.80529146192653 \t -0.41085242186652027\n",
      "13     \t [-1.50719018  0.85968908]. \t  \u001b[92m-0.09021385030854334\u001b[0m \t -0.09021385030854334\n",
      "14     \t [ 3.         -0.02844737]. \t  -108.81142349586388 \t -0.09021385030854334\n",
      "15     \t [-0.15546262 -0.53226155]. \t  \u001b[92m0.6339691956208368\u001b[0m \t 0.6339691956208368\n",
      "16     \t [1.5760097  0.76797757]. \t  -2.3300739206900754 \t 0.6339691956208368\n",
      "17     \t [-1.88056758  0.2767321 ]. \t  -1.8219023210548753 \t 0.6339691956208368\n",
      "18     \t [-1.74017268 -0.93908685]. \t  -3.3295188340215787 \t 0.6339691956208368\n",
      "19     \t [1.29353981 0.30900295]. \t  -2.4293068515491663 \t 0.6339691956208368\n",
      "20     \t [ 1.49345003 -0.90592126]. \t  -0.2317065814394299 \t 0.6339691956208368\n",
      "21     \t [-0.18367709  1.07393288]. \t  -0.642684716413877 \t 0.6339691956208368\n",
      "22     \t [-1.93856026  1.08905403]. \t  -1.8369173416822586 \t 0.6339691956208368\n",
      "23     \t [ 0.95396658 -0.86674875]. \t  -0.5778966258917353 \t 0.6339691956208368\n",
      "24     \t [ 1.53537046 -0.46479044]. \t  -0.7350935526809161 \t 0.6339691956208368\n",
      "25     \t [0.12505027 0.47630306]. \t  0.5799883688965797 \t 0.6339691956208368\n",
      "26     \t [-1.91098111 -0.55474573]. \t  -3.0434406119752553 \t 0.6339691956208368\n",
      "27     \t [-0.66105427 -1.09357311]. \t  -3.034796199628931 \t 0.6339691956208368\n",
      "28     \t [-1.89163431  0.74614901]. \t  -0.2981759403825949 \t 0.6339691956208368\n",
      "29     \t [1.66593516 2.        ]. \t  -53.383651528048084 \t 0.6339691956208368\n",
      "30     \t [-0.6513022   0.78225502]. \t  0.11503204316672933 \t 0.6339691956208368\n",
      "31     \t [ 1.81996031 -2.        ]. \t  -46.682883427229456 \t 0.6339691956208368\n",
      "32     \t [-1.74454015  2.        ]. \t  -46.63001191491883 \t 0.6339691956208368\n",
      "33     \t [2.44098492 0.8670214 ]. \t  -21.161001991412938 \t 0.6339691956208368\n",
      "34     \t [-1.95556142 -2.        ]. \t  -55.138858259659436 \t 0.6339691956208368\n",
      "35     \t [0.21424827 0.85248448]. \t  0.4325142910150628 \t 0.6339691956208368\n",
      "36     \t [-1.19829172  1.27901725]. \t  -5.028956364091981 \t 0.6339691956208368\n",
      "37     \t [-0.76454239 -0.47483859]. \t  -1.351663078100172 \t 0.6339691956208368\n",
      "38     \t [-0.11841799 -2.        ]. \t  -48.292515233897596 \t 0.6339691956208368\n",
      "39     \t [-0.15761662 -0.92850288]. \t  0.2310548590298979 \t 0.6339691956208368\n",
      "40     \t [ 2.30659932 -0.92466494]. \t  -9.409820776616883 \t 0.6339691956208368\n",
      "41     \t [ 1.8968936  -0.76138286]. \t  -0.3138512015473023 \t 0.6339691956208368\n",
      "42     \t [-3.          1.11189203]. \t  -106.73289758247927 \t 0.6339691956208368\n",
      "43     \t [ 0.3231965 -0.7067682]. \t  \u001b[92m0.8331334893238026\u001b[0m \t 0.8331334893238026\n",
      "44     \t [2.04512855 1.27037804]. \t  -10.94366682901216 \t 0.8331334893238026\n",
      "45     \t [0.47741264 0.37439669]. \t  -0.5031895032365699 \t 0.8331334893238026\n",
      "46     \t [ 1.98600279 -1.21537978]. \t  -3.96617776463708 \t 0.8331334893238026\n",
      "47     \t [1.22385592 1.36792087]. \t  -10.595084083839492 \t 0.8331334893238026\n",
      "48     \t [-2.19333752 -1.25055322]. \t  -14.024406339729914 \t 0.8331334893238026\n",
      "49     \t [ 1.33785695 -1.38993217]. \t  -7.6851642894893235 \t 0.8331334893238026\n",
      "50     \t [ 0.12201242 -0.09367902]. \t  -0.01285883259856313 \t 0.8331334893238026\n",
      "51     \t [-3.         -1.18204356]. \t  -114.66619566394223 \t 0.8331334893238026\n",
      "52     \t [3.         1.19742374]. \t  -114.98037743364902 \t 0.8331334893238026\n",
      "53     \t [ 3.         -1.12193301]. \t  -106.83690812821109 \t 0.8331334893238026\n",
      "54     \t [-0.16254463  0.76399315]. \t  \u001b[92m0.9919466570512931\u001b[0m \t 0.9919466570512931\n",
      "55     \t [-1.57073597 -1.45548426]. \t  -13.855450404249385 \t 0.9919466570512931\n",
      "56     \t [-0.05743216  2.        ]. \t  -47.898306657773034 \t 0.9919466570512931\n",
      "57     \t [ 0.08744984 -0.74326825]. \t  \u001b[92m1.0235284178846724\u001b[0m \t 1.0235284178846724\n",
      "58     \t [-1.13494251  0.26992006]. \t  -1.8039424963527126 \t 1.0235284178846724\n",
      "59     \t [1.94965981 0.74507443]. \t  -3.6343805645578717 \t 1.0235284178846724\n",
      "60     \t [-2.37872577  2.        ]. \t  -59.02789396807448 \t 1.0235284178846724\n",
      "61     \t [2.33861729 2.        ]. \t  -66.2696068238521 \t 1.0235284178846724\n",
      "62     \t [-0.42801772 -1.47546688]. \t  -11.545241695361343 \t 1.0235284178846724\n",
      "63     \t [ 0.10026073 -0.74376848]. \t  1.0232564100196886 \t 1.0235284178846724\n",
      "64     \t [-0.06069074  0.73706059]. \t  1.0225426364840084 \t 1.0235284178846724\n",
      "65     \t [ 0.09512394 -0.80981547]. \t  0.9439143579917698 \t 1.0235284178846724\n",
      "66     \t [-0.1033047   0.78278382]. \t  0.9875658557747575 \t 1.0235284178846724\n",
      "67     \t [-0.02548863  0.72885654]. \t  1.0120780428981258 \t 1.0235284178846724\n",
      "68     \t [ 2.24628749 -0.24382479]. \t  -8.7678787188025 \t 1.0235284178846724\n",
      "69     \t [ 2.40726736 -2.        ]. \t  -60.71164537365937 \t 1.0235284178846724\n",
      "70     \t [ 0.09676861 -0.72587908]. \t  \u001b[92m1.0300749905778621\u001b[0m \t 1.0300749905778621\n",
      "71     \t [ 0.15385291 -0.71110702]. \t  1.0157664860405944 \t 1.0300749905778621\n",
      "72     \t [0.05954748 0.67893646]. \t  0.9393156844247884 \t 1.0300749905778621\n",
      "73     \t [-0.02590642  0.73183829]. \t  1.0112098669867053 \t 1.0300749905778621\n",
      "74     \t [-0.14517325  0.78423047]. \t  0.9775617843294073 \t 1.0300749905778621\n",
      "75     \t [ 0.12606282 -0.77278553]. \t  0.996591806908678 \t 1.0300749905778621\n",
      "76     \t [ 0.04449859 -0.73500141]. \t  1.0183213883002846 \t 1.0300749905778621\n",
      "77     \t [-0.08041005  0.74969977]. \t  1.0191073117883214 \t 1.0300749905778621\n",
      "78     \t [-0.06486339  0.74263128]. \t  1.0207681933268786 \t 1.0300749905778621\n",
      "79     \t [ 0.14662273 -0.74264379]. \t  1.0132456541616777 \t 1.0300749905778621\n",
      "80     \t [ 0.0912781  -0.71329992]. \t  \u001b[92m1.0316179453490586\u001b[0m \t 1.0316179453490586\n",
      "81     \t [ 0.0814985  -0.67195011]. \t  1.018885027525359 \t 1.0316179453490586\n",
      "82     \t [ 0.06149606 -0.650702  ]. \t  1.0014563497959483 \t 1.0316179453490586\n",
      "83     \t [-0.13674695  0.75302098]. \t  1.0109287871710244 \t 1.0316179453490586\n",
      "84     \t [-0.08083739  0.78522408]. \t  0.9830656566524348 \t 1.0316179453490586\n",
      "85     \t [-0.0123049   0.75540909]. \t  0.9887279684842488 \t 1.0316179453490586\n",
      "86     \t [-2.45637536  1.35731057]. \t  -23.777332831969346 \t 1.0316179453490586\n",
      "87     \t [0.36857354 1.46118271]. \t  -10.737638930262836 \t 1.0316179453490586\n",
      "88     \t [-0.03228863 -0.6547898 ]. \t  0.9543833642644272 \t 1.0316179453490586\n",
      "89     \t [-0.05680494  0.75239441]. \t  1.0123789280329614 \t 1.0316179453490586\n",
      "90     \t [ 0.08629982 -0.73538374]. \t  1.0271341412923223 \t 1.0316179453490586\n",
      "91     \t [ 0.18699169 -0.6544577 ]. \t  0.9645127970153174 \t 1.0316179453490586\n",
      "92     \t [ 0.11404303 -0.761854  ]. \t  1.009344887429659 \t 1.0316179453490586\n",
      "93     \t [-0.04954427  0.71450456]. \t  1.0251513067459777 \t 1.0316179453490586\n",
      "94     \t [ 0.09196631 -0.72284939]. \t  1.0307695794847658 \t 1.0316179453490586\n",
      "95     \t [ 0.23673632 -0.69363846]. \t  0.9451467079201494 \t 1.0316179453490586\n",
      "96     \t [ 0.07212524 -0.76866712]. \t  1.0016746153262355 \t 1.0316179453490586\n",
      "97     \t [ 0.09044631 -0.68956504]. \t  1.0273858158677787 \t 1.0316179453490586\n",
      "98     \t [ 0.12890456 -0.70207573]. \t  1.0244124559261365 \t 1.0316179453490586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [0.03833401 0.79458175]. \t  0.8946450888827487 \t 1.0316179453490586\n",
      "100    \t [ 0.02885073 -0.69954614]. \t  1.0164019852085104 \t 1.0316179453490586\n"
     ]
    }
   ],
   "source": [
    "### 6(i). Bayesian optimization runs (x20): STP DF1 run number = 9\n",
    "\n",
    "np.random.seed(run_num_9)\n",
    "surrogate_stp_df1_9 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_9 = GPGO(surrogate_stp_df1_9, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_9.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.256704708026015, -6.4857546904907295)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(i). Training Regret Minimisation: run number = 9\n",
    "\n",
    "gp_output_9 = np.append(np.max(gpgo_gp_9.GP.y[0:n_init]),gpgo_gp_9.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_9 = np.append(np.max(gpgo_stp_df1_9.GP.y[0:n_init]),gpgo_stp_df1_9.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_9 = np.log(y_global_orig - gp_output_9)\n",
    "regret_stp_df1_9 = np.log(y_global_orig - stp_df1_output_9)\n",
    "\n",
    "train_regret_gp_9 = min_max_array(regret_gp_9)\n",
    "train_regret_stp_df1_9 = min_max_array(regret_stp_df1_9)\n",
    "\n",
    "# GP, STP df1, STP df2 - training regret minimization: run number = 9\n",
    "min_train_regret_gp_9 = min(train_regret_gp_9)\n",
    "min_train_regret_stp_df1_9 = min(train_regret_stp_df1_9)\n",
    "\n",
    "min_train_regret_gp_9, min_train_regret_stp_df1_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.92153751 -1.53997223]. \t  -13.677695110590259 \t -6.372423095293032\n",
      "init   \t [ 2.70169719 -0.07123439]. \t  -46.72852427361676 \t -6.372423095293032\n",
      "init   \t [ 2.23484721 -1.15066928]. \t  -8.26768569212749 \t -6.372423095293032\n",
      "init   \t [-2.75574225 -0.41122215]. \t  -55.82511776655432 \t -6.372423095293032\n",
      "init   \t [-1.60120682  1.3669629 ]. \t  -6.372423095293032 \t -6.372423095293032\n",
      "1      \t [ 2.5811386 -2.       ]. \t  -74.84682147294276 \t -6.372423095293032\n",
      "2      \t [ 1.57470162 -0.81229952]. \t  \u001b[92m0.08837188665466744\u001b[0m \t 0.08837188665466744\n",
      "3      \t [-0.16836985  2.        ]. \t  -47.77497389047966 \t 0.08837188665466744\n",
      "4      \t [-2.49962423  2.        ]. \t  -67.3181391293771 \t 0.08837188665466744\n",
      "5      \t [-1.21362493  0.74715068]. \t  -0.5077121324441677 \t 0.08837188665466744\n",
      "6      \t [-1.00460368 -1.88464791]. \t  -40.39026631870184 \t 0.08837188665466744\n",
      "7      \t [ 1.73224941 -0.97707973]. \t  -0.23468291614471115 \t 0.08837188665466744\n",
      "8      \t [ 0.52111376 -0.22732585]. \t  -0.623561182377702 \t 0.08837188665466744\n",
      "9      \t [-1.32471795  0.98994364]. \t  -0.9639570787650874 \t 0.08837188665466744\n",
      "10     \t [-0.17999769 -0.14544564]. \t  -0.07075581614962786 \t 0.08837188665466744\n",
      "11     \t [ 0.12099119 -0.37646287]. \t  \u001b[92m0.4739962657887828\u001b[0m \t 0.4739962657887828\n",
      "12     \t [ 0.7462506  -0.76713968]. \t  -0.09271599182304457 \t 0.4739962657887828\n",
      "13     \t [-0.54967934 -0.13782872]. \t  -1.0272868633296435 \t 0.4739962657887828\n",
      "14     \t [2.69481592 1.85940993]. \t  -84.95549658392102 \t 0.4739962657887828\n",
      "15     \t [ 0.59916777 -0.52908489]. \t  -0.05748911540703616 \t 0.4739962657887828\n",
      "16     \t [-1.58818898  0.5876488 ]. \t  -0.24034320668621223 \t 0.4739962657887828\n",
      "17     \t [-1.25160292  0.37715646]. \t  -1.4340171483967747 \t 0.4739962657887828\n",
      "18     \t [-2.78787591 -1.96479765]. \t  -110.38179581993715 \t 0.4739962657887828\n",
      "19     \t [ 1.24875125 -0.86771665]. \t  -0.5673217357331832 \t 0.4739962657887828\n",
      "20     \t [-1.39574473  0.78893703]. \t  -0.2459029307261329 \t 0.4739962657887828\n",
      "21     \t [ 0.1132437  -0.78232607]. \t  \u001b[92m0.9874350791693617\u001b[0m \t 0.9874350791693617\n",
      "22     \t [0.29550887 0.31781972]. \t  -0.06420251557533652 \t 0.9874350791693617\n",
      "23     \t [ 0.34080812 -0.75607904]. \t  0.8003476218015324 \t 0.9874350791693617\n",
      "24     \t [ 0.06131269 -0.7757057 ]. \t  \u001b[92m0.991165990753101\u001b[0m \t 0.991165990753101\n",
      "25     \t [0.08255045 0.15424011]. \t  0.05300270726969513 \t 0.991165990753101\n",
      "26     \t [2.13476842 0.6143083 ]. \t  -6.535692351817299 \t 0.991165990753101\n",
      "27     \t [1.52478489 0.73892642]. \t  -2.272730377929495 \t 0.991165990753101\n",
      "28     \t [1.55488417 0.18797203]. \t  -2.2623773378815177 \t 0.991165990753101\n",
      "29     \t [2.67669027 0.30631829]. \t  -43.933735469628125 \t 0.991165990753101\n",
      "30     \t [ 0.06526557 -0.67772669]. \t  \u001b[92m1.0206103421591821\u001b[0m \t 1.0206103421591821\n",
      "31     \t [ 1.63428609 -0.88268599]. \t  0.07694139238262276 \t 1.0206103421591821\n",
      "32     \t [-2.86195139  0.61201958]. \t  -72.35739599088193 \t 1.0206103421591821\n",
      "33     \t [-0.2509088   0.54609945]. \t  0.730586897383692 \t 1.0206103421591821\n",
      "34     \t [-0.27040837 -0.96833813]. \t  -0.3094825676788334 \t 1.0206103421591821\n",
      "35     \t [0.01585826 0.63383449]. \t  0.9503274134701899 \t 1.0206103421591821\n",
      "36     \t [ 0.08296447 -0.70147903]. \t  \u001b[92m1.030513445938779\u001b[0m \t 1.030513445938779\n",
      "37     \t [-0.0364743 -0.6080386]. \t  0.9046034771237113 \t 1.030513445938779\n",
      "38     \t [-2.89034399  1.27204281]. \t  -81.52572547728954 \t 1.030513445938779\n",
      "39     \t [ 0.81638987 -1.42533591]. \t  -9.051161659801737 \t 1.030513445938779\n",
      "40     \t [ 0.12451982 -0.6586628 ]. \t  1.002989111153076 \t 1.030513445938779\n",
      "41     \t [-0.08702852  1.43540279]. \t  -8.644411983134919 \t 1.030513445938779\n",
      "42     \t [-0.1963306  0.8224417]. \t  0.8859062452651587 \t 1.030513445938779\n",
      "43     \t [ 1.60287997 -1.00834182]. \t  -0.5199392992897433 \t 1.030513445938779\n",
      "44     \t [-2.74504984  0.48123736]. \t  -51.488734250744066 \t 1.030513445938779\n",
      "45     \t [2.67638905 0.66092075]. \t  -44.19808676366892 \t 1.030513445938779\n",
      "46     \t [-0.11444584  0.84084159]. \t  0.8727787895521331 \t 1.030513445938779\n",
      "47     \t [ 1.66682285 -0.63849379]. \t  -0.02176355265571417 \t 1.030513445938779\n",
      "48     \t [0.1903842  0.98731711]. \t  -0.23193249536012223 \t 1.030513445938779\n",
      "49     \t [-0.67818938 -1.69170675]. \t  -23.88900013268641 \t 1.030513445938779\n",
      "50     \t [ 0.12723363 -0.70932283]. \t  1.0260056436343195 \t 1.030513445938779\n",
      "51     \t [ 1.10803087 -1.3704361 ]. \t  -7.4405067847072495 \t 1.030513445938779\n",
      "52     \t [-0.15632649  0.7504683 ]. \t  1.004837166059053 \t 1.030513445938779\n",
      "53     \t [ 0.00148233 -0.75727758]. \t  0.9795227801906831 \t 1.030513445938779\n",
      "54     \t [2.79581991 1.08658394]. \t  -66.04549951077904 \t 1.030513445938779\n",
      "55     \t [ 0.08032289 -0.62943855]. \t  0.9817349169977259 \t 1.030513445938779\n",
      "56     \t [ 0.06747627 -0.71347231]. \t  1.0296466796122596 \t 1.030513445938779\n",
      "57     \t [ 2.0281526  -0.41041358]. \t  -2.7284919541159884 \t 1.030513445938779\n",
      "58     \t [-1.27305634  0.16225623]. \t  -2.0767178133917406 \t 1.030513445938779\n",
      "59     \t [1.92506769 1.9352494 ]. \t  -47.79856746651636 \t 1.030513445938779\n",
      "60     \t [-2.07614895  0.12052891]. \t  -4.612118253698222 \t 1.030513445938779\n",
      "61     \t [ 0.02957982 -0.71012929]. \t  1.0174338440773691 \t 1.030513445938779\n",
      "62     \t [ 2.68823408 -0.07644032]. \t  -44.80791360734754 \t 1.030513445938779\n",
      "63     \t [-2.6634366  1.2686209]. \t  -42.23689288604318 \t 1.030513445938779\n",
      "64     \t [-1.96101814  1.01095841]. \t  -1.3908827814512514 \t 1.030513445938779\n",
      "65     \t [ 1.86619423 -1.93773023]. \t  -40.298911362434026 \t 1.030513445938779\n",
      "66     \t [-2.06022129 -0.21581547]. \t  -4.901236965991056 \t 1.030513445938779\n",
      "67     \t [-1.42046835 -0.7807521 ]. \t  -2.416604313916984 \t 1.030513445938779\n",
      "68     \t [-0.51218763 -1.91364132]. \t  -40.88454432653726 \t 1.030513445938779\n",
      "69     \t [ 0.03119401 -0.68746469]. \t  1.0145531523293214 \t 1.030513445938779\n",
      "70     \t [-2.05895995 -1.86768905]. \t  -43.17687580612669 \t 1.030513445938779\n",
      "71     \t [ 2.0583589  -0.83649929]. \t  -2.039986723574948 \t 1.030513445938779\n",
      "72     \t [ 0.45243668 -0.26156537]. \t  -0.3603770730775245 \t 1.030513445938779\n",
      "73     \t [-0.14602888  0.7081339 ]. \t  1.0190535192624401 \t 1.030513445938779\n",
      "74     \t [2.98269366 0.65422908]. \t  -105.05867184138486 \t 1.030513445938779\n",
      "75     \t [-2.54004172  1.68853225]. \t  -44.73619958935012 \t 1.030513445938779\n",
      "76     \t [0.78801118 1.19049578]. \t  -5.057649231580321 \t 1.030513445938779\n",
      "77     \t [-2.88210765  1.73017947]. \t  -98.25984341909299 \t 1.030513445938779\n",
      "78     \t [ 0.05798271 -0.77096229]. \t  0.9956457401294769 \t 1.030513445938779\n",
      "79     \t [ 0.16231511 -0.76012353]. \t  0.9952425598083661 \t 1.030513445938779\n",
      "80     \t [-2.80964243  0.40516224]. \t  -63.001967894053784 \t 1.030513445938779\n",
      "81     \t [ 2.96091139 -1.62288339]. \t  -110.67896439468223 \t 1.030513445938779\n",
      "82     \t [ 0.10763693 -0.65051043]. \t  1.0003422793997896 \t 1.030513445938779\n",
      "83     \t [-1.71323206  1.37418432]. \t  -6.433885877833734 \t 1.030513445938779\n",
      "84     \t [-2.95256081 -0.16017044]. \t  -96.48707819542581 \t 1.030513445938779\n",
      "85     \t [-2.18775637 -1.12846761]. \t  -11.447744437308861 \t 1.030513445938779\n",
      "86     \t [ 0.32999429 -1.66886543]. \t  -19.747340796148112 \t 1.030513445938779\n",
      "87     \t [-1.51538819  0.06635407]. \t  -2.029914658998604 \t 1.030513445938779\n",
      "88     \t [ 2.13563403 -0.24182188]. \t  -5.448300544973153 \t 1.030513445938779\n",
      "89     \t [-2.45383138 -0.18643227]. \t  -21.04011729421002 \t 1.030513445938779\n",
      "90     \t [-0.01958063  0.59731677]. \t  0.9281230613370918 \t 1.030513445938779\n",
      "91     \t [ 0.6765134  -0.71638581]. \t  0.06118090557916078 \t 1.030513445938779\n",
      "92     \t [1.15290845 0.05935896]. \t  -2.4437662926618007 \t 1.030513445938779\n",
      "93     \t [-0.01181787  0.6729364 ]. \t  0.9984990878226371 \t 1.030513445938779\n",
      "94     \t [ 0.11151545 -0.70472042]. \t  1.0291231441748572 \t 1.030513445938779\n",
      "95     \t [-0.11155897  0.63997966]. \t  0.989231007265727 \t 1.030513445938779\n",
      "96     \t [-1.18736519  1.04948797]. \t  -1.6001087753452512 \t 1.030513445938779\n",
      "97     \t [-0.08400413  0.7151862 ]. \t  \u001b[92m1.031428075567166\u001b[0m \t 1.031428075567166\n",
      "98     \t [-0.95675261 -0.3437366 ]. \t  -2.069648106712903 \t 1.031428075567166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [ 2.88993136 -1.21569296]. \t  -80.421519592609 \t 1.031428075567166\n",
      "100    \t [2.95282291 0.70006488]. \t  -97.24887489921754 \t 1.031428075567166\n"
     ]
    }
   ],
   "source": [
    "### 6(j). Bayesian optimization runs (x20): GP run number = 10\n",
    "\n",
    "np.random.seed(run_num_10)\n",
    "surrogate_gp_10 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_10 = GPGO(surrogate_gp_10, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_10.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 0.92153751 -1.53997223]. \t  -13.677695110590259 \t -6.372423095293032\n",
      "init   \t [ 2.70169719 -0.07123439]. \t  -46.72852427361676 \t -6.372423095293032\n",
      "init   \t [ 2.23484721 -1.15066928]. \t  -8.26768569212749 \t -6.372423095293032\n",
      "init   \t [-2.75574225 -0.41122215]. \t  -55.82511776655432 \t -6.372423095293032\n",
      "init   \t [-1.60120682  1.3669629 ]. \t  -6.372423095293032 \t -6.372423095293032\n",
      "1      \t [ 3. -2.]. \t  -150.89999999999998 \t -6.372423095293032\n",
      "2      \t [0.45379365 2.        ]. \t  -49.645158997937294 \t -6.372423095293032\n",
      "3      \t [-3.  2.]. \t  -150.89999999999998 \t -6.372423095293032\n",
      "4      \t [-0.72026425  0.27159634]. \t  \u001b[92m-1.087568223651384\u001b[0m \t -1.087568223651384\n",
      "5      \t [ 1.3993511  -0.48633643]. \t  \u001b[92m-0.8803188725847272\u001b[0m \t -0.8803188725847272\n",
      "6      \t [-1.31516634 -2.        ]. \t  -52.99124047484474 \t -0.8803188725847272\n",
      "7      \t [3. 2.]. \t  -162.89999999999998 \t -0.8803188725847272\n",
      "8      \t [-3. -2.]. \t  -162.89999999999998 \t -0.8803188725847272\n",
      "9      \t [-0.88462618  2.        ]. \t  -48.234698551292404 \t -0.8803188725847272\n",
      "10     \t [-1.65590946  0.40622007]. \t  \u001b[92m-0.8271799878394883\u001b[0m \t -0.8271799878394883\n",
      "11     \t [-0.38304879 -0.90880728]. \t  \u001b[92m-0.31578908231213654\u001b[0m \t -0.31578908231213654\n",
      "12     \t [-0.14321549 -2.        ]. \t  -48.36759310716817 \t -0.31578908231213654\n",
      "13     \t [ 0.29918412 -0.04104827]. \t  -0.3224484267835573 \t -0.31578908231213654\n",
      "14     \t [1.1396082 0.8837841]. \t  -2.7062133183707653 \t -0.31578908231213654\n",
      "15     \t [-1.23768824 -0.63762414]. \t  -2.2219083212947295 \t -0.31578908231213654\n",
      "16     \t [ 1.65497541 -1.13111317]. \t  -1.6089814979052843 \t -0.31578908231213654\n",
      "17     \t [0.28655084 0.86100362]. \t  \u001b[92m0.20585207021439256\u001b[0m \t 0.20585207021439256\n",
      "18     \t [-1.16689318  0.9396407 ]. \t  -0.8846137835799903 \t 0.20585207021439256\n",
      "19     \t [0.80859101 0.47558872]. \t  -1.4951911036387788 \t 0.20585207021439256\n",
      "20     \t [ 2.02446369 -0.6855983 ]. \t  -1.6827389016794587 \t 0.20585207021439256\n",
      "21     \t [ 0.57352983 -0.81943691]. \t  \u001b[92m0.25196317048737216\u001b[0m \t 0.25196317048737216\n",
      "22     \t [-3.        0.543311]. \t  -106.4378607202176 \t 0.25196317048737216\n",
      "23     \t [1.49326669 2.        ]. \t  -53.16002648847877 \t 0.25196317048737216\n",
      "24     \t [-0.49436813 -0.4379106 ]. \t  -0.4535523854317909 \t 0.25196317048737216\n",
      "25     \t [ 1.59193906 -2.        ]. \t  -46.891370908567815 \t 0.25196317048737216\n",
      "26     \t [ 3.         -0.76523152]. \t  -105.63360069605294 \t 0.25196317048737216\n",
      "27     \t [1.87663212 0.46871346]. \t  -2.7949341966291765 \t 0.25196317048737216\n",
      "28     \t [-1.90231364 -1.01261513]. \t  -4.801566656572992 \t 0.25196317048737216\n",
      "29     \t [-1.84474794 -0.43402476]. \t  -2.6184079736166024 \t 0.25196317048737216\n",
      "30     \t [-0.13952144  0.49281449]. \t  \u001b[92m0.7272152252866704\u001b[0m \t 0.7272152252866704\n",
      "31     \t [ 0.0876218  -0.81892356]. \t  \u001b[92m0.9247025750475497\u001b[0m \t 0.9247025750475497\n",
      "32     \t [3.         0.85701586]. \t  -110.6909638920423 \t 0.9247025750475497\n",
      "33     \t [1.72254358 0.07833276]. \t  -2.198359689087609 \t 0.9247025750475497\n",
      "34     \t [-1.48084143  0.79491036]. \t  -0.08061749273655017 \t 0.9247025750475497\n",
      "35     \t [-1.73313106  2.        ]. \t  -46.635247815505004 \t 0.9247025750475497\n",
      "36     \t [-0.27246581  1.10454118]. \t  -1.05822816068788 \t 0.9247025750475497\n",
      "37     \t [-1.3814175  -1.15014922]. \t  -5.599363502269154 \t 0.9247025750475497\n",
      "38     \t [ 0.76813943 -0.32329696]. \t  -1.0747987347965076 \t 0.9247025750475497\n",
      "39     \t [ 0.22854833 -1.21050273]. \t  -2.653943398876127 \t 0.9247025750475497\n",
      "40     \t [-1.39283888  0.11254046]. \t  -2.083464110598667 \t 0.9247025750475497\n",
      "41     \t [ 1.82843892 -0.89846187]. \t  -0.0915373503416046 \t 0.9247025750475497\n",
      "42     \t [1.85289666 1.2534353 ]. \t  -8.380817430439267 \t 0.9247025750475497\n",
      "43     \t [-2.07554617 -2.        ]. \t  -57.05952392327089 \t 0.9247025750475497\n",
      "44     \t [-2.18050251  1.1515194 ]. \t  -6.591316201686283 \t 0.9247025750475497\n",
      "45     \t [-1.85321322  0.91950638]. \t  -0.24433370975454327 \t 0.9247025750475497\n",
      "46     \t [-0.54484816  0.77764783]. \t  0.3687266768035492 \t 0.9247025750475497\n",
      "47     \t [1.61945323 0.85527632]. \t  -2.6587504806569013 \t 0.9247025750475497\n",
      "48     \t [-3.        -1.1056027]. \t  -113.30400854731123 \t 0.9247025750475497\n",
      "49     \t [0.28923054 0.5211553 ]. \t  0.3204884612966523 \t 0.9247025750475497\n",
      "50     \t [2.19120365 2.        ]. \t  -60.071861565848394 \t 0.9247025750475497\n",
      "51     \t [ 2.27416193 -2.        ]. \t  -54.080139748493764 \t 0.9247025750475497\n",
      "52     \t [-0.1418916  -0.68605871]. \t  0.8195301704159027 \t 0.9247025750475497\n",
      "53     \t [0.6658441  1.35347554]. \t  -8.386661848760731 \t 0.9247025750475497\n",
      "54     \t [-2.33348948  2.        ]. \t  -56.665200218535155 \t 0.9247025750475497\n",
      "55     \t [ 0.55030343 -2.        ]. \t  -47.92739853280384 \t 0.9247025750475497\n",
      "56     \t [-2.21568998  0.1220203 ]. \t  -8.135512484607165 \t 0.9247025750475497\n",
      "57     \t [ 1.0970098  -0.95126065]. \t  -0.9655851318347803 \t 0.9247025750475497\n",
      "58     \t [-0.18094115  2.        ]. \t  -47.766837234872966 \t 0.9247025750475497\n",
      "59     \t [2.40876257 1.26537805]. \t  -24.520130177012064 \t 0.9247025750475497\n",
      "60     \t [-2.3900835  -1.47705071]. \t  -30.301875983936004 \t 0.9247025750475497\n",
      "61     \t [-2.28350219 -0.76269066]. \t  -11.786595753755954 \t 0.9247025750475497\n",
      "62     \t [-0.65694431 -1.48490501]. \t  -12.964777849339118 \t 0.9247025750475497\n",
      "63     \t [ 0.08345529 -0.61062604]. \t  \u001b[92m0.9585484933387184\u001b[0m \t 0.9585484933387184\n",
      "64     \t [-0.08371818  0.71666535]. \t  \u001b[92m1.0313251829198067\u001b[0m \t 1.0313251829198067\n",
      "65     \t [-0.01946157  0.64569144]. \t  0.9834406075838688 \t 1.0313251829198067\n",
      "66     \t [ 0.11599826 -0.73223113]. \t  1.0262636657010182 \t 1.0313251829198067\n",
      "67     \t [ 0.08529251 -0.75106483]. \t  1.0186375596160993 \t 1.0313251829198067\n",
      "68     \t [ 0.1387615  -0.72465937]. \t  1.0217856825692064 \t 1.0313251829198067\n",
      "69     \t [ 0.031194  -0.6874647]. \t  1.014553147345485 \t 1.0313251829198067\n",
      "70     \t [ 0.08990028 -0.70516082]. \t  1.0311726980494764 \t 1.0313251829198067\n",
      "71     \t [-0.08949439  0.68067737]. \t  1.0236331674062078 \t 1.0313251829198067\n",
      "72     \t [-3.          1.34571965]. \t  -110.73732006562408 \t 1.0313251829198067\n",
      "73     \t [-0.09122597  0.7200585 ]. \t  1.0311779071433584 \t 1.0313251829198067\n",
      "74     \t [-0.06756773  0.75577323]. \t  1.0125741517263467 \t 1.0313251829198067\n",
      "75     \t [-0.10699156  0.68608074]. \t  1.0244583846396043 \t 1.0313251829198067\n",
      "76     \t [ 0.06272375 -0.61775795]. \t  0.966992828436078 \t 1.0313251829198067\n",
      "77     \t [ 0.05638998 -0.73681301]. \t  1.0214913952419753 \t 1.0313251829198067\n",
      "78     \t [ 0.05798271 -0.77096229]. \t  0.9956457401294769 \t 1.0313251829198067\n",
      "79     \t [ 0.1623151  -0.76012353]. \t  0.9952425631692159 \t 1.0313251829198067\n",
      "80     \t [-0.07621191  0.70183126]. \t  1.0301046677755898 \t 1.0313251829198067\n",
      "81     \t [-0.02494043 -0.71398409]. \t  0.9793235692434786 \t 1.0313251829198067\n",
      "82     \t [ 0.10763789 -0.65050959]. \t  1.0003413226598539 \t 1.0313251829198067\n",
      "83     \t [ 0.13321725 -0.72991334]. \t  1.022612833649175 \t 1.0313251829198067\n",
      "84     \t [2.1397173  0.86167895]. \t  -7.3632518831693075 \t 1.0313251829198067\n",
      "85     \t [ 0.18663615 -0.78592339]. \t  0.954493270928553 \t 1.0313251829198067\n",
      "86     \t [ 0.0819444  -0.68099757]. \t  1.0237849636528704 \t 1.0313251829198067\n",
      "87     \t [ 2.0360309  -0.15744226]. \t  -3.822636753764387 \t 1.0313251829198067\n",
      "88     \t [-0.03541963  0.65079769]. \t  0.994650143551211 \t 1.0313251829198067\n",
      "89     \t [-1.78260409 -1.52252416]. \t  -17.137067598503872 \t 1.0313251829198067\n",
      "90     \t [-0.15090889  0.78077781]. \t  0.9797566219150058 \t 1.0313251829198067\n",
      "91     \t [ 0.17969107 -0.76009767]. \t  0.9854261230289353 \t 1.0313251829198067\n",
      "92     \t [ 0.11673217 -0.71711934]. \t  1.02878097232924 \t 1.0313251829198067\n",
      "93     \t [ 0.07348187 -0.651443  ]. \t  1.003457324218444 \t 1.0313251829198067\n",
      "94     \t [-0.06999742  0.69565524]. \t  1.028113708853404 \t 1.0313251829198067\n",
      "95     \t [-0.11155934  0.63997984]. \t  0.9892311013953451 \t 1.0313251829198067\n",
      "96     \t [ 0.14294393 -0.70753903]. \t  1.0202789656545246 \t 1.0313251829198067\n",
      "97     \t [-0.07076739  0.72250154]. \t  1.0292125894929127 \t 1.0313251829198067\n",
      "98     \t [0.04138209 0.65575537]. \t  0.9464281755547785 \t 1.0313251829198067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-0.07164347  0.68875939]. \t  1.0262456562191762 \t 1.0313251829198067\n",
      "100    \t [ 0.05861035 -0.6876052 ]. \t  1.0236256959914385 \t 1.0313251829198067\n"
     ]
    }
   ],
   "source": [
    "### 6(j). Bayesian optimization runs (x20): STP DF1 run number = 10\n",
    "\n",
    "np.random.seed(run_num_10)\n",
    "surrogate_stp_df1_10 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_10 = GPGO(surrogate_stp_df1_10, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_10.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.668455521679151, -8.199404844549841)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(j). Training Regret Minimisation: run number = 10\n",
    "\n",
    "gp_output_10 = np.append(np.max(gpgo_gp_10.GP.y[0:n_init]),gpgo_gp_10.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_10 = np.append(np.max(gpgo_stp_df1_10.GP.y[0:n_init]),gpgo_stp_df1_10.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_10 = np.log(y_global_orig - gp_output_10)\n",
    "regret_stp_df1_10 = np.log(y_global_orig - stp_df1_output_10)\n",
    "\n",
    "train_regret_gp_10 = min_max_array(regret_gp_10)\n",
    "train_regret_stp_df1_10 = min_max_array(regret_stp_df1_10)\n",
    "\n",
    "# GP, STP df1, STP df2 - training regret minimization: run number = 10\n",
    "min_train_regret_gp_10 = min(train_regret_gp_10)\n",
    "min_train_regret_stp_df1_10 = min(train_regret_stp_df1_10)\n",
    "\n",
    "min_train_regret_gp_10, min_train_regret_stp_df1_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.4267048   1.70001481]. \t  -36.52727706125721 \t -0.21514244643277425\n",
      "init   \t [-0.93855946 -0.75809223]. \t  -1.8557175865363904 \t -0.21514244643277425\n",
      "init   \t [-2.98794096 -1.0576211 ]. \t  -109.21818284867453 \t -0.21514244643277425\n",
      "init   \t [-1.57324968  0.94366349]. \t  -0.21514244643277425 \t -0.21514244643277425\n",
      "init   \t [-0.02719154  1.1377014 ]. \t  -1.4960801258622254 \t -0.21514244643277425\n",
      "1      \t [-0.94349261  0.51840508]. \t  -0.8565738868315744 \t -0.21514244643277425\n",
      "2      \t [-0.27363172 -1.39392591]. \t  -7.998622434595757 \t -0.21514244643277425\n",
      "3      \t [0.06583968 2.        ]. \t  -48.14897937607824 \t -0.21514244643277425\n",
      "4      \t [0.66749648 0.50218141]. \t  -0.9756563985822198 \t -0.21514244643277425\n",
      "5      \t [0.00293246 0.74525415]. \t  \u001b[92m0.9855018747612025\u001b[0m \t 0.9855018747612025\n",
      "6      \t [-1.04906151  0.96131878]. \t  -1.014054489600697 \t 0.9855018747612025\n",
      "7      \t [0.50038353 0.87688167]. \t  -0.6031660626109725 \t 0.9855018747612025\n",
      "8      \t [-1.55123512  0.55415357]. \t  -0.3992268504887958 \t 0.9855018747612025\n",
      "9      \t [ 1.85751592 -0.20785811]. \t  -1.9416882440126229 \t 0.9855018747612025\n",
      "10     \t [ 3. -2.]. \t  -150.89999999999998 \t 0.9855018747612025\n",
      "11     \t [1.72195899 0.27001855]. \t  -2.281720800455668 \t 0.9855018747612025\n",
      "12     \t [ 1.29529389 -0.22539455]. \t  -1.8891797309220235 \t 0.9855018747612025\n",
      "13     \t [-1.39957485  0.7419303 ]. \t  -0.254747890773648 \t 0.9855018747612025\n",
      "14     \t [-0.10095543  0.85675683]. \t  0.8268596263770236 \t 0.9855018747612025\n",
      "15     \t [-0.66893562 -0.3226805 ]. \t  -1.242002896068676 \t 0.9855018747612025\n",
      "16     \t [-1.05188351 -0.11935323]. \t  -2.3758124225674973 \t 0.9855018747612025\n",
      "17     \t [-0.95704926 -1.8399544 ]. \t  -36.22192077533009 \t 0.9855018747612025\n",
      "18     \t [2.81942466 0.41922623]. \t  -67.13534885689634 \t 0.9855018747612025\n",
      "19     \t [1.54300577 0.00689939]. \t  -2.128685508256744 \t 0.9855018747612025\n",
      "20     \t [ 0.7450882  -1.07253294]. \t  -1.5230100046545472 \t 0.9855018747612025\n",
      "21     \t [ 0.43282359 -0.56629231]. \t  0.4386547247709114 \t 0.9855018747612025\n",
      "22     \t [-1.96570111  0.74707975]. \t  -0.877365527857962 \t 0.9855018747612025\n",
      "23     \t [1.57923354 0.92951748]. \t  -3.0827703019529156 \t 0.9855018747612025\n",
      "24     \t [ 1.39187889 -0.67091248]. \t  -0.36738280366068765 \t 0.9855018747612025\n",
      "25     \t [ 0.88054539 -0.76423757]. \t  -0.3496513019461198 \t 0.9855018747612025\n",
      "26     \t [0.18579217 0.00164353]. \t  -0.1358809425109214 \t 0.9855018747612025\n",
      "27     \t [ 0.64039603 -1.97490834]. \t  -45.292655019443536 \t 0.9855018747612025\n",
      "28     \t [ 0.05094858 -0.87324652]. \t  0.7583718557768029 \t 0.9855018747612025\n",
      "29     \t [ 0.24667294 -0.84390716]. \t  0.7923987009847523 \t 0.9855018747612025\n",
      "30     \t [-1.9886068   0.71919191]. \t  -1.1628066409632365 \t 0.9855018747612025\n",
      "31     \t [ 1.53190437 -1.73617303]. \t  -23.756949561270776 \t 0.9855018747612025\n",
      "32     \t [-0.33375412 -1.16695785]. \t  -2.780180104165387 \t 0.9855018747612025\n",
      "33     \t [2.19627152 1.89979232]. \t  -49.68516474304249 \t 0.9855018747612025\n",
      "34     \t [ 0.89139981 -1.55902321]. \t  -14.538140515323716 \t 0.9855018747612025\n",
      "35     \t [-2.6590455  -0.57198694]. \t  -41.762583430380865 \t 0.9855018747612025\n",
      "36     \t [-1.77550693 -0.47550581]. \t  -2.3273964542248597 \t 0.9855018747612025\n",
      "37     \t [ 1.47430265 -0.5975813 ]. \t  -0.3966317791008047 \t 0.9855018747612025\n",
      "38     \t [-0.50244818  1.06272016]. \t  -0.9318258074331266 \t 0.9855018747612025\n",
      "39     \t [-0.76645211  1.89355586]. \t  -37.323917798475186 \t 0.9855018747612025\n",
      "40     \t [-0.21960876 -0.18907848]. \t  -0.09169800030307962 \t 0.9855018747612025\n",
      "41     \t [0.18517758 0.06722874]. \t  -0.12915923721279213 \t 0.9855018747612025\n",
      "42     \t [-2.83280196  0.25694218]. \t  -68.1477640263222 \t 0.9855018747612025\n",
      "43     \t [ 1.33168245 -0.88019237]. \t  -0.47808856827836677 \t 0.9855018747612025\n",
      "44     \t [-2.1602256 -1.7847889]. \t  -38.51188193501204 \t 0.9855018747612025\n",
      "45     \t [ 0.33143716 -0.54482096]. \t  0.6009583170847038 \t 0.9855018747612025\n",
      "46     \t [-2.6228309  -0.51727099]. \t  -37.227120883344526 \t 0.9855018747612025\n",
      "47     \t [-1.65355766 -0.77564358]. \t  -2.374885010151957 \t 0.9855018747612025\n",
      "48     \t [-2.9957187  -0.40682714]. \t  -108.35921943545252 \t 0.9855018747612025\n",
      "49     \t [-2.60028923 -0.51281847]. \t  -34.637206281640054 \t 0.9855018747612025\n",
      "50     \t [-2.86378777 -0.59285757]. \t  -76.21851198745338 \t 0.9855018747612025\n",
      "51     \t [-2.59697571 -0.678232  ]. \t  -34.481004433368824 \t 0.9855018747612025\n",
      "52     \t [-2.60475312  0.63771936]. \t  -31.950626242423578 \t 0.9855018747612025\n",
      "53     \t [-1.58522723 -1.25935667]. \t  -7.793934757601741 \t 0.9855018747612025\n",
      "54     \t [ 1.63459331 -1.72298121]. \t  -22.61471067193921 \t 0.9855018747612025\n",
      "55     \t [ 1.84054314 -0.78194187]. \t  -0.02013099217750669 \t 0.9855018747612025\n",
      "56     \t [-2.86671    -0.40629747]. \t  -76.66411238666814 \t 0.9855018747612025\n",
      "57     \t [-0.47113927  0.73989656]. \t  0.5515254849825049 \t 0.9855018747612025\n",
      "58     \t [ 2.05738054 -0.47501016]. \t  -2.9093605494902235 \t 0.9855018747612025\n",
      "59     \t [-0.0860413  -0.69182771]. \t  0.9091493129219326 \t 0.9855018747612025\n",
      "60     \t [ 1.39428881 -0.83679193]. \t  -0.2823023536036732 \t 0.9855018747612025\n",
      "61     \t [0.2870021  0.07749988]. \t  -0.3137809295176934 \t 0.9855018747612025\n",
      "62     \t [ 0.81040449 -1.97475399]. \t  -45.4458802790124 \t 0.9855018747612025\n",
      "63     \t [-1.76142776 -1.15341521]. \t  -5.940583299762148 \t 0.9855018747612025\n",
      "64     \t [ 0.75091533 -0.67503889]. \t  -0.14851536313143088 \t 0.9855018747612025\n",
      "65     \t [2.3218739  0.02813039]. \t  -12.821124895045264 \t 0.9855018747612025\n",
      "66     \t [ 0.00089587 -0.68615923]. \t  \u001b[92m0.9972043258608717\u001b[0m \t 0.9972043258608717\n",
      "67     \t [1.48783829 1.60269263]. \t  -20.6812506333947 \t 0.9972043258608717\n",
      "68     \t [-1.61157625  1.26148844]. \t  -3.7943436363144176 \t 0.9972043258608717\n",
      "69     \t [ 0.81127613 -0.15595124]. \t  -1.5965843946434908 \t 0.9972043258608717\n",
      "70     \t [-1.61311467 -1.54181542]. \t  -17.644893124343177 \t 0.9972043258608717\n",
      "71     \t [-0.9020958   0.79528543]. \t  -0.3968341417636141 \t 0.9972043258608717\n",
      "72     \t [2.45858218 0.08332687]. \t  -21.245551435079598 \t 0.9972043258608717\n",
      "73     \t [ 2.09407865 -0.75430265]. \t  -2.70623856519173 \t 0.9972043258608717\n",
      "74     \t [-2.70172779  0.8734725 ]. \t  -43.862269902178 \t 0.9972043258608717\n",
      "75     \t [0.53038561 0.11885564]. \t  -0.9738040696368243 \t 0.9972043258608717\n",
      "76     \t [ 0.05569058 -0.68979026]. \t  \u001b[92m1.0236887386127596\u001b[0m \t 1.0236887386127596\n",
      "77     \t [0.5945949  0.84886723]. \t  -0.865764224839046 \t 1.0236887386127596\n",
      "78     \t [ 0.40194838 -1.16078837]. \t  -1.998811514073678 \t 1.0236887386127596\n",
      "79     \t [1.01849084 0.83434872]. \t  -2.265333825812948 \t 1.0236887386127596\n",
      "80     \t [-2.78099946  1.01522812]. \t  -56.82930885480462 \t 1.0236887386127596\n",
      "81     \t [-0.10261469  0.6915841 ]. \t  \u001b[92m1.0271944942474156\u001b[0m \t 1.0271944942474156\n",
      "82     \t [-2.91061859  0.854148  ]. \t  -82.56561713396172 \t 1.0271944942474156\n",
      "83     \t [-1.65734065  1.70623527]. \t  -21.479485205501657 \t 1.0271944942474156\n",
      "84     \t [0.03153944 1.20450042]. \t  -2.6582104387278487 \t 1.0271944942474156\n",
      "85     \t [-2.45422939 -0.11943385]. \t  -20.982965081740474 \t 1.0271944942474156\n",
      "86     \t [ 0.18261843 -0.70304859]. \t  0.9971839030721666 \t 1.0271944942474156\n",
      "87     \t [-2.75357123 -0.81353326]. \t  -56.24345981243387 \t 1.0271944942474156\n",
      "88     \t [-1.28884585  1.11862243]. \t  -2.1939334671461808 \t 1.0271944942474156\n",
      "89     \t [ 0.13162208 -0.69587203]. \t  1.021929403663996 \t 1.0271944942474156\n",
      "90     \t [-2.13266796  1.367765  ]. \t  -9.713063361770887 \t 1.0271944942474156\n",
      "91     \t [ 0.93655289 -1.9131933 ]. \t  -39.27620895208851 \t 1.0271944942474156\n",
      "92     \t [-1.61774173  0.11601871]. \t  -1.8192752483983816 \t 1.0271944942474156\n",
      "93     \t [-0.15800836  1.79074622]. \t  -28.12206932629103 \t 1.0271944942474156\n",
      "94     \t [2.79895121 0.15962441]. \t  -63.06893309843212 \t 1.0271944942474156\n",
      "95     \t [-0.02884874  0.71850988]. \t  1.0163434731489933 \t 1.0271944942474156\n",
      "96     \t [-1.06350551 -1.49461521]. \t  -14.934845409435896 \t 1.0271944942474156\n",
      "97     \t [-0.17214069  0.58883897]. \t  0.8907036360605345 \t 1.0271944942474156\n",
      "98     \t [-2.00357649  1.1712952 ]. \t  -3.473829012199275 \t 1.0271944942474156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [ 2.25844889 -1.98158352]. \t  -51.49413376186263 \t 1.0271944942474156\n",
      "100    \t [-2.94862611  0.76517903]. \t  -91.88340605954673 \t 1.0271944942474156\n"
     ]
    }
   ],
   "source": [
    "### 6(k). Bayesian optimization runs (x20): GP run number = 11\n",
    "\n",
    "np.random.seed(run_num_11)\n",
    "surrogate_gp_11 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_11 = GPGO(surrogate_gp_11, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_11.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.4267048   1.70001481]. \t  -36.52727706125721 \t -0.21514244643277425\n",
      "init   \t [-0.93855946 -0.75809223]. \t  -1.8557175865363904 \t -0.21514244643277425\n",
      "init   \t [-2.98794096 -1.0576211 ]. \t  -109.21818284867453 \t -0.21514244643277425\n",
      "init   \t [-1.57324968  0.94366349]. \t  -0.21514244643277425 \t -0.21514244643277425\n",
      "init   \t [-0.02719154  1.1377014 ]. \t  -1.4960801258622254 \t -0.21514244643277425\n",
      "1      \t [ 0.78161739 -1.96612741]. \t  -44.50975349617191 \t -0.21514244643277425\n",
      "2      \t [3. 2.]. \t  -162.89999999999998 \t -0.21514244643277425\n",
      "3      \t [ 3.         -1.30197765]. \t  -109.70756096101604 \t -0.21514244643277425\n",
      "4      \t [ 0.55029818 -0.10906257]. \t  -0.9209595307769294 \t -0.21514244643277425\n",
      "5      \t [-0.8173707  2.       ]. \t  -48.19970302959238 \t -0.21514244643277425\n",
      "6      \t [-0.68686095  0.25495434]. \t  -1.0364832752240056 \t -0.21514244643277425\n",
      "7      \t [-1.00702337 -2.        ]. \t  -52.25843930014062 \t -0.21514244643277425\n",
      "8      \t [1.04607262 0.98739304]. \t  -3.234427739178619 \t -0.21514244643277425\n",
      "9      \t [0.70539439 2.        ]. \t  -50.92224574902872 \t -0.21514244643277425\n",
      "10     \t [-1.76461658  0.12020552]. \t  -1.8886319346123384 \t -0.21514244643277425\n",
      "11     \t [1.63575663 0.05380995]. \t  -2.1300360098999485 \t -0.21514244643277425\n",
      "12     \t [-3.          0.72141881]. \t  -105.73741558442121 \t -0.21514244643277425\n",
      "13     \t [0.75187529 0.50101376]. \t  -1.2750383406524772 \t -0.21514244643277425\n",
      "14     \t [ 1.12948715 -0.75782848]. \t  -0.5434050772376144 \t -0.21514244643277425\n",
      "15     \t [ 0.11775117 -0.97488475]. \t  \u001b[92m0.2482936707678731\u001b[0m \t 0.2482936707678731\n",
      "16     \t [-1.31522885  0.28830913]. \t  -1.676818980199944 \t 0.2482936707678731\n",
      "17     \t [3.         0.26386432]. \t  -109.43248565837791 \t 0.2482936707678731\n",
      "18     \t [-0.25209465 -0.49842607]. \t  \u001b[92m0.3753858004147075\u001b[0m \t 0.3753858004147075\n",
      "19     \t [-0.55442846  0.86145584]. \t  0.20233594708997804 \t 0.3753858004147075\n",
      "20     \t [-2.2301544 -2.       ]. \t  -61.41770141280702 \t 0.3753858004147075\n",
      "21     \t [-0.03770924  0.64270575]. \t  \u001b[92m0.988325421975861\u001b[0m \t 0.988325421975861\n",
      "22     \t [ 1.1690976  -0.18648819]. \t  -2.042929238865065 \t 0.988325421975861\n",
      "23     \t [-1.60898522 -0.59630647]. \t  -2.1073904152134655 \t 0.988325421975861\n",
      "24     \t [1.5139743  0.56305433]. \t  -2.1359568061759635 \t 0.988325421975861\n",
      "25     \t [ 0.56974518 -0.79705808]. \t  0.29233400868137693 \t 0.988325421975861\n",
      "26     \t [ 2.01156307 -2.        ]. \t  -47.86276377355361 \t 0.988325421975861\n",
      "27     \t [-1.8291537  2.       ]. \t  -46.701419520757156 \t 0.988325421975861\n",
      "28     \t [-3.  2.]. \t  -150.89999999999998 \t 0.988325421975861\n",
      "29     \t [-2.01166666  1.11517536]. \t  -2.8557966794989262 \t 0.988325421975861\n",
      "30     \t [-3. -2.]. \t  -162.89999999999998 \t 0.988325421975861\n",
      "31     \t [-1.50642752 -1.29440432]. \t  -8.635158663874966 \t 0.988325421975861\n",
      "32     \t [1.80727352 2.        ]. \t  -53.89112680453737 \t 0.988325421975861\n",
      "33     \t [ 1.89141981 -0.78208141]. \t  -0.2659202280188665 \t 0.988325421975861\n",
      "34     \t [ 1.64835173 -0.60833856]. \t  -0.11608845181158645 \t 0.988325421975861\n",
      "35     \t [ 1.60707006 -1.19871348]. \t  -2.65040197879704 \t 0.988325421975861\n",
      "36     \t [-2.20805259 -0.43255157]. \t  -8.561666938346589 \t 0.988325421975861\n",
      "37     \t [-0.38349435 -0.91937539]. \t  -0.37327973536548864 \t 0.988325421975861\n",
      "38     \t [ 3. -2.]. \t  -150.89999999999998 \t 0.988325421975861\n",
      "39     \t [2.1802133  1.06026958]. \t  -10.234732143259967 \t 0.988325421975861\n",
      "40     \t [1.72562259 1.14451122]. \t  -5.690335259282931 \t 0.988325421975861\n",
      "41     \t [1.97474946 0.61050686]. \t  -3.7013687818805354 \t 0.988325421975861\n",
      "42     \t [-0.07242719 -2.        ]. \t  -48.16577942780522 \t 0.988325421975861\n",
      "43     \t [-1.74537241  1.34936316]. \t  -5.743202418112405 \t 0.988325421975861\n",
      "44     \t [-3.         -0.19478377]. \t  -109.33834643298688 \t 0.988325421975861\n",
      "45     \t [0.37474444 0.91366841]. \t  -0.3119709639404349 \t 0.988325421975861\n",
      "46     \t [-2.01991214 -1.06572529]. \t  -6.77130958110615 \t 0.988325421975861\n",
      "47     \t [ 0.64819531 -1.1822524 ]. \t  -2.791914738358998 \t 0.988325421975861\n",
      "48     \t [3.         1.10472554]. \t  -113.29018799268242 \t 0.988325421975861\n",
      "49     \t [-0.06144538  2.        ]. \t  -47.892181460813035 \t 0.988325421975861\n",
      "50     \t [-0.05892545  0.18222535]. \t  0.1252879145618475 \t 0.988325421975861\n",
      "51     \t [ 2.2081001  -0.39526589]. \t  -6.816387617100976 \t 0.988325421975861\n",
      "52     \t [-0.20863112  0.73952695]. \t  0.9753332415869564 \t 0.988325421975861\n",
      "53     \t [-0.72543788 -0.30538552]. \t  -1.4553155087787257 \t 0.988325421975861\n",
      "54     \t [-1.7262815   0.62089031]. \t  -0.07297991955585792 \t 0.988325421975861\n",
      "55     \t [ 3.         -0.58226176]. \t  -106.25686168661042 \t 0.988325421975861\n",
      "56     \t [ 2.19712971 -1.4572573 ]. \t  -14.21290754167105 \t 0.988325421975861\n",
      "57     \t [-1.66144286 -2.        ]. \t  -53.37412785992748 \t 0.988325421975861\n",
      "58     \t [-3.          1.40963946]. \t  -112.51674999090908 \t 0.988325421975861\n",
      "59     \t [-0.45671617 -1.40225958]. \t  -8.986965392467283 \t 0.988325421975861\n",
      "60     \t [-0.03970452  0.78640159]. \t  0.968822864915602 \t 0.988325421975861\n",
      "61     \t [-2.28587641  0.39311576]. \t  -9.698193533431857 \t 0.988325421975861\n",
      "62     \t [ 0.08219032 -0.64357591]. \t  \u001b[92m0.996516988248847\u001b[0m \t 0.996516988248847\n",
      "63     \t [-0.97265633  1.30148842]. \t  -5.622350306849545 \t 0.996516988248847\n",
      "64     \t [ 0.10603836 -0.70692591]. \t  \u001b[92m1.0302494977381322\u001b[0m \t 1.0302494977381322\n",
      "65     \t [-0.04308012  0.74554925]. \t  1.0122279235282003 \t 1.0302494977381322\n",
      "66     \t [-0.00134399  0.71604122]. \t  1.0003084398303903 \t 1.0302494977381322\n",
      "67     \t [-0.02942942  0.75603336]. \t  0.998288361342167 \t 1.0302494977381322\n",
      "68     \t [-0.02234385  0.72816288]. \t  1.0106202177863508 \t 1.0302494977381322\n",
      "69     \t [ 0.09646155 -0.67348147]. \t  1.0193070219167302 \t 1.0302494977381322\n",
      "70     \t [2.37359649 2.        ]. \t  -68.23599935128455 \t 1.0302494977381322\n",
      "71     \t [ 0.06097498 -0.71688256]. \t  1.028093984980852 \t 1.0302494977381322\n",
      "72     \t [ 0.04783058 -0.73753377]. \t  1.0184080535362912 \t 1.0302494977381322\n",
      "73     \t [ 0.11221943 -0.75564478]. \t  1.0145941431963033 \t 1.0302494977381322\n",
      "74     \t [ 0.08033956 -0.75474668]. \t  1.0155052889889389 \t 1.0302494977381322\n",
      "75     \t [-0.0271399   0.79062835]. \t  0.9559191955066813 \t 1.0302494977381322\n",
      "76     \t [ 0.05569058 -0.68979026]. \t  1.0236887386127596 \t 1.0302494977381322\n",
      "77     \t [-1.87769806e-04  7.00158969e-01]. \t  0.9997489360639731 \t 1.0302494977381322\n",
      "78     \t [ 0.10372788 -0.72985224]. \t  1.0286377767462014 \t 1.0302494977381322\n",
      "79     \t [ 0.07144887 -0.65527691]. \t  1.0065094008442714 \t 1.0302494977381322\n",
      "80     \t [ 0.09197557 -0.68513706]. \t  1.0255856214423067 \t 1.0302494977381322\n",
      "81     \t [-0.10261469  0.6915841 ]. \t  1.0271944944695826 \t 1.0302494977381322\n",
      "82     \t [-0.11960859  0.79370003]. \t  0.9705791696806068 \t 1.0302494977381322\n",
      "83     \t [ 0.02988366 -0.68104871]. \t  1.0115479260836302 \t 1.0302494977381322\n",
      "84     \t [ 1.39936557 -1.71505683]. \t  -22.725311991885974 \t 1.0302494977381322\n",
      "85     \t [ 0.00330336 -0.67728094]. \t  0.995374020244443 \t 1.0302494977381322\n",
      "86     \t [-0.04802396  0.69775698]. \t  1.0236048813074634 \t 1.0302494977381322\n",
      "87     \t [0.0396556  0.70795174]. \t  0.9656349584361671 \t 1.0302494977381322\n",
      "88     \t [-0.07104594  0.72832166]. \t  1.027898250049329 \t 1.0302494977381322\n",
      "89     \t [ 0.13162204 -0.69587231]. \t  1.0219295069529069 \t 1.0302494977381322\n",
      "90     \t [ 0.18586575 -0.77336791]. \t  0.9695579452115479 \t 1.0302494977381322\n",
      "91     \t [ 0.11037578 -0.69994361]. \t  1.0284303104597246 \t 1.0302494977381322\n",
      "92     \t [-0.06266906  0.83715062]. \t  0.8754696189689881 \t 1.0302494977381322\n",
      "93     \t [-0.05695124 -0.70435313]. \t  0.9468740981229016 \t 1.0302494977381322\n",
      "94     \t [-1.20997911  0.71631232]. \t  -0.5349704233824651 \t 1.0302494977381322\n",
      "95     \t [-0.02884861  0.71850988]. \t  1.0163434110543321 \t 1.0302494977381322\n",
      "96     \t [-2.42679991 -1.52792951]. \t  -34.98033342468058 \t 1.0302494977381322\n",
      "97     \t [-0.09198142  0.74393869]. \t  1.0233109565736702 \t 1.0302494977381322\n",
      "98     \t [0.02238634 0.61588794]. \t  0.9259518304277113 \t 1.0302494977381322\n",
      "99     \t [-0.03569707  0.66186507]. \t  1.003189336281089 \t 1.0302494977381322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [ 0.02940033 -0.73693564]. \t  1.01078867768433 \t 1.0302494977381322\n"
     ]
    }
   ],
   "source": [
    "### 6(k). Bayesian optimization runs (x20): STP DF1 run number = 11\n",
    "\n",
    "np.random.seed(run_num_11)\n",
    "surrogate_stp_df1_11 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_11 = GPGO(surrogate_stp_df1_11, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_11.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.424900212884998, -6.60727870989566)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(k). Training Regret Minimisation: run number = 11\n",
    "\n",
    "gp_output_11 = np.append(np.max(gpgo_gp_11.GP.y[0:n_init]),gpgo_gp_11.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_11 = np.append(np.max(gpgo_stp_df1_11.GP.y[0:n_init]),gpgo_stp_df1_11.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_11 = np.log(y_global_orig - gp_output_11)\n",
    "regret_stp_df1_11 = np.log(y_global_orig - stp_df1_output_11)\n",
    "\n",
    "train_regret_gp_11 = min_max_array(regret_gp_11)\n",
    "train_regret_stp_df1_11 = min_max_array(regret_stp_df1_11)\n",
    "\n",
    "# GP, STP df1, STP df2 - training regret minimization: run number = 11\n",
    "min_train_regret_gp_11 = min(train_regret_gp_11)\n",
    "min_train_regret_stp_df1_11 = min(train_regret_stp_df1_11)\n",
    "\n",
    "min_train_regret_gp_11, min_train_regret_stp_df1_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.59508832 -0.66022802]. \t  -34.236132330101135 \t -1.79312229181728\n",
      "init   \t [-0.78963452 -0.06562059]. \t  -1.79312229181728 \t -1.79312229181728\n",
      "init   \t [-0.21712353 -1.84847942]. \t  -33.617953096264564 \t -1.79312229181728\n",
      "init   \t [-2.60610456 -1.6528092 ]. \t  -57.95952620003331 \t -1.79312229181728\n",
      "init   \t [ 2.73425945 -1.29691935]. \t  -52.86046385370973 \t -1.79312229181728\n",
      "1      \t [-0.6957603   0.73039265]. \t  \u001b[92m0.021659261064579383\u001b[0m \t 0.021659261064579383\n",
      "2      \t [-3.  2.]. \t  -150.89999999999998 \t 0.021659261064579383\n",
      "3      \t [-0.2039722   0.60017435]. \t  \u001b[92m0.881445420405786\u001b[0m \t 0.881445420405786\n",
      "4      \t [-0.49798058  0.49281668]. \t  0.11306663934209149 \t 0.881445420405786\n",
      "5      \t [0.25706129 1.57082978]. \t  -15.14337042295287 \t 0.881445420405786\n",
      "6      \t [0.63276493 0.31847454]. \t  -1.1232682416759299 \t 0.881445420405786\n",
      "7      \t [2.76133323 1.53446732]. \t  -73.17279982756338 \t 0.881445420405786\n",
      "8      \t [ 0.09496671 -0.00975005]. \t  -0.03459799060380191 \t 0.881445420405786\n",
      "9      \t [0.16563998 0.34199346]. \t  0.24829970619760577 \t 0.881445420405786\n",
      "10     \t [-0.42842918  0.94275551]. \t  0.13376354816020486 \t 0.881445420405786\n",
      "11     \t [ 0.53859234 -0.3316443 ]. \t  -0.42157036859130465 \t 0.881445420405786\n",
      "12     \t [-1.6792375  0.0893992]. \t  -1.873362673947077 \t 0.881445420405786\n",
      "13     \t [ 1.09527589 -0.34812428]. \t  -1.5445459443652096 \t 0.881445420405786\n",
      "14     \t [0.02543413 0.65557157]. \t  \u001b[92m0.9610126881462894\u001b[0m \t 0.9610126881462894\n",
      "15     \t [ 1.36354378 -1.92507562]. \t  -39.80672362261527 \t 0.9610126881462894\n",
      "16     \t [-1.33573926  0.52594671]. \t  -0.8420469126777604 \t 0.9610126881462894\n",
      "17     \t [-1.22700154  0.24126565]. \t  -1.884388477530704 \t 0.9610126881462894\n",
      "18     \t [-0.16433537 -0.49660715]. \t  0.5550820473968691 \t 0.9610126881462894\n",
      "19     \t [-0.14202189  0.66649298]. \t  \u001b[92m1.002378541527423\u001b[0m \t 1.002378541527423\n",
      "20     \t [-2.16157006  0.26036696]. \t  -6.029705016912743 \t 1.002378541527423\n",
      "21     \t [-0.20684298  0.70336111]. \t  0.9780554746382866 \t 1.002378541527423\n",
      "22     \t [-0.85676003  1.52358483]. \t  -12.89982776547486 \t 1.002378541527423\n",
      "23     \t [-1.70244385  1.27294802]. \t  -3.9223136158254888 \t 1.002378541527423\n",
      "24     \t [ 0.44221055 -0.76248892]. \t  0.606294174926564 \t 1.002378541527423\n",
      "25     \t [ 0.24672284 -0.51938764]. \t  0.6803270013016026 \t 1.002378541527423\n",
      "26     \t [ 0.95793702 -0.84446052]. \t  -0.5325305009851603 \t 1.002378541527423\n",
      "27     \t [0.8496009  0.48841168]. \t  -1.6068815981750293 \t 1.002378541527423\n",
      "28     \t [-0.18218823  0.73930591]. \t  0.9955478462755533 \t 1.002378541527423\n",
      "29     \t [1.29713213 1.41667948]. \t  -12.29448970953973 \t 1.002378541527423\n",
      "30     \t [-2.35839289  0.85604189]. \t  -11.835894005001048 \t 1.002378541527423\n",
      "31     \t [-1.69781423  0.83912509]. \t  0.1931011090564586 \t 1.002378541527423\n",
      "32     \t [-1.45644552  1.36997966]. \t  -6.804797365541087 \t 1.002378541527423\n",
      "33     \t [1.26988529 0.82593892]. \t  -2.5688358834957787 \t 1.002378541527423\n",
      "34     \t [2.03994461 0.0951775 ]. \t  -4.458860080782038 \t 1.002378541527423\n",
      "35     \t [0.36473373 0.87367193]. \t  -0.09171422979998778 \t 1.002378541527423\n",
      "36     \t [ 0.71561315 -0.37501207]. \t  -0.7906645698657255 \t 1.002378541527423\n",
      "37     \t [-1.44282302 -0.75413265]. \t  -2.3404528080702054 \t 1.002378541527423\n",
      "38     \t [ 2.25745221 -0.63833133]. \t  -7.5557099938975 \t 1.002378541527423\n",
      "39     \t [2.54788137 0.63198296]. \t  -29.31037195810807 \t 1.002378541527423\n",
      "40     \t [ 1.61650489 -0.51838679]. \t  -0.43663695519080636 \t 1.002378541527423\n",
      "41     \t [1.12053467 1.38575519]. \t  -10.993507732303492 \t 1.002378541527423\n",
      "42     \t [2.97833594 0.07706116]. \t  -103.1078087763216 \t 1.002378541527423\n",
      "43     \t [2.35307203 1.38454171]. \t  -24.638942333525414 \t 1.002378541527423\n",
      "44     \t [1.934818   0.79721152]. \t  -3.6479110179851206 \t 1.002378541527423\n",
      "45     \t [ 0.73445898 -0.61968233]. \t  -0.197661027052507 \t 1.002378541527423\n",
      "46     \t [-0.59931668 -0.67136408]. \t  -0.5933155875767812 \t 1.002378541527423\n",
      "47     \t [1.22349976 0.69507549]. \t  -2.251709919709414 \t 1.002378541527423\n",
      "48     \t [2.6855377  1.84891963]. \t  -82.69883632095133 \t 1.002378541527423\n",
      "49     \t [-1.17330091 -1.51987371]. \t  -16.284313323608426 \t 1.002378541527423\n",
      "50     \t [ 0.24760565 -1.94901841]. \t  -42.27979772183922 \t 1.002378541527423\n",
      "51     \t [-1.34779849 -0.15393889]. \t  -2.4495558894590097 \t 1.002378541527423\n",
      "52     \t [-0.23334338  1.027904  ]. \t  -0.21092454651950582 \t 1.002378541527423\n",
      "53     \t [0.58739063 0.12286022]. \t  -1.1565092735355125 \t 1.002378541527423\n",
      "54     \t [0.16951475 1.60108825]. \t  -16.41648106221688 \t 1.002378541527423\n",
      "55     \t [1.78588775 1.08968542]. \t  -5.046515607796403 \t 1.002378541527423\n",
      "56     \t [1.36972629 1.61026309]. \t  -21.041371659559807 \t 1.002378541527423\n",
      "57     \t [1.46944457 1.83873166]. \t  -37.102809734595596 \t 1.002378541527423\n",
      "58     \t [-2.78294415 -0.45803367]. \t  -60.47736682212321 \t 1.002378541527423\n",
      "59     \t [-2.26063685 -1.66912472]. \t  -33.76239827070223 \t 1.002378541527423\n",
      "60     \t [-2.56092194  1.17098816]. \t  -28.974126546309 \t 1.002378541527423\n",
      "61     \t [-1.26936026  1.97384819]. \t  -45.0152889834558 \t 1.002378541527423\n",
      "62     \t [-1.92360253 -0.61527833]. \t  -3.1783982185168913 \t 1.002378541527423\n",
      "63     \t [0.38463128 0.51291009]. \t  0.03130594072732018 \t 1.002378541527423\n",
      "64     \t [ 0.06053465 -0.81900843]. \t  0.9182926541211356 \t 1.002378541527423\n",
      "65     \t [-2.93828357  0.72939427]. \t  -89.37298337797955 \t 1.002378541527423\n",
      "66     \t [-0.49663123  1.15255397]. \t  -2.036286933128035 \t 1.002378541527423\n",
      "67     \t [-1.4508789  -0.21862699]. \t  -2.35907846135585 \t 1.002378541527423\n",
      "68     \t [-0.01881035 -0.73584075]. \t  0.9778672660853229 \t 1.002378541527423\n",
      "69     \t [-2.52440449  0.80971285]. \t  -23.526330419114796 \t 1.002378541527423\n",
      "70     \t [ 2.47805272 -1.50486656]. \t  -30.287659116608374 \t 1.002378541527423\n",
      "71     \t [ 1.98474838 -0.88718166]. \t  -1.1146529900542697 \t 1.002378541527423\n",
      "72     \t [ 0.70479012 -1.53262676]. \t  -13.103824227377057 \t 1.002378541527423\n",
      "73     \t [-0.18299088  0.17135474]. \t  0.013757081713341696 \t 1.002378541527423\n",
      "74     \t [ 0.05948535 -0.6548633 ]. \t  \u001b[92m1.0045754201519035\u001b[0m \t 1.0045754201519035\n",
      "75     \t [1.7710062  0.24400656]. \t  -2.380352190790096 \t 1.0045754201519035\n",
      "76     \t [-0.15702481  0.78429446]. \t  0.9727898056981648 \t 1.0045754201519035\n",
      "77     \t [-2.89527666 -0.12418367]. \t  -82.61029803998237 \t 1.0045754201519035\n",
      "78     \t [1.0890872  0.54125991]. \t  -2.107207564282901 \t 1.0045754201519035\n",
      "79     \t [ 0.01708489 -0.6756886 ]. \t  1.0028268310375827 \t 1.0045754201519035\n",
      "80     \t [ 1.46265516 -1.76987842]. \t  -26.340746175328093 \t 1.0045754201519035\n",
      "81     \t [-1.95815627 -1.87687732]. \t  -42.47525904511965 \t 1.0045754201519035\n",
      "82     \t [-2.81772214 -0.97614693]. \t  -68.77979463279209 \t 1.0045754201519035\n",
      "83     \t [-1.77320563  0.01751028]. \t  -2.1451579582505644 \t 1.0045754201519035\n",
      "84     \t [ 2.10540865 -1.92559425]. \t  -41.60960905997213 \t 1.0045754201519035\n",
      "85     \t [ 0.08239228 -0.70942073]. \t  \u001b[92m1.031350536367301\u001b[0m \t 1.031350536367301\n",
      "86     \t [-0.0849949   0.70940557]. \t  \u001b[92m1.0314663796713426\u001b[0m \t 1.0314663796713426\n",
      "87     \t [0.96681121 0.82105097]. \t  -2.0914116320900216 \t 1.0314663796713426\n",
      "88     \t [-2.97943874 -1.25108987]. \t  -110.46705284858393 \t 1.0314663796713426\n",
      "89     \t [1.53375911 1.5651781 ]. \t  -18.73508309544804 \t 1.0314663796713426\n",
      "90     \t [0.00557428 0.66651822]. \t  0.9837265567831807 \t 1.0314663796713426\n",
      "91     \t [2.88560712 0.76903508]. \t  -81.40014462891715 \t 1.0314663796713426\n",
      "92     \t [-1.20801032 -0.75092443]. \t  -2.32446954203067 \t 1.0314663796713426\n",
      "93     \t [0.98766625 1.83926402]. \t  -36.273902119562734 \t 1.0314663796713426\n",
      "94     \t [0.51920458 0.81232565]. \t  -0.4562175617562598 \t 1.0314663796713426\n",
      "95     \t [-0.45768796 -1.86137097]. \t  -35.758583164854116 \t 1.0314663796713426\n",
      "96     \t [-1.83076167 -0.00302894]. \t  -2.3719995438075214 \t 1.0314663796713426\n",
      "97     \t [ 0.0902199 -0.7598069]. \t  1.0122249407131239 \t 1.0314663796713426\n",
      "98     \t [ 0.08714112 -0.7114925 ]. \t  \u001b[92m1.031592067107672\u001b[0m \t 1.031592067107672\n",
      "99     \t [ 2.42910653 -1.72880666]. \t  -38.54300184132494 \t 1.031592067107672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [ 1.93175448 -0.89637953]. \t  -0.6419060223861355 \t 1.031592067107672\n"
     ]
    }
   ],
   "source": [
    "### 6(l). Bayesian optimization runs (x20): GP run number = 12\n",
    "\n",
    "np.random.seed(run_num_12)\n",
    "surrogate_gp_12 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_12 = GPGO(surrogate_gp_12, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_12.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.59508832 -0.66022802]. \t  -34.236132330101135 \t -1.79312229181728\n",
      "init   \t [-0.78963452 -0.06562059]. \t  -1.79312229181728 \t -1.79312229181728\n",
      "init   \t [-0.21712353 -1.84847942]. \t  -33.617953096264564 \t -1.79312229181728\n",
      "init   \t [-2.60610456 -1.6528092 ]. \t  -57.95952620003331 \t -1.79312229181728\n",
      "init   \t [ 2.73425945 -1.29691935]. \t  -52.86046385370973 \t -1.79312229181728\n",
      "1      \t [-0.70676351  1.80222169]. \t  -29.44796080843851 \t -1.79312229181728\n",
      "2      \t [3. 2.]. \t  -162.89999999999998 \t -1.79312229181728\n",
      "3      \t [-3.  2.]. \t  -150.89999999999998 \t -1.79312229181728\n",
      "4      \t [0.7824856  0.27345075]. \t  \u001b[92m-1.6756117200592315\u001b[0m \t -1.6756117200592315\n",
      "5      \t [0.71288991 2.        ]. \t  -50.95999461098898 \t -1.6756117200592315\n",
      "6      \t [ 1.27731445 -2.        ]. \t  -47.8291725841426 \t -1.6756117200592315\n",
      "7      \t [ 0.29426944 -0.54177826]. \t  \u001b[92m0.6580515114454025\u001b[0m \t 0.6580515114454025\n",
      "8      \t [ 1.83123668 -0.09176366]. \t  -2.1670672562757307 \t 0.6580515114454025\n",
      "9      \t [3.         0.02922556]. \t  -108.98426306411696 \t 0.6580515114454025\n",
      "10     \t [ 1.24145494 -0.4456863 ]. \t  -1.206924750406755 \t 0.6580515114454025\n",
      "11     \t [-1.01339698 -0.94420825]. \t  -2.824156638995176 \t 0.6580515114454025\n",
      "12     \t [-1.86248482  0.42542096]. \t  -1.134479410334928 \t 0.6580515114454025\n",
      "13     \t [-3.          0.27491744]. \t  -107.79577839284389 \t 0.6580515114454025\n",
      "14     \t [-1.61132178 -0.23467209]. \t  -2.233235568360163 \t 0.6580515114454025\n",
      "15     \t [-1.31464953  0.84257843]. \t  -0.4298791495748038 \t 0.6580515114454025\n",
      "16     \t [1.43733283 0.33261856]. \t  -2.3244609473630686 \t 0.6580515114454025\n",
      "17     \t [-1.31776881 -2.        ]. \t  -52.994558532868304 \t 0.6580515114454025\n",
      "18     \t [-0.38259683 -0.70522063]. \t  0.18858671903849933 \t 0.6580515114454025\n",
      "19     \t [ 3. -2.]. \t  -150.89999999999998 \t 0.6580515114454025\n",
      "20     \t [-1.56651962  2.        ]. \t  -46.962612675233764 \t 0.6580515114454025\n",
      "21     \t [ 1.9375202  -0.84801534]. \t  -0.6051403997553656 \t 0.6580515114454025\n",
      "22     \t [-0.15057931  0.75020766]. \t  \u001b[92m1.007563839439658\u001b[0m \t 1.007563839439658\n",
      "23     \t [-0.03225022  0.09110121]. \t  0.031702201026237865 \t 1.007563839439658\n",
      "24     \t [-1.44257836  0.39735538]. \t  -1.1287116445856475 \t 1.007563839439658\n",
      "25     \t [ 0.60865534 -1.26547348]. \t  -4.29287995929844 \t 1.007563839439658\n",
      "26     \t [0.69732816 0.99733269]. \t  -2.16110884891863 \t 1.007563839439658\n",
      "27     \t [-1.73601318  0.90273559]. \t  0.0647658483226442 \t 1.007563839439658\n",
      "28     \t [1.70401958 2.        ]. \t  -53.477563713330575 \t 1.007563839439658\n",
      "29     \t [ 1.89210152 -0.53515328]. \t  -0.8698373597948178 \t 1.007563839439658\n",
      "30     \t [0.27392855 0.71958446]. \t  0.5131535303688999 \t 1.007563839439658\n",
      "31     \t [-1.83329942 -0.9779603 ]. \t  -4.00347630022632 \t 1.007563839439658\n",
      "32     \t [2.0299486  1.00687076]. \t  -6.247619027431644 \t 1.007563839439658\n",
      "33     \t [1.54967058 1.03460131]. \t  -4.016242619993812 \t 1.007563839439658\n",
      "34     \t [0.00307146 1.20612691]. \t  -2.6498724043874473 \t 1.007563839439658\n",
      "35     \t [ 0.49117874 -2.        ]. \t  -47.86511957734321 \t 1.007563839439658\n",
      "36     \t [ 1.20664162 -1.0290768 ]. \t  -1.409202823017475 \t 1.007563839439658\n",
      "37     \t [-1.65352261  0.70093101]. \t  0.10769719930392108 \t 1.007563839439658\n",
      "38     \t [-0.08460918 -1.02280234]. \t  -0.30807425606052 \t 1.007563839439658\n",
      "39     \t [1.87544636 0.6138297 ]. \t  -2.8058314397001536 \t 1.007563839439658\n",
      "40     \t [-3. -2.]. \t  -162.89999999999998 \t 1.007563839439658\n",
      "41     \t [-0.72580946  1.12452298]. \t  -2.095111812833236 \t 1.007563839439658\n",
      "42     \t [3.         1.02412598]. \t  -112.17725312867498 \t 1.007563839439658\n",
      "43     \t [-2.10232745 -2.        ]. \t  -57.64075401685844 \t 1.007563839439658\n",
      "44     \t [-1.44651123  1.24027312]. \t  -3.7471288848557074 \t 1.007563839439658\n",
      "45     \t [ 0.66036502 -0.81460176]. \t  0.0582870272010656 \t 1.007563839439658\n",
      "46     \t [-3.          1.16865697]. \t  -107.39218443360184 \t 1.007563839439658\n",
      "47     \t [ 2.13338053 -2.        ]. \t  -49.864124943317606 \t 1.007563839439658\n",
      "48     \t [-0.56293393  0.66317986]. \t  0.2915343337360755 \t 1.007563839439658\n",
      "49     \t [ 1.66425133 -0.78974791]. \t  0.20158653146840777 \t 1.007563839439658\n",
      "50     \t [-3.         -1.07649809]. \t  -112.8658177778175 \t 1.007563839439658\n",
      "51     \t [-0.60469217 -1.15474868]. \t  -3.6749192870605443 \t 1.007563839439658\n",
      "52     \t [ 3.         -0.78794557]. \t  -105.59459012170632 \t 1.007563839439658\n",
      "53     \t [ 0.06376147 -0.72751825]. \t  \u001b[92m1.0267302898407664\u001b[0m \t 1.0267302898407664\n",
      "54     \t [ 1.86368831 -1.37495097]. \t  -6.697695195454502 \t 1.0267302898407664\n",
      "55     \t [-1.78633515 -1.4476729 ]. \t  -13.983338462104529 \t 1.0267302898407664\n",
      "56     \t [-0.03643548  2.        ]. \t  -47.932435510673805 \t 1.0267302898407664\n",
      "57     \t [-2.25253798  1.76761534]. \t  -32.3436938719622 \t 1.0267302898407664\n",
      "58     \t [-2.03773362 -0.12978488]. \t  -4.4643891147695856 \t 1.0267302898407664\n",
      "59     \t [2.34012532 2.        ]. \t  -66.34998735791024 \t 1.0267302898407664\n",
      "60     \t [ 0.08863547 -0.77154191]. \t  1.0007796774671924 \t 1.0267302898407664\n",
      "61     \t [-0.07092396  0.60437121]. \t  0.9501821010601931 \t 1.0267302898407664\n",
      "62     \t [-2.19862171 -1.08293441]. \t  -11.107929146944263 \t 1.0267302898407664\n",
      "63     \t [-2.17901343  0.97364368]. \t  -5.011320042909658 \t 1.0267302898407664\n",
      "64     \t [-0.02011826 -0.70116379]. \t  0.9839949913029823 \t 1.0267302898407664\n",
      "65     \t [-0.02609447  0.77859648]. \t  0.9724699904829098 \t 1.0267302898407664\n",
      "66     \t [-0.0391152   0.75887187]. \t  1.0005332967046079 \t 1.0267302898407664\n",
      "67     \t [ 0.07370036 -0.72023053]. \t  \u001b[92m1.0300126286747344\u001b[0m \t 1.0300126286747344\n",
      "68     \t [-0.00813342 -0.72616397]. \t  0.9908449609617511 \t 1.0300126286747344\n",
      "69     \t [2.38592589 0.3041864 ]. \t  -16.59975151832637 \t 1.0300126286747344\n",
      "70     \t [1.16167749 0.7536419 ]. \t  -2.2867695644876913 \t 1.0300126286747344\n",
      "71     \t [-0.02023398  0.67402767]. \t  1.003651862669615 \t 1.0300126286747344\n",
      "72     \t [ 0.05729528 -0.68746081]. \t  1.0232773603741558 \t 1.0300126286747344\n",
      "73     \t [ 0.06365734 -0.57084934]. \t  0.8988777247633704 \t 1.0300126286747344\n",
      "74     \t [ 0.05948535 -0.6548633 ]. \t  1.0045754201519035 \t 1.0300126286747344\n",
      "75     \t [-0.10744627  0.74920103]. \t  1.0195675954100714 \t 1.0300126286747344\n",
      "76     \t [-0.15701957  0.78428984]. \t  0.9727980550654747 \t 1.0300126286747344\n",
      "77     \t [-0.0838907   0.71962082]. \t  \u001b[92m1.031047710623423\u001b[0m \t 1.031047710623423\n",
      "78     \t [ 0.00655351 -0.70177409]. \t  1.004201507818873 \t 1.031047710623423\n",
      "79     \t [-0.07275876  0.75538279]. \t  1.0139049456492562 \t 1.031047710623423\n",
      "80     \t [-0.02361121  0.72989903]. \t  1.0107135647377377 \t 1.031047710623423\n",
      "81     \t [-0.17792412  0.59556885]. \t  0.8969863265828366 \t 1.031047710623423\n",
      "82     \t [-0.05801624  0.73913055]. \t  1.0208618854372757 \t 1.031047710623423\n",
      "83     \t [-0.04859577  0.73381987]. \t  1.020299641022956 \t 1.031047710623423\n",
      "84     \t [-0.03893275  0.76499667]. \t  0.994675479584877 \t 1.031047710623423\n",
      "85     \t [ 0.11748085 -0.70766224]. \t  1.0283264396389236 \t 1.031047710623423\n",
      "86     \t [-0.10114358  0.67857999]. \t  1.0216831021081718 \t 1.031047710623423\n",
      "87     \t [ 0.08804689 -0.69598889]. \t  1.0294233135980277 \t 1.031047710623423\n",
      "88     \t [-0.04027667  0.77661312]. \t  0.982254594885711 \t 1.031047710623423\n",
      "89     \t [ 0.02406365 -0.71453418]. \t  1.0144327913571973 \t 1.031047710623423\n",
      "90     \t [ 0.02473488 -0.75652526]. \t  0.995339304704191 \t 1.031047710623423\n",
      "91     \t [-0.13121588  0.77522772]. \t  0.9926863551747231 \t 1.031047710623423\n",
      "92     \t [-0.14507486  0.62027462]. \t  0.9535876014942021 \t 1.031047710623423\n",
      "93     \t [ 0.07005283 -0.71630884]. \t  1.029914131155487 \t 1.031047710623423\n",
      "94     \t [0.09085378 0.7863393 ]. \t  0.8396758884815347 \t 1.031047710623423\n",
      "95     \t [-0.01336228 -0.77323377]. \t  0.9506235240306932 \t 1.031047710623423\n",
      "96     \t [ 0.02783883 -0.74094669]. \t  1.0079235658519636 \t 1.031047710623423\n",
      "97     \t [ 0.09888149 -0.69950317]. \t  1.0298006103832513 \t 1.031047710623423\n",
      "98     \t [ 0.08714093 -0.71149233]. \t  \u001b[92m1.0315920604469084\u001b[0m \t 1.0315920604469084\n",
      "99     \t [ 0.0028618  -0.65249149]. \t  0.979779407266197 \t 1.0315920604469084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [2.03616856 1.5374818 ]. \t  -20.26832829940616 \t 1.0315920604469084\n"
     ]
    }
   ],
   "source": [
    "### 6(l). Bayesian optimization runs (x20): STP DF1 run number = 12\n",
    "\n",
    "np.random.seed(run_num_12)\n",
    "surrogate_stp_df1_12 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_12 = GPGO(surrogate_stp_df1_12, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_12.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11.744492856389474, -11.743653569976935)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(l). Training Regret Minimisation: run number = 12\n",
    "\n",
    "gp_output_12 = np.append(np.max(gpgo_gp_12.GP.y[0:n_init]),gpgo_gp_12.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_12 = np.append(np.max(gpgo_stp_df1_12.GP.y[0:n_init]),gpgo_stp_df1_12.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_12 = np.log(y_global_orig - gp_output_12)\n",
    "regret_stp_df1_12 = np.log(y_global_orig - stp_df1_output_12)\n",
    "\n",
    "train_regret_gp_12 = min_max_array(regret_gp_12)\n",
    "train_regret_stp_df1_12 = min_max_array(regret_stp_df1_12)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 12\n",
    "min_train_regret_gp_12 = min(train_regret_gp_12)\n",
    "min_train_regret_stp_df1_12 = min(train_regret_stp_df1_12)\n",
    "\n",
    "min_train_regret_gp_12, min_train_regret_stp_df1_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.20248745 -1.94972064]. \t  -47.34265872952369 \t -3.3855955096031627\n",
      "init   \t [-0.67943252  1.21320478]. \t  -3.3855955096031627 \t -3.3855955096031627\n",
      "init   \t [0.478725   1.25937469]. \t  -5.1311178846540475 \t -3.3855955096031627\n",
      "init   \t [2.61502198 0.35750001]. \t  -36.23378797270707 \t -3.3855955096031627\n",
      "init   \t [2.55659457 0.57599269]. \t  -30.093760262197183 \t -3.3855955096031627\n",
      "1      \t [2.31307725 2.        ]. \t  -64.96567635049229 \t -3.3855955096031627\n",
      "2      \t [-3.  2.]. \t  -150.89999999999998 \t -3.3855955096031627\n",
      "3      \t [-0.14513507  0.72944989]. \t  \u001b[92m1.0184197562596728\u001b[0m \t 1.0184197562596728\n",
      "4      \t [-0.25401626  0.2408698 ]. \t  0.03034992642845985 \t 1.0184197562596728\n",
      "5      \t [-0.1728286   0.64425668]. \t  0.9648771405650878 \t 1.0184197562596728\n",
      "6      \t [-0.14346187  1.17016666]. \t  -1.9362247989263413 \t 1.0184197562596728\n",
      "7      \t [0.60200378 0.34889985]. \t  -0.9720749915142467 \t 1.0184197562596728\n",
      "8      \t [0.24229339 0.6765609 ]. \t  0.601273984484493 \t 1.0184197562596728\n",
      "9      \t [-0.44231699  0.69751252]. \t  0.603102772991982 \t 1.0184197562596728\n",
      "10     \t [ 0.28577312 -0.694507  ]. \t  0.8843829689653624 \t 1.0184197562596728\n",
      "11     \t [ 1.01937561 -1.7810586 ]. \t  -28.0093675680257 \t 1.0184197562596728\n",
      "12     \t [ 0.10033706 -0.4546341 ]. \t  0.6614411156260614 \t 1.0184197562596728\n",
      "13     \t [ 0.32821276 -0.58012269]. \t  0.6765880751436983 \t 1.0184197562596728\n",
      "14     \t [-2.81552885 -0.98747295]. \t  -68.47672636964278 \t 1.0184197562596728\n",
      "15     \t [0.69437491 0.85587158]. \t  -1.2883426913276672 \t 1.0184197562596728\n",
      "16     \t [ 2.83992288 -1.92023655]. \t  -104.71579849901003 \t 1.0184197562596728\n",
      "17     \t [-0.21453437 -0.65250218]. \t  0.6582849652520155 \t 1.0184197562596728\n",
      "18     \t [ 0.07527126 -0.65655572]. \t  1.0078161660490887 \t 1.0184197562596728\n",
      "19     \t [-0.27641964 -0.50405536]. \t  0.32522664006298674 \t 1.0184197562596728\n",
      "20     \t [-0.10213299 -0.93863826]. \t  0.28186622641432624 \t 1.0184197562596728\n",
      "21     \t [-0.41888729  1.03931445]. \t  -0.5500654298754426 \t 1.0184197562596728\n",
      "22     \t [2.03363802 0.53665782]. \t  -4.474473579768521 \t 1.0184197562596728\n",
      "23     \t [1.557082   0.48989618]. \t  -2.1375557759952954 \t 1.0184197562596728\n",
      "24     \t [1.36472062 0.84217344]. \t  -2.643406730920786 \t 1.0184197562596728\n",
      "25     \t [ 0.30763672 -0.88777858]. \t  0.5809550394039702 \t 1.0184197562596728\n",
      "26     \t [ 0.1125089 -1.9910515]. \t  -46.8313983227659 \t 1.0184197562596728\n",
      "27     \t [-0.95889415 -0.39875407]. \t  -2.0090833659520477 \t 1.0184197562596728\n",
      "28     \t [-0.92820317 -1.78385129]. \t  -31.531579263938053 \t 1.0184197562596728\n",
      "29     \t [-0.19071964  0.65463809]. \t  0.9616989901476796 \t 1.0184197562596728\n",
      "30     \t [-0.89730632  0.10257936]. \t  -1.899542846529409 \t 1.0184197562596728\n",
      "31     \t [ 2.97897392 -1.6164128 ]. \t  -115.11494755172114 \t 1.0184197562596728\n",
      "32     \t [1.21418451 1.57332476]. \t  -18.919233655196724 \t 1.0184197562596728\n",
      "33     \t [ 0.13161801 -0.64987512]. \t  0.9927447877290259 \t 1.0184197562596728\n",
      "34     \t [0.74183874 1.02594059]. \t  -2.6032017221188144 \t 1.0184197562596728\n",
      "35     \t [-0.16309303  0.66631002]. \t  0.9911948314529515 \t 1.0184197562596728\n",
      "36     \t [-0.79147525 -1.22323392]. \t  -5.702218726131639 \t 1.0184197562596728\n",
      "37     \t [-2.30739625  1.36590629]. \t  -15.384066698974216 \t 1.0184197562596728\n",
      "38     \t [-2.13287597  0.7460183 ]. \t  -3.540469243629401 \t 1.0184197562596728\n",
      "39     \t [-1.82471012  1.1224466 ]. \t  -1.6030812331943765 \t 1.0184197562596728\n",
      "40     \t [ 0.03045543 -0.68684498]. \t  1.0140189427365685 \t 1.0184197562596728\n",
      "41     \t [0.29494378 1.98858692]. \t  -47.652487884219305 \t 1.0184197562596728\n",
      "42     \t [-1.48244226 -1.15255003]. \t  -5.639666511744199 \t 1.0184197562596728\n",
      "43     \t [ 2.4204346 -0.8121288]. \t  -15.519116594979842 \t 1.0184197562596728\n",
      "44     \t [ 1.71552376 -0.89061537]. \t  0.10394794218569925 \t 1.0184197562596728\n",
      "45     \t [ 1.89726865 -0.61986279]. \t  -0.6128809963006092 \t 1.0184197562596728\n",
      "46     \t [ 1.30687221 -1.46198043]. \t  -10.180183161386267 \t 1.0184197562596728\n",
      "47     \t [0.2376441 1.4699412]. \t  -10.600642574862258 \t 1.0184197562596728\n",
      "48     \t [-0.66612075 -1.49607581]. \t  -13.473049495615351 \t 1.0184197562596728\n",
      "49     \t [ 1.22811692 -0.48922805]. \t  -1.070482348576535 \t 1.0184197562596728\n",
      "50     \t [ 1.25353558 -0.80037173]. \t  -0.4692721653170797 \t 1.0184197562596728\n",
      "51     \t [-2.1364035   0.16485891]. \t  -5.745598552167186 \t 1.0184197562596728\n",
      "52     \t [-1.58444317 -0.1517573 ]. \t  -2.23121371872188 \t 1.0184197562596728\n",
      "53     \t [ 2.77852395 -1.10339914]. \t  -57.089343404890414 \t 1.0184197562596728\n",
      "54     \t [0.31826889 1.10708063]. \t  -1.8424697928911389 \t 1.0184197562596728\n",
      "55     \t [0.81718559 1.7071469 ]. \t  -25.545358205111537 \t 1.0184197562596728\n",
      "56     \t [-0.01144996 -0.65159351]. \t  0.9692586412058538 \t 1.0184197562596728\n",
      "57     \t [ 1.2440559  -1.48708452]. \t  -11.26211114943431 \t 1.0184197562596728\n",
      "58     \t [2.73365764 0.89652902]. \t  -53.54427530981493 \t 1.0184197562596728\n",
      "59     \t [ 2.02271331 -1.10352272]. \t  -2.870451948650995 \t 1.0184197562596728\n",
      "60     \t [-0.0418855   0.65648884]. \t  1.0014298765072063 \t 1.0184197562596728\n",
      "61     \t [-2.32216431 -0.84898303]. \t  -13.939473167052327 \t 1.0184197562596728\n",
      "62     \t [-1.8150667  -0.65131534]. \t  -2.5094940972007715 \t 1.0184197562596728\n",
      "63     \t [ 0.42836514 -1.01404637]. \t  -0.34731643077581176 \t 1.0184197562596728\n",
      "64     \t [0.11199827 0.38743958]. \t  0.4170691011118485 \t 1.0184197562596728\n",
      "65     \t [ 0.00089324 -0.01016456]. \t  0.0004191184377549365 \t 1.0184197562596728\n",
      "66     \t [-2.94555851 -0.16667952]. \t  -94.71660979300877 \t 1.0184197562596728\n",
      "67     \t [-2.86546134 -0.13201816]. \t  -76.09581474809677 \t 1.0184197562596728\n",
      "68     \t [2.68665206 1.79297599]. \t  -78.1138674318178 \t 1.0184197562596728\n",
      "69     \t [0.70119917 1.77000068]. \t  -29.468491493381247 \t 1.0184197562596728\n",
      "70     \t [-1.40280261 -0.41437042]. \t  -2.291806195020299 \t 1.0184197562596728\n",
      "71     \t [-0.06745046  1.28862963]. \t  -4.318892808797828 \t 1.0184197562596728\n",
      "72     \t [-1.51865915  0.77915852]. \t  -0.006929419998401243 \t 1.0184197562596728\n",
      "73     \t [ 0.08269435 -0.7130005 ]. \t  \u001b[92m1.0314255781682993\u001b[0m \t 1.0314255781682993\n",
      "74     \t [ 2.17230177 -1.97215283]. \t  -47.80724003691499 \t 1.0314255781682993\n",
      "75     \t [-1.43206411  0.91244933]. \t  -0.3818379454140646 \t 1.0314255781682993\n",
      "76     \t [ 1.60220822 -0.17804429]. \t  -1.6604219392325728 \t 1.0314255781682993\n",
      "77     \t [ 0.08440553 -0.71180239]. \t  \u001b[92m1.031511786884918\u001b[0m \t 1.031511786884918\n",
      "78     \t [ 0.14421973 -0.66064541]. \t  0.9968330575463916 \t 1.031511786884918\n",
      "79     \t [-1.90049211  1.71593924]. \t  -22.398218200746143 \t 1.031511786884918\n",
      "80     \t [ 2.69416351 -1.8344952 ]. \t  -72.76657765554019 \t 1.031511786884918\n",
      "81     \t [0.95985972 1.88178375]. \t  -39.963078686929066 \t 1.031511786884918\n",
      "82     \t [1.86425878 0.73205041]. \t  -2.899355048162244 \t 1.031511786884918\n",
      "83     \t [ 0.00782898 -1.82393037]. \t  -30.94739494350308 \t 1.031511786884918\n",
      "84     \t [-2.6097188  0.3374797]. \t  -33.853293109255496 \t 1.031511786884918\n",
      "85     \t [-1.05964242 -0.10295879]. \t  -2.3827726251625783 \t 1.031511786884918\n",
      "86     \t [-2.45467516  1.92921751]. \t  -56.56533905175524 \t 1.031511786884918\n",
      "87     \t [ 0.18261967 -0.73238546]. \t  0.9973750273724485 \t 1.031511786884918\n",
      "88     \t [-0.41819814 -0.72916333]. \t  0.05394061385892923 \t 1.031511786884918\n",
      "89     \t [-1.49664767 -0.8240951 ]. \t  -2.5312666974528484 \t 1.031511786884918\n",
      "90     \t [-0.07641232  0.69797735]. \t  1.029392033106872 \t 1.031511786884918\n",
      "91     \t [2.42804817 1.01007418]. \t  -21.429608516533868 \t 1.031511786884918\n",
      "92     \t [ 2.14258841 -1.01885082]. \t  -4.330194349115766 \t 1.031511786884918\n",
      "93     \t [-1.47408551  1.8991827 ]. \t  -37.00785550098979 \t 1.031511786884918\n",
      "94     \t [ 1.56624203 -0.88016909]. \t  -0.019177103915718474 \t 1.031511786884918\n",
      "95     \t [-1.40218051 -1.58428237]. \t  -19.66115096287558 \t 1.031511786884918\n",
      "96     \t [-2.94814154 -1.56722917]. \t  -113.91476048003632 \t 1.031511786884918\n",
      "97     \t [ 0.16151735 -0.75793538]. \t  0.9973108198956482 \t 1.031511786884918\n",
      "98     \t [ 2.64262941 -1.85155996]. \t  -67.45121091182921 \t 1.031511786884918\n",
      "99     \t [-1.54978918 -1.18870554]. \t  -6.2880814178546265 \t 1.031511786884918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [ 1.84908458 -1.25345136]. \t  -3.7219049521410486 \t 1.031511786884918\n"
     ]
    }
   ],
   "source": [
    "### 6(m). Bayesian optimization runs (x20): GP run number = 13\n",
    "\n",
    "np.random.seed(run_num_13)\n",
    "surrogate_gp_13 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_13 = GPGO(surrogate_gp_13, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_13.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.20248745 -1.94972064]. \t  -47.34265872952369 \t -3.3855955096031627\n",
      "init   \t [-0.67943252  1.21320478]. \t  -3.3855955096031627 \t -3.3855955096031627\n",
      "init   \t [0.478725   1.25937469]. \t  -5.1311178846540475 \t -3.3855955096031627\n",
      "init   \t [2.61502198 0.35750001]. \t  -36.23378797270707 \t -3.3855955096031627\n",
      "init   \t [2.55659457 0.57599269]. \t  -30.093760262197183 \t -3.3855955096031627\n",
      "1      \t [-3.  2.]. \t  -150.89999999999998 \t -3.3855955096031627\n",
      "2      \t [ 1.52764075 -2.        ]. \t  -47.07916095372899 \t -3.3855955096031627\n",
      "3      \t [3. 2.]. \t  -162.89999999999998 \t -3.3855955096031627\n",
      "4      \t [-3.         -0.87825667]. \t  -110.82926024848506 \t -3.3855955096031627\n",
      "5      \t [ 0.02308298 -0.2583812 ]. \t  \u001b[92m0.2530488540639987\u001b[0m \t 0.2530488540639987\n",
      "6      \t [1.34730657 0.44471678]. \t  -2.299590791605795 \t 0.2530488540639987\n",
      "7      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.2530488540639987\n",
      "8      \t [ 0.2627785 -2.       ]. \t  -47.74074958180849 \t 0.2530488540639987\n",
      "9      \t [-1.12746246  0.03477607]. \t  -2.3319895930038452 \t 0.2530488540639987\n",
      "10     \t [-0.20283796  2.        ]. \t  -47.75536543689371 \t 0.2530488540639987\n",
      "11     \t [-0.28357937  0.48639002]. \t  \u001b[92m0.5520979524982954\u001b[0m \t 0.5520979524982954\n",
      "12     \t [1.39622509 1.42788211]. \t  -12.752439446993202 \t 0.5520979524982954\n",
      "13     \t [-1.57735639  0.81642949]. \t  0.09045861916984754 \t 0.5520979524982954\n",
      "14     \t [ 0.96137897 -0.80812769]. \t  -0.4830812949587907 \t 0.5520979524982954\n",
      "15     \t [-3. -2.]. \t  -162.89999999999998 \t 0.5520979524982954\n",
      "16     \t [-3.          0.39179025]. \t  -107.20487933298342 \t 0.5520979524982954\n",
      "17     \t [-1.0985659   0.72846984]. \t  -0.5581867833460916 \t 0.5520979524982954\n",
      "18     \t [-1.45510877  2.        ]. \t  -47.30867416870932 \t 0.5520979524982954\n",
      "19     \t [0.53991991 0.2820605 ]. \t  -0.8552289648470868 \t 0.5520979524982954\n",
      "20     \t [-0.90338809 -0.90826199]. \t  -2.2898081604036093 \t 0.5520979524982954\n",
      "21     \t [-1.69445725 -0.60102566]. \t  -2.158134240633638 \t 0.5520979524982954\n",
      "22     \t [-1.75740978  0.08431568]. \t  -1.9662623243995043 \t 0.5520979524982954\n",
      "23     \t [ 0.42378172 -0.96159092]. \t  0.0336065676244941 \t 0.5520979524982954\n",
      "24     \t [1.30060566 0.89952601]. \t  -2.9229605249344788 \t 0.5520979524982954\n",
      "25     \t [ 0.59282575 -0.53286401]. \t  -0.0316890908338997 \t 0.5520979524982954\n",
      "26     \t [0.08384921 0.79405951]. \t  \u001b[92m0.8372468083878437\u001b[0m \t 0.8372468083878437\n",
      "27     \t [0.97932001 2.        ]. \t  -52.15736164283369 \t 0.8372468083878437\n",
      "28     \t [ 1.92308006 -0.74404622]. \t  -0.5121811156787701 \t 0.8372468083878437\n",
      "29     \t [ 1.60256055 -0.44181822]. \t  -0.7318130741026203 \t 0.8372468083878437\n",
      "30     \t [ 1.64464204 -1.0234038 ]. \t  -0.5670302902713343 \t 0.8372468083878437\n",
      "31     \t [1.87334578 0.7049577 ]. \t  -2.902065525169403 \t 0.8372468083878437\n",
      "32     \t [ 3.         -0.80319277]. \t  -105.57465935014272 \t 0.8372468083878437\n",
      "33     \t [-1.32727031 -0.57096772]. \t  -2.2307397664164816 \t 0.8372468083878437\n",
      "34     \t [-1.62590529 -1.24714769]. \t  -7.539701976605271 \t 0.8372468083878437\n",
      "35     \t [-1.54570018  0.5095467 ]. \t  -0.5589835793903202 \t 0.8372468083878437\n",
      "36     \t [-0.40230767 -0.57588546]. \t  0.061134229815549834 \t 0.8372468083878437\n",
      "37     \t [1.99765674 2.        ]. \t  -55.698837086236225 \t 0.8372468083878437\n",
      "38     \t [-1.30235214  1.13086102]. \t  -2.3232595362129853 \t 0.8372468083878437\n",
      "39     \t [-0.17617466  0.99263961]. \t  0.11054690367563146 \t 0.8372468083878437\n",
      "40     \t [ 1.67469418 -0.77448994]. \t  0.2034497227341152 \t 0.8372468083878437\n",
      "41     \t [ 0.97539338 -1.37965859]. \t  -7.724875457039797 \t 0.8372468083878437\n",
      "42     \t [-0.48591574 -0.0833274 ]. \t  -0.844678580360096 \t 0.8372468083878437\n",
      "43     \t [1.91518813 0.06917616]. \t  -2.9814849396266934 \t 0.8372468083878437\n",
      "44     \t [-2.03283416 -2.        ]. \t  -56.256816634239115 \t 0.8372468083878437\n",
      "45     \t [-0.25114691 -1.13441381]. \t  -2.0057455392307943 \t 0.8372468083878437\n",
      "46     \t [-0.01421475 -0.74348953]. \t  \u001b[92m0.9774818179360639\u001b[0m \t 0.9774818179360639\n",
      "47     \t [-2.1198788   1.44836519]. \t  -11.958391710255214 \t 0.9774818179360639\n",
      "48     \t [-3.          1.21654689]. \t  -108.09185217181455 \t 0.9774818179360639\n",
      "49     \t [2.14129834 1.30609017]. \t  -13.936442313810389 \t 0.9774818179360639\n",
      "50     \t [-1.9978584   0.88369482]. \t  -1.25623390008482 \t 0.9774818179360639\n",
      "51     \t [3.        1.0010903]. \t  -111.91201714154059 \t 0.9774818179360639\n",
      "52     \t [-0.52290261  0.79611409]. \t  0.40116136359577426 \t 0.9774818179360639\n",
      "53     \t [-2.29943922 -1.3112511 ]. \t  -19.676205112725224 \t 0.9774818179360639\n",
      "54     \t [-0.45406488 -2.        ]. \t  -49.646483790906075 \t 0.9774818179360639\n",
      "55     \t [ 2.26991524 -2.        ]. \t  -53.915596828454106 \t 0.9774818179360639\n",
      "56     \t [-2.14655422  2.        ]. \t  -50.16131198337361 \t 0.9774818179360639\n",
      "57     \t [ 2.25128944 -1.31898774]. \t  -11.905021417207386 \t 0.9774818179360639\n",
      "58     \t [0.63119413 0.77389698]. \t  -0.8089931393813201 \t 0.9774818179360639\n",
      "59     \t [-2.36624192 -0.37574298]. \t  -15.476121325021708 \t 0.9774818179360639\n",
      "60     \t [-0.04188521  0.656489  ]. \t  \u001b[92m1.0014299042611507\u001b[0m \t 1.0014299042611507\n",
      "61     \t [-2.0521036   0.36628199]. \t  -3.2804770681992124 \t 1.0014299042611507\n",
      "62     \t [ 1.16688469 -0.17475873]. \t  -2.0721914518477185 \t 1.0014299042611507\n",
      "63     \t [-0.04930999  0.69113813]. \t  \u001b[92m1.022372351607304\u001b[0m \t 1.022372351607304\n",
      "64     \t [ 0.13096964 -0.70753377]. \t  \u001b[92m1.02466799112666\u001b[0m \t 1.02466799112666\n",
      "65     \t [-1.99548128 -0.95459315]. \t  -5.257549143611555 \t 1.02466799112666\n",
      "66     \t [ 0.13960244 -0.66079991]. \t  0.9990394698369813 \t 1.02466799112666\n",
      "67     \t [ 0.16410239 -0.79788961]. \t  0.9500649671326556 \t 1.02466799112666\n",
      "68     \t [ 0.04465025 -0.69372634]. \t  1.0216035060249287 \t 1.02466799112666\n",
      "69     \t [-0.07153223  0.70375832]. \t  \u001b[92m1.0298396270889827\u001b[0m \t 1.0298396270889827\n",
      "70     \t [-0.2352545   0.73163525]. \t  0.952136052765105 \t 1.0298396270889827\n",
      "71     \t [ 0.02241441 -0.64913069]. \t  0.9878104922015425 \t 1.0298396270889827\n",
      "72     \t [-0.16509586  0.69812671]. \t  1.0071476798607863 \t 1.0298396270889827\n",
      "73     \t [-0.07830997  0.71711563]. \t  \u001b[92m1.0308935957138354\u001b[0m \t 1.0308935957138354\n",
      "74     \t [ 0.18063063 -0.65146761]. \t  0.9665339188376798 \t 1.0308935957138354\n",
      "75     \t [-0.06700193  0.78084986]. \t  0.9862440832223655 \t 1.0308935957138354\n",
      "76     \t [0.03184001 0.70450012]. \t  0.9734615676994034 \t 1.0308935957138354\n",
      "77     \t [ 0.10410048 -0.73363795]. \t  1.0274261273972147 \t 1.0308935957138354\n",
      "78     \t [ 0.14047712 -0.66223921]. \t  0.9998102843857636 \t 1.0308935957138354\n",
      "79     \t [-0.06770222  0.68443097]. \t  1.0240645365559569 \t 1.0308935957138354\n",
      "80     \t [-0.0755348   0.70135639]. \t  1.0299607003288824 \t 1.0308935957138354\n",
      "81     \t [ 0.05213383 -0.68256649]. \t  1.0200765118605315 \t 1.0308935957138354\n",
      "82     \t [0.39974746 2.        ]. \t  -49.386422836264686 \t 1.0308935957138354\n",
      "83     \t [-0.02132295  0.64209752]. \t  0.9811004505445088 \t 1.0308935957138354\n",
      "84     \t [ 0.09228674 -0.77771202]. \t  0.9938949249247554 \t 1.0308935957138354\n",
      "85     \t [0.02028843 0.69699239]. \t  0.9834062504205124 \t 1.0308935957138354\n",
      "86     \t [-0.09886243 -0.65585336]. \t  0.8767462732267106 \t 1.0308935957138354\n",
      "87     \t [-0.11565822  0.69805277]. \t  1.0269557894677164 \t 1.0308935957138354\n",
      "88     \t [ 0.0526344  -0.78988391]. \t  0.969088374302215 \t 1.0308935957138354\n",
      "89     \t [-0.02658353  0.59779477]. \t  0.9316795112242543 \t 1.0308935957138354\n",
      "90     \t [-0.0579691   0.67888965]. \t  1.0198186493817292 \t 1.0308935957138354\n",
      "91     \t [-0.01641301  0.6742261 ]. \t  1.001737078638455 \t 1.0308935957138354\n",
      "92     \t [-0.11642153  0.73301531]. \t  1.0259392609529645 \t 1.0308935957138354\n",
      "93     \t [-0.0157135   0.78121118]. \t  0.962631699923817 \t 1.0308935957138354\n",
      "94     \t [-0.11540486  0.65404263]. \t  1.0017106025387177 \t 1.0308935957138354\n",
      "95     \t [-0.10173913  0.65582189]. \t  1.0060012466442467 \t 1.0308935957138354\n",
      "96     \t [ 0.01791314 -0.68778023]. \t  1.0081299868426232 \t 1.0308935957138354\n",
      "97     \t [-0.01654003  0.69902707]. \t  1.0099514951725217 \t 1.0308935957138354\n",
      "98     \t [-0.02225431  0.66526212]. \t  0.9996333170157568 \t 1.0308935957138354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [0.08698724 0.74832136]. \t  0.8903658276703512 \t 1.0308935957138354\n",
      "100    \t [-0.13553722  0.64880585]. \t  0.9901663835556774 \t 1.0308935957138354\n"
     ]
    }
   ],
   "source": [
    "### 6(m). Bayesian optimization runs (x20): STP DF1 run number = 13\n",
    "\n",
    "np.random.seed(run_num_13)\n",
    "surrogate_stp_df1_13 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_13 = GPGO(surrogate_stp_df1_13, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_13.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.335754908929719, -7.255322841075943)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(m). Training Regret Minimisation: run number = 13\n",
    "\n",
    "gp_output_13 = np.append(np.max(gpgo_gp_13.GP.y[0:n_init]),gpgo_gp_13.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_13 = np.append(np.max(gpgo_stp_df1_13.GP.y[0:n_init]),gpgo_stp_df1_13.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_13 = np.log(y_global_orig - gp_output_13)\n",
    "regret_stp_df1_13 = np.log(y_global_orig - stp_df1_output_13)\n",
    "\n",
    "train_regret_gp_13 = min_max_array(regret_gp_13)\n",
    "train_regret_stp_df1_13 = min_max_array(regret_stp_df1_13)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 13\n",
    "min_train_regret_gp_13 = min(train_regret_gp_13)\n",
    "min_train_regret_stp_df1_13 = min(train_regret_stp_df1_13)\n",
    "\n",
    "min_train_regret_gp_13, min_train_regret_stp_df1_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.39464238  1.25388735]. \t  -4.138312267019178 \t 0.24125148557223622\n",
      "init   \t [-0.04688864  0.25218514]. \t  0.24125148557223622 \t 0.24125148557223622\n",
      "init   \t [-2.85464659 -1.14516098]. \t  -78.42708226340747 \t 0.24125148557223622\n",
      "init   \t [-1.80715709 -1.77283449]. \t  -32.42054322939494 \t 0.24125148557223622\n",
      "init   \t [ 2.72288879 -0.23960965]. \t  -49.201762899807605 \t 0.24125148557223622\n",
      "1      \t [ 0.00842743 -2.        ]. \t  -47.98342922218862 \t 0.24125148557223622\n",
      "2      \t [0.01705806 0.80988516]. \t  \u001b[92m0.8877845282134982\u001b[0m \t 0.8877845282134982\n",
      "3      \t [-3.  2.]. \t  -150.89999999999998 \t 0.8877845282134982\n",
      "4      \t [-0.84729185  0.86988923]. \t  -0.4391813241954694 \t 0.8877845282134982\n",
      "5      \t [-0.70237783  1.85085443]. \t  -33.44026080882604 \t 0.8877845282134982\n",
      "6      \t [0.68902147 0.71828039]. \t  -0.9572802584833953 \t 0.8877845282134982\n",
      "7      \t [-1.3629791   0.77025288]. \t  -0.30557017072986115 \t 0.8877845282134982\n",
      "8      \t [-1.20929189  0.90583256]. \t  -0.7165627510110466 \t 0.8877845282134982\n",
      "9      \t [-0.43601639  0.47920868]. \t  0.2297333443587048 \t 0.8877845282134982\n",
      "10     \t [0.46382977 0.33767614]. \t  -0.5192046910189962 \t 0.8877845282134982\n",
      "11     \t [1.79595344 1.6599643 ]. \t  -24.56974897170347 \t 0.8877845282134982\n",
      "12     \t [-0.13259248  0.64941446]. \t  \u001b[92m0.9919326243027725\u001b[0m \t 0.9919326243027725\n",
      "13     \t [-0.40169212 -0.29369792]. \t  -0.39485548898313944 \t 0.9919326243027725\n",
      "14     \t [ 0.09130815 -0.27056749]. \t  0.26289222008833946 \t 0.9919326243027725\n",
      "15     \t [-0.13691648  0.83123686]. \t  0.8937064935865763 \t 0.9919326243027725\n",
      "16     \t [-1.93589076  0.24880038]. \t  -2.327573220907465 \t 0.9919326243027725\n",
      "17     \t [-1.19389658  0.22141289]. \t  -1.9494265403262785 \t 0.9919326243027725\n",
      "18     \t [ 2.01020472 -1.88175317]. \t  -36.07538492609796 \t 0.9919326243027725\n",
      "19     \t [2.8806084  1.87974143]. \t  -120.26854825205396 \t 0.9919326243027725\n",
      "20     \t [1.08039964 1.68006559]. \t  -24.731333035957725 \t 0.9919326243027725\n",
      "21     \t [0.04393344 0.73792948]. \t  0.9519322376843808 \t 0.9919326243027725\n",
      "22     \t [-1.8648362  0.7164551]. \t  -0.19730327883971321 \t 0.9919326243027725\n",
      "23     \t [ 2.90720863 -1.96669914]. \t  -123.69967794984096 \t 0.9919326243027725\n",
      "24     \t [ 1.14108767 -1.66269302]. \t  -19.99924183642574 \t 0.9919326243027725\n",
      "25     \t [ 0.39293996 -0.1616411 ]. \t  -0.4034744348704197 \t 0.9919326243027725\n",
      "26     \t [1.37157836 0.30907178]. \t  -2.390521665899445 \t 0.9919326243027725\n",
      "27     \t [1.64226186 0.94423396]. \t  -3.2161661524209593 \t 0.9919326243027725\n",
      "28     \t [ 2.21483777 -1.98702915]. \t  -50.59805659546462 \t 0.9919326243027725\n",
      "29     \t [-1.98414885 -1.53984604]. \t  -19.59846780219873 \t 0.9919326243027725\n",
      "30     \t [-1.57948091 -0.74218708]. \t  -2.267264101193564 \t 0.9919326243027725\n",
      "31     \t [-0.1235903   0.73071015]. \t  \u001b[92m1.0250922381082097\u001b[0m \t 1.0250922381082097\n",
      "32     \t [ 0.62785342 -1.21590058]. \t  -3.3366620008856556 \t 1.0250922381082097\n",
      "33     \t [ 0.89806575 -0.96922561]. \t  -0.9368148305588581 \t 1.0250922381082097\n",
      "34     \t [-0.01913657  0.65591744]. \t  0.9916147565964006 \t 1.0250922381082097\n",
      "35     \t [ 0.45471644 -0.76615836]. \t  0.5778754539142761 \t 1.0250922381082097\n",
      "36     \t [ 1.37892492 -0.54512266]. \t  -0.7176975031919172 \t 1.0250922381082097\n",
      "37     \t [ 0.61005477 -0.39367887]. \t  -0.45096400094614 \t 1.0250922381082097\n",
      "38     \t [-0.04597164  0.76762478]. \t  0.9949841014139822 \t 1.0250922381082097\n",
      "39     \t [-0.60934566  1.67615236]. \t  -20.526314568897742 \t 1.0250922381082097\n",
      "40     \t [2.64533898 0.57384056]. \t  -40.01643513439098 \t 1.0250922381082097\n",
      "41     \t [-2.46440528  1.24321605]. \t  -21.815037005050552 \t 1.0250922381082097\n",
      "42     \t [-0.17443853 -0.61111142]. \t  0.7095660874680045 \t 1.0250922381082097\n",
      "43     \t [-0.04548554 -0.72948607]. \t  0.9544177101361776 \t 1.0250922381082097\n",
      "44     \t [ 1.38202063 -0.5236907 ]. \t  -0.7817181347241904 \t 1.0250922381082097\n",
      "45     \t [ 1.27434314 -1.30275174]. \t  -5.457854641181957 \t 1.0250922381082097\n",
      "46     \t [ 0.18551699 -0.31508599]. \t  0.28095274789346514 \t 1.0250922381082097\n",
      "47     \t [-1.23858234  0.83061965]. \t  -0.5131130533091219 \t 1.0250922381082097\n",
      "48     \t [ 1.93846849 -1.44051311]. \t  -9.195779739872497 \t 1.0250922381082097\n",
      "49     \t [1.46864163 1.3357059 ]. \t  -9.760158782991308 \t 1.0250922381082097\n",
      "50     \t [-2.94659803 -1.24294974]. \t  -101.62625426046591 \t 1.0250922381082097\n",
      "51     \t [-2.02097098 -0.71804513]. \t  -4.468999439150954 \t 1.0250922381082097\n",
      "52     \t [-3.          0.26767502]. \t  -107.830910130791 \t 1.0250922381082097\n",
      "53     \t [ 1.71020662 -0.9527978 ]. \t  -0.11066898307892076 \t 1.0250922381082097\n",
      "54     \t [-0.84675461 -0.3188222 ]. \t  -1.8159731238142554 \t 1.0250922381082097\n",
      "55     \t [1.09590378 1.39701508]. \t  -11.312559260441907 \t 1.0250922381082097\n",
      "56     \t [-1.65884314  1.11364555]. \t  -1.3953245430118206 \t 1.0250922381082097\n",
      "57     \t [-1.94401433  0.39545605]. \t  -1.819306660518726 \t 1.0250922381082097\n",
      "58     \t [-2.47755869  0.29267355]. \t  -21.48387218530935 \t 1.0250922381082097\n",
      "59     \t [ 0.74415574 -1.10646122]. \t  -1.9025036528997121 \t 1.0250922381082097\n",
      "60     \t [-0.03265341  0.76784472]. \t  0.988707903403004 \t 1.0250922381082097\n",
      "61     \t [ 0.11019986 -0.68784918]. \t  1.0246473590375524 \t 1.0250922381082097\n",
      "62     \t [-1.53889132 -1.27776985]. \t  -8.220821197263696 \t 1.0250922381082097\n",
      "63     \t [ 0.09569908 -0.6814326 ]. \t  1.0236715196775132 \t 1.0250922381082097\n",
      "64     \t [-1.49028415  1.67050306]. \t  -19.674513109532974 \t 1.0250922381082097\n",
      "65     \t [-1.76051532  1.20880893]. \t  -2.716629550879157 \t 1.0250922381082097\n",
      "66     \t [-2.05757766  0.51028998]. \t  -2.7685698291857843 \t 1.0250922381082097\n",
      "67     \t [0.37897702 0.69578609]. \t  0.20314052331035282 \t 1.0250922381082097\n",
      "68     \t [-2.91174617 -0.8302949 ]. \t  -87.66611107664936 \t 1.0250922381082097\n",
      "69     \t [0.85425257 1.43799285]. \t  -11.990902098945579 \t 1.0250922381082097\n",
      "70     \t [-0.03036038  0.69681555]. \t  1.0166353705408195 \t 1.0250922381082097\n",
      "71     \t [2.49425609 1.99888243]. \t  -76.73074458527879 \t 1.0250922381082097\n",
      "72     \t [-0.17677241 -1.06031003]. \t  -0.8691761299860095 \t 1.0250922381082097\n",
      "73     \t [ 2.08999545 -1.79305142]. \t  -29.923390640796313 \t 1.0250922381082097\n",
      "74     \t [1.10192832 0.04275271]. \t  -2.397329330319137 \t 1.0250922381082097\n",
      "75     \t [-0.05959607  0.687969  ]. \t  1.0239686842851252 \t 1.0250922381082097\n",
      "76     \t [-0.13837968  0.73578424]. \t  1.0191408338892562 \t 1.0250922381082097\n",
      "77     \t [-2.55187354 -0.39789507]. \t  -29.52817464541393 \t 1.0250922381082097\n",
      "78     \t [ 2.47609305 -1.45667212]. \t  -28.322360976693655 \t 1.0250922381082097\n",
      "79     \t [2.01145073 0.00418311]. \t  -3.892707639863994 \t 1.0250922381082097\n",
      "80     \t [ 0.05608116 -0.67123924]. \t  1.0153078333516343 \t 1.0250922381082097\n",
      "81     \t [-0.10223807  0.7020151 ]. \t  \u001b[92m1.0299853254322677\u001b[0m \t 1.0299853254322677\n",
      "82     \t [-1.16543541  0.29453338]. \t  -1.7339237162264705 \t 1.0299853254322677\n",
      "83     \t [2.58571477 0.09210095]. \t  -32.69860706555961 \t 1.0299853254322677\n",
      "84     \t [-0.11477742  0.71320619]. \t  1.0292280399031 \t 1.0299853254322677\n",
      "85     \t [-2.63222568 -0.28583362]. \t  -38.225702635236054 \t 1.0299853254322677\n",
      "86     \t [-0.12333791  0.68170702]. \t  1.0187386977621629 \t 1.0299853254322677\n",
      "87     \t [ 2.22942706 -0.34468355]. \t  -7.744754667744101 \t 1.0299853254322677\n",
      "88     \t [-0.06807493  0.64676333]. \t  0.9988389258012533 \t 1.0299853254322677\n",
      "89     \t [-2.56725579  0.90555345]. \t  -27.65877985431883 \t 1.0299853254322677\n",
      "90     \t [0.87437026 0.34562585]. \t  -1.8610616846549464 \t 1.0299853254322677\n",
      "91     \t [-2.95600875 -1.4276592 ]. \t  -109.68525476012792 \t 1.0299853254322677\n",
      "92     \t [-0.04467728  0.69047834]. \t  1.0207124933769538 \t 1.0299853254322677\n",
      "93     \t [ 1.1985221  -1.13320003]. \t  -2.5020202958276423 \t 1.0299853254322677\n",
      "94     \t [-2.73487271 -0.30679236]. \t  -52.41169853797475 \t 1.0299853254322677\n",
      "95     \t [ 0.20242018 -0.69537596]. \t  0.9792823779064604 \t 1.0299853254322677\n",
      "96     \t [-0.70086797 -0.07281194]. \t  -1.527594861572749 \t 1.0299853254322677\n",
      "97     \t [-1.59149318  1.38667064]. \t  -6.9667579095768435 \t 1.0299853254322677\n",
      "98     \t [-0.71824057 -0.6579522 ]. \t  -1.0409615394416387 \t 1.0299853254322677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-0.03336494 -0.69700434]. \t  0.9714893667192406 \t 1.0299853254322677\n",
      "100    \t [-0.09727965  0.73577376]. \t  1.0270666738804894 \t 1.0299853254322677\n"
     ]
    }
   ],
   "source": [
    "### 6(n). Bayesian optimization runs (x20): GP run number = 14\n",
    "\n",
    "np.random.seed(run_num_14)\n",
    "surrogate_gp_14 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_14 = GPGO(surrogate_gp_14, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_14.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-1.39464238  1.25388735]. \t  -4.138312267019178 \t 0.24125148557223622\n",
      "init   \t [-0.04688864  0.25218514]. \t  0.24125148557223622 \t 0.24125148557223622\n",
      "init   \t [-2.85464659 -1.14516098]. \t  -78.42708226340747 \t 0.24125148557223622\n",
      "init   \t [-1.80715709 -1.77283449]. \t  -32.42054322939494 \t 0.24125148557223622\n",
      "init   \t [ 2.72288879 -0.23960965]. \t  -49.201762899807605 \t 0.24125148557223622\n",
      "1      \t [ 0.25114328 -2.        ]. \t  -47.74173465413369 \t 0.24125148557223622\n",
      "2      \t [0.70192089 2.        ]. \t  -50.90471271407896 \t 0.24125148557223622\n",
      "3      \t [-3.  2.]. \t  -150.89999999999998 \t 0.24125148557223622\n",
      "4      \t [3. 2.]. \t  -162.89999999999998 \t 0.24125148557223622\n",
      "5      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.24125148557223622\n",
      "6      \t [-1.21850474 -0.01272231]. \t  -2.4154765352528687 \t 0.24125148557223622\n",
      "7      \t [ 1.17994959 -0.20075665]. \t  -2.006409040814841 \t 0.24125148557223622\n",
      "8      \t [-0.71573237  2.        ]. \t  -48.111348124191885 \t 0.24125148557223622\n",
      "9      \t [-0.92315912  0.70775013]. \t  -0.43665122663590006 \t 0.24125148557223622\n",
      "10     \t [-0.0999731  -0.70158112]. \t  \u001b[92m0.889849364437233\u001b[0m \t 0.889849364437233\n",
      "11     \t [-2.14968779  0.45851847]. \t  -4.884189627536778 \t 0.889849364437233\n",
      "12     \t [1.28074648 0.69637774]. \t  -2.2748831328071093 \t 0.889849364437233\n",
      "13     \t [-0.88309314 -2.        ]. \t  -51.7665350252071 \t 0.889849364437233\n",
      "14     \t [ 0.47355463 -0.22009687]. \t  -0.5065548214166075 \t 0.889849364437233\n",
      "15     \t [ 1.29492478 -1.3814103 ]. \t  -7.518590399595684 \t 0.889849364437233\n",
      "16     \t [-1.58678371  0.68618305]. \t  0.006432026489853748 \t 0.889849364437233\n",
      "17     \t [-3.          0.29041815]. \t  -107.71982953263924 \t 0.889849364437233\n",
      "18     \t [-1.79491188 -0.52184044]. \t  -2.38057038852991 \t 0.889849364437233\n",
      "19     \t [0.22109842 0.99375159]. \t  -0.3610651635009809 \t 0.889849364437233\n",
      "20     \t [ 0.77680914 -0.96462342]. \t  -0.7142850164775358 \t 0.889849364437233\n",
      "21     \t [-3. -2.]. \t  -162.89999999999998 \t 0.889849364437233\n",
      "22     \t [-1.10064241 -0.9247042 ]. \t  -2.878538503872817 \t 0.889849364437233\n",
      "23     \t [ 1.23269869 -2.        ]. \t  -47.93339857105445 \t 0.889849364437233\n",
      "24     \t [0.76396056 0.64920044]. \t  -1.2061235039855267 \t 0.889849364437233\n",
      "25     \t [ 1.55576922 -0.82727564]. \t  0.04546449954327936 \t 0.889849364437233\n",
      "26     \t [-0.49053401 -0.36438216]. \t  -0.5637095797682934 \t 0.889849364437233\n",
      "27     \t [3.         0.66557728]. \t  -109.90973098698392 \t 0.889849364437233\n",
      "28     \t [-0.39057853  0.95487046]. \t  0.13219016689244328 \t 0.889849364437233\n",
      "29     \t [-1.73538739  2.        ]. \t  -46.63397395714761 \t 0.889849364437233\n",
      "30     \t [1.70186606 2.        ]. \t  -53.47156949656525 \t 0.889849364437233\n",
      "31     \t [-1.8873912   0.10823673]. \t  -2.4180551491392928 \t 0.889849364437233\n",
      "32     \t [1.88191831 0.08069292]. \t  -2.7596026798129234 \t 0.889849364437233\n",
      "33     \t [1.03256669 1.24530163]. \t  -6.983944358234712 \t 0.889849364437233\n",
      "34     \t [-1.64998596 -1.08064852]. \t  -4.618072434907839 \t 0.889849364437233\n",
      "35     \t [-0.11683438  0.69031266]. \t  \u001b[92m1.024238536487602\u001b[0m \t 1.024238536487602\n",
      "36     \t [-1.95904397  1.05256549]. \t  -1.679115668355732 \t 1.024238536487602\n",
      "37     \t [ 2.17358603 -1.12773805]. \t  -6.107075922484018 \t 1.024238536487602\n",
      "38     \t [ 1.92829247 -0.72243612]. \t  -0.5840951432016185 \t 1.024238536487602\n",
      "39     \t [ 0.286386   -0.75771638]. \t  0.8808904725802069 \t 1.024238536487602\n",
      "40     \t [ 3.        -1.0406471]. \t  -106.13736467421172 \t 1.024238536487602\n",
      "41     \t [-0.14912862 -1.14925709]. \t  -1.954106681009237 \t 1.024238536487602\n",
      "42     \t [ 1.80424545 -1.05866952]. \t  -0.8977057154132787 \t 1.024238536487602\n",
      "43     \t [1.9932187  1.11770634]. \t  -7.1215066428589004 \t 1.024238536487602\n",
      "44     \t [ 2.09783041 -2.        ]. \t  -49.147362654066406 \t 1.024238536487602\n",
      "45     \t [1.7195501  0.88034727]. \t  -2.9007159191137992 \t 1.024238536487602\n",
      "46     \t [-1.84940218  0.77820522]. \t  -0.05723426656867614 \t 1.024238536487602\n",
      "47     \t [-3.         1.1635843]. \t  -107.32602216720214 \t 1.024238536487602\n",
      "48     \t [-2.27708262 -0.55066515]. \t  -11.157768672375651 \t 1.024238536487602\n",
      "49     \t [1.66456361 1.28374046]. \t  -8.459972640616943 \t 1.024238536487602\n",
      "50     \t [-2.2183835  -1.28737867]. \t  -15.767980960305128 \t 1.024238536487602\n",
      "51     \t [ 0.83300592 -0.66047326]. \t  -0.34191529212459115 \t 1.024238536487602\n",
      "52     \t [ 0.07196508 -0.43066755]. \t  0.6146283444436162 \t 1.024238536487602\n",
      "53     \t [-0.01901217  2.        ]. \t  -47.96342123002506 \t 1.024238536487602\n",
      "54     \t [0.10003958 0.66986843]. \t  0.8826479339741813 \t 1.024238536487602\n",
      "55     \t [ 1.71693739 -0.40909715]. \t  -0.8217498154682683 \t 1.024238536487602\n",
      "56     \t [2.33087044 2.        ]. \t  -65.86272676264707 \t 1.024238536487602\n",
      "57     \t [-1.15855036 -0.56249941]. \t  -2.178157639866151 \t 1.024238536487602\n",
      "58     \t [-2.27024639 -2.        ]. \t  -63.00931974162419 \t 1.024238536487602\n",
      "59     \t [-2.36920508  2.        ]. \t  -58.500351948894576 \t 1.024238536487602\n",
      "60     \t [-0.07698706  0.71981522]. \t  \u001b[92m1.0304667686333557\u001b[0m \t 1.0304667686333557\n",
      "61     \t [ 0.02690389 -0.75989882]. \t  0.9935583906088661 \t 1.0304667686333557\n",
      "62     \t [-0.05616741  0.73514755]. \t  1.022150917888215 \t 1.0304667686333557\n",
      "63     \t [2.33515354 0.41111365]. \t  -13.814350740609626 \t 1.0304667686333557\n",
      "64     \t [-0.13523882  0.75119395]. \t  1.012598827151363 \t 1.0304667686333557\n",
      "65     \t [ 0.69183521 -1.59508894]. \t  -16.083254685804167 \t 1.0304667686333557\n",
      "66     \t [ 0.07808683 -0.72743397]. \t  1.029089539679961 \t 1.0304667686333557\n",
      "67     \t [ 0.16901952 -0.66260537]. \t  0.9845672844619011 \t 1.0304667686333557\n",
      "68     \t [-0.02639349 -0.77383011]. \t  0.9377344068505392 \t 1.0304667686333557\n",
      "69     \t [0.0465945  0.71490598]. \t  0.9575230200161127 \t 1.0304667686333557\n",
      "70     \t [-0.03036463  0.6968117 ]. \t  1.0166365613846684 \t 1.0304667686333557\n",
      "71     \t [-0.04370808  0.72454912]. \t  1.021540438829999 \t 1.0304667686333557\n",
      "72     \t [-0.06914589  0.75132869]. \t  1.0162363232262208 \t 1.0304667686333557\n",
      "73     \t [-1.40652587  0.93607507]. \t  -0.5248921741183742 \t 1.0304667686333557\n",
      "74     \t [ 0.08684281 -0.77355815]. \t  0.9984064566427664 \t 1.0304667686333557\n",
      "75     \t [-0.05959732  0.68796914]. \t  1.0239689993373768 \t 1.0304667686333557\n",
      "76     \t [ 0.121347   -0.73020377]. \t  1.0257536263098592 \t 1.0304667686333557\n",
      "77     \t [-0.05501676  0.74073701]. \t  1.0191814281294147 \t 1.0304667686333557\n",
      "78     \t [-0.04945899  0.70927023]. \t  1.0252700249326194 \t 1.0304667686333557\n",
      "79     \t [-0.06354239  0.7197736 ]. \t  1.028313124882473 \t 1.0304667686333557\n",
      "80     \t [ 0.12609345 -0.69018941]. \t  1.0217245330667528 \t 1.0304667686333557\n",
      "81     \t [ 0.11270806 -0.72574513]. \t  1.02847024976127 \t 1.0304667686333557\n",
      "82     \t [-0.02134391  0.68850826]. \t  1.0101787108425277 \t 1.0304667686333557\n",
      "83     \t [ 0.05242656 -0.7393188 ]. \t  1.0190982576023115 \t 1.0304667686333557\n",
      "84     \t [ 0.08824153 -0.7273561 ]. \t  1.0297890222013513 \t 1.0304667686333557\n",
      "85     \t [-0.40317924 -0.8183909 ]. \t  -0.04139311826408787 \t 1.0304667686333557\n",
      "86     \t [-0.12333791  0.68170702]. \t  1.0187386977621629 \t 1.0304667686333557\n",
      "87     \t [-0.06755118  0.80259573]. \t  0.9528790171354694 \t 1.0304667686333557\n",
      "88     \t [-0.12038494  0.75059899]. \t  1.0167530811948404 \t 1.0304667686333557\n",
      "89     \t [ 0.03474733 -0.76668191]. \t  0.9909775312380966 \t 1.0304667686333557\n",
      "90     \t [ 0.1176081  -0.71107826]. \t  1.0285758897505115 \t 1.0304667686333557\n",
      "91     \t [ 0.17329976 -0.82727972]. \t  0.8891200169576264 \t 1.0304667686333557\n",
      "92     \t [-0.04467728  0.69047834]. \t  1.0207124933769538 \t 1.0304667686333557\n",
      "93     \t [ 0.00298348 -0.71773898]. \t  1.0011877576309602 \t 1.0304667686333557\n",
      "94     \t [ 0.1358657  -0.70538283]. \t  1.0226891442064954 \t 1.0304667686333557\n",
      "95     \t [ 0.10742984 -0.79164568]. \t  0.974946410216121 \t 1.0304667686333557\n",
      "96     \t [ 0.07462165 -0.74174228]. \t  1.0230687497329214 \t 1.0304667686333557\n",
      "97     \t [3.         1.39757944]. \t  -120.54022822222241 \t 1.0304667686333557\n",
      "98     \t [ 0.05199902 -0.66455553]. \t  1.0101296522236103 \t 1.0304667686333557\n",
      "99     \t [ 0.00755558 -0.78465204]. \t  0.9521737993568404 \t 1.0304667686333557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [-0.06691612  0.73495112]. \t  1.024861984220707 \t 1.0304667686333557\n"
     ]
    }
   ],
   "source": [
    "### 6(n). Bayesian optimization runs (x20): STP DF1 run number = 14\n",
    "\n",
    "np.random.seed(run_num_14)\n",
    "surrogate_stp_df1_14 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_14 = GPGO(surrogate_stp_df1_14, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_14.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.428621848660673, -6.782682110683666)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(n). Training Regret Minimisation: run number = 14\n",
    "\n",
    "gp_output_14 = np.append(np.max(gpgo_gp_14.GP.y[0:n_init]),gpgo_gp_14.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_14 = np.append(np.max(gpgo_stp_df1_14.GP.y[0:n_init]),gpgo_stp_df1_14.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_14 = np.log(y_global_orig - gp_output_14)\n",
    "regret_stp_df1_14 = np.log(y_global_orig - stp_df1_output_14)\n",
    "\n",
    "train_regret_gp_14 = min_max_array(regret_gp_14)\n",
    "train_regret_stp_df1_14 = min_max_array(regret_stp_df1_14)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 14\n",
    "min_train_regret_gp_14 = min(train_regret_gp_14)\n",
    "min_train_regret_stp_df1_14 = min(train_regret_stp_df1_14)\n",
    "\n",
    "min_train_regret_gp_14, min_train_regret_stp_df1_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.62098529  1.04287489]. \t  -34.08534662113232 \t -10.33497247526879\n",
      "init   \t [0.55383081 1.42880521]. \t  -10.33497247526879 \t -10.33497247526879\n",
      "init   \t [2.98273183 1.07450664]. \t  -108.01579010340602 \t -10.33497247526879\n",
      "init   \t [-1.65746631 -1.76827175]. \t  -31.58185954845167 \t -10.33497247526879\n",
      "init   \t [2.62454288 1.81814608]. \t  -72.11481054100958 \t -10.33497247526879\n",
      "1      \t [ 1.57979098 -2.        ]. \t  -46.924823727110756 \t -10.33497247526879\n",
      "2      \t [-0.23235379 -0.02749016]. \t  \u001b[92m-0.2132515343908683\u001b[0m \t -0.2132515343908683\n",
      "3      \t [-0.55163713  1.56133581]. \t  -14.190657746780094 \t -0.2132515343908683\n",
      "4      \t [0.26855632 0.37818311]. \t  \u001b[92m0.11101311658343055\u001b[0m \t 0.11101311658343055\n",
      "5      \t [0.12880879 0.08477449]. \t  -0.04816967369509341 \t 0.11101311658343055\n",
      "6      \t [-0.42421123  0.36614127]. \t  -0.0340858815326997 \t 0.11101311658343055\n",
      "7      \t [-0.07820183  0.30338872]. \t  \u001b[92m0.33363186407726025\u001b[0m \t 0.33363186407726025\n",
      "8      \t [-1.39191006 -0.01002833]. \t  -2.3047841089588483 \t 0.33363186407726025\n",
      "9      \t [-2.91765302 -1.08873907]. \t  -91.55471288129907 \t 0.33363186407726025\n",
      "10     \t [-0.92167195  0.06046083]. \t  -2.0165640978387356 \t 0.33363186407726025\n",
      "11     \t [-0.22200257 -0.99862591]. \t  -0.40282203691672125 \t 0.33363186407726025\n",
      "12     \t [-1.20141695  0.46933481]. \t  -1.1499646315882706 \t 0.33363186407726025\n",
      "13     \t [ 0.09095522 -0.77470579]. \t  \u001b[92m0.9973803008982152\u001b[0m \t 0.9973803008982152\n",
      "14     \t [ 0.12586786 -0.72460597]. \t  \u001b[92m1.025848712453225\u001b[0m \t 1.025848712453225\n",
      "15     \t [-0.02407754 -0.63105946]. \t  0.9410638243984077 \t 1.025848712453225\n",
      "16     \t [ 0.81354915 -0.28808751]. \t  -1.285366278530232 \t 1.025848712453225\n",
      "17     \t [-0.38896531 -1.77582881]. \t  -28.41468897229502 \t 1.025848712453225\n",
      "18     \t [-0.65891169 -0.751345  ]. \t  -0.8798115653253034 \t 1.025848712453225\n",
      "19     \t [-0.12964799 -0.79238758]. \t  0.7652146672653721 \t 1.025848712453225\n",
      "20     \t [1.25846478 0.41575646]. \t  -2.3431165859275342 \t 1.025848712453225\n",
      "21     \t [ 2.87749919 -1.6426823 ]. \t  -91.97372885631984 \t 1.025848712453225\n",
      "22     \t [0.92470828 0.5060744 ]. \t  -1.7991849555666897 \t 1.025848712453225\n",
      "23     \t [ 1.45323753 -0.20642826]. \t  -1.7579453876390798 \t 1.025848712453225\n",
      "24     \t [ 0.24903678 -0.52965178]. \t  0.6991568604062945 \t 1.025848712453225\n",
      "25     \t [-0.15842457  0.76660903]. \t  0.9916161774444822 \t 1.025848712453225\n",
      "26     \t [-0.01899602  0.73137201]. \t  1.0075765940666515 \t 1.025848712453225\n",
      "27     \t [ 0.53725966 -0.86767655]. \t  0.22276841569446437 \t 1.025848712453225\n",
      "28     \t [-0.3593257   0.71826248]. \t  0.7749099081428203 \t 1.025848712453225\n",
      "29     \t [ 0.1511629  -0.79226787]. \t  0.9642358314988699 \t 1.025848712453225\n",
      "30     \t [ 0.10573786 -0.71045825]. \t  \u001b[92m1.030572110714754\u001b[0m \t 1.030572110714754\n",
      "31     \t [-0.03071702  0.62127675]. \t  0.9633136310639371 \t 1.030572110714754\n",
      "32     \t [-1.19044206  1.60389937]. \t  -16.671397498064348 \t 1.030572110714754\n",
      "33     \t [-0.01838981  0.77479048]. \t  0.972655156754368 \t 1.030572110714754\n",
      "34     \t [0.03258279 0.7162254 ]. \t  0.9717453965015953 \t 1.030572110714754\n",
      "35     \t [ 0.21275689 -0.75466074]. \t  0.9644410715221499 \t 1.030572110714754\n",
      "36     \t [0.10165606 1.69753815]. \t  -21.9024326163214 \t 1.030572110714754\n",
      "37     \t [ 0.10101742 -0.70939311]. \t  \u001b[92m1.0310193546857909\u001b[0m \t 1.0310193546857909\n",
      "38     \t [2.49091415 0.82107964]. \t  -24.761651683463946 \t 1.0310193546857909\n",
      "39     \t [2.14421669 0.16162784]. \t  -6.640512465410828 \t 1.0310193546857909\n",
      "40     \t [1.77134962 1.12044898]. \t  -5.440261004708861 \t 1.0310193546857909\n",
      "41     \t [1.7193935  0.60305694]. \t  -2.195442727864606 \t 1.0310193546857909\n",
      "42     \t [ 2.60350982 -0.74026758]. \t  -31.51955416683856 \t 1.0310193546857909\n",
      "43     \t [ 0.09032991 -0.70351722]. \t  1.0309477506344662 \t 1.0310193546857909\n",
      "44     \t [-0.49851767 -1.85987011]. \t  -35.82216321443935 \t 1.0310193546857909\n",
      "45     \t [2.33977287 0.9159658 ]. \t  -15.254438597130013 \t 1.0310193546857909\n",
      "46     \t [-0.09009384  0.70414057]. \t  \u001b[92m1.0310392142579128\u001b[0m \t 1.0310392142579128\n",
      "47     \t [-1.88403113 -0.7109019 ]. \t  -2.9864635833658357 \t 1.0310392142579128\n",
      "48     \t [-1.51325619 -0.81791769]. \t  -2.5023557594659147 \t 1.0310392142579128\n",
      "49     \t [ 0.03540793 -0.73331588]. \t  1.0152527057202418 \t 1.0310392142579128\n",
      "50     \t [ 1.58033253 -0.75577864]. \t  0.09012984247063915 \t 1.0310392142579128\n",
      "51     \t [-0.09880591 -1.16833711]. \t  -2.147269514595369 \t 1.0310392142579128\n",
      "52     \t [-0.08128074  0.70854087]. \t  \u001b[92m1.031239566681169\u001b[0m \t 1.031239566681169\n",
      "53     \t [ 0.07677345 -0.76193023]. \t  1.0090469766825687 \t 1.031239566681169\n",
      "54     \t [ 1.95761908 -1.93844918]. \t  -40.90118474287687 \t 1.031239566681169\n",
      "55     \t [1.99439642 0.10693541]. \t  -3.830710109096632 \t 1.031239566681169\n",
      "56     \t [1.26104774 0.85554931]. \t  -2.6849656539478097 \t 1.031239566681169\n",
      "57     \t [1.14550612 1.79939182]. \t  -33.42966684349355 \t 1.031239566681169\n",
      "58     \t [1.64046725 1.40417473]. \t  -12.019674949463896 \t 1.031239566681169\n",
      "59     \t [1.96268358 0.59749233]. \t  -3.555095457928481 \t 1.031239566681169\n",
      "60     \t [-1.90776554  0.32582769]. \t  -1.8100022199338084 \t 1.031239566681169\n",
      "61     \t [ 1.41512445 -1.66316546]. \t  -19.453236785256095 \t 1.031239566681169\n",
      "62     \t [-2.04525388 -0.46884482]. \t  -4.657774681653819 \t 1.031239566681169\n",
      "63     \t [1.66964531 0.19899234]. \t  -2.232582401110484 \t 1.031239566681169\n",
      "64     \t [ 0.1612934  -0.68940737]. \t  1.006106232491304 \t 1.031239566681169\n",
      "65     \t [-2.59684065  1.48728536]. \t  -40.56018689200172 \t 1.031239566681169\n",
      "66     \t [2.37785924 0.2369086 ]. \t  -16.08634058677259 \t 1.031239566681169\n",
      "67     \t [ 0.1618023  -0.54916627]. \t  0.8280934772723983 \t 1.031239566681169\n",
      "68     \t [1.32524015 0.72449656]. \t  -2.31600554528031 \t 1.031239566681169\n",
      "69     \t [ 0.91160141 -1.14890544]. \t  -2.707277248302725 \t 1.031239566681169\n",
      "70     \t [ 0.14222479 -1.61540111]. \t  -16.65061583346864 \t 1.031239566681169\n",
      "71     \t [2.20797735 0.05221641]. \t  -8.316939958275857 \t 1.031239566681169\n",
      "72     \t [ 0.95007588 -0.41248083]. \t  -1.1880563780956406 \t 1.031239566681169\n",
      "73     \t [ 0.11450393 -0.66452184]. \t  1.0103587511140242 \t 1.031239566681169\n",
      "74     \t [0.07612038 0.8521303 ]. \t  0.7074967542333932 \t 1.031239566681169\n",
      "75     \t [ 0.07855887 -0.70553056]. \t  1.030799772563267 \t 1.031239566681169\n",
      "76     \t [-2.89235613  0.69952712]. \t  -78.63019868610601 \t 1.031239566681169\n",
      "77     \t [-1.82277624  0.92036275]. \t  -0.1380089408308024 \t 1.031239566681169\n",
      "78     \t [1.90501593 1.06426417]. \t  -5.419260736412995 \t 1.031239566681169\n",
      "79     \t [ 0.01300806 -0.70794417]. \t  1.008526587122316 \t 1.031239566681169\n",
      "80     \t [-2.66878855 -0.20825313]. \t  -42.78662758376742 \t 1.031239566681169\n",
      "81     \t [2.85293343 1.17716797]. \t  -78.66783280350317 \t 1.031239566681169\n",
      "82     \t [ 2.95363074 -1.80417092]. \t  -120.4205260951154 \t 1.031239566681169\n",
      "83     \t [ 0.2254304  -1.78183334]. \t  -27.417219462812433 \t 1.031239566681169\n",
      "84     \t [-0.53787681  1.70480239]. \t  -22.23467576196339 \t 1.031239566681169\n",
      "85     \t [ 2.11583549 -1.47250579]. \t  -12.743920217849391 \t 1.031239566681169\n",
      "86     \t [-1.14618815 -0.27827773]. \t  -2.4195364166549176 \t 1.031239566681169\n",
      "87     \t [-2.36376444 -0.49053673]. \t  -15.362442290086065 \t 1.031239566681169\n",
      "88     \t [-0.15309203  0.74838111]. \t  1.0075360653506744 \t 1.031239566681169\n",
      "89     \t [ 0.41852102 -1.08636644]. \t  -1.033978339859822 \t 1.031239566681169\n",
      "90     \t [ 0.81526554 -0.51039145]. \t  -0.6421272064805831 \t 1.031239566681169\n",
      "91     \t [-0.92313442 -0.52801927]. \t  -1.7731044207996862 \t 1.031239566681169\n",
      "92     \t [-1.77288972  0.6838789 ]. \t  0.03159384333183479 \t 1.031239566681169\n",
      "93     \t [2.87939305 0.55852867]. \t  -79.53094007102979 \t 1.031239566681169\n",
      "94     \t [1.81410626 0.22819461]. \t  -2.517332768296396 \t 1.031239566681169\n",
      "95     \t [-1.86695189 -0.03960588]. \t  -2.612176725262452 \t 1.031239566681169\n",
      "96     \t [2.95728238 0.43879235]. \t  -98.00561843019408 \t 1.031239566681169\n",
      "97     \t [-0.41527097 -1.30839096]. \t  -6.0470736740564135 \t 1.031239566681169\n",
      "98     \t [-0.3793786   0.30838256]. \t  -0.07198714155968838 \t 1.031239566681169\n",
      "99     \t [-1.77459144 -0.19784531]. \t  -2.3814564117233825 \t 1.031239566681169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [-1.93364276 -1.30135232]. \t  -10.235868365973989 \t 1.031239566681169\n"
     ]
    }
   ],
   "source": [
    "### 6(o). Bayesian optimization runs (x20): GP run number = 15\n",
    "\n",
    "np.random.seed(run_num_15)\n",
    "surrogate_gp_15 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_15 = GPGO(surrogate_gp_15, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_15.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.62098529  1.04287489]. \t  -34.08534662113232 \t -10.33497247526879\n",
      "init   \t [0.55383081 1.42880521]. \t  -10.33497247526879 \t -10.33497247526879\n",
      "init   \t [2.98273183 1.07450664]. \t  -108.01579010340602 \t -10.33497247526879\n",
      "init   \t [-1.65746631 -1.76827175]. \t  -31.58185954845167 \t -10.33497247526879\n",
      "init   \t [2.62454288 1.81814608]. \t  -72.11481054100958 \t -10.33497247526879\n",
      "1      \t [ 1.58125288 -2.        ]. \t  -46.92073746131564 \t -10.33497247526879\n",
      "2      \t [-0.23620174 -0.08197588]. \t  \u001b[92m-0.20934964652610688\u001b[0m \t -0.20934964652610688\n",
      "3      \t [-0.87859947  2.        ]. \t  -48.232515967631464 \t -0.20934964652610688\n",
      "4      \t [-3.         -0.81853932]. \t  -110.47122694672292 \t -0.20934964652610688\n",
      "5      \t [-0.27335027 -2.        ]. \t  -48.83399648745459 \t -0.20934964652610688\n",
      "6      \t [0.93881773 0.01130194]. \t  -2.1325014351397864 \t -0.20934964652610688\n",
      "7      \t [ 3. -2.]. \t  -150.89999999999998 \t -0.20934964652610688\n",
      "8      \t [-3.  2.]. \t  -150.89999999999998 \t -0.20934964652610688\n",
      "9      \t [-1.52061076  0.43028151]. \t  -0.8844133094016355 \t -0.20934964652610688\n",
      "10     \t [ 0.75320105 -0.926502  ]. \t  -0.4702163549854347 \t -0.20934964652610688\n",
      "11     \t [1.22771396 2.        ]. \t  -52.855032163969646 \t -0.20934964652610688\n",
      "12     \t [-0.16024953  0.77756051]. \t  \u001b[92m0.9794983446259398\u001b[0m \t 0.9794983446259398\n",
      "13     \t [ 1.76361548 -0.62163803]. \t  -0.11079958557765457 \t 0.9794983446259398\n",
      "14     \t [-1.10935147 -0.66149623]. \t  -2.11284602122345 \t 0.9794983446259398\n",
      "15     \t [ 1.27765601 -0.70981347]. \t  -0.47679623881479394 \t 0.9794983446259398\n",
      "16     \t [-3. -2.]. \t  -162.90000000000003 \t 0.9794983446259398\n",
      "17     \t [-2.27282277  0.24787353]. \t  -9.779579190794552 \t 0.9794983446259398\n",
      "18     \t [ 3.         -0.43975204]. \t  -106.95680260797681 \t 0.9794983446259398\n",
      "19     \t [1.64865151 0.38993793]. \t  -2.17843903285607 \t 0.9794983446259398\n",
      "20     \t [-0.29646554 -0.90037272]. \t  0.011433378995805543 \t 0.9794983446259398\n",
      "21     \t [0.77999107 0.77576901]. \t  -1.3778852282590612 \t 0.9794983446259398\n",
      "22     \t [-3.          0.44524023]. \t  -106.92851845254589 \t 0.9794983446259398\n",
      "23     \t [-1.95307727  0.94865365]. \t  -0.9900385919371866 \t 0.9794983446259398\n",
      "24     \t [-1.79136183 -0.52901755]. \t  -2.3674464085728433 \t 0.9794983446259398\n",
      "25     \t [-1.94210584  0.48901158]. \t  -1.4205111927990652 \t 0.9794983446259398\n",
      "26     \t [ 1.59909965 -0.15469022]. \t  -1.7296296555433255 \t 0.9794983446259398\n",
      "27     \t [-0.74828795  0.86957246]. \t  -0.251624406813152 \t 0.9794983446259398\n",
      "28     \t [-0.79920903  0.22057055]. \t  -1.4236216581007186 \t 0.9794983446259398\n",
      "29     \t [ 0.24487756 -0.58496011]. \t  0.8112321197007875 \t 0.9794983446259398\n",
      "30     \t [0.11431874 2.        ]. \t  -48.280554645887335 \t 0.9794983446259398\n",
      "31     \t [-1.7702744  -0.10090859]. \t  -2.3087981722294204 \t 0.9794983446259398\n",
      "32     \t [-1.03738332 -1.30472263]. \t  -8.423640471507117 \t 0.9794983446259398\n",
      "33     \t [ 0.74057867 -2.        ]. \t  -48.13597240361871 \t 0.9794983446259398\n",
      "34     \t [ 1.52597334 -1.16470514]. \t  -2.293578776634881 \t 0.9794983446259398\n",
      "35     \t [-1.86072259  2.        ]. \t  -46.78874188232996 \t 0.9794983446259398\n",
      "36     \t [0.27946797 0.41695128]. \t  0.15821769924621304 \t 0.9794983446259398\n",
      "37     \t [1.64360995 1.21392306]. \t  -6.838804063017141 \t 0.9794983446259398\n",
      "38     \t [1.35854507 0.79104459]. \t  -2.4627239039046107 \t 0.9794983446259398\n",
      "39     \t [0.13788681 1.00319517]. \t  -0.23938769474573302 \t 0.9794983446259398\n",
      "40     \t [-0.43031549 -0.62944551]. \t  0.015247118223343459 \t 0.9794983446259398\n",
      "41     \t [ 2.17205792 -1.2544611 ]. \t  -8.019081494560115 \t 0.9794983446259398\n",
      "42     \t [-1.37500482  0.84691848]. \t  -0.33308898893943517 \t 0.9794983446259398\n",
      "43     \t [ 0.22141945 -0.93439858]. \t  0.45897946932700273 \t 0.9794983446259398\n",
      "44     \t [-0.70090904  0.60938375]. \t  -0.13686479823851105 \t 0.9794983446259398\n",
      "45     \t [ 1.81902677 -0.96748805]. \t  -0.3198314479648697 \t 0.9794983446259398\n",
      "46     \t [2.1771836 0.1603867]. \t  -7.5266329410409085 \t 0.9794983446259398\n",
      "47     \t [-1.6803434  -1.13216889]. \t  -5.402927922530202 \t 0.9794983446259398\n",
      "48     \t [1.96767728 0.80209886]. \t  -4.013975143039209 \t 0.9794983446259398\n",
      "49     \t [3. 2.]. \t  -162.89999999999998 \t 0.9794983446259398\n",
      "50     \t [2.06801177 2.        ]. \t  -56.907209696418185 \t 0.9794983446259398\n",
      "51     \t [ 2.26548248 -2.        ]. \t  -53.74660730831134 \t 0.9794983446259398\n",
      "52     \t [-2.32650251 -1.20446877]. \t  -18.402583415758752 \t 0.9794983446259398\n",
      "53     \t [-2.18179267 -0.53756952]. \t  -7.7615416452247 \t 0.9794983446259398\n",
      "54     \t [-1.51307076  1.43907961]. \t  -8.84472491380341 \t 0.9794983446259398\n",
      "55     \t [ 0.14411684 -1.41652411]. \t  -7.956688425054807 \t 0.9794983446259398\n",
      "56     \t [-2.28849923 -2.        ]. \t  -63.80914963332468 \t 0.9794983446259398\n",
      "57     \t [ 3.         -1.22198107]. \t  -108.18014153477102 \t 0.9794983446259398\n",
      "58     \t [-0.00148384 -0.64165278]. \t  0.9678644372754741 \t 0.9794983446259398\n",
      "59     \t [ 2.1956033  -0.53952629]. \t  -5.81338310300121 \t 0.9794983446259398\n",
      "60     \t [-2.28709878  1.58972572]. \t  -22.97459129832142 \t 0.9794983446259398\n",
      "61     \t [-0.03132014  0.7097505 ]. \t  \u001b[92m1.0182515780725987\u001b[0m \t 1.0182515780725987\n",
      "62     \t [-1.05360133 -2.        ]. \t  -52.415712861210196 \t 1.0182515780725987\n",
      "63     \t [-0.36561269  1.40727183]. \t  -7.749949261916418 \t 1.0182515780725987\n",
      "64     \t [2.13432595 1.3203586 ]. \t  -14.155237322236337 \t 1.0182515780725987\n",
      "65     \t [ 0.00961944 -0.64874106]. \t  0.9808209943246389 \t 1.0182515780725987\n",
      "66     \t [ 0.12731937 -0.64522529]. \t  0.9898469230121848 \t 1.0182515780725987\n",
      "67     \t [-0.16273452  0.76981865]. \t  0.9864981444272195 \t 1.0182515780725987\n",
      "68     \t [ 0.07665427 -0.72141166]. \t  \u001b[92m1.0301978918752395\u001b[0m \t 1.0301978918752395\n",
      "69     \t [-0.13254329  0.71397275]. \t  1.0246269056502184 \t 1.0301978918752395\n",
      "70     \t [ 0.0854108  -0.71489348]. \t  \u001b[92m1.031500813875371\u001b[0m \t 1.031500813875371\n",
      "71     \t [ 0.03262417 -0.64432357]. \t  0.9879694088997242 \t 1.031500813875371\n",
      "72     \t [0.00285857 0.72391762]. \t  0.9955830421393509 \t 1.031500813875371\n",
      "73     \t [-0.10473533  0.70907821]. \t  1.030608656321137 \t 1.031500813875371\n",
      "74     \t [ 0.00940505 -0.75423715]. \t  0.9877655020928746 \t 1.031500813875371\n",
      "75     \t [ 0.07855887 -0.70553056]. \t  1.030799772563267 \t 1.031500813875371\n",
      "76     \t [-0.09042369  0.611974  ]. \t  0.9597826092613246 \t 1.031500813875371\n",
      "77     \t [ 0.04843974 -0.69728606]. \t  1.0236413860624072 \t 1.031500813875371\n",
      "78     \t [ 0.09519258 -0.73597787]. \t  1.0270419475059471 \t 1.031500813875371\n",
      "79     \t [ 0.01300672 -0.70794297]. \t  1.0085257758701462 \t 1.031500813875371\n",
      "80     \t [-3.          1.43030148]. \t  -113.1666202257172 \t 1.031500813875371\n",
      "81     \t [-0.01855599  0.64976504]. \t  0.9864652623414673 \t 1.031500813875371\n",
      "82     \t [ 0.04704699 -0.69658198]. \t  1.0230556639500799 \t 1.031500813875371\n",
      "83     \t [-0.14717763  0.74319991]. \t  1.0127588753237438 \t 1.031500813875371\n",
      "84     \t [3.         0.39207659]. \t  -109.55585789770129 \t 1.031500813875371\n",
      "85     \t [ 0.12497548 -0.71960697]. \t  1.026696532328415 \t 1.031500813875371\n",
      "86     \t [-0.13299233  0.75711033]. \t  1.009154763092307 \t 1.031500813875371\n",
      "87     \t [-0.04008358  0.69086089]. \t  1.0192076251574527 \t 1.031500813875371\n",
      "88     \t [ 0.02272978 -0.68211157]. \t  1.0086152637349595 \t 1.031500813875371\n",
      "89     \t [0.03906548 0.66710668]. \t  0.95575337530133 \t 1.031500813875371\n",
      "90     \t [ 0.04510095 -0.72285313]. \t  1.0224456709848617 \t 1.031500813875371\n",
      "91     \t [-0.09280069  0.726513  ]. \t  1.0300325075003751 \t 1.031500813875371\n",
      "92     \t [ 0.07923833 -0.73424958]. \t  1.0270262983997678 \t 1.031500813875371\n",
      "93     \t [-0.10550599  0.69738132]. \t  1.0285652979148552 \t 1.031500813875371\n",
      "94     \t [-0.08002344  0.6787991 ]. \t  1.0226343336561614 \t 1.031500813875371\n",
      "95     \t [ 0.69250422 -0.48272008]. \t  -0.42288438581648213 \t 1.031500813875371\n",
      "96     \t [ 0.10178452 -0.73400281]. \t  1.0274854070629407 \t 1.031500813875371\n",
      "97     \t [ 0.18900043 -0.72596555]. \t  0.9940659450811606 \t 1.031500813875371\n",
      "98     \t [-0.03027469  0.57306731]. \t  0.8959071589560413 \t 1.031500813875371\n",
      "99     \t [ 0.10504671 -0.68268793]. \t  1.0232232070765366 \t 1.031500813875371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [ 0.07318431 -0.62578461]. \t  0.977437324975016 \t 1.031500813875371\n"
     ]
    }
   ],
   "source": [
    "### 6(o). Bayesian optimization runs (x20): STP DF1 run number = 15\n",
    "\n",
    "np.random.seed(run_num_15)\n",
    "surrogate_stp_df1_15 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_15 = GPGO(surrogate_stp_df1_15, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_15.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.928203586916229, -9.21851242614693)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(o). Training Regret Minimisation: run number = 15\n",
    "\n",
    "gp_output_15 = np.append(np.max(gpgo_gp_15.GP.y[0:n_init]),gpgo_gp_15.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_15 = np.append(np.max(gpgo_stp_df1_15.GP.y[0:n_init]),gpgo_stp_df1_15.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_15 = np.log(y_global_orig - gp_output_15)\n",
    "regret_stp_df1_15 = np.log(y_global_orig - stp_df1_output_15)\n",
    "\n",
    "train_regret_gp_15 = min_max_array(regret_gp_15)\n",
    "train_regret_stp_df1_15 = min_max_array(regret_stp_df1_15)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 15\n",
    "min_train_regret_gp_15 = min(train_regret_gp_15)\n",
    "min_train_regret_stp_df1_15 = min(train_regret_stp_df1_15)\n",
    "\n",
    "min_train_regret_gp_15, min_train_regret_stp_df1_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 2.18368999 -0.73453599]. \t  -4.868217712547965 \t 0.15481417016151777\n",
      "init   \t [1.03290467 0.03164667]. \t  -2.310710708702905 \t 0.15481417016151777\n",
      "init   \t [ 1.68996256 -0.86527329]. \t  0.15481417016151777 \t 0.15481417016151777\n",
      "init   \t [-1.5977473   0.25519875]. \t  -1.420015353077075 \t 0.15481417016151777\n",
      "init   \t [2.25014619 0.87577168]. \t  -10.939300534748709 \t 0.15481417016151777\n",
      "1      \t [ 1.00985699 -1.38885986]. \t  -8.01358667079328 \t 0.15481417016151777\n",
      "2      \t [-3. -2.]. \t  -162.89999999999998 \t 0.15481417016151777\n",
      "3      \t [-1.49519069  1.00020552]. \t  -0.6773840108385066 \t 0.15481417016151777\n",
      "4      \t [-3.  2.]. \t  -150.89999999999998 \t 0.15481417016151777\n",
      "5      \t [-0.78766289  0.98906345]. \t  -0.8887676913014384 \t 0.15481417016151777\n",
      "6      \t [-0.97361143  1.11769586]. \t  -2.34590303713561 \t 0.15481417016151777\n",
      "7      \t [-1.25461805  0.63257036]. \t  -0.6393903035679279 \t 0.15481417016151777\n",
      "8      \t [0.27070379 1.05977224]. \t  -1.1219608169994832 \t 0.15481417016151777\n",
      "9      \t [-1.90768755  0.50421967]. \t  -1.0902969691131519 \t 0.15481417016151777\n",
      "10     \t [-0.03357332  0.5143319 ]. \t  \u001b[92m0.7909910963516258\u001b[0m \t 0.7909910963516258\n",
      "11     \t [-0.14448113  0.84996338]. \t  \u001b[92m0.8423023362588701\u001b[0m \t 0.8423023362588701\n",
      "12     \t [1.22344116 2.        ]. \t  -52.84703577630079 \t 0.8423023362588701\n",
      "13     \t [-0.75371584 -0.73114422]. \t  -1.2115985165927794 \t 0.8423023362588701\n",
      "14     \t [ 1.83488056 -1.32971084]. \t  -5.377005600598951 \t 0.8423023362588701\n",
      "15     \t [ 0.68939697 -0.51758881]. \t  -0.3211704413224429 \t 0.8423023362588701\n",
      "16     \t [ 1.42211712 -0.71903315]. \t  -0.23626114299646572 \t 0.8423023362588701\n",
      "17     \t [ 0.00152693 -0.55664401]. \t  \u001b[92m0.856216420419344\u001b[0m \t 0.856216420419344\n",
      "18     \t [0.27446106 0.62923691]. \t  0.49444263336372135 \t 0.856216420419344\n",
      "19     \t [ 0.1466609 -0.2447318]. \t  0.17604877438100539 \t 0.856216420419344\n",
      "20     \t [ 0.04959797 -0.81966515]. \t  \u001b[92m0.9126955903111142\u001b[0m \t 0.9126955903111142\n",
      "21     \t [2.95642866 1.51867499]. \t  -113.65092779445001 \t 0.9126955903111142\n",
      "22     \t [1.7341125  0.57456978]. \t  -2.21469586880614 \t 0.9126955903111142\n",
      "23     \t [2.67912602 0.26364761]. \t  -44.23169528294859 \t 0.9126955903111142\n",
      "24     \t [ 0.1807103  -1.96951697]. \t  -44.44296998401471 \t 0.9126955903111142\n",
      "25     \t [-0.18610861 -0.85796922]. \t  0.48129038675012836 \t 0.9126955903111142\n",
      "26     \t [-1.74476969 -0.40249317]. \t  -2.278709154576716 \t 0.9126955903111142\n",
      "27     \t [1.75432254 0.88293776]. \t  -2.998256802540766 \t 0.9126955903111142\n",
      "28     \t [-0.0263908   0.65667486]. \t  \u001b[92m0.9956235774067448\u001b[0m \t 0.9956235774067448\n",
      "29     \t [ 2.7787833  -1.93238217]. \t  -94.60890787685028 \t 0.9956235774067448\n",
      "30     \t [0.0254775  0.79436433]. \t  0.9085066659785855 \t 0.9956235774067448\n",
      "31     \t [ 1.16006307 -1.42403575]. \t  -9.07788399308901 \t 0.9956235774067448\n",
      "32     \t [-0.590951   -1.87775729]. \t  -37.890679461121174 \t 0.9956235774067448\n",
      "33     \t [1.58476494 1.21281658]. \t  -6.773319884253189 \t 0.9956235774067448\n",
      "34     \t [0.0011967  0.69418676]. \t  \u001b[92m0.997852411692912\u001b[0m \t 0.997852411692912\n",
      "35     \t [-0.92499965 -1.60176692]. \t  -19.64329435847691 \t 0.997852411692912\n",
      "36     \t [ 1.59121066 -0.50113126]. \t  -0.526099360979377 \t 0.997852411692912\n",
      "37     \t [-0.43552111  0.14346979]. \t  -0.5423118285680255 \t 0.997852411692912\n",
      "38     \t [-1.65152292  1.87485109]. \t  -34.317232286957825 \t 0.997852411692912\n",
      "39     \t [-2.08942913  0.06695537]. \t  -5.016291437368888 \t 0.997852411692912\n",
      "40     \t [ 0.11093152 -1.98101709]. \t  -45.73599653867532 \t 0.997852411692912\n",
      "41     \t [-0.49690119  1.97896082]. \t  -45.56532430579879 \t 0.997852411692912\n",
      "42     \t [2.21827117 1.96065619]. \t  -56.63377226491582 \t 0.997852411692912\n",
      "43     \t [ 0.04940441 -0.75562736]. \t  \u001b[92m1.0074321494287037\u001b[0m \t 1.0074321494287037\n",
      "44     \t [-0.10645837  0.71473478]. \t  \u001b[92m1.030554685425427\u001b[0m \t 1.030554685425427\n",
      "45     \t [-0.89775871 -1.6124698 ]. \t  -20.122860266160462 \t 1.030554685425427\n",
      "46     \t [0.99149593 1.09304245]. \t  -4.233879355183807 \t 1.030554685425427\n",
      "47     \t [-0.32324254 -0.37129543]. \t  -0.039996073069283766 \t 1.030554685425427\n",
      "48     \t [ 0.162227   -0.67779611]. \t  0.9995438639326215 \t 1.030554685425427\n",
      "49     \t [1.40229604 0.22165236]. \t  -2.4039258096964105 \t 1.030554685425427\n",
      "50     \t [-0.0451006  -0.09975659]. \t  0.026782738471090778 \t 1.030554685425427\n",
      "51     \t [-2.40975476  0.82515777]. \t  -14.827831552487309 \t 1.030554685425427\n",
      "52     \t [-0.98902035 -0.98631503]. \t  -3.0850448128396297 \t 1.030554685425427\n",
      "53     \t [-1.86370466 -1.82081755]. \t  -36.625260451302594 \t 1.030554685425427\n",
      "54     \t [ 1.20875711 -1.30544156]. \t  -5.623231024010353 \t 1.030554685425427\n",
      "55     \t [-0.93842378 -1.43326778]. \t  -12.129471971749108 \t 1.030554685425427\n",
      "56     \t [-0.10395013  0.71489637]. \t  \u001b[92m1.0308450472832202\u001b[0m \t 1.0308450472832202\n",
      "57     \t [-1.76279819  0.64155545]. \t  -0.054119100443345114 \t 1.0308450472832202\n",
      "58     \t [ 2.55713393 -1.85211105]. \t  -58.17204951785956 \t 1.0308450472832202\n",
      "59     \t [ 0.13176523 -0.72033628]. \t  1.0246717803684542 \t 1.0308450472832202\n",
      "60     \t [-0.20861753  0.74525062]. \t  0.9730614138466095 \t 1.0308450472832202\n",
      "61     \t [-1.14461476  0.52225754]. \t  -0.9943654894472209 \t 1.0308450472832202\n",
      "62     \t [ 1.98461331 -0.39381778]. \t  -2.2384753512446833 \t 1.0308450472832202\n",
      "63     \t [-0.00913986 -0.71092033]. \t  0.9930511794555171 \t 1.0308450472832202\n",
      "64     \t [ 0.22835015 -0.7083746 ]. \t  0.9588319866793009 \t 1.0308450472832202\n",
      "65     \t [-0.5267027   1.94130659]. \t  -41.669520784412626 \t 1.0308450472832202\n",
      "66     \t [-2.28575626 -1.68877761]. \t  -36.10148036780675 \t 1.0308450472832202\n",
      "67     \t [-2.08193746 -1.02057588]. \t  -7.326623365146662 \t 1.0308450472832202\n",
      "68     \t [ 2.15379535 -0.1148423 ]. \t  -6.340509925469137 \t 1.0308450472832202\n",
      "69     \t [1.90139351 1.03652246]. \t  -5.0549803120941 \t 1.0308450472832202\n",
      "70     \t [ 1.87066426 -0.05430607]. \t  -2.4523633639431703 \t 1.0308450472832202\n",
      "71     \t [-0.14323188  0.76567151]. \t  0.9987298338020258 \t 1.0308450472832202\n",
      "72     \t [-0.30060069 -0.20153082]. \t  -0.24926219649462772 \t 1.0308450472832202\n",
      "73     \t [0.97526732 0.73008194]. \t  -1.907972443799164 \t 1.0308450472832202\n",
      "74     \t [ 0.13192895 -0.63195665]. \t  0.9738805783926698 \t 1.0308450472832202\n",
      "75     \t [-0.0897056   0.78608958]. \t  0.982827695221619 \t 1.0308450472832202\n",
      "76     \t [-1.66110534  1.01313952]. \t  -0.47688773519325334 \t 1.0308450472832202\n",
      "77     \t [-1.86750568  0.70426339]. \t  -0.2324756996214492 \t 1.0308450472832202\n",
      "78     \t [-0.0307248   0.02334333]. \t  -0.0008785049358762055 \t 1.0308450472832202\n",
      "79     \t [ 0.13185308 -0.7798099 ]. \t  0.9871669093224957 \t 1.0308450472832202\n",
      "80     \t [2.80156731 0.96082609]. \t  -65.60661081112652 \t 1.0308450472832202\n",
      "81     \t [-2.89226964 -1.95592372]. \t  -130.53011185358824 \t 1.0308450472832202\n",
      "82     \t [-0.08653126  0.72004402]. \t  \u001b[92m1.0311096900332253\u001b[0m \t 1.0311096900332253\n",
      "83     \t [-0.13307561  0.65766346]. \t  0.9991256924045604 \t 1.0311096900332253\n",
      "84     \t [ 0.21706747 -0.73010678]. \t  0.9702659255941001 \t 1.0311096900332253\n",
      "85     \t [-1.05880544 -1.26619925]. \t  -7.524050429022926 \t 1.0311096900332253\n",
      "86     \t [0.3473684  1.15989825]. \t  -2.714141654336306 \t 1.0311096900332253\n",
      "87     \t [ 0.76379738 -1.69355155]. \t  -21.823395040306888 \t 1.0311096900332253\n",
      "88     \t [-2.43203835 -0.79476976]. \t  -20.169540227053655 \t 1.0311096900332253\n",
      "89     \t [0.18337496 0.88162559]. \t  0.398687728010978 \t 1.0311096900332253\n",
      "90     \t [ 0.40001542 -1.3566967 ]. \t  -6.234058703140568 \t 1.0311096900332253\n",
      "91     \t [1.53165474 1.54256082]. \t  -17.62277393064972 \t 1.0311096900332253\n",
      "92     \t [-0.10296326 -1.54889969]. \t  -13.6278251233956 \t 1.0311096900332253\n",
      "93     \t [-2.30940352 -1.23800489]. \t  -18.292581845782465 \t 1.0311096900332253\n",
      "94     \t [ 0.00372845 -0.74159598]. \t  0.992723552577655 \t 1.0311096900332253\n",
      "95     \t [-0.99061714  1.71493951]. \t  -23.35342319187397 \t 1.0311096900332253\n",
      "96     \t [ 0.15352823 -0.75439378]. \t  1.0035946854663889 \t 1.0311096900332253\n",
      "97     \t [-1.70697496  1.38578229]. \t  -6.776549152514686 \t 1.0311096900332253\n",
      "98     \t [ 0.20155206 -0.72713384]. \t  0.9842053783441223 \t 1.0311096900332253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-2.12458244  1.61086327]. \t  -19.056246462062564 \t 1.0311096900332253\n",
      "100    \t [-0.01343013  0.6652738 ]. \t  0.9950293221425383 \t 1.0311096900332253\n"
     ]
    }
   ],
   "source": [
    "### 6(p). Bayesian optimization runs (x20): GP run number = 16\n",
    "\n",
    "np.random.seed(run_num_16)\n",
    "surrogate_gp_16 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_16 = GPGO(surrogate_gp_16, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_16.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [ 2.18368999 -0.73453599]. \t  -4.868217712547965 \t 0.15481417016151777\n",
      "init   \t [1.03290467 0.03164667]. \t  -2.310710708702905 \t 0.15481417016151777\n",
      "init   \t [ 1.68996256 -0.86527329]. \t  0.15481417016151777 \t 0.15481417016151777\n",
      "init   \t [-1.5977473   0.25519875]. \t  -1.420015353077075 \t 0.15481417016151777\n",
      "init   \t [2.25014619 0.87577168]. \t  -10.939300534748709 \t 0.15481417016151777\n",
      "1      \t [ 0.89723142 -1.49748312]. \t  -11.834083239269262 \t 0.15481417016151777\n",
      "2      \t [-3. -2.]. \t  -162.89999999999998 \t 0.15481417016151777\n",
      "3      \t [-3.  2.]. \t  -150.89999999999998 \t 0.15481417016151777\n",
      "4      \t [0.13739262 2.        ]. \t  -48.34954612313377 \t 0.15481417016151777\n",
      "5      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.15481417016151777\n",
      "6      \t [-0.65986814 -0.78836107]. \t  -0.950347218458835 \t 0.15481417016151777\n",
      "7      \t [3. 2.]. \t  -162.89999999999998 \t 0.15481417016151777\n",
      "8      \t [2.06522144 0.06602693]. \t  -4.840559156086656 \t 0.15481417016151777\n",
      "9      \t [-0.39254724  0.38907168]. \t  0.09884739212557447 \t 0.15481417016151777\n",
      "10     \t [-0.61484073 -2.        ]. \t  -50.45970285721255 \t 0.15481417016151777\n",
      "11     \t [1.28174883 1.21200835]. \t  -6.690636518522945 \t 0.15481417016151777\n",
      "12     \t [-3.         -0.00972526]. \t  -108.92879747847726 \t 0.15481417016151777\n",
      "13     \t [3.         0.05590539]. \t  -109.05525359795293 \t 0.15481417016151777\n",
      "14     \t [-1.19218507  2.        ]. \t  -48.01568643744139 \t 0.15481417016151777\n",
      "15     \t [-0.99913199 -0.09201901]. \t  -2.2902977393742363 \t 0.15481417016151777\n",
      "16     \t [ 0.13660218 -0.66147259]. \t  \u001b[92m1.0008450140440042\u001b[0m \t 1.0008450140440042\n",
      "17     \t [1.6672244  0.69849336]. \t  -2.2171232403672967 \t 1.0008450140440042\n",
      "18     \t [-1.22661332  0.88776606]. \t  -0.6428850570746131 \t 1.0008450140440042\n",
      "19     \t [1.54871662 2.        ]. \t  -53.209906483758274 \t 1.0008450140440042\n",
      "20     \t [0.38151519 0.71646748]. \t  0.18719363924612764 \t 1.0008450140440042\n",
      "21     \t [-1.61302838 -0.9747712 ]. \t  -3.4453484384820916 \t 1.0008450140440042\n",
      "22     \t [ 1.42154395 -2.        ]. \t  -47.41522365429951 \t 1.0008450140440042\n",
      "23     \t [-0.45632895  1.07137602]. \t  -0.9348143277759372 \t 1.0008450140440042\n",
      "24     \t [ 1.7583486  -0.46138578]. \t  -0.663038359892032 \t 1.0008450140440042\n",
      "25     \t [ 0.38465504 -0.06996535]. \t  -0.5005472035373961 \t 1.0008450140440042\n",
      "26     \t [-0.89703871  0.65858643]. \t  -0.45941277430043637 \t 1.0008450140440042\n",
      "27     \t [-1.51983108 -0.51868998]. \t  -2.1447210724685357 \t 1.0008450140440042\n",
      "28     \t [-1.58855546 -2.        ]. \t  -53.254792536739 \t 1.0008450140440042\n",
      "29     \t [ 0.79075263 -0.7502296 ]. \t  -0.18413078684457673 \t 1.0008450140440042\n",
      "30     \t [-2.11905295  0.89312794]. \t  -3.2606456130989154 \t 1.0008450140440042\n",
      "31     \t [-1.75574323  0.74782713]. \t  0.15956495586089203 \t 1.0008450140440042\n",
      "32     \t [ 0.10041789 -1.22978672]. \t  -3.0162449287386064 \t 1.0008450140440042\n",
      "33     \t [-1.21908697 -1.08718758]. \t  -4.586321527446494 \t 1.0008450140440042\n",
      "34     \t [-3.          0.92796395]. \t  -105.63773036231126 \t 1.0008450140440042\n",
      "35     \t [-1.87416035  1.44861043]. \t  -9.091749726018953 \t 1.0008450140440042\n",
      "36     \t [ 0.40889527 -2.        ]. \t  -47.79384477760849 \t 1.0008450140440042\n",
      "37     \t [0.61700879 1.35970811]. \t  -8.35289736793738 \t 1.0008450140440042\n",
      "38     \t [-2.04269402 -0.31428443]. \t  -4.629879143535519 \t 1.0008450140440042\n",
      "39     \t [-3.         -1.02893184]. \t  -112.23538156316596 \t 1.0008450140440042\n",
      "40     \t [0.85704667 0.6901191 ]. \t  -1.5309156476535632 \t 1.0008450140440042\n",
      "41     \t [ 3.        -1.0687415]. \t  -106.34350200731507 \t 1.0008450140440042\n",
      "42     \t [ 0.36588071 -0.91129229]. \t  0.3979851380817383 \t 1.0008450140440042\n",
      "43     \t [-0.16378489 -0.85556091]. \t  0.5388076439843457 \t 1.0008450140440042\n",
      "44     \t [-1.9980024   0.32901095]. \t  -2.664411051681797 \t 1.0008450140440042\n",
      "45     \t [-0.31049524 -0.36809961]. \t  -0.012151678209369077 \t 1.0008450140440042\n",
      "46     \t [3.         1.03731363]. \t  -112.3391350381715 \t 1.0008450140440042\n",
      "47     \t [ 2.04765255 -1.38953117]. \t  -8.767071877030277 \t 1.0008450140440042\n",
      "48     \t [2.04412771 1.44584875]. \t  -16.440791896499032 \t 1.0008450140440042\n",
      "49     \t [ 1.88949093 -0.95278467]. \t  -0.547370080583458 \t 1.0008450140440042\n",
      "50     \t [-1.76250836  1.04712278]. \t  -0.7306965880981722 \t 1.0008450140440042\n",
      "51     \t [ 1.60190301 -1.24207403]. \t  -3.4282642303219686 \t 1.0008450140440042\n",
      "52     \t [-0.20574947  0.76350069]. \t  0.9639848133912314 \t 1.0008450140440042\n",
      "53     \t [-2.25259115 -1.50042383]. \t  -24.42374085855073 \t 1.0008450140440042\n",
      "54     \t [-2.07566656  2.        ]. \t  -48.75933044252913 \t 1.0008450140440042\n",
      "55     \t [0.8384092 2.       ]. \t  -51.5666812235002 \t 1.0008450140440042\n",
      "56     \t [ 2.18940287 -2.        ]. \t  -51.256485078802136 \t 1.0008450140440042\n",
      "57     \t [0.06752197 0.96894208]. \t  0.14602898511886178 \t 1.0008450140440042\n",
      "58     \t [-2.11289999 -0.91288562]. \t  -7.035640832881682 \t 1.0008450140440042\n",
      "59     \t [-2.26202679 -2.        ]. \t  -62.66491133230595 \t 1.0008450140440042\n",
      "60     \t [2.32065136 2.        ]. \t  -65.34123332100513 \t 1.0008450140440042\n",
      "61     \t [-0.00365227  0.51580204]. \t  0.7829033516866221 \t 1.0008450140440042\n",
      "62     \t [-0.68056214 -1.34181472]. \t  -8.113326866855548 \t 1.0008450140440042\n",
      "63     \t [ 0.04451552 -0.67530872]. \t  \u001b[92m1.0144141678542429\u001b[0m \t 1.0144141678542429\n",
      "64     \t [ 0.10349016 -0.74970952]. \t  \u001b[92m1.019579242226761\u001b[0m \t 1.019579242226761\n",
      "65     \t [ 0.09067112 -0.66986178]. \t  1.0174731735590345 \t 1.019579242226761\n",
      "66     \t [ 0.10364118 -0.76807944]. \t  1.0045194146758936 \t 1.019579242226761\n",
      "67     \t [-2.41903223  1.51875003]. \t  -26.671409607572272 \t 1.019579242226761\n",
      "68     \t [-0.04611185  0.70606544]. \t  \u001b[92m1.0240536010929653\u001b[0m \t 1.0240536010929653\n",
      "69     \t [ 0.04786529 -0.73250828]. \t  1.020559410923268 \t 1.0240536010929653\n",
      "70     \t [1.60408551 0.17798419]. \t  -2.2301302337817317 \t 1.0240536010929653\n",
      "71     \t [-0.14323188  0.76567151]. \t  0.9987298338020258 \t 1.0240536010929653\n",
      "72     \t [-0.5806937  2.       ]. \t  -47.96142879907395 \t 1.0240536010929653\n",
      "73     \t [-0.12446211  0.69134805]. \t  1.022643384335129 \t 1.0240536010929653\n",
      "74     \t [-0.06596889  0.69226666]. \t  \u001b[92m1.0265751793076703\u001b[0m \t 1.0265751793076703\n",
      "75     \t [ 0.07043808 -0.71678879]. \t  \u001b[92m1.0299345537718847\u001b[0m \t 1.0299345537718847\n",
      "76     \t [-0.03884281  0.60401963]. \t  0.9443583371301706 \t 1.0299345537718847\n",
      "77     \t [-0.11883791  0.70015839]. \t  1.0267510035713512 \t 1.0299345537718847\n",
      "78     \t [ 0.17550523 -0.71659284]. \t  1.003810550595236 \t 1.0299345537718847\n",
      "79     \t [ 0.08471689 -0.70995342]. \t  \u001b[92m1.031480196732831\u001b[0m \t 1.031480196732831\n",
      "80     \t [ 0.13114386 -0.7486968 ]. \t  1.0153479059697987 \t 1.031480196732831\n",
      "81     \t [ 0.1879156  -0.70676664]. \t  0.9941663933576641 \t 1.031480196732831\n",
      "82     \t [-0.0705809   0.70209969]. \t  1.0294811000582 \t 1.031480196732831\n",
      "83     \t [-0.13307398  0.65766414]. \t  0.9991268955387775 \t 1.031480196732831\n",
      "84     \t [ 0.20358578 -0.70555066]. \t  0.9814158663664903 \t 1.031480196732831\n",
      "85     \t [ 0.08244109 -0.69889734]. \t  1.0299957078376298 \t 1.031480196732831\n",
      "86     \t [-0.11350993  0.72469891]. \t  1.0285325699981096 \t 1.031480196732831\n",
      "87     \t [ 0.06024246 -0.69101875]. \t  1.025115940849461 \t 1.031480196732831\n",
      "88     \t [-0.08793525  0.71108758]. \t  \u001b[92m1.0315971542742073\u001b[0m \t 1.0315971542742073\n",
      "89     \t [-0.03447328  0.70049598]. \t  1.0190513688507534 \t 1.0315971542742073\n",
      "90     \t [ 0.09744647 -0.67011525]. \t  1.0171243841040765 \t 1.0315971542742073\n",
      "91     \t [0.00266012 0.6213696 ]. \t  0.9464261036672927 \t 1.0315971542742073\n",
      "92     \t [-0.21154989  0.80069978]. \t  0.9148910833012933 \t 1.0315971542742073\n",
      "93     \t [ 0.04513847 -0.80233351]. \t  0.9454312224892666 \t 1.0315971542742073\n",
      "94     \t [ 0.00372845 -0.74159598]. \t  0.992723552577655 \t 1.0315971542742073\n",
      "95     \t [ 0.1825347  -0.63760031]. \t  0.9504840389097406 \t 1.0315971542742073\n",
      "96     \t [ 0.06493015 -0.66232892]. \t  1.0111379561208362 \t 1.0315971542742073\n",
      "97     \t [-0.01412365  0.76291224]. \t  0.9830582533201645 \t 1.0315971542742073\n",
      "98     \t [ 0.20155291 -0.72713301]. \t  0.9842047954753973 \t 1.0315971542742073\n",
      "99     \t [-0.11432024  0.77551336]. \t  0.9955934914761545 \t 1.0315971542742073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [-0.03516904  0.7076907 ]. \t  1.0199418399922435 \t 1.0315971542742073\n"
     ]
    }
   ],
   "source": [
    "### 6(p). Bayesian optimization runs (x20): STP DF1 run number = 16\n",
    "\n",
    "np.random.seed(run_num_16)\n",
    "surrogate_stp_df1_16 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_16 = GPGO(surrogate_stp_df1_16, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_16.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.6204727816026345, -12.769692411220804)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(p). Training Regret Minimisation: run number = 16\n",
    "\n",
    "gp_output_16 = np.append(np.max(gpgo_gp_16.GP.y[0:n_init]),gpgo_gp_16.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_16 = np.append(np.max(gpgo_stp_df1_16.GP.y[0:n_init]),gpgo_stp_df1_16.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_16 = np.log(y_global_orig - gp_output_16)\n",
    "regret_stp_df1_16 = np.log(y_global_orig - stp_df1_output_16)\n",
    "\n",
    "train_regret_gp_16 = min_max_array(regret_gp_16)\n",
    "train_regret_stp_df1_16 = min_max_array(regret_stp_df1_16)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 16\n",
    "min_train_regret_gp_16 = min(train_regret_gp_16)\n",
    "min_train_regret_stp_df1_16 = min(train_regret_stp_df1_16)\n",
    "\n",
    "min_train_regret_gp_16, min_train_regret_stp_df1_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.81627749 -1.68284875]. \t  -91.42701077910272 \t -1.8602616420471212\n",
      "init   \t [0.8246462  0.20732642]. \t  -1.8602616420471212 \t -1.8602616420471212\n",
      "init   \t [ 1.44512157 -0.11221246]. \t  -2.018872186435816 \t -1.8602616420471212\n",
      "init   \t [1.33931249 0.04194237]. \t  -2.391135348947162 \t -1.8602616420471212\n",
      "init   \t [-2.04856542 -0.7823346 ]. \t  -5.091387292793844 \t -1.8602616420471212\n",
      "1      \t [-1.50922678 -0.15334798]. \t  -2.294575055940585 \t -1.8602616420471212\n",
      "2      \t [-1.7084126  -0.53513916]. \t  -2.170025620178202 \t -1.8602616420471212\n",
      "3      \t [-2.52597553  0.14067666]. \t  -26.182405564278792 \t -1.8602616420471212\n",
      "4      \t [-0.71948017  0.86857727]. \t  \u001b[92m-0.1881283333551349\u001b[0m \t -0.1881283333551349\n",
      "5      \t [-0.86414671  0.47306149]. \t  -0.8511490159908626 \t -0.1881283333551349\n",
      "6      \t [ 1.70695074 -1.41977957]. \t  -7.83875358024784 \t -0.1881283333551349\n",
      "7      \t [0.29731438 2.        ]. \t  -48.93203333934366 \t -0.1881283333551349\n",
      "8      \t [-1.21544469  0.98173087]. \t  -1.068007317524679 \t -0.1881283333551349\n",
      "9      \t [ 3.        -0.2106397]. \t  -108.09847901856003 \t -0.1881283333551349\n",
      "10     \t [ 1.02823965 -0.66881108]. \t  -0.5990163111840638 \t -0.1881283333551349\n",
      "11     \t [ 1.20429535 -0.36745823]. \t  -1.491259500394256 \t -0.1881283333551349\n",
      "12     \t [ 0.56915282 -1.76292119]. \t  -26.287722287078548 \t -0.1881283333551349\n",
      "13     \t [0.08020107 0.49000994]. \t  \u001b[92m0.6648868277040642\u001b[0m \t 0.6648868277040642\n",
      "14     \t [ 0.23582384 -0.059421  ]. \t  -0.1879275669291816 \t 0.6648868277040642\n",
      "15     \t [0.1415197  0.42169394]. \t  0.44586545545982975 \t 0.6648868277040642\n",
      "16     \t [ 0.24977122 -0.69034249]. \t  \u001b[92m0.928781898690354\u001b[0m \t 0.928781898690354\n",
      "17     \t [ 0.37413003 -0.56522496]. \t  0.5614537155423159 \t 0.928781898690354\n",
      "18     \t [-0.04730463 -0.44142086]. \t  0.5977180576930378 \t 0.928781898690354\n",
      "19     \t [-2.90380288  1.97104413]. \t  -123.36802636964904 \t 0.928781898690354\n",
      "20     \t [ 1.48685487 -0.84828356]. \t  -0.1126460634819425 \t 0.928781898690354\n",
      "21     \t [-1.02922206  0.58634484]. \t  -0.7710877701649841 \t 0.928781898690354\n",
      "22     \t [0.71359743 0.75889799]. \t  -1.1009634472158947 \t 0.928781898690354\n",
      "23     \t [-2.13046963 -0.47643423]. \t  -6.374938356688409 \t 0.928781898690354\n",
      "24     \t [-1.05609674 -1.5429716 ]. \t  -17.0900638613129 \t 0.928781898690354\n",
      "25     \t [2.18218375 1.85162213]. \t  -44.767080628945756 \t 0.928781898690354\n",
      "26     \t [-0.08831797  1.02655999]. \t  -0.16729934667342153 \t 0.928781898690354\n",
      "27     \t [-0.78907037  1.42119998]. \t  -8.874733910114555 \t 0.928781898690354\n",
      "28     \t [0.36712676 0.70215394]. \t  0.24023024850540808 \t 0.928781898690354\n",
      "29     \t [ 2.22566484 -1.84111501]. \t  -37.10541614231513 \t 0.928781898690354\n",
      "30     \t [ 1.09519758 -0.99334791]. \t  -1.211534181163474 \t 0.928781898690354\n",
      "31     \t [-0.12156913  0.75289579]. \t  \u001b[92m1.014993479071173\u001b[0m \t 1.014993479071173\n",
      "32     \t [-0.53465526  0.0392535 ]. \t  -0.9524712222154181 \t 1.014993479071173\n",
      "33     \t [-0.20583195  0.77243482]. \t  0.9558994555648946 \t 1.014993479071173\n",
      "34     \t [ 0.11854131 -0.65232824]. \t  0.9993515617156451 \t 1.014993479071173\n",
      "35     \t [-2.67825374  1.88597883]. \t  -74.99341814173948 \t 1.014993479071173\n",
      "36     \t [-1.87433516  1.41588232]. \t  -7.9901880239840475 \t 1.014993479071173\n",
      "37     \t [-1.87346058  1.92564314]. \t  -39.14212202836949 \t 1.014993479071173\n",
      "38     \t [ 0.06960259 -0.61220428]. \t  0.9605760849096864 \t 1.014993479071173\n",
      "39     \t [-2.91559791 -0.16549645]. \t  -87.38814024201119 \t 1.014993479071173\n",
      "40     \t [-2.00255067  0.76917168]. \t  -1.259476467002728 \t 1.014993479071173\n",
      "41     \t [-1.85199302  0.07104263]. \t  -2.313089978410856 \t 1.014993479071173\n",
      "42     \t [1.78218903 0.65357241]. \t  -2.386257616463545 \t 1.014993479071173\n",
      "43     \t [ 0.12249084 -1.20571889]. \t  -2.5504725578613288 \t 1.014993479071173\n",
      "44     \t [-0.04737473  0.73865369]. \t  \u001b[92m1.01770580698341\u001b[0m \t 1.01770580698341\n",
      "45     \t [ 0.12643113 -0.27176639]. \t  0.24456409853874808 \t 1.01770580698341\n",
      "46     \t [-2.75219845 -1.59691432]. \t  -74.88207647067388 \t 1.01770580698341\n",
      "47     \t [-0.13880583 -0.86495042]. \t  0.5573564656712662 \t 1.01770580698341\n",
      "48     \t [ 0.97228797 -1.86317463]. \t  -34.692066298377895 \t 1.01770580698341\n",
      "49     \t [-0.17633251  0.15868311]. \t  0.003813719153165626 \t 1.01770580698341\n",
      "50     \t [-0.81059052 -0.06891334]. \t  -1.8531180592216847 \t 1.01770580698341\n",
      "51     \t [-2.7670851   0.14786914]. \t  -56.64611589492763 \t 1.01770580698341\n",
      "52     \t [-2.00546832 -1.02775229]. \t  -6.103229718601228 \t 1.01770580698341\n",
      "53     \t [-0.6173888   1.99445338]. \t  -47.38827766416238 \t 1.01770580698341\n",
      "54     \t [0.02534492 0.44313556]. \t  0.6174333400001536 \t 1.01770580698341\n",
      "55     \t [-0.48154655  1.69025516]. \t  -21.225936542169904 \t 1.01770580698341\n",
      "56     \t [ 0.08202219 -0.70807066]. \t  \u001b[92m1.0312544516646462\u001b[0m \t 1.0312544516646462\n",
      "57     \t [-0.7060402   1.38872963]. \t  -7.696172446231672 \t 1.0312544516646462\n",
      "58     \t [1.7965926  0.06308306]. \t  -2.3391965285836775 \t 1.0312544516646462\n",
      "59     \t [-0.19147362 -1.32637105]. \t  -5.740752008874017 \t 1.0312544516646462\n",
      "60     \t [ 2.10636872 -1.48079516]. \t  -12.863895417707287 \t 1.0312544516646462\n",
      "61     \t [1.638933  0.5595671]. \t  -2.1096064299118367 \t 1.0312544516646462\n",
      "62     \t [2.34153019 0.07509353]. \t  -13.895560946931889 \t 1.0312544516646462\n",
      "63     \t [ 0.01707737 -0.63904931]. \t  0.976172963457112 \t 1.0312544516646462\n",
      "64     \t [1.17729822 1.99871365]. \t  -52.60657445760119 \t 1.0312544516646462\n",
      "65     \t [-0.22844099 -1.45190488]. \t  -9.877757394052534 \t 1.0312544516646462\n",
      "66     \t [-2.89652444  0.96049158]. \t  -79.52619227249951 \t 1.0312544516646462\n",
      "67     \t [-2.65655127 -1.48268988]. \t  -55.27758419919831 \t 1.0312544516646462\n",
      "68     \t [ 2.94125182 -1.68056899]. \t  -108.91858415969003 \t 1.0312544516646462\n",
      "69     \t [-1.5930583  -1.75588045]. \t  -30.561641702294867 \t 1.0312544516646462\n",
      "70     \t [-0.98869446 -1.1507665 ]. \t  -5.070184894384823 \t 1.0312544516646462\n",
      "71     \t [ 0.20779912 -0.76031744]. \t  0.9647725450281777 \t 1.0312544516646462\n",
      "72     \t [-0.03949173  0.71730935]. \t  1.0212497099667548 \t 1.0312544516646462\n",
      "73     \t [-0.12661532  0.77359172]. \t  0.9955961458868068 \t 1.0312544516646462\n",
      "74     \t [ 2.00633811 -1.47375309]. \t  -11.040616087014905 \t 1.0312544516646462\n",
      "75     \t [ 0.14464644 -0.72481059]. \t  1.0194965655581432 \t 1.0312544516646462\n",
      "76     \t [-0.7561373  -1.88775112]. \t  -39.63288676086699 \t 1.0312544516646462\n",
      "77     \t [1.41142003 0.37479136]. \t  -2.3158571214459385 \t 1.0312544516646462\n",
      "78     \t [1.49414533 1.24494591]. \t  -7.441671007513262 \t 1.0312544516646462\n",
      "79     \t [-2.17240135  0.6161567 ]. \t  -4.861768474364632 \t 1.0312544516646462\n",
      "80     \t [ 1.92828999 -0.68655044]. \t  -0.6546358286480891 \t 1.0312544516646462\n",
      "81     \t [-0.26362348 -0.26699422]. \t  -0.07352753136952062 \t 1.0312544516646462\n",
      "82     \t [-1.2188124  -0.75401931]. \t  -2.3383995325711604 \t 1.0312544516646462\n",
      "83     \t [-2.59804821  0.68098372]. \t  -31.067319292619572 \t 1.0312544516646462\n",
      "84     \t [-2.02298132 -0.78635623]. \t  -4.692504807217393 \t 1.0312544516646462\n",
      "85     \t [0.32716651 1.97457828]. \t  -46.26221640039076 \t 1.0312544516646462\n",
      "86     \t [-1.08233385  1.6412835 ]. \t  -18.814656218596838 \t 1.0312544516646462\n",
      "87     \t [0.74438135 1.07958155]. \t  -3.2035205073148294 \t 1.0312544516646462\n",
      "88     \t [ 0.01896114 -0.72544986]. \t  1.0095554975837087 \t 1.0312544516646462\n",
      "89     \t [-0.94275922 -1.81834205]. \t  -34.34736718552752 \t 1.0312544516646462\n",
      "90     \t [0.31928793 1.22905331]. \t  -3.8637527977868467 \t 1.0312544516646462\n",
      "91     \t [-0.11907598  0.65031406]. \t  0.997369203451561 \t 1.0312544516646462\n",
      "92     \t [-0.03521943  0.76881216]. \t  0.9889421930733614 \t 1.0312544516646462\n",
      "93     \t [-0.08055267  0.70231077]. \t  1.0305236363500214 \t 1.0312544516646462\n",
      "94     \t [-0.89726605  0.0656788 ]. \t  -1.957031879627239 \t 1.0312544516646462\n",
      "95     \t [0.79883352 1.69650554]. \t  -24.761260261897913 \t 1.0312544516646462\n",
      "96     \t [ 0.13111817 -0.73194171]. \t  1.0227129409296694 \t 1.0312544516646462\n",
      "97     \t [-0.92177738 -0.09692874]. \t  -2.1392010255946423 \t 1.0312544516646462\n",
      "98     \t [-2.30582255  0.45199007]. \t  -10.31044736078543 \t 1.0312544516646462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [0.29151042 1.19388704]. \t  -3.098194452525717 \t 1.0312544516646462\n",
      "100    \t [1.71762173 1.11223723]. \t  -5.165779886969516 \t 1.0312544516646462\n"
     ]
    }
   ],
   "source": [
    "### 6(q). Bayesian optimization runs (x20): GP run number = 17\n",
    "\n",
    "np.random.seed(run_num_17)\n",
    "surrogate_gp_17 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_17 = GPGO(surrogate_gp_17, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_17.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [-2.81627749 -1.68284875]. \t  -91.42701077910272 \t -1.8602616420471212\n",
      "init   \t [0.8246462  0.20732642]. \t  -1.8602616420471212 \t -1.8602616420471212\n",
      "init   \t [ 1.44512157 -0.11221246]. \t  -2.018872186435816 \t -1.8602616420471212\n",
      "init   \t [1.33931249 0.04194237]. \t  -2.391135348947162 \t -1.8602616420471212\n",
      "init   \t [-2.04856542 -0.7823346 ]. \t  -5.091387292793844 \t -1.8602616420471212\n",
      "1      \t [-1.42673523  0.06682422]. \t  -2.1392031544630408 \t -1.8602616420471212\n",
      "2      \t [-0.51055204 -1.42031385]. \t  -9.839709284838728 \t -1.8602616420471212\n",
      "3      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.8602616420471212\n",
      "4      \t [-3.          0.79295521]. \t  -105.58746942433355 \t -1.8602616420471212\n",
      "5      \t [3. 2.]. \t  -162.89999999999998 \t -1.8602616420471212\n",
      "6      \t [-0.25803523  2.        ]. \t  -47.741046958383684 \t -1.8602616420471212\n",
      "7      \t [ 0.75661235 -2.        ]. \t  -48.15096138291321 \t -1.8602616420471212\n",
      "8      \t [-1.15973084 -0.68735139]. \t  -2.192268003502912 \t -1.8602616420471212\n",
      "9      \t [ 3.         -0.03017968]. \t  -108.80582104011408 \t -1.8602616420471212\n",
      "10     \t [-1.22042593 -2.        ]. \t  -52.84131258362106 \t -1.8602616420471212\n",
      "11     \t [ 0.50609953 -0.69301872]. \t  \u001b[92m0.45680447855648576\u001b[0m \t 0.45680447855648576\n",
      "12     \t [-1.7825416  2.       ]. \t  -46.63610241884933 \t 0.45680447855648576\n",
      "13     \t [1.07248333 2.        ]. \t  -52.474783548484766 \t 0.45680447855648576\n",
      "14     \t [-0.46496589  0.4759865 ]. \t  0.1522582823088119 \t 0.45680447855648576\n",
      "15     \t [-0.20607005 -0.2686951 ]. \t  0.04647042070608848 \t 0.45680447855648576\n",
      "16     \t [-3.  2.]. \t  -150.89999999999998 \t 0.45680447855648576\n",
      "17     \t [-3.         -0.44241197]. \t  -109.59756085598266 \t 0.45680447855648576\n",
      "18     \t [-1.22785244  1.09006888]. \t  -1.9558936075948654 \t 0.45680447855648576\n",
      "19     \t [ 0.9094837 -0.2751684]. \t  -1.5302807781058898 \t 0.45680447855648576\n",
      "20     \t [-1.6867396  -0.56005727]. \t  -2.1419493130157967 \t 0.45680447855648576\n",
      "21     \t [ 1.45503433 -1.09124205]. \t  -1.5400553195712177 \t 0.45680447855648576\n",
      "22     \t [0.72958565 1.03422651]. \t  -2.6368888457149713 \t 0.45680447855648576\n",
      "23     \t [-0.2161933  -0.87981459]. \t  0.32691979806956334 \t 0.45680447855648576\n",
      "24     \t [ 1.20282457 -0.8031093 ]. \t  -0.5189939302632249 \t 0.45680447855648576\n",
      "25     \t [-1.67199126 -1.10429217]. \t  -4.969856046197314 \t 0.45680447855648576\n",
      "26     \t [-1.03866322  0.51112678]. \t  -0.986836067893022 \t 0.45680447855648576\n",
      "27     \t [-1.76149504  0.80446564]. \t  0.1794003612189211 \t 0.45680447855648576\n",
      "28     \t [0.1429795  0.82827182]. \t  \u001b[92m0.6622414316552603\u001b[0m \t 0.6622414316552603\n",
      "29     \t [1.72167376 1.04260921]. \t  -4.260273292305569 \t 0.6622414316552603\n",
      "30     \t [1.35806278 0.85600011]. \t  -2.7044187434488953 \t 0.6622414316552603\n",
      "31     \t [2.00350396 0.55678024]. \t  -4.0385030505863995 \t 0.6622414316552603\n",
      "32     \t [ 1.727797 -2.      ]. \t  -46.63871287373226 \t 0.6622414316552603\n",
      "33     \t [0.11678644 0.3967832 ]. \t  0.43009673092612166 \t 0.6622414316552603\n",
      "34     \t [-1.97320173  0.27635248]. \t  -2.58629931408814 \t 0.6622414316552603\n",
      "35     \t [ 2.02746823 -0.94032398]. \t  -1.7950351311157293 \t 0.6622414316552603\n",
      "36     \t [ 1.720664   -0.83857776]. \t  0.19208430308256508 \t 0.6622414316552603\n",
      "37     \t [-1.63500283  0.58740057]. \t  -0.18941126694030008 \t 0.6622414316552603\n",
      "38     \t [-0.69377505 -0.1110058 ]. \t  -1.5042838895679178 \t 0.6622414316552603\n",
      "39     \t [-0.75429836 -1.00944939]. \t  -2.4962633107981573 \t 0.6622414316552603\n",
      "40     \t [1.9615297 2.       ]. \t  -55.21165850701802 \t 0.6622414316552603\n",
      "41     \t [ 3.         -1.00618949]. \t  -105.93171745826521 \t 0.6622414316552603\n",
      "42     \t [-0.59775241  1.01445216]. \t  -0.6897845230436142 \t 0.6622414316552603\n",
      "43     \t [-2.17324335 -2.        ]. \t  -59.51249647984693 \t 0.6622414316552603\n",
      "44     \t [3.         0.99732543]. \t  -111.8707225255609 \t 0.6622414316552603\n",
      "45     \t [-1.04303478  2.        ]. \t  -48.20932434944667 \t 0.6622414316552603\n",
      "46     \t [-0.17705276 -2.        ]. \t  -48.47744288726462 \t 0.6622414316552603\n",
      "47     \t [ 0.49530962 -1.20150421]. \t  -2.826355022888171 \t 0.6622414316552603\n",
      "48     \t [ 2.03792205 -0.4802519 ]. \t  -2.5805840495188686 \t 0.6622414316552603\n",
      "49     \t [0.15357834 1.3229935 ]. \t  -5.549482874841747 \t 0.6622414316552603\n",
      "50     \t [1.39695263 1.44460079]. \t  -13.376485181614951 \t 0.6622414316552603\n",
      "51     \t [-0.2524776   0.76064352]. \t  \u001b[92m0.9208141629778431\u001b[0m \t 0.9208141629778431\n",
      "52     \t [ 0.27148496 -0.15628173]. \t  -0.14580404699365235 \t 0.9208141629778431\n",
      "53     \t [-2.17755028  1.42625   ]. \t  -12.597385844994186 \t 0.9208141629778431\n",
      "54     \t [-1.75505459  1.22808686]. \t  -3.0485379460548883 \t 0.9208141629778431\n",
      "55     \t [-3. -2.]. \t  -162.89999999999998 \t 0.9208141629778431\n",
      "56     \t [-0.48568208 -0.62823934]. \t  -0.18056364066514674 \t 0.9208141629778431\n",
      "57     \t [ 2.16448635 -1.60158326]. \t  -19.51544158633093 \t 0.9208141629778431\n",
      "58     \t [ 1.88657865 -0.00777762]. \t  -2.6484511589626543 \t 0.9208141629778431\n",
      "59     \t [-3.         -1.12092372]. \t  -113.55175849441798 \t 0.9208141629778431\n",
      "60     \t [2.38756057 1.38999027]. \t  -26.829609451973365 \t 0.9208141629778431\n",
      "61     \t [-2.10929512 -1.29156113]. \t  -12.766387036371952 \t 0.9208141629778431\n",
      "62     \t [ 0.08311758 -0.70044417]. \t  \u001b[92m1.0303334289991275\u001b[0m \t 1.0303334289991275\n",
      "63     \t [-2.05173318 -0.24563231]. \t  -4.767822820287535 \t 1.0303334289991275\n",
      "64     \t [-0.12904662  0.7439692 ]. \t  1.0185306360237887 \t 1.0303334289991275\n",
      "65     \t [-0.13462516  0.72385793]. \t  1.0233432713628994 \t 1.0303334289991275\n",
      "66     \t [-2.39104929  2.        ]. \t  -59.73577233770922 \t 1.0303334289991275\n",
      "67     \t [ 0.07208691 -0.65234802]. \t  1.0041298438567836 \t 1.0303334289991275\n",
      "68     \t [ 2.36189151 -2.        ]. \t  -58.10630629456454 \t 1.0303334289991275\n",
      "69     \t [-0.02266029  0.71418527]. \t  1.0137253805524238 \t 1.0303334289991275\n",
      "70     \t [-0.05963192  0.67649   ]. \t  1.01896516063489 \t 1.0303334289991275\n",
      "71     \t [ 0.1997602  -0.76342473]. \t  0.9687732285415058 \t 1.0303334289991275\n",
      "72     \t [ 0.05470764 -0.6814929 ]. \t  1.0202698019338305 \t 1.0303334289991275\n",
      "73     \t [-0.14204862  0.67178765]. \t  1.006080246245033 \t 1.0303334289991275\n",
      "74     \t [-0.11153381  0.81297571]. \t  0.9376462289067803 \t 1.0303334289991275\n",
      "75     \t [-0.10237697  0.67231351]. \t  1.0179216425040947 \t 1.0303334289991275\n",
      "76     \t [-0.10926847  0.78785871]. \t  0.9803339366588937 \t 1.0303334289991275\n",
      "77     \t [ 0.05646196 -0.63614701]. \t  0.9868463166619169 \t 1.0303334289991275\n",
      "78     \t [2.47781514 0.45985118]. \t  -23.014919810754378 \t 1.0303334289991275\n",
      "79     \t [ 0.0220533  -0.78308594]. \t  0.9640464060311124 \t 1.0303334289991275\n",
      "80     \t [ 0.14867775 -0.76276392]. \t  0.9992375435134959 \t 1.0303334289991275\n",
      "81     \t [ 0.07418627 -0.69485213]. \t  1.0284169485335006 \t 1.0303334289991275\n",
      "82     \t [-0.12058964  0.79456871]. \t  0.9690921801898276 \t 1.0303334289991275\n",
      "83     \t [ 0.0273785 -0.795454 ]. \t  0.9482940487059647 \t 1.0303334289991275\n",
      "84     \t [ 0.1198979  -0.75040364]. \t  1.0169735055505946 \t 1.0303334289991275\n",
      "85     \t [-0.09760053  0.68837278]. \t  1.026538556600146 \t 1.0303334289991275\n",
      "86     \t [-0.05570018  0.68683263]. \t  1.0226721446674139 \t 1.0303334289991275\n",
      "87     \t [-0.06087813  0.65775415]. \t  1.0070978899770353 \t 1.0303334289991275\n",
      "88     \t [-0.14332896  0.74294459]. \t  1.0143939330781901 \t 1.0303334289991275\n",
      "89     \t [-0.06920317  0.69160287]. \t  1.0268718846082938 \t 1.0303334289991275\n",
      "90     \t [ 0.06069946 -0.58891777]. \t  0.9271863992776423 \t 1.0303334289991275\n",
      "91     \t [-0.09904205  0.74467627]. \t  1.0228190605150382 \t 1.0303334289991275\n",
      "92     \t [-0.03521943  0.76881216]. \t  0.9889421924704852 \t 1.0303334289991275\n",
      "93     \t [-0.08751526  0.72826359]. \t  1.0295327030651966 \t 1.0303334289991275\n",
      "94     \t [0.03021045 0.6451237 ]. \t  0.9487614908552567 \t 1.0303334289991275\n",
      "95     \t [-0.10455366  0.73620185]. \t  1.0264435309299276 \t 1.0303334289991275\n",
      "96     \t [ 0.13112101 -0.73193963]. \t  1.022712693746993 \t 1.0303334289991275\n",
      "97     \t [-0.06589447  0.66634213]. \t  1.0140408051467753 \t 1.0303334289991275\n",
      "98     \t [0.37671259 2.        ]. \t  -49.27973518532436 \t 1.0303334289991275\n",
      "99     \t [-0.08892906  0.68033924]. \t  1.0234825136012162 \t 1.0303334289991275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [ 0.0286162 -0.7905834]. \t  0.9568272402716597 \t 1.0303334289991275\n"
     ]
    }
   ],
   "source": [
    "### 6(q). Bayesian optimization runs (x20): STP DF1 run number = 17\n",
    "\n",
    "np.random.seed(run_num_17)\n",
    "surrogate_stp_df1_17 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_17 = GPGO(surrogate_stp_df1_17, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_17.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.970378024819956, -6.671442029397026)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(q). Training Regret Minimisation: run number = 17\n",
    "\n",
    "gp_output_17 = np.append(np.max(gpgo_gp_17.GP.y[0:n_init]),gpgo_gp_17.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_17 = np.append(np.max(gpgo_stp_df1_17.GP.y[0:n_init]),gpgo_stp_df1_17.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_17 = np.log(y_global_orig - gp_output_17)\n",
    "regret_stp_df1_17 = np.log(y_global_orig - stp_df1_output_17)\n",
    "\n",
    "train_regret_gp_17 = min_max_array(regret_gp_17)\n",
    "train_regret_stp_df1_17 = min_max_array(regret_stp_df1_17)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 17\n",
    "min_train_regret_gp_17 = min(train_regret_gp_17)\n",
    "min_train_regret_stp_df1_17 = min(train_regret_stp_df1_17)\n",
    "\n",
    "min_train_regret_gp_17, min_train_regret_stp_df1_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.41748681 1.99163084]. \t  -48.53570877355798 \t -2.250840972663185\n",
      "init   \t [-2.53540889  0.66515467]. \t  -24.807234377714284 \t -2.250840972663185\n",
      "init   \t [0.57376458 1.0587427 ]. \t  -2.250840972663185 \t -2.250840972663185\n",
      "init   \t [-2.67325396  0.75525252]. \t  -39.99244968284648 \t -2.250840972663185\n",
      "init   \t [-0.70590144 -1.06542003]. \t  -2.878590587551586 \t -2.250840972663185\n",
      "1      \t [-1.59480144  0.13833323]. \t  \u001b[92m-1.777572176687142\u001b[0m \t -1.777572176687142\n",
      "2      \t [0.95641149 0.26027269]. \t  -2.153221712662773 \t -1.777572176687142\n",
      "3      \t [-2.34765762 -0.33038621]. \t  -14.448639643937959 \t -1.777572176687142\n",
      "4      \t [-1.66599661  0.80716684]. \t  \u001b[92m0.2011153515401961\u001b[0m \t 0.2011153515401961\n",
      "5      \t [-0.2863932  -1.85840387]. \t  -34.742920774261684 \t 0.2011153515401961\n",
      "6      \t [0.42920088 0.51533848]. \t  -0.10868109714515872 \t 0.2011153515401961\n",
      "7      \t [1.18953482 0.85119849]. \t  -2.613910964359864 \t 0.2011153515401961\n",
      "8      \t [-1.90669978  0.44350164]. \t  -1.3255875382037328 \t 0.2011153515401961\n",
      "9      \t [-0.82073058 -0.37150954]. \t  -1.6724585641380032 \t 0.2011153515401961\n",
      "10     \t [-1.17386444 -0.95987409]. \t  -3.233492852073806 \t 0.2011153515401961\n",
      "11     \t [-0.83269408  1.05056835]. \t  -1.4579930794028637 \t 0.2011153515401961\n",
      "12     \t [0.68485003 0.71128674]. \t  -0.9357785142049436 \t 0.2011153515401961\n",
      "13     \t [ 1.8204536  -0.62137531]. \t  -0.24541198039372392 \t 0.2011153515401961\n",
      "14     \t [2.51315309 1.20227829]. \t  -31.072874416566737 \t 0.2011153515401961\n",
      "15     \t [ 1.10442901 -0.5652349 ]. \t  -0.8656293195838173 \t 0.2011153515401961\n",
      "16     \t [-0.33825369  0.6440744 ]. \t  \u001b[92m0.7581755091725241\u001b[0m \t 0.7581755091725241\n",
      "17     \t [-1.47863785  1.28987906]. \t  -4.701149117079831 \t 0.7581755091725241\n",
      "18     \t [-1.19864687  0.69646861]. \t  -0.5667498180767336 \t 0.7581755091725241\n",
      "19     \t [-0.03922094  0.82896776]. \t  \u001b[92m0.8862080146432372\u001b[0m \t 0.8862080146432372\n",
      "20     \t [ 2.80272389 -1.05827801]. \t  -60.981545211493085 \t 0.8862080146432372\n",
      "21     \t [ 1.61172438 -0.30833481]. \t  -1.221965869951402 \t 0.8862080146432372\n",
      "22     \t [ 1.613979   -0.83887456]. \t  0.12604366492488128 \t 0.8862080146432372\n",
      "23     \t [ 1.6932359 -0.7160595]. \t  0.14986387990148453 \t 0.8862080146432372\n",
      "24     \t [ 0.38244298 -0.45691338]. \t  0.2943145542559339 \t 0.8862080146432372\n",
      "25     \t [ 1.36003691 -1.66259427]. \t  -19.568969468714144 \t 0.8862080146432372\n",
      "26     \t [-0.46793567  0.86992707]. \t  0.36467040403477025 \t 0.8862080146432372\n",
      "27     \t [-2.86923797 -1.93035846]. \t  -122.76306016986564 \t 0.8862080146432372\n",
      "28     \t [-0.10630269  0.71573205]. \t  \u001b[92m1.0305484311151407\u001b[0m \t 1.0305484311151407\n",
      "29     \t [ 0.41350464 -0.09440942]. \t  -0.5498410556636537 \t 1.0305484311151407\n",
      "30     \t [ 0.58205501 -0.84049044]. \t  0.19168642752637732 \t 1.0305484311151407\n",
      "31     \t [-0.02280665  0.77739013]. \t  0.9721061376970044 \t 1.0305484311151407\n",
      "32     \t [-1.3883403  -0.47202448]. \t  -2.257692479827101 \t 1.0305484311151407\n",
      "33     \t [1.96644332 1.88928492]. \t  -43.74026159345603 \t 1.0305484311151407\n",
      "34     \t [-2.38303231  1.25717914]. \t  -16.71210508030411 \t 1.0305484311151407\n",
      "35     \t [-2.23311248 -1.46856574]. \t  -22.319400034473727 \t 1.0305484311151407\n",
      "36     \t [ 0.07563168 -0.81308897]. \t  0.9348528676351539 \t 1.0305484311151407\n",
      "37     \t [ 0.10365627 -0.72336028]. \t  1.0300820970063969 \t 1.0305484311151407\n",
      "38     \t [-1.70006403 -1.62270628]. \t  -22.026951134280168 \t 1.0305484311151407\n",
      "39     \t [-2.49086932  1.73666867]. \t  -43.58697151139244 \t 1.0305484311151407\n",
      "40     \t [-1.73316328 -0.87292628]. \t  -2.8890557840917124 \t 1.0305484311151407\n",
      "41     \t [-0.00691346  0.71559819]. \t  1.0041723026254463 \t 1.0305484311151407\n",
      "42     \t [-1.62832867  0.05802629]. \t  -1.9478944320664031 \t 1.0305484311151407\n",
      "43     \t [-0.05963826 -0.7320307 ]. \t  0.9369962930406349 \t 1.0305484311151407\n",
      "44     \t [2.45500833 1.99329112]. \t  -72.94972206257279 \t 1.0305484311151407\n",
      "45     \t [2.44264335 0.06121681]. \t  -20.04325651219188 \t 1.0305484311151407\n",
      "46     \t [-0.3501585  -1.23738827]. \t  -4.145684098112504 \t 1.0305484311151407\n",
      "47     \t [2.17680559 1.27880237]. \t  -14.206551298149947 \t 1.0305484311151407\n",
      "48     \t [0.48717986 1.59848466]. \t  -17.508904204964107 \t 1.0305484311151407\n",
      "49     \t [-1.31619409 -1.65210901]. \t  -23.416705355189237 \t 1.0305484311151407\n",
      "50     \t [ 0.27646345 -1.31027496]. \t  -4.853974277726476 \t 1.0305484311151407\n",
      "51     \t [1.03639215 1.29324956]. \t  -8.126001172306742 \t 1.0305484311151407\n",
      "52     \t [2.6974441  1.95069712]. \t  -94.29239807533023 \t 1.0305484311151407\n",
      "53     \t [-1.77173779  1.30968889]. \t  -4.7611659041048 \t 1.0305484311151407\n",
      "54     \t [0.64965594 0.12715795]. \t  -1.3581792950734097 \t 1.0305484311151407\n",
      "55     \t [1.82207618 1.85936072]. \t  -39.69959238957311 \t 1.0305484311151407\n",
      "56     \t [ 2.4393776  -0.37800897]. \t  -18.265826007372905 \t 1.0305484311151407\n",
      "57     \t [-0.18868395  0.69220273]. \t  0.9891078878730054 \t 1.0305484311151407\n",
      "58     \t [2.07909872 1.39915675]. \t  -15.382649939103683 \t 1.0305484311151407\n",
      "59     \t [ 0.15696565 -0.70717613]. \t  1.0137192613385395 \t 1.0305484311151407\n",
      "60     \t [2.5181417  0.62870348]. \t  -26.54121381565201 \t 1.0305484311151407\n",
      "61     \t [-0.12508102  0.66427142]. \t  1.0072162613043267 \t 1.0305484311151407\n",
      "62     \t [2.42851257 0.77012261]. \t  -19.83095796588569 \t 1.0305484311151407\n",
      "63     \t [-0.10525393  0.75476345]. \t  1.015971092468059 \t 1.0305484311151407\n",
      "64     \t [-1.10736493  0.63782661]. \t  -0.6903095378212118 \t 1.0305484311151407\n",
      "65     \t [ 0.0806283  -0.71211513]. \t  \u001b[92m1.0312995072969773\u001b[0m \t 1.0312995072969773\n",
      "66     \t [-0.06013981  0.67693465]. \t  1.0192955732184363 \t 1.0312995072969773\n",
      "67     \t [ 1.84437686 -0.14827571]. \t  -2.068060947684952 \t 1.0312995072969773\n",
      "68     \t [-1.58948075 -0.17710176]. \t  -2.236981823740197 \t 1.0312995072969773\n",
      "69     \t [-1.32156538  0.92607649]. \t  -0.6438912310693801 \t 1.0312995072969773\n",
      "70     \t [-0.3360826   0.69511824]. \t  0.8069922451696392 \t 1.0312995072969773\n",
      "71     \t [ 0.09345351 -0.70484638]. \t  1.0310553447100061 \t 1.0312995072969773\n",
      "72     \t [ 0.07892291 -0.5918042 ]. \t  0.9321514370428671 \t 1.0312995072969773\n",
      "73     \t [ 0.64694806 -0.75737449]. \t  0.13756998679757304 \t 1.0312995072969773\n",
      "74     \t [2.40751604 1.44321706]. \t  -30.038588559487053 \t 1.0312995072969773\n",
      "75     \t [0.2386366  0.08894714]. \t  -0.21087098968745505 \t 1.0312995072969773\n",
      "76     \t [0.44555133 1.61735073]. \t  -18.34136089708233 \t 1.0312995072969773\n",
      "77     \t [ 2.73555167 -1.0270556 ]. \t  -49.44158900208751 \t 1.0312995072969773\n",
      "78     \t [-0.99916214  1.58161826]. \t  -15.675967390672874 \t 1.0312995072969773\n",
      "79     \t [ 2.07872967 -1.11016614]. \t  -3.806173287139805 \t 1.0312995072969773\n",
      "80     \t [ 0.05211602 -0.22876885]. \t  0.19945854097340798 \t 1.0312995072969773\n",
      "81     \t [-0.17588516  0.76350371]. \t  0.9850316811087715 \t 1.0312995072969773\n",
      "82     \t [ 2.68283724 -0.20868114]. \t  -43.56452667273437 \t 1.0312995072969773\n",
      "83     \t [ 0.02251917 -0.71940017]. \t  1.012942252503699 \t 1.0312995072969773\n",
      "84     \t [-0.19929092 -1.21163429]. \t  -3.145585976222548 \t 1.0312995072969773\n",
      "85     \t [-0.07770939  0.78282312]. \t  0.9858479887737732 \t 1.0312995072969773\n",
      "86     \t [-2.43364075  1.00001815]. \t  -16.84425322236066 \t 1.0312995072969773\n",
      "87     \t [ 1.79547898 -0.02482036]. \t  -2.191260033807798 \t 1.0312995072969773\n",
      "88     \t [-0.79140747 -1.84776381]. \t  -36.19671146783655 \t 1.0312995072969773\n",
      "89     \t [2.37032988 1.26824421]. \t  -22.22321668075886 \t 1.0312995072969773\n",
      "90     \t [ 0.19722088 -0.75180323]. \t  0.9788360986385842 \t 1.0312995072969773\n",
      "91     \t [ 0.19997462 -0.74703398]. \t  0.9792816774261291 \t 1.0312995072969773\n",
      "92     \t [ 0.16778157 -0.692445  ]. \t  1.0035493493323082 \t 1.0312995072969773\n",
      "93     \t [ 1.33525018 -0.96861919]. \t  -0.8201938987813475 \t 1.0312995072969773\n",
      "94     \t [-1.55901341 -0.34573467]. \t  -2.220548850729546 \t 1.0312995072969773\n",
      "95     \t [-1.93001849  1.04075791]. \t  -1.341724512595397 \t 1.0312995072969773\n",
      "96     \t [ 2.43436044 -0.22885064]. \t  -18.57197302436539 \t 1.0312995072969773\n",
      "97     \t [ 1.43309588 -1.31204549]. \t  -5.3325278528708075 \t 1.0312995072969773\n",
      "98     \t [0.83626407 0.71861307]. \t  -1.4863327412757341 \t 1.0312995072969773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [ 2.65329142 -1.41392419]. \t  -44.62275290858517 \t 1.0312995072969773\n",
      "100    \t [ 0.11405125 -0.7268677 ]. \t  1.0280121423433426 \t 1.0312995072969773\n"
     ]
    }
   ],
   "source": [
    "### 6(r). Bayesian optimization runs (x20): GP run number = 18\n",
    "\n",
    "np.random.seed(run_num_18)\n",
    "surrogate_gp_18 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_18 = GPGO(surrogate_gp_18, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_18.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.41748681 1.99163084]. \t  -48.53570877355798 \t -2.250840972663185\n",
      "init   \t [-2.53540889  0.66515467]. \t  -24.807234377714284 \t -2.250840972663185\n",
      "init   \t [0.57376458 1.0587427 ]. \t  -2.250840972663185 \t -2.250840972663185\n",
      "init   \t [-2.67325396  0.75525252]. \t  -39.99244968284648 \t -2.250840972663185\n",
      "init   \t [-0.70590144 -1.06542003]. \t  -2.878590587551586 \t -2.250840972663185\n",
      "1      \t [-1.46319295  0.1888815 ]. \t  \u001b[92m-1.7952562981846232\u001b[0m \t -1.7952562981846232\n",
      "2      \t [ 1.24641616 -0.04185717]. \t  -2.3364854928385657 \t -1.7952562981846232\n",
      "3      \t [-2.51207729 -0.79529722]. \t  -26.450008225916495 \t -1.7952562981846232\n",
      "4      \t [ 0.30292274 -2.        ]. \t  -47.74377819279274 \t -1.7952562981846232\n",
      "5      \t [3.         1.37362294]. \t  -119.71416922422875 \t -1.7952562981846232\n",
      "6      \t [ 3. -2.]. \t  -150.89999999999998 \t -1.7952562981846232\n",
      "7      \t [ 0.21014605 -0.01901612]. \t  \u001b[92m-0.16713659841418835\u001b[0m \t -0.16713659841418835\n",
      "8      \t [-1.51781531  2.        ]. \t  -47.10964647414354 \t -0.16713659841418835\n",
      "9      \t [-1.50560596 -2.        ]. \t  -53.17035199015828 \t -0.16713659841418835\n",
      "10     \t [-3. -2.]. \t  -162.89999999999998 \t -0.16713659841418835\n",
      "11     \t [-2.10544468 -0.12576153]. \t  -5.704227203110837 \t -0.16713659841418835\n",
      "12     \t [-0.62392845  0.94404629]. \t  -0.2817745193563262 \t -0.16713659841418835\n",
      "13     \t [-1.5618333  0.8626296]. \t  \u001b[92m0.00898542130910418\u001b[0m \t 0.00898542130910418\n",
      "14     \t [ 3.         -0.24817981]. \t  -107.92426259156285 \t 0.00898542130910418\n",
      "15     \t [-3.         -0.25486644]. \t  -109.42164930676584 \t 0.00898542130910418\n",
      "16     \t [-1.6496524  -0.95852171]. \t  -3.3338894885516703 \t 0.00898542130910418\n",
      "17     \t [ 1.21824154 -1.04788961]. \t  -1.55482246388426 \t 0.00898542130910418\n",
      "18     \t [1.70787904 2.        ]. \t  -53.48852919823197 \t 0.00898542130910418\n",
      "19     \t [ 0.46024172 -0.86884907]. \t  \u001b[92m0.38375371131090313\u001b[0m \t 0.38375371131090313\n",
      "20     \t [-2.77389275  2.        ]. \t  -100.75023843772024 \t 0.38375371131090313\n",
      "21     \t [0.0137308 0.724961 ]. \t  \u001b[92m0.9866766577479589\u001b[0m \t 0.9866766577479589\n",
      "22     \t [-0.40839371 -0.44561343]. \t  -0.15569439764712711 \t 0.9866766577479589\n",
      "23     \t [1.36544781 0.81632168]. \t  -2.5435952134280155 \t 0.9866766577479589\n",
      "24     \t [ 1.46750819 -2.        ]. \t  -47.26906696559847 \t 0.9866766577479589\n",
      "25     \t [0.88675389 0.56403989]. \t  -1.6413838868927666 \t 0.9866766577479589\n",
      "26     \t [-1.89264155  0.55798574]. \t  -0.7898196596089047 \t 0.9866766577479589\n",
      "27     \t [-0.63703445  0.40044812]. \t  -0.5060175407048559 \t 0.9866766577479589\n",
      "28     \t [ 0.90389063 -0.58909184]. \t  -0.6092008588579971 \t 0.9866766577479589\n",
      "29     \t [ 1.79769493 -0.6968383 ]. \t  0.006722541246014124 \t 0.9866766577479589\n",
      "30     \t [1.93610553 0.14436977]. \t  -3.2413028798797385 \t 0.9866766577479589\n",
      "31     \t [ 1.5956948  -0.48053353]. \t  -0.5955086688288981 \t 0.9866766577479589\n",
      "32     \t [-0.62030228 -2.        ]. \t  -50.48778443295576 \t 0.9866766577479589\n",
      "33     \t [-1.20146479 -0.52722369]. \t  -2.2314890816073225 \t 0.9866766577479589\n",
      "34     \t [-0.05090093 -0.77587602]. \t  0.908555044473022 \t 0.9866766577479589\n",
      "35     \t [3. 2.]. \t  -162.89999999999998 \t 0.9866766577479589\n",
      "36     \t [1.96440927 0.82626587]. \t  -4.075378378408265 \t 0.9866766577479589\n",
      "37     \t [-0.59394493  2.        ]. \t  -47.976487348865014 \t 0.9866766577479589\n",
      "38     \t [-1.12068377  0.73083042]. \t  -0.5572406314015176 \t 0.9866766577479589\n",
      "39     \t [1.71685943 0.505825  ]. \t  -2.188315030762603 \t 0.9866766577479589\n",
      "40     \t [-2.04043108  1.10355582]. \t  -3.1176603639638842 \t 0.9866766577479589\n",
      "41     \t [-1.95384304 -0.70953324]. \t  -3.596959595202605 \t 0.9866766577479589\n",
      "42     \t [ 1.71857575 -1.14136693]. \t  -1.6992156240571796 \t 0.9866766577479589\n",
      "43     \t [ 0.34841403 -0.53389214]. \t  0.5459658980902337 \t 0.9866766577479589\n",
      "44     \t [-1.24672411  1.24331502]. \t  -4.220556307711548 \t 0.9866766577479589\n",
      "45     \t [-2.09618519 -1.374989  ]. \t  -14.92667887051134 \t 0.9866766577479589\n",
      "46     \t [0.59810537 0.03783015]. \t  -1.194351308008467 \t 0.9866766577479589\n",
      "47     \t [ 3.         -1.17664547]. \t  -107.49938611421524 \t 0.9866766577479589\n",
      "48     \t [1.15057542 1.5246275 ]. \t  -16.45760295496013 \t 0.9866766577479589\n",
      "49     \t [2.58306558 0.55555124]. \t  -32.794105141054445 \t 0.9866766577479589\n",
      "50     \t [-0.07677497 -1.32522259]. \t  -5.437552370875384 \t 0.9866766577479589\n",
      "51     \t [ 2.21850444 -2.        ]. \t  -52.12134509425074 \t 0.9866766577479589\n",
      "52     \t [-0.0806853   1.21597838]. \t  -2.7584986759483376 \t 0.9866766577479589\n",
      "53     \t [-3.         -1.28378175]. \t  -117.02383898524225 \t 0.9866766577479589\n",
      "54     \t [ 1.56148216 -0.81570554]. \t  0.06408886938679981 \t 0.9866766577479589\n",
      "55     \t [-2.16037836  2.        ]. \t  -50.492629574591604 \t 0.9866766577479589\n",
      "56     \t [-2.22400175 -2.        ]. \t  -61.19248743141933 \t 0.9866766577479589\n",
      "57     \t [2.17599736 1.61322296]. \t  -27.436081248326232 \t 0.9866766577479589\n",
      "58     \t [1.73204627 1.29884088]. \t  -8.985404855971822 \t 0.9866766577479589\n",
      "59     \t [-0.16888674  0.76387466]. \t  \u001b[92m0.9887260887425886\u001b[0m \t 0.9887260887425886\n",
      "60     \t [ 2.29295059 -1.28981376]. \t  -12.884378839310216 \t 0.9887260887425886\n",
      "61     \t [-0.12689157  0.82211765]. \t  0.9167254934050552 \t 0.9887260887425886\n",
      "62     \t [-1.7818472   1.36883667]. \t  -6.308634557923016 \t 0.9887260887425886\n",
      "63     \t [-0.07475822  0.75168957]. \t  \u001b[92m1.0169859867273676\u001b[0m \t 1.0169859867273676\n",
      "64     \t [ 0.71552494 -1.49055398]. \t  -11.33336593334768 \t 1.0169859867273676\n",
      "65     \t [ 0.08829754 -0.70357087]. \t  \u001b[92m1.0309657233197016\u001b[0m \t 1.0309657233197016\n",
      "66     \t [ 0.09570741 -0.72712421]. \t  1.0298305145650213 \t 1.0309657233197016\n",
      "67     \t [ 0.0810887 -0.7225302]. \t  1.0304334353317384 \t 1.0309657233197016\n",
      "68     \t [ 0.06575249 -0.75308289]. \t  1.0142349352773135 \t 1.0309657233197016\n",
      "69     \t [-0.02019882  0.76764809]. \t  0.981987730125536 \t 1.0309657233197016\n",
      "70     \t [-0.08491078  0.70802058]. \t  \u001b[92m1.0313815654804106\u001b[0m \t 1.0313815654804106\n",
      "71     \t [ 0.09323151 -0.72443695]. \t  1.0304684095332926 \t 1.0313815654804106\n",
      "72     \t [-0.12705232  0.75558587]. \t  1.0118626556992196 \t 1.0313815654804106\n",
      "73     \t [-0.17669544  0.62292997]. \t  0.9370820422136654 \t 1.0313815654804106\n",
      "74     \t [-0.15949373  0.75493641]. \t  1.0004478052489532 \t 1.0313815654804106\n",
      "75     \t [-0.09119472  0.68277388]. \t  1.0245693927580921 \t 1.0313815654804106\n",
      "76     \t [-0.09012716  0.7107954 ]. \t  \u001b[92m1.0315993177945955\u001b[0m \t 1.0315993177945955\n",
      "77     \t [-0.02835337  0.72089579]. \t  1.0156746284349811 \t 1.0315993177945955\n",
      "78     \t [-0.08357778  0.75949646]. \t  1.0120240090297268 \t 1.0315993177945955\n",
      "79     \t [-0.24001301  0.78223822]. \t  0.9141440226163967 \t 1.0315993177945955\n",
      "80     \t [-0.12825756  0.74457349]. \t  1.018431002584542 \t 1.0315993177945955\n",
      "81     \t [-0.06456961  0.68822859]. \t  1.0250227143633746 \t 1.0315993177945955\n",
      "82     \t [ 0.0576217  -0.67637327]. \t  1.0184843430367492 \t 1.0315993177945955\n",
      "83     \t [ 0.0994348  -0.69192958]. \t  1.0276542924170953 \t 1.0315993177945955\n",
      "84     \t [ 0.10325114 -0.76011966]. \t  1.011878205734118 \t 1.0315993177945955\n",
      "85     \t [-0.07770954  0.78282278]. \t  0.9858484750654222 \t 1.0315993177945955\n",
      "86     \t [0.05870631 0.62122978]. \t  0.897717986689711 \t 1.0315993177945955\n",
      "87     \t [ 0.05705556 -0.7067883 ]. \t  1.027326285644972 \t 1.0315993177945955\n",
      "88     \t [0.0217719  0.66157146]. \t  0.9681640132454785 \t 1.0315993177945955\n",
      "89     \t [ 0.01514152 -0.80516461]. \t  0.923314714416768 \t 1.0315993177945955\n",
      "90     \t [ 0.12514728 -0.73064617]. \t  1.0247232313958772 \t 1.0315993177945955\n",
      "91     \t [ 0.0788844  -0.78865838]. \t  0.9778846100187638 \t 1.0315993177945955\n",
      "92     \t [ 0.05650528 -0.67492388]. \t  1.0174736921575074 \t 1.0315993177945955\n",
      "93     \t [-0.07713893  0.70842793]. \t  1.0309060102939744 \t 1.0315993177945955\n",
      "94     \t [ 0.08005424 -0.69366   ]. \t  1.0285627107936477 \t 1.0315993177945955\n",
      "95     \t [-0.1449463   0.75394442]. \t  1.0074357184681064 \t 1.0315993177945955\n",
      "96     \t [ 0.11250108 -0.73849344]. \t  1.024556375629285 \t 1.0315993177945955\n",
      "97     \t [-0.15286528  0.67320667]. \t  1.0018229543251806 \t 1.0315993177945955\n",
      "98     \t [ 0.05952161 -0.70597807]. \t  1.0278658308311308 \t 1.0315993177945955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-1.35242016 -1.42688513]. \t  -12.697409007421088 \t 1.0315993177945955\n",
      "100    \t [-0.07555845  0.70344477]. \t  1.0302765362167443 \t 1.0315993177945955\n"
     ]
    }
   ],
   "source": [
    "### 6(r). Bayesian optimization runs (x20): STP DF1 run number = 18\n",
    "\n",
    "np.random.seed(run_num_18)\n",
    "surrogate_stp_df1_18 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_18 = GPGO(surrogate_stp_df1_18, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_18.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.110087087069893, -14.197935044665726)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(r). Training Regret Minimisation: run number = 18\n",
    "\n",
    "gp_output_18 = np.append(np.max(gpgo_gp_18.GP.y[0:n_init]),gpgo_gp_18.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_18 = np.append(np.max(gpgo_stp_df1_18.GP.y[0:n_init]),gpgo_stp_df1_18.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_18 = np.log(y_global_orig - gp_output_18)\n",
    "regret_stp_df1_18 = np.log(y_global_orig - stp_df1_output_18)\n",
    "\n",
    "train_regret_gp_18 = min_max_array(regret_gp_18)\n",
    "train_regret_stp_df1_18 = min_max_array(regret_stp_df1_18)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 18\n",
    "min_train_regret_gp_18 = min(train_regret_gp_18)\n",
    "min_train_regret_stp_df1_18 = min(train_regret_stp_df1_18)\n",
    "\n",
    "min_train_regret_gp_18, min_train_regret_stp_df1_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.94712104 1.93850703]. \t  -48.37297032591504 \t -3.2450535172753834\n",
      "init   \t [ 2.3588671  -0.72141234]. \t  -11.963845633073099 \t -3.2450535172753834\n",
      "init   \t [ 0.55954023 -1.21803073]. \t  -3.2450535172753834 \t -3.2450535172753834\n",
      "init   \t [2.16130056 1.45720206]. \t  -19.529713238408224 \t -3.2450535172753834\n",
      "init   \t [-2.52829291  0.8676483 ]. \t  -23.887732441775174 \t -3.2450535172753834\n",
      "1      \t [2.8590371  0.71930409]. \t  -75.49377642730794 \t -3.2450535172753834\n",
      "2      \t [1.27704827 0.61373809]. \t  \u001b[92m-2.2285407637219583\u001b[0m \t -2.2285407637219583\n",
      "3      \t [ 2.19771544 -1.6388134 ]. \t  -22.39616496992334 \t -2.2285407637219583\n",
      "4      \t [-0.73027116 -1.78653479]. \t  -30.87228279656744 \t -2.2285407637219583\n",
      "5      \t [ 1.29025299 -0.62234382]. \t  \u001b[92m-0.624780448659007\u001b[0m \t -0.624780448659007\n",
      "6      \t [-2.99648926 -0.77994609]. \t  -109.29342436587504 \t -0.624780448659007\n",
      "7      \t [-1.70825091  2.        ]. \t  -46.6565974047746 \t -0.624780448659007\n",
      "8      \t [ 0.16907459 -0.60271495]. \t  \u001b[92m0.9144816921250104\u001b[0m \t 0.9144816921250104\n",
      "9      \t [ 0.43013634 -0.59552477]. \t  0.5013557706340848 \t 0.9144816921250104\n",
      "10     \t [ 0.02005941 -0.43441066]. \t  0.6195055092888148 \t 0.9144816921250104\n",
      "11     \t [1.42142907 0.25758063]. \t  -2.3767930001670408 \t 0.9144816921250104\n",
      "12     \t [-0.77351175  0.30670879]. \t  -1.134778246990774 \t 0.9144816921250104\n",
      "13     \t [-0.2830865  -0.30266968]. \t  -0.06005175255761824 \t 0.9144816921250104\n",
      "14     \t [1.75385428 0.63627368]. \t  -2.2878971660538214 \t 0.9144816921250104\n",
      "15     \t [-0.25659097  0.14274804]. \t  -0.1378728601387668 \t 0.9144816921250104\n",
      "16     \t [-0.57653966  0.48006666]. \t  -0.1236294242725019 \t 0.9144816921250104\n",
      "17     \t [ 0.30658773 -0.70160105]. \t  0.8571547171861031 \t 0.9144816921250104\n",
      "18     \t [-0.02573421  1.25884022]. \t  -3.676364310211674 \t 0.9144816921250104\n",
      "19     \t [-0.22252464  0.81470601]. \t  0.8810810827253494 \t 0.9144816921250104\n",
      "20     \t [-0.07136921  0.70669972]. \t  \u001b[92m1.0301154588411285\u001b[0m \t 1.0301154588411285\n",
      "21     \t [-2.89553682  1.97632291]. \t  -122.04714883011903 \t 1.0301154588411285\n",
      "22     \t [-1.96731591  0.5604672 ]. \t  -1.385199175374452 \t 1.0301154588411285\n",
      "23     \t [-1.58979359  0.64390298]. \t  -0.0822728283888311 \t 1.0301154588411285\n",
      "24     \t [-0.1636906   0.68909954]. \t  1.004593504607381 \t 1.0301154588411285\n",
      "25     \t [-0.35182093  1.7133171 ]. \t  -22.58656299761576 \t 1.0301154588411285\n",
      "26     \t [ 2.98649901 -1.90627146]. \t  -137.72153006104742 \t 1.0301154588411285\n",
      "27     \t [ 1.63113608 -1.35284982]. \t  -5.925954689911881 \t 1.0301154588411285\n",
      "28     \t [ 1.54054958 -0.68741594]. \t  -0.06477158820242301 \t 1.0301154588411285\n",
      "29     \t [ 1.66130538 -0.40509459]. \t  -0.8295554011222268 \t 1.0301154588411285\n",
      "30     \t [ 0.19812399 -1.79928675]. \t  -28.77146824803778 \t 1.0301154588411285\n",
      "31     \t [-2.07755404 -1.93681463]. \t  -50.252183955967624 \t 1.0301154588411285\n",
      "32     \t [-1.08840141 -1.27864782]. \t  -7.8896725202503735 \t 1.0301154588411285\n",
      "33     \t [-0.04403228 -0.63575625]. \t  0.9275374409554479 \t 1.0301154588411285\n",
      "34     \t [-1.60404494  0.44935944]. \t  -0.7019567182242011 \t 1.0301154588411285\n",
      "35     \t [-1.08720039  0.39045253]. \t  -1.4031635092013701 \t 1.0301154588411285\n",
      "36     \t [ 0.4215799  -0.28943883]. \t  -0.21740735511879544 \t 1.0301154588411285\n",
      "37     \t [-0.10790669  0.7549216 ]. \t  1.0156221256712425 \t 1.0301154588411285\n",
      "38     \t [-1.65704063  0.56116966]. \t  -0.25815072857469823 \t 1.0301154588411285\n",
      "39     \t [-2.31113726 -1.52091801]. \t  -27.914392406843483 \t 1.0301154588411285\n",
      "40     \t [-1.19402761 -0.67615132]. \t  -2.214943418077949 \t 1.0301154588411285\n",
      "41     \t [1.95904896 0.8783894 ]. \t  -4.278852189347472 \t 1.0301154588411285\n",
      "42     \t [ 0.0328747  -0.78176322]. \t  0.9719590852778643 \t 1.0301154588411285\n",
      "43     \t [-1.60730681 -1.0680743 ]. \t  -4.424585686560949 \t 1.0301154588411285\n",
      "44     \t [0.71253648 1.47352461]. \t  -12.755721912203555 \t 1.0301154588411285\n",
      "45     \t [-0.33095623 -0.36815935]. \t  -0.0665370673859157 \t 1.0301154588411285\n",
      "46     \t [-1.90627479  0.14892308]. \t  -2.429447722475121 \t 1.0301154588411285\n",
      "47     \t [1.62161583 0.92079146]. \t  -3.0355602264327732 \t 1.0301154588411285\n",
      "48     \t [-0.73953187 -0.51662787]. \t  -1.2134285469296264 \t 1.0301154588411285\n",
      "49     \t [-1.23683884  1.00035516]. \t  -1.1635541899258022 \t 1.0301154588411285\n",
      "50     \t [ 2.43310258 -0.1960577 ]. \t  -18.615748445973082 \t 1.0301154588411285\n",
      "51     \t [1.69190008 0.95514381]. \t  -3.35712557113727 \t 1.0301154588411285\n",
      "52     \t [-2.9450382   1.47903669]. \t  -100.23792777202758 \t 1.0301154588411285\n",
      "53     \t [ 2.66970986 -0.6070492 ]. \t  -39.967482777156434 \t 1.0301154588411285\n",
      "54     \t [1.6348476  1.75432111]. \t  -30.498815223867034 \t 1.0301154588411285\n",
      "55     \t [-0.14838526  0.7019188 ]. \t  1.0168824423124212 \t 1.0301154588411285\n",
      "56     \t [0.03983899 0.71886839]. \t  0.9638925453706606 \t 1.0301154588411285\n",
      "57     \t [ 0.9939239  -0.48364077]. \t  -1.0259959080454673 \t 1.0301154588411285\n",
      "58     \t [-2.25861159  1.39288649]. \t  -14.157338237373809 \t 1.0301154588411285\n",
      "59     \t [-1.82563475  1.04432129]. \t  -0.8339617306468985 \t 1.0301154588411285\n",
      "60     \t [-0.08778431  0.6980913 ]. \t  1.0299397080952775 \t 1.0301154588411285\n",
      "61     \t [-0.03313335  0.61219691]. \t  0.9531802579766794 \t 1.0301154588411285\n",
      "62     \t [-0.01568696 -0.66935924]. \t  0.9777169689617633 \t 1.0301154588411285\n",
      "63     \t [-0.06088593 -1.37962936]. \t  -6.976669598610451 \t 1.0301154588411285\n",
      "64     \t [ 1.32848804 -1.7600199 ]. \t  -26.00424734413629 \t 1.0301154588411285\n",
      "65     \t [ 0.1500396  -0.71790933]. \t  1.0177798707992485 \t 1.0301154588411285\n",
      "66     \t [0.5741475  1.82343259]. \t  -33.06962741794802 \t 1.0301154588411285\n",
      "67     \t [ 1.70076313 -1.33353456]. \t  -5.335331811672244 \t 1.0301154588411285\n",
      "68     \t [2.88810915 0.01860746]. \t  -80.75542212556043 \t 1.0301154588411285\n",
      "69     \t [-0.27494772 -0.31158484]. \t  -0.025559092212517842 \t 1.0301154588411285\n",
      "70     \t [-1.70923035 -0.45299219]. \t  -2.195868024217803 \t 1.0301154588411285\n",
      "71     \t [ 2.55777314 -0.64388908]. \t  -27.00653927411966 \t 1.0301154588411285\n",
      "72     \t [0.08398278 0.75317355]. \t  0.8905370876433476 \t 1.0301154588411285\n",
      "73     \t [ 0.11292076 -0.75510532]. \t  1.0149002232080342 \t 1.0301154588411285\n",
      "74     \t [ 0.07284033 -0.88794073]. \t  0.7107264986381504 \t 1.0301154588411285\n",
      "75     \t [ 0.02502111 -0.71321789]. \t  1.0150407516965763 \t 1.0301154588411285\n",
      "76     \t [1.40365443 1.08552498]. \t  -4.642886422353046 \t 1.0301154588411285\n",
      "77     \t [ 0.05893657 -0.73460348]. \t  1.0231402150931417 \t 1.0301154588411285\n",
      "78     \t [-0.02522138  0.72333324]. \t  1.0135448413105088 \t 1.0301154588411285\n",
      "79     \t [1.8685536  1.14221397]. \t  -6.277733563078956 \t 1.0301154588411285\n",
      "80     \t [-2.8919153  -0.77871259]. \t  -82.85125425500637 \t 1.0301154588411285\n",
      "81     \t [-0.09680428  0.7901818 ]. \t  0.9773040742264055 \t 1.0301154588411285\n",
      "82     \t [ 0.04669553 -0.95423065]. \t  0.3616210668371037 \t 1.0301154588411285\n",
      "83     \t [-2.03995434 -0.75631985]. \t  -4.864367745374999 \t 1.0301154588411285\n",
      "84     \t [-0.05690041  0.71180048]. \t  1.0273956967678572 \t 1.0301154588411285\n",
      "85     \t [2.66575667 1.68525492]. \t  -67.3932172423348 \t 1.0301154588411285\n",
      "86     \t [2.22415916 1.1126428 ]. \t  -12.402987220056872 \t 1.0301154588411285\n",
      "87     \t [-1.97895652 -1.58605992]. \t  -21.867611516321475 \t 1.0301154588411285\n",
      "88     \t [ 0.13228794 -0.79454437]. \t  0.9667900401728916 \t 1.0301154588411285\n",
      "89     \t [-1.02421248  1.83579544]. \t  -32.340621799865495 \t 1.0301154588411285\n",
      "90     \t [-0.67408672 -0.79401951]. \t  -1.0185763066275788 \t 1.0301154588411285\n",
      "91     \t [-1.22767843 -0.87313204]. \t  -2.746864856835269 \t 1.0301154588411285\n",
      "92     \t [ 0.1239038  -0.71725094]. \t  1.0271201671511767 \t 1.0301154588411285\n",
      "93     \t [-2.59611282  0.47633612]. \t  -31.680249348617586 \t 1.0301154588411285\n",
      "94     \t [ 1.75668099 -1.80527956]. \t  -28.41900889997234 \t 1.0301154588411285\n",
      "95     \t [2.11723476 1.34877787]. \t  -14.574924669876168 \t 1.0301154588411285\n",
      "96     \t [-2.86831971 -0.99307437]. \t  -79.18696820924706 \t 1.0301154588411285\n",
      "97     \t [0.71339308 0.5933373 ]. \t  -1.0465786775206454 \t 1.0301154588411285\n",
      "98     \t [-0.18362242  0.70943365]. \t  0.9977303006894802 \t 1.0301154588411285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-1.66648224 -1.0884364 ]. \t  -4.740949768013759 \t 1.0301154588411285\n",
      "100    \t [-2.67282224  0.72216265]. \t  -40.00544237640576 \t 1.0301154588411285\n"
     ]
    }
   ],
   "source": [
    "### 6(s). Bayesian optimization runs (x20): GP run number = 19\n",
    "\n",
    "np.random.seed(run_num_19)\n",
    "surrogate_gp_19 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_19 = GPGO(surrogate_gp_19, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_19.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [1.94712104 1.93850703]. \t  -48.37297032591504 \t -3.2450535172753834\n",
      "init   \t [ 2.3588671  -0.72141234]. \t  -11.963845633073099 \t -3.2450535172753834\n",
      "init   \t [ 0.55954023 -1.21803073]. \t  -3.2450535172753834 \t -3.2450535172753834\n",
      "init   \t [2.16130056 1.45720206]. \t  -19.529713238408224 \t -3.2450535172753834\n",
      "init   \t [-2.52829291  0.8676483 ]. \t  -23.887732441775174 \t -3.2450535172753834\n",
      "1      \t [3.         0.68299227]. \t  -109.95347158242312 \t -3.2450535172753834\n",
      "2      \t [1.1531022  0.53147062]. \t  \u001b[92m-2.191590024972859\u001b[0m \t -2.191590024972859\n",
      "3      \t [ 2.33382322 -2.        ]. \t  -56.6813329167827 \t -2.191590024972859\n",
      "4      \t [-1.69886044 -2.        ]. \t  -53.46334980542664 \t -2.191590024972859\n",
      "5      \t [-0.99287757  2.        ]. \t  -48.23600031603514 \t -2.191590024972859\n",
      "6      \t [-3.         -0.69398336]. \t  -109.98330241901918 \t -2.191590024972859\n",
      "7      \t [-3.  2.]. \t  -150.89999999999998 \t -2.191590024972859\n",
      "8      \t [-1.15417761  0.27319969]. \t  \u001b[92m-1.7983178265443829\u001b[0m \t -1.7983178265443829\n",
      "9      \t [-0.1532541 -2.       ]. \t  -48.3993013744633 \t -1.7983178265443829\n",
      "10     \t [ 1.38106536 -0.60192912]. \t  \u001b[92m-0.5471274476683203\u001b[0m \t -0.5471274476683203\n",
      "11     \t [-0.05695771 -0.33298805]. \t  \u001b[92m0.3624248720321589\u001b[0m \t 0.3624248720321589\n",
      "12     \t [-0.10448215  0.90388194]. \t  \u001b[92m0.6490607780790587\u001b[0m \t 0.6490607780790587\n",
      "13     \t [0.27343053 2.        ]. \t  -48.834319010674186 \t 0.6490607780790587\n",
      "14     \t [-1.53281794  0.86424144]. \t  -0.04801128642220309 \t 0.6490607780790587\n",
      "15     \t [ 3.         -1.26731557]. \t  -108.9917826591038 \t 0.6490607780790587\n",
      "16     \t [ 1.205926 -2.      ]. \t  -47.98914778639866 \t 0.6490607780790587\n",
      "17     \t [1.8811609  0.20396101]. \t  -2.853083248455418 \t 0.6490607780790587\n",
      "18     \t [-0.58778944 -0.96015908]. \t  -1.4214486449389103 \t 0.6490607780790587\n",
      "19     \t [1.51357306 1.03830548]. \t  -4.058297803790527 \t 0.6490607780790587\n",
      "20     \t [-3. -2.]. \t  -162.89999999999998 \t 0.6490607780790587\n",
      "21     \t [-1.97115388  0.28158591]. \t  -2.544133211762528 \t 0.6490607780790587\n",
      "22     \t [3. 2.]. \t  -162.89999999999998 \t 0.6490607780790587\n",
      "23     \t [0.28760407 0.42867972]. \t  0.16001000909353985 \t 0.6490607780790587\n",
      "24     \t [ 0.11204145 -0.87853029]. \t  \u001b[92m0.7530143331777616\u001b[0m \t 0.7530143331777616\n",
      "25     \t [-1.44847557 -0.77497402]. \t  -2.389786671448249 \t 0.7530143331777616\n",
      "26     \t [ 1.8073012  -1.01575461]. \t  -0.5719641756387435 \t 0.7530143331777616\n",
      "27     \t [-0.74857124  0.93252465]. \t  -0.4890445860802228 \t 0.7530143331777616\n",
      "28     \t [ 1.88056271 -0.56737767]. \t  -0.6850139744895313 \t 0.7530143331777616\n",
      "29     \t [ 0.59516388 -0.62346427]. \t  0.1533153202293075 \t 0.7530143331777616\n",
      "30     \t [1.81854771 0.82616747]. \t  -2.9531170501476676 \t 0.7530143331777616\n",
      "31     \t [-3.          0.38473086]. \t  -107.24137317581105 \t 0.7530143331777616\n",
      "32     \t [-0.38620438  0.4935711 ]. \t  0.3766780111800184 \t 0.7530143331777616\n",
      "33     \t [-1.90512611  0.71883946]. \t  -0.42324426977594864 \t 0.7530143331777616\n",
      "34     \t [-1.62920975 -0.29075098]. \t  -2.21963900457403 \t 0.7530143331777616\n",
      "35     \t [ 1.22049028 -1.07158664]. \t  -1.7737545660821854 \t 0.7530143331777616\n",
      "36     \t [0.55601138 1.0426472 ]. \t  -2.0042715719165782 \t 0.7530143331777616\n",
      "37     \t [-1.92035445  2.        ]. \t  -47.068550081422615 \t 0.7530143331777616\n",
      "38     \t [-2.05421263 -0.92688376]. \t  -5.951849586135191 \t 0.7530143331777616\n",
      "39     \t [-0.58884511 -0.4951622 ]. \t  -0.6996674114920056 \t 0.7530143331777616\n",
      "40     \t [ 0.96198953 -0.03705551]. \t  -2.126284499694599 \t 0.7530143331777616\n",
      "41     \t [-1.09410356 -1.57391387]. \t  -18.710198394753725 \t 0.7530143331777616\n",
      "42     \t [ 3.         -0.25916569]. \t  -107.87188107394988 \t 0.7530143331777616\n",
      "43     \t [1.0922409 2.       ]. \t  -52.53363354254553 \t 0.7530143331777616\n",
      "44     \t [0.17475196 0.74954023]. \t  0.7335301343293611 \t 0.7530143331777616\n",
      "45     \t [-1.88802235  1.2781819 ]. \t  -4.401089221413521 \t 0.7530143331777616\n",
      "46     \t [-1.99343051 -0.49989938]. \t  -3.8973995406000794 \t 0.7530143331777616\n",
      "47     \t [-1.28343298  1.3227281 ]. \t  -5.929166343023303 \t 0.7530143331777616\n",
      "48     \t [-1.65329285 -1.17517187]. \t  -6.098763056488455 \t 0.7530143331777616\n",
      "49     \t [ 3. -2.]. \t  -150.89999999999998 \t 0.7530143331777616\n",
      "50     \t [ 0.6802708  -0.88788178]. \t  -0.16292959047378353 \t 0.7530143331777616\n",
      "51     \t [-0.14934456 -1.27512424]. \t  -4.349587131320259 \t 0.7530143331777616\n",
      "52     \t [-3.          1.25921982]. \t  -108.83675010342517 \t 0.7530143331777616\n",
      "53     \t [1.56581402 0.19728477]. \t  -2.2555684792710196 \t 0.7530143331777616\n",
      "54     \t [ 1.79271112 -1.54148344]. \t  -12.546566795536984 \t 0.7530143331777616\n",
      "55     \t [-0.14838332  0.70191714]. \t  \u001b[92m1.016882946933633\u001b[0m \t 1.016882946933633\n",
      "56     \t [-2.36040389 -2.        ]. \t  -67.46894565014813 \t 1.016882946933633\n",
      "57     \t [-0.45689345  1.55831356]. \t  -13.908541540767429 \t 1.016882946933633\n",
      "58     \t [ 2.30627749 -1.37800346]. \t  -15.673310790293575 \t 1.016882946933633\n",
      "59     \t [ 0.0563306  -0.68346422]. \t  \u001b[92m1.0215050394260532\u001b[0m \t 1.0215050394260532\n",
      "60     \t [-0.06680378  0.6866126 ]. \t  \u001b[92m1.0247957192888273\u001b[0m \t 1.0247957192888273\n",
      "61     \t [ 0.13228676 -0.69790195]. \t  1.022296323987991 \t 1.0247957192888273\n",
      "62     \t [3.         1.38561928]. \t  -120.12178523030997 \t 1.0247957192888273\n",
      "63     \t [ 0.07247729 -0.69078667]. \t  \u001b[92m1.027030540721852\u001b[0m \t 1.027030540721852\n",
      "64     \t [-2.59499872 -1.42136733]. \t  -45.43006362514537 \t 1.027030540721852\n",
      "65     \t [ 0.15003828 -0.71790987]. \t  1.017780454278922 \t 1.027030540721852\n",
      "66     \t [ 0.18136591 -0.71794238]. \t  0.9999424815964071 \t 1.027030540721852\n",
      "67     \t [-0.0312623   0.66359318]. \t  1.0026084555878323 \t 1.027030540721852\n",
      "68     \t [ 0.15444781 -0.71334095]. \t  1.0156341920884333 \t 1.027030540721852\n",
      "69     \t [ 0.19203729 -0.70505412]. \t  0.9906890935109414 \t 1.027030540721852\n",
      "70     \t [ 0.07557008 -0.66396023]. \t  1.0134024911657433 \t 1.027030540721852\n",
      "71     \t [ 0.46490458 -2.        ]. \t  -47.84000024661273 \t 1.027030540721852\n",
      "72     \t [2.34040887 0.88818803]. \t  -15.096851021562498 \t 1.027030540721852\n",
      "73     \t [ 0.09792885 -0.71324552]. \t  \u001b[92m1.0313758207871948\u001b[0m \t 1.0313758207871948\n",
      "74     \t [ 0.09175929 -0.73660649]. \t  1.0268047634077302 \t 1.0313758207871948\n",
      "75     \t [ 0.02502184 -0.71321724]. \t  1.0150411719126446 \t 1.0313758207871948\n",
      "76     \t [-2.43676171  1.62424501]. \t  -32.823775198512216 \t 1.0313758207871948\n",
      "77     \t [0.00813114 0.69857757]. \t  0.9934803354002587 \t 1.0313758207871948\n",
      "78     \t [-0.08770343  0.70682739]. \t  1.0313470906340605 \t 1.0313758207871948\n",
      "79     \t [0.01474115 0.71088338]. \t  0.9885369410154373 \t 1.0313758207871948\n",
      "80     \t [-2.46287056 -0.14591382]. \t  -21.66578650801527 \t 1.0313758207871948\n",
      "81     \t [-0.03235339  0.72004075]. \t  1.0177481983860468 \t 1.0313758207871948\n",
      "82     \t [ 0.17120064 -0.77734472]. \t  0.9741543006825744 \t 1.0313758207871948\n",
      "83     \t [ 0.23264616 -0.77052836]. \t  0.9337332604246593 \t 1.0313758207871948\n",
      "84     \t [-0.08254342  0.6903616 ]. \t  1.0276381236946983 \t 1.0313758207871948\n",
      "85     \t [ 0.13028008 -0.70856159]. \t  1.0250062347088011 \t 1.0313758207871948\n",
      "86     \t [-0.04950333  0.65211844]. \t  1.000147127972961 \t 1.0313758207871948\n",
      "87     \t [ 0.17591376 -0.72564572]. \t  1.0030475165589996 \t 1.0313758207871948\n",
      "88     \t [-0.14738233  0.67903101]. \t  1.0081202859473763 \t 1.0313758207871948\n",
      "89     \t [ 0.11469315 -0.67061401]. \t  1.0145483387605811 \t 1.0313758207871948\n",
      "90     \t [-0.06267524  0.61467327]. \t  0.9631357762382329 \t 1.0313758207871948\n",
      "91     \t [-0.02030033  0.66109287]. \t  0.9959184067965626 \t 1.0313758207871948\n",
      "92     \t [ 0.1239066 -0.7172478]. \t  1.0271195745512478 \t 1.0313758207871948\n",
      "93     \t [ 0.19067837 -0.76898284]. \t  0.9705874056780563 \t 1.0313758207871948\n",
      "94     \t [-0.04366351  0.62882513]. \t  0.9760912995933371 \t 1.0313758207871948\n",
      "95     \t [0.00318236 0.7421798 ]. \t  0.9872625028893256 \t 1.0313758207871948\n",
      "96     \t [-0.16862511  0.66231803]. \t  0.984588119258039 \t 1.0313758207871948\n",
      "97     \t [ 0.13532591 -0.68641702]. \t  1.017014765089144 \t 1.0313758207871948\n",
      "98     \t [ 0.1537888  -0.76120535]. \t  0.9983923639376855 \t 1.0313758207871948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99     \t [-0.05867185  0.51668787]. \t  0.7993516342361362 \t 1.0313758207871948\n",
      "100    \t [ 0.13943331 -0.74350017]. \t  1.0155452048888878 \t 1.0313758207871948\n"
     ]
    }
   ],
   "source": [
    "### 6(s). Bayesian optimization runs (x20): STP DF1 run number = 19\n",
    "\n",
    "np.random.seed(run_num_19)\n",
    "surrogate_stp_df1_19 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_19 = GPGO(surrogate_stp_df1_19, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_19.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.512649538397736, -8.403064768818009)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(s). Training Regret Minimisation: run number = 19\n",
    "\n",
    "gp_output_19 = np.append(np.max(gpgo_gp_19.GP.y[0:n_init]),gpgo_gp_19.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_19 = np.append(np.max(gpgo_stp_df1_19.GP.y[0:n_init]),gpgo_stp_df1_19.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_19 = np.log(y_global_orig - gp_output_19)\n",
    "regret_stp_df1_19 = np.log(y_global_orig - stp_df1_output_19)\n",
    "\n",
    "train_regret_gp_19 = min_max_array(regret_gp_19)\n",
    "train_regret_stp_df1_19 = min_max_array(regret_stp_df1_19)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 19\n",
    "min_train_regret_gp_19 = min(train_regret_gp_19)\n",
    "min_train_regret_stp_df1_19 = min(train_regret_stp_df1_19)\n",
    "\n",
    "min_train_regret_gp_19, min_train_regret_stp_df1_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.42310371 0.25811502]. \t  -0.5111512856704337 \t 0.9146183273252478\n",
      "init   \t [-0.069349   -0.65408899]. \t  0.9146183273252478 \t 0.9146183273252478\n",
      "init   \t [-0.74479093  0.12814348]. \t  -1.4695211123708676 \t 0.9146183273252478\n",
      "init   \t [-2.59136227  0.33811624]. \t  -31.819735064764004 \t 0.9146183273252478\n",
      "init   \t [-1.57261342 -1.35697367]. \t  -10.421507729581124 \t 0.9146183273252478\n",
      "1      \t [-0.14109941 -0.15343054]. \t  -0.008508372529648214 \t 0.9146183273252478\n",
      "2      \t [ 0.50053142 -1.42718012]. \t  -8.608757763160128 \t 0.9146183273252478\n",
      "3      \t [1.38215766 0.87576994]. \t  -2.7970295613821525 \t 0.9146183273252478\n",
      "4      \t [-0.39610382  1.66004099]. \t  -19.27301701457772 \t 0.9146183273252478\n",
      "5      \t [1.02776724 0.03875557]. \t  -2.3087826391962536 \t 0.9146183273252478\n",
      "6      \t [-0.47325748 -0.77589186]. \t  -0.20311110431458623 \t 0.9146183273252478\n",
      "7      \t [3. 2.]. \t  -162.89999999999998 \t 0.9146183273252478\n",
      "8      \t [0.91712206 0.80482988]. \t  -1.902565763326674 \t 0.9146183273252478\n",
      "9      \t [1.09063056 0.59591867]. \t  -2.08157898064945 \t 0.9146183273252478\n",
      "10     \t [ 3. -2.]. \t  -150.89999999999998 \t 0.9146183273252478\n",
      "11     \t [ 0.34255668 -0.41440266]. \t  0.2699082750699223 \t 0.9146183273252478\n",
      "12     \t [-0.28548574 -1.26341441]. \t  -4.479683960979575 \t 0.9146183273252478\n",
      "13     \t [1.03096635 1.82076077]. \t  -34.85724569420337 \t 0.9146183273252478\n",
      "14     \t [-0.06424212  0.66311043]. \t  \u001b[92m1.0115902506348842\u001b[0m \t 1.0115902506348842\n",
      "15     \t [1.73875072 0.07913889]. \t  -2.2225003429877965 \t 1.0115902506348842\n",
      "16     \t [0.05067318 0.56896691]. \t  0.8366175582987107 \t 1.0115902506348842\n",
      "17     \t [-0.54685437  0.71234605]. \t  0.3720192947377198 \t 1.0115902506348842\n",
      "18     \t [-2.45443226 -1.76743731]. \t  -51.63710217674941 \t 1.0115902506348842\n",
      "19     \t [-0.3539167  0.6164445]. \t  0.6918380695327568 \t 1.0115902506348842\n",
      "20     \t [-2.93308739  1.92957439]. \t  -126.12625451200103 \t 1.0115902506348842\n",
      "21     \t [-1.46468183 -0.45383031]. \t  -2.2180114045860684 \t 1.0115902506348842\n",
      "22     \t [-1.49665459  0.0429097 ]. \t  -2.0979520264098555 \t 1.0115902506348842\n",
      "23     \t [ 0.10172959 -0.50067633]. \t  0.7611142455075717 \t 1.0115902506348842\n",
      "24     \t [2.40576203 0.22100924]. \t  -17.77628783602815 \t 1.0115902506348842\n",
      "25     \t [ 1.15768582 -0.75681001]. \t  -0.5363429178601061 \t 1.0115902506348842\n",
      "26     \t [ 1.24532974 -0.34713449]. \t  -1.5397272611429655 \t 1.0115902506348842\n",
      "27     \t [ 0.21042367 -0.87409273]. \t  0.7320410593980813 \t 1.0115902506348842\n",
      "28     \t [-0.1249432   0.69344902]. \t  \u001b[92m1.0232454309393322\u001b[0m \t 1.0232454309393322\n",
      "29     \t [ 0.73655129 -0.67690304]. \t  -0.11360890499210385 \t 1.0232454309393322\n",
      "30     \t [-1.66145743 -0.36139022]. \t  -2.1974947754210867 \t 1.0232454309393322\n",
      "31     \t [0.63498595 0.24208286]. \t  -1.226310123768032 \t 1.0232454309393322\n",
      "32     \t [1.76454506 1.75355096]. \t  -30.773058715602147 \t 1.0232454309393322\n",
      "33     \t [-0.70063536 -1.49000954]. \t  -13.376267448872674 \t 1.0232454309393322\n",
      "34     \t [-1.76588361 -0.05751031]. \t  -2.248865967433256 \t 1.0232454309393322\n",
      "35     \t [-0.042137   -0.70719929]. \t  0.9631051838337794 \t 1.0232454309393322\n",
      "36     \t [-1.20861921  1.21160752]. \t  -3.684685961525207 \t 1.0232454309393322\n",
      "37     \t [1.93528781 1.15383591]. \t  -7.0336234600326355 \t 1.0232454309393322\n",
      "38     \t [ 0.01025272 -0.79312933]. \t  0.9410913960677343 \t 1.0232454309393322\n",
      "39     \t [-0.21181931  1.31563517]. \t  -4.957014144297905 \t 1.0232454309393322\n",
      "40     \t [ 0.09039275 -0.71869576]. \t  \u001b[92m1.0313293924375388\u001b[0m \t 1.0313293924375388\n",
      "41     \t [0.33567907 0.84587172]. \t  0.10576416026576307 \t 1.0313293924375388\n",
      "42     \t [-0.12862961  0.64521919]. \t  0.9893678250213382 \t 1.0313293924375388\n",
      "43     \t [ 0.08158329 -0.62395067]. \t  0.9753683746920428 \t 1.0313293924375388\n",
      "44     \t [-0.10883336  0.73852319]. \t  1.0250405926363717 \t 1.0313293924375388\n",
      "45     \t [ 0.220423   -0.67723323]. \t  0.9530106735638181 \t 1.0313293924375388\n",
      "46     \t [-1.26778253  0.79166584]. \t  -0.4487301246208374 \t 1.0313293924375388\n",
      "47     \t [ 1.86169714 -1.66893029]. \t  -19.299309473598427 \t 1.0313293924375388\n",
      "48     \t [2.22582705 0.85300953]. \t  -9.913042978039233 \t 1.0313293924375388\n",
      "49     \t [-2.73300823  0.36249973]. \t  -50.17615223964773 \t 1.0313293924375388\n",
      "50     \t [-1.93294373  0.71893578]. \t  -0.6269136672873437 \t 1.0313293924375388\n",
      "51     \t [-1.77388587  0.54186839]. \t  -0.3882372700102702 \t 1.0313293924375388\n",
      "52     \t [2.86596799 1.35194377]. \t  -85.81964848600569 \t 1.0313293924375388\n",
      "53     \t [ 2.50809148 -1.9411586 ]. \t  -61.890306381826484 \t 1.0313293924375388\n",
      "54     \t [0.68684727 1.576156  ]. \t  -17.28651740726995 \t 1.0313293924375388\n",
      "55     \t [ 1.6876843  -1.06361766]. \t  -0.8578843170988343 \t 1.0313293924375388\n",
      "56     \t [1.61908395 0.84616162]. \t  -2.6160829030643655 \t 1.0313293924375388\n",
      "57     \t [ 1.73464608 -0.76688479]. \t  0.1955466987241965 \t 1.0313293924375388\n",
      "58     \t [ 0.06915295 -0.69681081]. \t  1.0282702372232535 \t 1.0313293924375388\n",
      "59     \t [ 0.18133602 -0.76305834]. \t  0.9820322506520267 \t 1.0313293924375388\n",
      "60     \t [-0.95114137 -0.52735464]. \t  -1.8453259498234824 \t 1.0313293924375388\n",
      "61     \t [-0.16063737  0.72765648]. \t  1.011586740702901 \t 1.0313293924375388\n",
      "62     \t [-1.37697643  1.99735281]. \t  -47.26063798593281 \t 1.0313293924375388\n",
      "63     \t [ 0.83770616 -1.62121248]. \t  -17.64909715689385 \t 1.0313293924375388\n",
      "64     \t [0.65001593 1.09752317]. \t  -3.039336773075536 \t 1.0313293924375388\n",
      "65     \t [1.73840271 1.06707025]. \t  -4.595694977471223 \t 1.0313293924375388\n",
      "66     \t [ 0.19764621 -0.70416827]. \t  0.9860360228473105 \t 1.0313293924375388\n",
      "67     \t [0.12038614 0.56886193]. \t  0.7495233589753024 \t 1.0313293924375388\n",
      "68     \t [ 0.11798213 -0.78541251]. \t  0.9827544844772327 \t 1.0313293924375388\n",
      "69     \t [1.3353567  1.04700935]. \t  -4.165381765206539 \t 1.0313293924375388\n",
      "70     \t [0.00615685 0.23329082]. \t  0.20426231579659207 \t 1.0313293924375388\n",
      "71     \t [0.87655999 0.96016329]. \t  -2.5385368155372108 \t 1.0313293924375388\n",
      "72     \t [2.96244727 0.78664517]. \t  -100.06067106051304 \t 1.0313293924375388\n",
      "73     \t [-0.92118385 -1.14758204]. \t  -4.8125465261924765 \t 1.0313293924375388\n",
      "74     \t [0.01525143 0.69519879]. \t  0.9873515367409686 \t 1.0313293924375388\n",
      "75     \t [0.56516436 1.69716506]. \t  -23.698064532884224 \t 1.0313293924375388\n",
      "76     \t [-2.88492799 -0.52827373]. \t  -80.71660737594533 \t 1.0313293924375388\n",
      "77     \t [ 1.69156201 -0.93166013]. \t  -0.0266658478363333 \t 1.0313293924375388\n",
      "78     \t [-0.74782999  1.64496886]. \t  -18.872726333510375 \t 1.0313293924375388\n",
      "79     \t [-1.55413022 -0.38824081]. \t  -2.198501298752952 \t 1.0313293924375388\n",
      "80     \t [ 0.52780801 -0.00876636]. \t  -0.9536217085611318 \t 1.0313293924375388\n",
      "81     \t [-2.56522298 -1.49674733]. \t  -45.32165847174537 \t 1.0313293924375388\n",
      "82     \t [-0.1538417   0.74760567]. \t  1.0076321782521729 \t 1.0313293924375388\n",
      "83     \t [ 0.15159605 -1.21007528]. \t  -2.626738233352941 \t 1.0313293924375388\n",
      "84     \t [ 0.07386613 -0.71885296]. \t  1.030214334963538 \t 1.0313293924375388\n",
      "85     \t [-1.54479312  1.77040155]. \t  -26.140109675074886 \t 1.0313293924375388\n",
      "86     \t [-1.25157199 -1.40329153]. \t  -11.784961769668035 \t 1.0313293924375388\n",
      "87     \t [-1.81141394 -0.5683477 ]. \t  -2.4458799782390996 \t 1.0313293924375388\n",
      "88     \t [-2.09444163  1.19667487]. \t  -5.242459497536333 \t 1.0313293924375388\n",
      "89     \t [-2.75848662  1.78661372]. \t  -78.76463662692397 \t 1.0313293924375388\n",
      "90     \t [-0.00709024 -0.69535786]. \t  0.9937826376602398 \t 1.0313293924375388\n",
      "91     \t [-0.06683585  0.6538729 ]. \t  1.0048797576315551 \t 1.0313293924375388\n",
      "92     \t [2.34358413 0.81141137]. \t  -14.850598955553561 \t 1.0313293924375388\n",
      "93     \t [-0.06437637  0.71151594]. \t  1.0291070937669684 \t 1.0313293924375388\n",
      "94     \t [1.74749468 0.86841508]. \t  -2.9000546789739157 \t 1.0313293924375388\n",
      "95     \t [ 1.83828023 -0.60114099]. \t  -0.37116675153433265 \t 1.0313293924375388\n",
      "96     \t [2.30985615 1.83555002]. \t  -48.35912842854276 \t 1.0313293924375388\n",
      "97     \t [0.88287554 1.78244895]. \t  -31.241494035851236 \t 1.0313293924375388\n",
      "98     \t [-2.91923265 -1.74870989]. \t  -118.15330446754632 \t 1.0313293924375388\n",
      "99     \t [ 0.16676387 -0.67378003]. \t  0.994266858801935 \t 1.0313293924375388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [-1.05347936  1.81735804]. \t  -30.816346862556998 \t 1.0313293924375388\n"
     ]
    }
   ],
   "source": [
    "### 6(t). Bayesian optimization runs (x20): GP run number = 20\n",
    "\n",
    "np.random.seed(run_num_20)\n",
    "surrogate_gp_20 = GaussianProcess(cov_func, optimize = optimize)\n",
    "\n",
    "gpgo_gp_20 = GPGO(surrogate_gp_20, Acquisition_new(util_gp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_gp_20.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
      "init   \t [0.42310371 0.25811502]. \t  -0.5111512856704337 \t 0.9146183273252478\n",
      "init   \t [-0.069349   -0.65408899]. \t  0.9146183273252478 \t 0.9146183273252478\n",
      "init   \t [-0.74479093  0.12814348]. \t  -1.4695211123708676 \t 0.9146183273252478\n",
      "init   \t [-2.59136227  0.33811624]. \t  -31.819735064764004 \t 0.9146183273252478\n",
      "init   \t [-1.57261342 -1.35697367]. \t  -10.421507729581124 \t 0.9146183273252478\n",
      "1      \t [ 3. -2.]. \t  -150.89999999999998 \t 0.9146183273252478\n",
      "2      \t [3. 2.]. \t  -162.89999999999998 \t 0.9146183273252478\n",
      "3      \t [-0.57997506  2.        ]. \t  -47.96061490296319 \t 0.9146183273252478\n",
      "4      \t [-3. -2.]. \t  -162.89999999999998 \t 0.9146183273252478\n",
      "5      \t [-0.40777325 -2.        ]. \t  -49.424132776635936 \t 0.9146183273252478\n",
      "6      \t [-3.  2.]. \t  -150.89999999999998 \t 0.9146183273252478\n",
      "7      \t [ 1.69566633 -0.19763816]. \t  -1.5781969806021894 \t 0.9146183273252478\n",
      "8      \t [-1.51818394 -0.47066517]. \t  -2.16961299720769 \t 0.9146183273252478\n",
      "9      \t [0.93333628 2.        ]. \t  -51.97791353445777 \t 0.9146183273252478\n",
      "10     \t [3.00000000e+00 3.73149816e-04]. \t  -108.90111889248377 \t 0.9146183273252478\n",
      "11     \t [ 1.07525667 -0.90410439]. \t  -0.7635531186647235 \t 0.9146183273252478\n",
      "12     \t [ 1.01884137 -0.22554929]. \t  -1.839253464221934 \t 0.9146183273252478\n",
      "13     \t [ 1.18187136 -2.        ]. \t  -48.03466245526883 \t 0.9146183273252478\n",
      "14     \t [-0.92637995 -0.88188477]. \t  -2.2222777065026142 \t 0.9146183273252478\n",
      "15     \t [-3.         -0.39336049]. \t  -109.55692012150445 \t 0.9146183273252478\n",
      "16     \t [-1.63162901  0.79732733]. \t  0.17252286873392753 \t 0.9146183273252478\n",
      "17     \t [1.42198531 0.80525822]. \t  -2.4910088165016573 \t 0.9146183273252478\n",
      "18     \t [-0.10512927  1.00901229]. \t  -0.01161031464295946 \t 0.9146183273252478\n",
      "19     \t [-1.67622233  0.31778165]. \t  -1.1583561106824476 \t 0.9146183273252478\n",
      "20     \t [0.72697095 0.92142526]. \t  -1.7337443278586608 \t 0.9146183273252478\n",
      "21     \t [-0.89695065  0.8955013 ]. \t  -0.5938348398892819 \t 0.9146183273252478\n",
      "22     \t [ 0.45622606 -1.20457754]. \t  -2.8126940465179224 \t 0.9146183273252478\n",
      "23     \t [-0.17473294  0.57005767]. \t  0.8568815801968656 \t 0.9146183273252478\n",
      "24     \t [1.44701566 0.33238724]. \t  -2.316388533619125 \t 0.9146183273252478\n",
      "25     \t [ 0.48136872 -0.66949197]. \t  0.4932908091562123 \t 0.9146183273252478\n",
      "26     \t [-1.54756695 -2.        ]. \t  -53.208753157674025 \t 0.9146183273252478\n",
      "27     \t [ 1.91818368 -0.90709319]. \t  -0.568653725389906 \t 0.9146183273252478\n",
      "28     \t [ 1.63950348 -0.69406326]. \t  0.083895406527006 \t 0.9146183273252478\n",
      "29     \t [-1.63878835  2.        ]. \t  -46.77526489407053 \t 0.9146183273252478\n",
      "30     \t [1.82133519 2.        ]. \t  -53.970809387688774 \t 0.9146183273252478\n",
      "31     \t [ 3.         -0.92772756]. \t  -105.63717302435883 \t 0.9146183273252478\n",
      "32     \t [2.19017078 0.88029663]. \t  -8.888670044217513 \t 0.9146183273252478\n",
      "33     \t [-3.          0.88264452]. \t  -105.56356738731147 \t 0.9146183273252478\n",
      "34     \t [-0.27660183 -0.24917567]. \t  -0.12987941056093497 \t 0.9146183273252478\n",
      "35     \t [ 1.7048949  -1.28993737]. \t  -4.290038521155687 \t 0.9146183273252478\n",
      "36     \t [1.897727   0.55888837]. \t  -2.9399777910011653 \t 0.9146183273252478\n",
      "37     \t [0.21338145 0.75804749]. \t  0.6381601408169868 \t 0.9146183273252478\n",
      "38     \t [-1.96396837  0.59112841]. \t  -1.2437959547001798 \t 0.9146183273252478\n",
      "39     \t [-2.01062615 -0.60290566]. \t  -4.159938178814226 \t 0.9146183273252478\n",
      "40     \t [-1.62516414 -0.8640174 ]. \t  -2.704222069288915 \t 0.9146183273252478\n",
      "41     \t [-1.97726846 -0.06401985]. \t  -3.569564646675686 \t 0.9146183273252478\n",
      "42     \t [-0.41912645 -1.20453581]. \t  -3.7614168617663184 \t 0.9146183273252478\n",
      "43     \t [ 2.06023648 -2.        ]. \t  -48.514026456975756 \t 0.9146183273252478\n",
      "44     \t [-2.12480423 -1.40153848]. \t  -16.484479995092006 \t 0.9146183273252478\n",
      "45     \t [-1.14291138  1.37120326]. \t  -7.4373654186335365 \t 0.9146183273252478\n",
      "46     \t [-0.54326165 -0.59591133]. \t  -0.4138921863350017 \t 0.9146183273252478\n",
      "47     \t [3.         0.97681805]. \t  -111.65554838251346 \t 0.9146183273252478\n",
      "48     \t [1.80494025 1.18604934]. \t  -6.697917030341544 \t 0.9146183273252478\n",
      "49     \t [-2.06868506  1.40966289]. \t  -9.713562771316903 \t 0.9146183273252478\n",
      "50     \t [-1.76459273  1.0717834 ]. \t  -0.9497464737667313 \t 0.9146183273252478\n",
      "51     \t [ 0.17534233 -0.86099138]. \t  0.7970492077767111 \t 0.9146183273252478\n",
      "52     \t [0.18878046 2.        ]. \t  -48.5174611002851 \t 0.9146183273252478\n",
      "53     \t [ 0.32378908 -2.        ]. \t  -47.74908170560792 \t 0.9146183273252478\n",
      "54     \t [-3.         -1.29664017]. \t  -117.37156981833792 \t 0.9146183273252478\n",
      "55     \t [ 2.11866972 -0.43307143]. \t  -4.263138639785275 \t 0.9146183273252478\n",
      "56     \t [0.4015286  1.27287498]. \t  -5.122295108416738 \t 0.9146183273252478\n",
      "57     \t [-2.28011849  2.        ]. \t  -54.31535079051575 \t 0.9146183273252478\n",
      "58     \t [ 0.20724657 -0.29679214]. \t  0.21485827872041416 \t 0.9146183273252478\n",
      "59     \t [-2.19680977 -2.        ]. \t  -60.25414222202073 \t 0.9146183273252478\n",
      "60     \t [2.39727533 1.61523633]. \t  -37.562416011668596 \t 0.9146183273252478\n",
      "61     \t [ 2.39627254 -1.48785396]. \t  -24.018940657521693 \t 0.9146183273252478\n",
      "62     \t [-0.06428307  0.68765813]. \t  \u001b[92m1.0247680138300699\u001b[0m \t 1.0247680138300699\n",
      "63     \t [-0.04844288  0.70521372]. \t  1.0247587001612763 \t 1.0247680138300699\n",
      "64     \t [2.28503068 0.23217399]. \t  -11.409840297605035 \t 1.0247680138300699\n",
      "65     \t [-0.00438343  0.58922631]. \t  0.9090995162304639 \t 1.0247680138300699\n",
      "66     \t [ 0.08108062 -0.72735591]. \t  \u001b[92m1.0293940406391804\u001b[0m \t 1.0293940406391804\n",
      "67     \t [-0.04412372  0.64431218]. \t  0.9918436867766078 \t 1.0293940406391804\n",
      "68     \t [ 0.03709734 -0.73782969]. \t  1.0139878148003214 \t 1.0293940406391804\n",
      "69     \t [-2.25093316  1.01047615]. \t  -7.524776349262685 \t 1.0293940406391804\n",
      "70     \t [ 0.18092028 -0.75954051]. \t  0.9850703827209566 \t 1.0293940406391804\n",
      "71     \t [-0.04471968  0.70600677]. \t  1.0235717290135 \t 1.0293940406391804\n",
      "72     \t [ 0.03444805 -0.69104792]. \t  1.0170450271653777 \t 1.0293940406391804\n",
      "73     \t [ 0.05215591 -0.78889463]. \t  0.9703973722215119 \t 1.0293940406391804\n",
      "74     \t [0.01525185 0.69519898]. \t  0.9873512204766836 \t 1.0293940406391804\n",
      "75     \t [-0.00463599  0.65157543]. \t  0.980164240568754 \t 1.0293940406391804\n",
      "76     \t [-0.0458827   0.74972478]. \t  1.0105685108670952 \t 1.0293940406391804\n",
      "77     \t [ 0.05307187 -0.70787998]. \t  1.0263138855909013 \t 1.0293940406391804\n",
      "78     \t [-0.03914739  0.65346995]. \t  0.9981539156544212 \t 1.0293940406391804\n",
      "79     \t [-0.07502278  0.72984143]. \t  1.0280386011638607 \t 1.0293940406391804\n",
      "80     \t [-0.07288634  0.67096093]. \t  1.017788710963968 \t 1.0293940406391804\n",
      "81     \t [-0.02613287 -0.66001894]. \t  0.9634445139019858 \t 1.0293940406391804\n",
      "82     \t [ 0.12818647 -0.75043716]. \t  1.015079646015101 \t 1.0293940406391804\n",
      "83     \t [-0.03732842 -0.75118497]. \t  0.9498628034091683 \t 1.0293940406391804\n",
      "84     \t [ 0.07825957 -0.73821772]. \t  1.0252655048184187 \t 1.0293940406391804\n",
      "85     \t [-0.14195058  0.71075723]. \t  1.0210352915855325 \t 1.0293940406391804\n",
      "86     \t [ 0.09178941 -0.69378717]. \t  1.0287373140792695 \t 1.0293940406391804\n",
      "87     \t [ 0.20353068 -0.73916584]. \t  0.9797246188067641 \t 1.0293940406391804\n",
      "88     \t [2.38826309 2.        ]. \t  -69.12627579944481 \t 1.0293940406391804\n",
      "89     \t [-0.09002138  0.72210916]. \t  \u001b[92m1.030888626601323\u001b[0m \t 1.030888626601323\n",
      "90     \t [-0.0070915  -0.69535841]. \t  0.9937817865747615 \t 1.030888626601323\n",
      "91     \t [ 0.08553886 -0.72919643]. \t  1.0291928220397595 \t 1.030888626601323\n",
      "92     \t [ 0.06404474 -0.72893843]. \t  1.0263814645517908 \t 1.030888626601323\n",
      "93     \t [-0.09910076  0.72706411]. \t  1.029694069899476 \t 1.030888626601323\n",
      "94     \t [ 0.00906554 -0.75529962]. \t  0.9866501606470953 \t 1.030888626601323\n",
      "95     \t [ 0.14890507 -0.66070319]. \t  0.9946055463855392 \t 1.030888626601323\n",
      "96     \t [-0.10227721  0.5764368 ]. \t  0.9048224325142123 \t 1.030888626601323\n",
      "97     \t [ 0.18027056 -0.73534213]. \t  0.9981418848680104 \t 1.030888626601323\n",
      "98     \t [ 0.09859838 -0.80447604]. \t  0.9539818191353805 \t 1.030888626601323\n",
      "99     \t [ 0.01383825 -0.68304758]. \t  1.0042117324101505 \t 1.030888626601323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    \t [-0.14004912  0.68651306]. \t  1.0152011617377723 \t 1.030888626601323\n"
     ]
    }
   ],
   "source": [
    "### 6(t). Bayesian optimization runs (x20): STP DF1 run number = 20\n",
    "\n",
    "np.random.seed(run_num_20)\n",
    "surrogate_stp_df1_20 = tStudentProcess(cov_func, nu = df1, optimize = optimize)\n",
    "\n",
    "gpgo_stp_df1_20 = GPGO(surrogate_stp_df1_20, Acquisition_new(util_stp), f_syn_polarity, param, n_jobs = -1) # Define Bayesian optimisation;\n",
    "gpgo_stp_df1_20.run(max_iter = max_iter, init_evals = n_init) # Run Bayesian optimisation sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.214840895606928, -7.248313092068654)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 6(t). Training Regret Minimisation: run number = 20\n",
    "\n",
    "gp_output_20 = np.append(np.max(gpgo_gp_20.GP.y[0:n_init]),gpgo_gp_20.GP.y[n_init:(n_init+max_iter)]) \n",
    "stp_df1_output_20 = np.append(np.max(gpgo_stp_df1_20.GP.y[0:n_init]),gpgo_stp_df1_20.GP.y[n_init:(n_init+max_iter)])\n",
    "\n",
    "regret_gp_20 = np.log(y_global_orig - gp_output_20)\n",
    "regret_stp_df1_20 = np.log(y_global_orig - stp_df1_output_20)\n",
    "\n",
    "train_regret_gp_20 = min_max_array(regret_gp_20)\n",
    "train_regret_stp_df1_20 = min_max_array(regret_stp_df1_20)\n",
    "\n",
    "# GP, STP df1 - training regret minimization: run number = 20\n",
    "min_train_regret_gp_20 = min(train_regret_gp_20)\n",
    "min_train_regret_stp_df1_20 = min(train_regret_stp_df1_20)\n",
    "\n",
    "min_train_regret_gp_20, min_train_regret_stp_df1_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Run 11</th>\n",
       "      <td>-5.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 4</th>\n",
       "      <td>-5.945825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 1</th>\n",
       "      <td>-5.970904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 9</th>\n",
       "      <td>-6.256705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 14</th>\n",
       "      <td>-6.428622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 3</th>\n",
       "      <td>-6.451728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 19</th>\n",
       "      <td>-6.512650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 2</th>\n",
       "      <td>-6.708105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 6</th>\n",
       "      <td>-6.995756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 7</th>\n",
       "      <td>-7.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 8</th>\n",
       "      <td>-7.289033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 16</th>\n",
       "      <td>-7.620473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 5</th>\n",
       "      <td>-7.800841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 15</th>\n",
       "      <td>-7.928204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 17</th>\n",
       "      <td>-7.970378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 18</th>\n",
       "      <td>-8.110087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 20</th>\n",
       "      <td>-8.214841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 10</th>\n",
       "      <td>-8.668456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 13</th>\n",
       "      <td>-9.335755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 12</th>\n",
       "      <td>-11.744493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GP\n",
       "Run 11  -5.424900\n",
       "Run 4   -5.945825\n",
       "Run 1   -5.970904\n",
       "Run 9   -6.256705\n",
       "Run 14  -6.428622\n",
       "Run 3   -6.451728\n",
       "Run 19  -6.512650\n",
       "Run 2   -6.708105\n",
       "Run 6   -6.995756\n",
       "Run 7   -7.035996\n",
       "Run 8   -7.289033\n",
       "Run 16  -7.620473\n",
       "Run 5   -7.800841\n",
       "Run 15  -7.928204\n",
       "Run 17  -7.970378\n",
       "Run 18  -8.110087\n",
       "Run 20  -8.214841\n",
       "Run 10  -8.668456\n",
       "Run 13  -9.335755\n",
       "Run 12 -11.744493"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7(a). Sort GP results:\n",
    "\n",
    "gp_regret = [min_train_regret_gp_1,\n",
    "                 min_train_regret_gp_2,\n",
    "                 min_train_regret_gp_3,\n",
    "                 min_train_regret_gp_4,\n",
    "                 min_train_regret_gp_5,\n",
    "                 min_train_regret_gp_6,\n",
    "                 min_train_regret_gp_7,\n",
    "                 min_train_regret_gp_8,\n",
    "                 min_train_regret_gp_9,\n",
    "                 min_train_regret_gp_10,\n",
    "                 min_train_regret_gp_11,\n",
    "                 min_train_regret_gp_12,\n",
    "                 min_train_regret_gp_13,\n",
    "                 min_train_regret_gp_14,\n",
    "                 min_train_regret_gp_15,\n",
    "                 min_train_regret_gp_16,\n",
    "                 min_train_regret_gp_17,\n",
    "                 min_train_regret_gp_18,\n",
    "                 min_train_regret_gp_19,\n",
    "                 min_train_regret_gp_20]\n",
    "\n",
    "fields = [\"Run 1\",\"Run 2\",\"Run 3\",\"Run 4\",\"Run 5\",\"Run 6\",\"Run 7\",\"Run 8\",\"Run 9\",\"Run 10\",\n",
    "          \"Run 11\",\"Run 12\",\"Run 13\",\"Run 14\",\"Run 15\",\"Run 16\",\"Run 17\",\"Run 18\",\"Run 19\",\"Run 20\"]\n",
    "\n",
    "IndexTitle = [\"GP\"]\n",
    "\n",
    "gp_results = pd.DataFrame(gp_regret, fields, IndexTitle).sort_values(by=[\"GP\"], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp = gp_results[4:5]\n",
    "median_gp = gp_results[9:10]\n",
    "upper_gp = gp_results[14:15]\n",
    "best_gp = gp_results[19:20]\n",
    "\n",
    "gp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              GP\n",
       " Run 14 -6.428622,              GP\n",
       " Run 7 -7.035996,               GP\n",
       " Run 17 -7.970378)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7(b). Training regret minimization - GP:\n",
    "lower_gp, median_gp, upper_gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STP ($\\nu$ = 5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Run 1</th>\n",
       "      <td>-6.112563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 9</th>\n",
       "      <td>-6.485755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 2</th>\n",
       "      <td>-6.526757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 11</th>\n",
       "      <td>-6.607279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 3</th>\n",
       "      <td>-6.631318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 17</th>\n",
       "      <td>-6.671442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 14</th>\n",
       "      <td>-6.782682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 20</th>\n",
       "      <td>-7.248313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 13</th>\n",
       "      <td>-7.255323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 5</th>\n",
       "      <td>-7.418908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 4</th>\n",
       "      <td>-7.880140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 6</th>\n",
       "      <td>-8.143854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 10</th>\n",
       "      <td>-8.199405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 19</th>\n",
       "      <td>-8.403065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 7</th>\n",
       "      <td>-8.768405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 15</th>\n",
       "      <td>-9.218512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 8</th>\n",
       "      <td>-9.727489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 12</th>\n",
       "      <td>-11.743654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 16</th>\n",
       "      <td>-12.769692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run 18</th>\n",
       "      <td>-14.197935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STP ($\\nu$ = 5)\n",
       "Run 1         -6.112563\n",
       "Run 9         -6.485755\n",
       "Run 2         -6.526757\n",
       "Run 11        -6.607279\n",
       "Run 3         -6.631318\n",
       "Run 17        -6.671442\n",
       "Run 14        -6.782682\n",
       "Run 20        -7.248313\n",
       "Run 13        -7.255323\n",
       "Run 5         -7.418908\n",
       "Run 4         -7.880140\n",
       "Run 6         -8.143854\n",
       "Run 10        -8.199405\n",
       "Run 19        -8.403065\n",
       "Run 7         -8.768405\n",
       "Run 15        -9.218512\n",
       "Run 8         -9.727489\n",
       "Run 12       -11.743654\n",
       "Run 16       -12.769692\n",
       "Run 18       -14.197935"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7(c). Sort STP DF1 results:\n",
    "\n",
    "stp_df1_regret = [min_train_regret_stp_df1_1,\n",
    "                  min_train_regret_stp_df1_2,\n",
    "                  min_train_regret_stp_df1_3,\n",
    "                  min_train_regret_stp_df1_4,\n",
    "                  min_train_regret_stp_df1_5,\n",
    "                  min_train_regret_stp_df1_6,\n",
    "                  min_train_regret_stp_df1_7,\n",
    "                  min_train_regret_stp_df1_8,\n",
    "                  min_train_regret_stp_df1_9,\n",
    "                  min_train_regret_stp_df1_10,\n",
    "                  min_train_regret_stp_df1_11,\n",
    "                  min_train_regret_stp_df1_12,\n",
    "                  min_train_regret_stp_df1_13,\n",
    "                  min_train_regret_stp_df1_14,\n",
    "                  min_train_regret_stp_df1_15,\n",
    "                  min_train_regret_stp_df1_16,\n",
    "                  min_train_regret_stp_df1_17,\n",
    "                  min_train_regret_stp_df1_18,\n",
    "                  min_train_regret_stp_df1_19,\n",
    "                  min_train_regret_stp_df1_20]\n",
    "\n",
    "fields = [\"Run 1\",\"Run 2\",\"Run 3\",\"Run 4\",\"Run 5\",\"Run 6\",\"Run 7\",\"Run 8\",\"Run 9\",\"Run 10\",\n",
    "          \"Run 11\",\"Run 12\",\"Run 13\",\"Run 14\",\"Run 15\",\"Run 16\",\"Run 17\",\"Run 18\",\"Run 19\",\"Run 20\"]\n",
    "\n",
    "IndexTitle = ['STP ' r'($\\nu$' ' = {})'.format(df1)]\n",
    "\n",
    "stp_df1_results = pd.DataFrame(stp_df1_regret, fields, IndexTitle).sort_values(by=['STP ' r'($\\nu$' ' = {})'.format(df1)], ascending=False)\n",
    "\n",
    "### training regret minimization IQR - STP DF1:\n",
    "lower_stp_df1 = stp_df1_results[4:5]\n",
    "median_stp_df1 = stp_df1_results[9:10]\n",
    "upper_stp_df1 = stp_df1_results[14:15]\n",
    "best_stp_df1 = stp_df1_results[19:20]\n",
    "\n",
    "stp_df1_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       STP ($\\nu$ = 5)\n",
       " Run 3        -6.631318,        STP ($\\nu$ = 5)\n",
       " Run 5        -7.418908,        STP ($\\nu$ = 5)\n",
       " Run 7        -8.768405)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7(d). Sort STP DF 1 results:\n",
    "\n",
    "### Training regret minimization - STP DF1:\n",
    "lower_stp_df1, median_stp_df1, upper_stp_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              GP\n",
       " Run 14 -6.428622,               GP\n",
       " Run 17 -7.970378,        STP ($\\nu$ = 5)\n",
       " Run 3        -6.631318,        STP ($\\nu$ = 5)\n",
       " Run 7        -8.768405)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 8(a). IQR inputs:\n",
    "\n",
    "lower_gp, upper_gp, lower_stp_df1, upper_stp_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 8(b). Regret minimisation plot: GP v STP DF 1\n",
    "\n",
    "title = obj_func\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(train_regret_gp_7, label = 'GP ERM Regret: Median', marker = 'D', color = 'Red')\n",
    "plt.plot(train_regret_stp_df1_5, label = 'STP ERM Regret: Median ' r'($\\nu$' ' = {})'.format(df1), marker = '*', color = 'Blue')\n",
    "\n",
    "plt.title(title, weight = 'bold')\n",
    "plt.xlabel('(post-initialization) iteration $\\it{k}$', weight = 'bold') # x-axis label\n",
    "plt.ylabel('ln(Regret)', weight = 'bold') # y-axis label\n",
    "plt.legend(loc=0) # add plot legend\n",
    "\n",
    "plt.show() #visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 8(c). Regret minimisation plot: IQR GP v STP DF 1\n",
    "\n",
    "title = obj_func\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(train_regret_gp_7, marker = 'D', color = 'Red')\n",
    "plt.plot(train_regret_stp_df1_5, marker = '*', color = 'Blue')\n",
    "\n",
    "xstar = np.arange(0, 101, step=1)\n",
    "plt.fill_between(xstar, train_regret_gp_14, train_regret_gp_17, facecolor = 'Red', alpha=0.4, label='GP ERM Regret: IQR')\n",
    "plt.fill_between(xstar, train_regret_stp_df1_3, train_regret_stp_df1_7, facecolor = 'Blue', alpha=0.4, label='STP ERM Regret: IQR ' r'($\\nu$' ' = {})'.format(df1))\n",
    "\n",
    "plt.title(title, weight = 'bold')\n",
    "plt.xlabel('(post-initialization) iteration $\\it{k}$', weight = 'bold') # x-axis label\n",
    "plt.ylabel('ln(Regret)', weight = 'bold') # y-axis label\n",
    "plt.legend(loc=0) # add plot legend\n",
    "\n",
    "plt.show() #visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.453170815272413,\n",
       " 0.932583227627826,\n",
       " 0.2205341068195849,\n",
       " 1.453170815272413,\n",
       " 0.932583227627826,\n",
       " 0.2205341068195849)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration1 :\n",
    "\n",
    "slice1 = 0\n",
    "\n",
    "gp1 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp1 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp1_results = pd.DataFrame(gp1).sort_values(by=[0], ascending=False)\n",
    "stp1_results = pd.DataFrame(stp1).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp1 = np.asarray(gp1_results[4:5][0])[0]\n",
    "median_gp1 = np.asarray(gp1_results[9:10][0])[0]\n",
    "upper_gp1 = np.asarray(gp1_results[14:15][0])[0]\n",
    "\n",
    "lower_stp1 = np.asarray(stp1_results[4:5][0])[0]\n",
    "median_stp1 = np.asarray(stp1_results[9:10][0])[0]\n",
    "upper_stp1 = np.asarray(stp1_results[14:15][0])[0]\n",
    "\n",
    "lower_gp1, median_gp1, upper_gp1, lower_stp1, median_stp1, upper_stp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.18574583479583393,\n",
       " -1.281852554730428,\n",
       " -1.9392242470871357,\n",
       " 0.45661910965152,\n",
       " 0.20298679641378103,\n",
       " -0.2503205918108705)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration11 :\n",
    "\n",
    "slice11 = 10\n",
    "\n",
    "gp11 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp11 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp11_results = pd.DataFrame(gp11).sort_values(by=[0], ascending=False)\n",
    "stp11_results = pd.DataFrame(stp11).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp11 = np.asarray(gp11_results[4:5][0])[0]\n",
    "median_gp11 = np.asarray(gp11_results[9:10][0])[0]\n",
    "upper_gp11 = np.asarray(gp11_results[14:15][0])[0]\n",
    "\n",
    "lower_stp11 = np.asarray(stp11_results[4:5][0])[0]\n",
    "median_stp11 = np.asarray(stp11_results[9:10][0])[0]\n",
    "upper_stp11 = np.asarray(stp11_results[14:15][0])[0]\n",
    "\n",
    "lower_gp11, median_gp11, upper_gp11, lower_stp11, median_stp11, upper_stp11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.013085997393315,\n",
       " -2.2747938586831666,\n",
       " -3.567735794938741,\n",
       " -0.43410181958144467,\n",
       " -0.9847074607347619,\n",
       " -1.9536858526963758)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration21 :\n",
    "\n",
    "slice21 = 20\n",
    "\n",
    "gp21 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp21 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp21_results = pd.DataFrame(gp21).sort_values(by=[0], ascending=False)\n",
    "stp21_results = pd.DataFrame(stp21).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp21 = np.asarray(gp21_results[4:5][0])[0]\n",
    "median_gp21 = np.asarray(gp21_results[9:10][0])[0]\n",
    "upper_gp21 = np.asarray(gp21_results[14:15][0])[0]\n",
    "\n",
    "lower_stp21 = np.asarray(stp21_results[4:5][0])[0]\n",
    "median_stp21 = np.asarray(stp21_results[9:10][0])[0]\n",
    "upper_stp21 = np.asarray(stp21_results[14:15][0])[0]\n",
    "\n",
    "lower_gp21, median_gp21, upper_gp21, lower_stp21, median_stp21, upper_stp21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.0769829970776734,\n",
       " -3.567735794938741,\n",
       " -4.784946696880455,\n",
       " -1.1894626716130274,\n",
       " -1.84267799242898,\n",
       " -2.954558557712974)"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration31 :\n",
    "\n",
    "slice31 = 30\n",
    "\n",
    "gp31 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp31 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp31_results = pd.DataFrame(gp31).sort_values(by=[0], ascending=False)\n",
    "stp31_results = pd.DataFrame(stp31).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp31 = np.asarray(gp31_results[4:5][0])[0]\n",
    "median_gp31 = np.asarray(gp31_results[9:10][0])[0]\n",
    "upper_gp31 = np.asarray(gp31_results[14:15][0])[0]\n",
    "\n",
    "lower_stp31 = np.asarray(stp31_results[4:5][0])[0]\n",
    "median_stp31 = np.asarray(stp31_results[9:10][0])[0]\n",
    "upper_stp31 = np.asarray(stp31_results[14:15][0])[0]\n",
    "\n",
    "lower_gp31, median_gp31, upper_gp31, lower_stp31, median_stp31, upper_stp31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.5328519604015534,\n",
       " -4.329036256882474,\n",
       " -6.085550974184749,\n",
       " -1.3725104883580868,\n",
       " -2.14573800025984,\n",
       " -3.1027977473374513)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration41 :\n",
    "\n",
    "slice41 = 40\n",
    "\n",
    "gp41 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp41 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp41_results = pd.DataFrame(gp41).sort_values(by=[0], ascending=False)\n",
    "stp41_results = pd.DataFrame(stp41).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp41 = np.asarray(gp41_results[4:5][0])[0]\n",
    "median_gp41 = np.asarray(gp41_results[9:10][0])[0]\n",
    "upper_gp41 = np.asarray(gp41_results[14:15][0])[0]\n",
    "\n",
    "lower_stp41 = np.asarray(stp41_results[4:5][0])[0]\n",
    "median_stp41 = np.asarray(stp41_results[9:10][0])[0]\n",
    "upper_stp41 = np.asarray(stp41_results[14:15][0])[0]\n",
    "\n",
    "lower_gp41, median_gp41, upper_gp41, lower_stp41, median_stp41, upper_stp41\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.7512393232368244,\n",
       " -4.983037282468382,\n",
       " -6.512649538397736,\n",
       " -1.84267799242898,\n",
       " -2.7098704090117267,\n",
       " -3.1401899289982773)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration51 :\n",
    "\n",
    "slice51 = 50\n",
    "\n",
    "gp51 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp51 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp51_results = pd.DataFrame(gp51).sort_values(by=[0], ascending=False)\n",
    "stp51_results = pd.DataFrame(stp51).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp51 = np.asarray(gp51_results[4:5][0])[0]\n",
    "median_gp51 = np.asarray(gp51_results[9:10][0])[0]\n",
    "upper_gp51 = np.asarray(gp51_results[14:15][0])[0]\n",
    "\n",
    "lower_stp51 = np.asarray(stp51_results[4:5][0])[0]\n",
    "median_stp51 = np.asarray(stp51_results[9:10][0])[0]\n",
    "upper_stp51 = np.asarray(stp51_results[14:15][0])[0]\n",
    "\n",
    "lower_gp51, median_gp51, upper_gp51, lower_stp51, median_stp51, upper_stp51\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.983037282468382,\n",
       " -5.809000589194058,\n",
       " -6.824744002284245,\n",
       " -2.954558557712974,\n",
       " -3.7236168929840363,\n",
       " -5.279426808928781)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration61 :\n",
    "\n",
    "slice61 = 60\n",
    "\n",
    "gp61 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp61 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp61_results = pd.DataFrame(gp61).sort_values(by=[0], ascending=False)\n",
    "stp61_results = pd.DataFrame(stp61).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp61 = np.asarray(gp61_results[4:5][0])[0]\n",
    "median_gp61 = np.asarray(gp61_results[9:10][0])[0]\n",
    "upper_gp61 = np.asarray(gp61_results[14:15][0])[0]\n",
    "\n",
    "lower_stp61 = np.asarray(stp61_results[4:5][0])[0]\n",
    "median_stp61 = np.asarray(stp61_results[9:10][0])[0]\n",
    "upper_stp61 = np.asarray(stp61_results[14:15][0])[0]\n",
    "\n",
    "lower_gp61, median_gp61, upper_gp61, lower_stp61, median_stp61, upper_stp61\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.034759677296762,\n",
       " -6.053350161324649,\n",
       " -7.188855437458066,\n",
       " -5.674642959152586,\n",
       " -6.445675885433328,\n",
       " -6.782682110683666)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration71 :\n",
    "\n",
    "slice71 = 70\n",
    "\n",
    "gp71 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp71 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp71_results = pd.DataFrame(gp71).sort_values(by=[0], ascending=False)\n",
    "stp71_results = pd.DataFrame(stp71).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp71 = np.asarray(gp71_results[4:5][0])[0]\n",
    "median_gp71 = np.asarray(gp71_results[9:10][0])[0]\n",
    "upper_gp71 = np.asarray(gp71_results[14:15][0])[0]\n",
    "\n",
    "lower_stp71 = np.asarray(stp71_results[4:5][0])[0]\n",
    "median_stp71 = np.asarray(stp71_results[9:10][0])[0]\n",
    "upper_stp71 = np.asarray(stp71_results[14:15][0])[0]\n",
    "\n",
    "lower_gp71, median_gp71, upper_gp71, lower_stp71, median_stp71, upper_stp71\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.346452056822993,\n",
       " -6.451728156644326,\n",
       " -7.800841090559586,\n",
       " -6.315929342219681,\n",
       " -6.782682110683666,\n",
       " -8.403064768818009)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration81 :\n",
    "\n",
    "slice81 = 80\n",
    "\n",
    "gp81 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp81 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp81_results = pd.DataFrame(gp81).sort_values(by=[0], ascending=False)\n",
    "stp81_results = pd.DataFrame(stp81).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp81 = np.asarray(gp81_results[4:5][0])[0]\n",
    "median_gp81 = np.asarray(gp81_results[9:10][0])[0]\n",
    "upper_gp81 = np.asarray(gp81_results[14:15][0])[0]\n",
    "\n",
    "lower_stp81 = np.asarray(stp81_results[4:5][0])[0]\n",
    "median_stp81 = np.asarray(stp81_results[9:10][0])[0]\n",
    "upper_stp81 = np.asarray(stp81_results[14:15][0])[0]\n",
    "\n",
    "lower_gp81, median_gp81, upper_gp81, lower_stp81, median_stp81, upper_stp81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.053350161324649,\n",
       " -6.708104661818667,\n",
       " -7.928203586916229,\n",
       " -6.671442029397026,\n",
       " -7.418907526359189,\n",
       " -8.403064768818009)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration91 :\n",
    "\n",
    "slice1 = 90\n",
    "\n",
    "gp91 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp91 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp91_results = pd.DataFrame(gp91).sort_values(by=[0], ascending=False)\n",
    "stp91_results = pd.DataFrame(stp91).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp91 = np.asarray(gp91_results[4:5][0])[0]\n",
    "median_gp91 = np.asarray(gp91_results[9:10][0])[0]\n",
    "upper_gp91 = np.asarray(gp91_results[14:15][0])[0]\n",
    "\n",
    "lower_stp91 = np.asarray(stp91_results[4:5][0])[0]\n",
    "median_stp91 = np.asarray(stp91_results[9:10][0])[0]\n",
    "upper_stp91 = np.asarray(stp91_results[14:15][0])[0]\n",
    "\n",
    "lower_gp91, median_gp91, upper_gp91, lower_stp91, median_stp91, upper_stp91\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.428621848660673,\n",
       " -7.035995711203121,\n",
       " -7.970378024819956,\n",
       " -6.671442029397026,\n",
       " -7.880139912603991,\n",
       " -9.21851242614693)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration101 :\n",
    "\n",
    "slice1 = 100\n",
    "\n",
    "gp101 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp101 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp101_results = pd.DataFrame(gp101).sort_values(by=[0], ascending=False)\n",
    "stp101_results = pd.DataFrame(stp101).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp101 = np.asarray(gp101_results[4:5][0])[0]\n",
    "median_gp101 = np.asarray(gp101_results[9:10][0])[0]\n",
    "upper_gp101 = np.asarray(gp101_results[14:15][0])[0]\n",
    "\n",
    "lower_stp101 = np.asarray(stp101_results[4:5][0])[0]\n",
    "median_stp101 = np.asarray(stp101_results[9:10][0])[0]\n",
    "upper_stp101 = np.asarray(stp101_results[14:15][0])[0]\n",
    "\n",
    "lower_gp101, median_gp101, upper_gp101, lower_stp101, median_stp101, upper_stp101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration2 :\n",
    "\n",
    "slice1 = 1\n",
    "\n",
    "gp2 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp2 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp2_results = pd.DataFrame(gp2).sort_values(by=[0], ascending=False)\n",
    "stp2_results = pd.DataFrame(stp2).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp2 = np.asarray(gp2_results[4:5][0])[0]\n",
    "median_gp2 = np.asarray(gp2_results[9:10][0])[0]\n",
    "upper_gp2 = np.asarray(gp2_results[14:15][0])[0]\n",
    "\n",
    "lower_stp2 = np.asarray(stp2_results[4:5][0])[0]\n",
    "median_stp2 = np.asarray(stp2_results[9:10][0])[0]\n",
    "upper_stp2 = np.asarray(stp2_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration12 :\n",
    "\n",
    "slice11 = 11\n",
    "\n",
    "gp12 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp12 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp12_results = pd.DataFrame(gp12).sort_values(by=[0], ascending=False)\n",
    "stp12_results = pd.DataFrame(stp12).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp12 = np.asarray(gp12_results[4:5][0])[0]\n",
    "median_gp12 = np.asarray(gp12_results[9:10][0])[0]\n",
    "upper_gp12 = np.asarray(gp12_results[14:15][0])[0]\n",
    "\n",
    "lower_stp12 = np.asarray(stp12_results[4:5][0])[0]\n",
    "median_stp12 = np.asarray(stp12_results[9:10][0])[0]\n",
    "upper_stp12 = np.asarray(stp12_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration22 :\n",
    "\n",
    "slice21 = 21\n",
    "\n",
    "gp22 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp22 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp22_results = pd.DataFrame(gp22).sort_values(by=[0], ascending=False)\n",
    "stp22_results = pd.DataFrame(stp22).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp22 = np.asarray(gp22_results[4:5][0])[0]\n",
    "median_gp22 = np.asarray(gp22_results[9:10][0])[0]\n",
    "upper_gp22 = np.asarray(gp22_results[14:15][0])[0]\n",
    "\n",
    "lower_stp22 = np.asarray(stp22_results[4:5][0])[0]\n",
    "median_stp22 = np.asarray(stp22_results[9:10][0])[0]\n",
    "upper_stp22 = np.asarray(stp22_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration32 :\n",
    "\n",
    "slice31 = 31\n",
    "\n",
    "gp32 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp32 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp32_results = pd.DataFrame(gp32).sort_values(by=[0], ascending=False)\n",
    "stp32_results = pd.DataFrame(stp32).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp32 = np.asarray(gp32_results[4:5][0])[0]\n",
    "median_gp32 = np.asarray(gp32_results[9:10][0])[0]\n",
    "upper_gp32 = np.asarray(gp32_results[14:15][0])[0]\n",
    "\n",
    "lower_stp32 = np.asarray(stp32_results[4:5][0])[0]\n",
    "median_stp32 = np.asarray(stp32_results[9:10][0])[0]\n",
    "upper_stp32 = np.asarray(stp32_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration42 :\n",
    "\n",
    "slice41 = 41\n",
    "\n",
    "gp42 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp42 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp42_results = pd.DataFrame(gp42).sort_values(by=[0], ascending=False)\n",
    "stp42_results = pd.DataFrame(stp42).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp42 = np.asarray(gp42_results[4:5][0])[0]\n",
    "median_gp42 = np.asarray(gp42_results[9:10][0])[0]\n",
    "upper_gp42 = np.asarray(gp42_results[14:15][0])[0]\n",
    "\n",
    "lower_stp42 = np.asarray(stp42_results[4:5][0])[0]\n",
    "median_stp42 = np.asarray(stp42_results[9:10][0])[0]\n",
    "upper_stp42 = np.asarray(stp42_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration52 :\n",
    "\n",
    "slice51 = 51\n",
    "\n",
    "gp52 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp52 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp52_results = pd.DataFrame(gp52).sort_values(by=[0], ascending=False)\n",
    "stp52_results = pd.DataFrame(stp52).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp52 = np.asarray(gp52_results[4:5][0])[0]\n",
    "median_gp52 = np.asarray(gp52_results[9:10][0])[0]\n",
    "upper_gp52 = np.asarray(gp52_results[14:15][0])[0]\n",
    "\n",
    "lower_stp52 = np.asarray(stp52_results[4:5][0])[0]\n",
    "median_stp52 = np.asarray(stp52_results[9:10][0])[0]\n",
    "upper_stp52 = np.asarray(stp52_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration62 :\n",
    "\n",
    "slice61 = 61\n",
    "\n",
    "gp62 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp62 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp62_results = pd.DataFrame(gp62).sort_values(by=[0], ascending=False)\n",
    "stp62_results = pd.DataFrame(stp62).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp62 = np.asarray(gp62_results[4:5][0])[0]\n",
    "median_gp62 = np.asarray(gp62_results[9:10][0])[0]\n",
    "upper_gp62 = np.asarray(gp62_results[14:15][0])[0]\n",
    "\n",
    "lower_stp62 = np.asarray(stp62_results[4:5][0])[0]\n",
    "median_stp62 = np.asarray(stp62_results[9:10][0])[0]\n",
    "upper_stp62 = np.asarray(stp62_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration72 :\n",
    "\n",
    "slice71 = 71\n",
    "\n",
    "gp72 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp72 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp72_results = pd.DataFrame(gp72).sort_values(by=[0], ascending=False)\n",
    "stp72_results = pd.DataFrame(stp72).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp72 = np.asarray(gp72_results[4:5][0])[0]\n",
    "median_gp72 = np.asarray(gp72_results[9:10][0])[0]\n",
    "upper_gp72 = np.asarray(gp72_results[14:15][0])[0]\n",
    "\n",
    "lower_stp72 = np.asarray(stp72_results[4:5][0])[0]\n",
    "median_stp72 = np.asarray(stp72_results[9:10][0])[0]\n",
    "upper_stp72 = np.asarray(stp72_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration82 :\n",
    "\n",
    "slice81 = 81\n",
    "\n",
    "gp82 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp82 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp82_results = pd.DataFrame(gp82).sort_values(by=[0], ascending=False)\n",
    "stp82_results = pd.DataFrame(stp82).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp82 = np.asarray(gp82_results[4:5][0])[0]\n",
    "median_gp82 = np.asarray(gp82_results[9:10][0])[0]\n",
    "upper_gp82 = np.asarray(gp82_results[14:15][0])[0]\n",
    "\n",
    "lower_stp82 = np.asarray(stp82_results[4:5][0])[0]\n",
    "median_stp82 = np.asarray(stp82_results[9:10][0])[0]\n",
    "upper_stp82 = np.asarray(stp82_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration92 :\n",
    "\n",
    "slice1 = 91\n",
    "\n",
    "gp92 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp92 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp92_results = pd.DataFrame(gp92).sort_values(by=[0], ascending=False)\n",
    "stp92_results = pd.DataFrame(stp92).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp92 = np.asarray(gp92_results[4:5][0])[0]\n",
    "median_gp92 = np.asarray(gp92_results[9:10][0])[0]\n",
    "upper_gp92 = np.asarray(gp92_results[14:15][0])[0]\n",
    "\n",
    "lower_stp92 = np.asarray(stp92_results[4:5][0])[0]\n",
    "median_stp92 = np.asarray(stp92_results[9:10][0])[0]\n",
    "upper_stp92 = np.asarray(stp92_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration3 :\n",
    "\n",
    "slice1 = 2\n",
    "\n",
    "gp3 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp3 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp3_results = pd.DataFrame(gp3).sort_values(by=[0], ascending=False)\n",
    "stp3_results = pd.DataFrame(stp3).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp3 = np.asarray(gp3_results[4:5][0])[0]\n",
    "median_gp3 = np.asarray(gp3_results[9:10][0])[0]\n",
    "upper_gp3 = np.asarray(gp3_results[14:15][0])[0]\n",
    "\n",
    "lower_stp3 = np.asarray(stp3_results[4:5][0])[0]\n",
    "median_stp3 = np.asarray(stp3_results[9:10][0])[0]\n",
    "upper_stp3 = np.asarray(stp3_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration13 :\n",
    "\n",
    "slice11 = 12\n",
    "\n",
    "gp13 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp13 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp13_results = pd.DataFrame(gp12).sort_values(by=[0], ascending=False)\n",
    "stp13_results = pd.DataFrame(stp12).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp13 = np.asarray(gp13_results[4:5][0])[0]\n",
    "median_gp13 = np.asarray(gp13_results[9:10][0])[0]\n",
    "upper_gp13 = np.asarray(gp13_results[14:15][0])[0]\n",
    "\n",
    "lower_stp13 = np.asarray(stp13_results[4:5][0])[0]\n",
    "median_stp13 = np.asarray(stp13_results[9:10][0])[0]\n",
    "upper_stp13 = np.asarray(stp13_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration23 :\n",
    "\n",
    "slice21 = 22\n",
    "\n",
    "gp23 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp23 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp23_results = pd.DataFrame(gp23).sort_values(by=[0], ascending=False)\n",
    "stp23_results = pd.DataFrame(stp23).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp23 = np.asarray(gp23_results[4:5][0])[0]\n",
    "median_gp23 = np.asarray(gp23_results[9:10][0])[0]\n",
    "upper_gp23 = np.asarray(gp23_results[14:15][0])[0]\n",
    "\n",
    "lower_stp23 = np.asarray(stp23_results[4:5][0])[0]\n",
    "median_stp23 = np.asarray(stp23_results[9:10][0])[0]\n",
    "upper_stp23 = np.asarray(stp23_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration33 :\n",
    "\n",
    "slice31 = 32\n",
    "\n",
    "gp33 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp33 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp33_results = pd.DataFrame(gp33).sort_values(by=[0], ascending=False)\n",
    "stp33_results = pd.DataFrame(stp33).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp33 = np.asarray(gp33_results[4:5][0])[0]\n",
    "median_gp33 = np.asarray(gp33_results[9:10][0])[0]\n",
    "upper_gp33 = np.asarray(gp33_results[14:15][0])[0]\n",
    "\n",
    "lower_stp33 = np.asarray(stp33_results[4:5][0])[0]\n",
    "median_stp33 = np.asarray(stp33_results[9:10][0])[0]\n",
    "upper_stp33 = np.asarray(stp33_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration43 :\n",
    "\n",
    "slice41 = 42\n",
    "\n",
    "gp43 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp43 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp43_results = pd.DataFrame(gp43).sort_values(by=[0], ascending=False)\n",
    "stp43_results = pd.DataFrame(stp43).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp43 = np.asarray(gp43_results[4:5][0])[0]\n",
    "median_gp43 = np.asarray(gp43_results[9:10][0])[0]\n",
    "upper_gp43 = np.asarray(gp43_results[14:15][0])[0]\n",
    "\n",
    "lower_stp43 = np.asarray(stp43_results[4:5][0])[0]\n",
    "median_stp43 = np.asarray(stp43_results[9:10][0])[0]\n",
    "upper_stp43 = np.asarray(stp43_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration53 :\n",
    "\n",
    "slice51 = 52\n",
    "\n",
    "gp53 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp53 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp53_results = pd.DataFrame(gp53).sort_values(by=[0], ascending=False)\n",
    "stp53_results = pd.DataFrame(stp53).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp53 = np.asarray(gp53_results[4:5][0])[0]\n",
    "median_gp53 = np.asarray(gp53_results[9:10][0])[0]\n",
    "upper_gp53 = np.asarray(gp53_results[14:15][0])[0]\n",
    "\n",
    "lower_stp53 = np.asarray(stp53_results[4:5][0])[0]\n",
    "median_stp53 = np.asarray(stp53_results[9:10][0])[0]\n",
    "upper_stp53 = np.asarray(stp53_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration63 :\n",
    "\n",
    "slice61 = 62\n",
    "\n",
    "gp63 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp63 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp63_results = pd.DataFrame(gp63).sort_values(by=[0], ascending=False)\n",
    "stp63_results = pd.DataFrame(stp63).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp63 = np.asarray(gp63_results[4:5][0])[0]\n",
    "median_gp63 = np.asarray(gp63_results[9:10][0])[0]\n",
    "upper_gp63 = np.asarray(gp63_results[14:15][0])[0]\n",
    "\n",
    "lower_stp63 = np.asarray(stp63_results[4:5][0])[0]\n",
    "median_stp63 = np.asarray(stp63_results[9:10][0])[0]\n",
    "upper_stp63 = np.asarray(stp63_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration73 :\n",
    "\n",
    "slice71 = 72\n",
    "\n",
    "gp73 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp73 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp73_results = pd.DataFrame(gp73).sort_values(by=[0], ascending=False)\n",
    "stp73_results = pd.DataFrame(stp73).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp73 = np.asarray(gp73_results[4:5][0])[0]\n",
    "median_gp73 = np.asarray(gp73_results[9:10][0])[0]\n",
    "upper_gp73 = np.asarray(gp73_results[14:15][0])[0]\n",
    "\n",
    "lower_stp73 = np.asarray(stp73_results[4:5][0])[0]\n",
    "median_stp73 = np.asarray(stp73_results[9:10][0])[0]\n",
    "upper_stp73 = np.asarray(stp73_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration83 :\n",
    "\n",
    "slice81 = 82\n",
    "\n",
    "gp83 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp83 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp83_results = pd.DataFrame(gp83).sort_values(by=[0], ascending=False)\n",
    "stp83_results = pd.DataFrame(stp83).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp83 = np.asarray(gp83_results[4:5][0])[0]\n",
    "median_gp83 = np.asarray(gp83_results[9:10][0])[0]\n",
    "upper_gp83 = np.asarray(gp83_results[14:15][0])[0]\n",
    "\n",
    "lower_stp83 = np.asarray(stp83_results[4:5][0])[0]\n",
    "median_stp83 = np.asarray(stp83_results[9:10][0])[0]\n",
    "upper_stp83 = np.asarray(stp83_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration93 :\n",
    "\n",
    "slice1 = 92\n",
    "\n",
    "gp93 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp93 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp93_results = pd.DataFrame(gp93).sort_values(by=[0], ascending=False)\n",
    "stp93_results = pd.DataFrame(stp93).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp93 = np.asarray(gp93_results[4:5][0])[0]\n",
    "median_gp93 = np.asarray(gp93_results[9:10][0])[0]\n",
    "upper_gp93 = np.asarray(gp93_results[14:15][0])[0]\n",
    "\n",
    "lower_stp93 = np.asarray(stp93_results[4:5][0])[0]\n",
    "median_stp93 = np.asarray(stp93_results[9:10][0])[0]\n",
    "upper_stp93 = np.asarray(stp93_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration4 :\n",
    "\n",
    "slice1 = 3\n",
    "\n",
    "gp4 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp4 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp4_results = pd.DataFrame(gp4).sort_values(by=[0], ascending=False)\n",
    "stp4_results = pd.DataFrame(stp4).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp4 = np.asarray(gp4_results[4:5][0])[0]\n",
    "median_gp4 = np.asarray(gp4_results[9:10][0])[0]\n",
    "upper_gp4 = np.asarray(gp4_results[14:15][0])[0]\n",
    "\n",
    "lower_stp4 = np.asarray(stp4_results[4:5][0])[0]\n",
    "median_stp4 = np.asarray(stp4_results[9:10][0])[0]\n",
    "upper_stp4 = np.asarray(stp4_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration14 :\n",
    "\n",
    "slice11 = 13\n",
    "\n",
    "gp14 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp14 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp14_results = pd.DataFrame(gp14).sort_values(by=[0], ascending=False)\n",
    "stp14_results = pd.DataFrame(stp14).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp14 = np.asarray(gp14_results[4:5][0])[0]\n",
    "median_gp14 = np.asarray(gp14_results[9:10][0])[0]\n",
    "upper_gp14 = np.asarray(gp14_results[14:15][0])[0]\n",
    "\n",
    "lower_stp14 = np.asarray(stp14_results[4:5][0])[0]\n",
    "median_stp14 = np.asarray(stp14_results[9:10][0])[0]\n",
    "upper_stp14 = np.asarray(stp14_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration24 :\n",
    "\n",
    "slice21 = 23\n",
    "\n",
    "gp24 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp24 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp24_results = pd.DataFrame(gp24).sort_values(by=[0], ascending=False)\n",
    "stp24_results = pd.DataFrame(stp24).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp24 = np.asarray(gp24_results[4:5][0])[0]\n",
    "median_gp24 = np.asarray(gp24_results[9:10][0])[0]\n",
    "upper_gp24 = np.asarray(gp24_results[14:15][0])[0]\n",
    "\n",
    "lower_stp24 = np.asarray(stp24_results[4:5][0])[0]\n",
    "median_stp24 = np.asarray(stp24_results[9:10][0])[0]\n",
    "upper_stp24 = np.asarray(stp24_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration34 :\n",
    "\n",
    "slice31 = 33\n",
    "\n",
    "gp34 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp34 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp34_results = pd.DataFrame(gp34).sort_values(by=[0], ascending=False)\n",
    "stp34_results = pd.DataFrame(stp34).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp34 = np.asarray(gp34_results[4:5][0])[0]\n",
    "median_gp34 = np.asarray(gp34_results[9:10][0])[0]\n",
    "upper_gp34 = np.asarray(gp34_results[14:15][0])[0]\n",
    "\n",
    "lower_stp34 = np.asarray(stp34_results[4:5][0])[0]\n",
    "median_stp34 = np.asarray(stp34_results[9:10][0])[0]\n",
    "upper_stp34 = np.asarray(stp34_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration44 :\n",
    "\n",
    "slice41 = 43\n",
    "\n",
    "gp44 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp44 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp44_results = pd.DataFrame(gp44).sort_values(by=[0], ascending=False)\n",
    "stp44_results = pd.DataFrame(stp44).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp44 = np.asarray(gp44_results[4:5][0])[0]\n",
    "median_gp44 = np.asarray(gp44_results[9:10][0])[0]\n",
    "upper_gp44 = np.asarray(gp44_results[14:15][0])[0]\n",
    "\n",
    "lower_stp44 = np.asarray(stp44_results[4:5][0])[0]\n",
    "median_stp44 = np.asarray(stp44_results[9:10][0])[0]\n",
    "upper_stp44 = np.asarray(stp44_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration54 :\n",
    "\n",
    "slice51 = 53\n",
    "\n",
    "gp54 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp54 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp54_results = pd.DataFrame(gp54).sort_values(by=[0], ascending=False)\n",
    "stp54_results = pd.DataFrame(stp54).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp54 = np.asarray(gp54_results[4:5][0])[0]\n",
    "median_gp54 = np.asarray(gp54_results[9:10][0])[0]\n",
    "upper_gp54 = np.asarray(gp54_results[14:15][0])[0]\n",
    "\n",
    "lower_stp54 = np.asarray(stp54_results[4:5][0])[0]\n",
    "median_stp54 = np.asarray(stp54_results[9:10][0])[0]\n",
    "upper_stp54 = np.asarray(stp54_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration64 :\n",
    "\n",
    "slice61 = 63\n",
    "\n",
    "gp64 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp64 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp64_results = pd.DataFrame(gp64).sort_values(by=[0], ascending=False)\n",
    "stp64_results = pd.DataFrame(stp64).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp64 = np.asarray(gp64_results[4:5][0])[0]\n",
    "median_gp64 = np.asarray(gp64_results[9:10][0])[0]\n",
    "upper_gp64 = np.asarray(gp64_results[14:15][0])[0]\n",
    "\n",
    "lower_stp64 = np.asarray(stp64_results[4:5][0])[0]\n",
    "median_stp64 = np.asarray(stp64_results[9:10][0])[0]\n",
    "upper_stp64 = np.asarray(stp64_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration74 :\n",
    "\n",
    "slice71 = 73\n",
    "\n",
    "gp74 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp74 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp74_results = pd.DataFrame(gp74).sort_values(by=[0], ascending=False)\n",
    "stp74_results = pd.DataFrame(stp74).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp74 = np.asarray(gp74_results[4:5][0])[0]\n",
    "median_gp74 = np.asarray(gp74_results[9:10][0])[0]\n",
    "upper_gp74 = np.asarray(gp74_results[14:15][0])[0]\n",
    "\n",
    "lower_stp74 = np.asarray(stp74_results[4:5][0])[0]\n",
    "median_stp74 = np.asarray(stp74_results[9:10][0])[0]\n",
    "upper_stp74 = np.asarray(stp74_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration84 :\n",
    "\n",
    "slice81 = 83\n",
    "\n",
    "gp84 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp84 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp84_results = pd.DataFrame(gp84).sort_values(by=[0], ascending=False)\n",
    "stp84_results = pd.DataFrame(stp84).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp84 = np.asarray(gp84_results[4:5][0])[0]\n",
    "median_gp84 = np.asarray(gp84_results[9:10][0])[0]\n",
    "upper_gp84 = np.asarray(gp84_results[14:15][0])[0]\n",
    "\n",
    "lower_stp84 = np.asarray(stp84_results[4:5][0])[0]\n",
    "median_stp84 = np.asarray(stp84_results[9:10][0])[0]\n",
    "upper_stp84 = np.asarray(stp84_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration94 :\n",
    "\n",
    "slice1 = 93\n",
    "\n",
    "gp94 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp94 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp94_results = pd.DataFrame(gp94).sort_values(by=[0], ascending=False)\n",
    "stp94_results = pd.DataFrame(stp94).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp94 = np.asarray(gp94_results[4:5][0])[0]\n",
    "median_gp94 = np.asarray(gp94_results[9:10][0])[0]\n",
    "upper_gp94 = np.asarray(gp94_results[14:15][0])[0]\n",
    "\n",
    "lower_stp94 = np.asarray(stp94_results[4:5][0])[0]\n",
    "median_stp94 = np.asarray(stp94_results[9:10][0])[0]\n",
    "upper_stp94 = np.asarray(stp94_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration5 :\n",
    "\n",
    "slice1 = 4\n",
    "\n",
    "gp5 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp5 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp5_results = pd.DataFrame(gp5).sort_values(by=[0], ascending=False)\n",
    "stp5_results = pd.DataFrame(stp5).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp5 = np.asarray(gp5_results[4:5][0])[0]\n",
    "median_gp5 = np.asarray(gp5_results[9:10][0])[0]\n",
    "upper_gp5 = np.asarray(gp5_results[14:15][0])[0]\n",
    "\n",
    "lower_stp5 = np.asarray(stp5_results[4:5][0])[0]\n",
    "median_stp5 = np.asarray(stp5_results[9:10][0])[0]\n",
    "upper_stp5 = np.asarray(stp5_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration15 :\n",
    "\n",
    "slice11 = 14\n",
    "\n",
    "gp15 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp15 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp15_results = pd.DataFrame(gp15).sort_values(by=[0], ascending=False)\n",
    "stp15_results = pd.DataFrame(stp15).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp15 = np.asarray(gp15_results[4:5][0])[0]\n",
    "median_gp15 = np.asarray(gp15_results[9:10][0])[0]\n",
    "upper_gp15 = np.asarray(gp15_results[14:15][0])[0]\n",
    "\n",
    "lower_stp15 = np.asarray(stp15_results[4:5][0])[0]\n",
    "median_stp15 = np.asarray(stp15_results[9:10][0])[0]\n",
    "upper_stp15 = np.asarray(stp15_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration25 :\n",
    "\n",
    "slice21 = 24\n",
    "\n",
    "gp25 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp25 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp25_results = pd.DataFrame(gp25).sort_values(by=[0], ascending=False)\n",
    "stp25_results = pd.DataFrame(stp25).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp25 = np.asarray(gp25_results[4:5][0])[0]\n",
    "median_gp25 = np.asarray(gp25_results[9:10][0])[0]\n",
    "upper_gp25 = np.asarray(gp25_results[14:15][0])[0]\n",
    "\n",
    "lower_stp25 = np.asarray(stp25_results[4:5][0])[0]\n",
    "median_stp25 = np.asarray(stp25_results[9:10][0])[0]\n",
    "upper_stp25= np.asarray(stp25_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration35 :\n",
    "\n",
    "slice31 = 34\n",
    "\n",
    "gp35 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp35 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp35_results = pd.DataFrame(gp35).sort_values(by=[0], ascending=False)\n",
    "stp35_results = pd.DataFrame(stp35).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp35 = np.asarray(gp35_results[4:5][0])[0]\n",
    "median_gp35 = np.asarray(gp35_results[9:10][0])[0]\n",
    "upper_gp35 = np.asarray(gp35_results[14:15][0])[0]\n",
    "\n",
    "lower_stp35 = np.asarray(stp35_results[4:5][0])[0]\n",
    "median_stp35 = np.asarray(stp35_results[9:10][0])[0]\n",
    "upper_stp35 = np.asarray(stp35_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration45 :\n",
    "\n",
    "slice41 = 44\n",
    "\n",
    "gp45 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp45 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp45_results = pd.DataFrame(gp45).sort_values(by=[0], ascending=False)\n",
    "stp45_results = pd.DataFrame(stp45).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp45 = np.asarray(gp45_results[4:5][0])[0]\n",
    "median_gp45 = np.asarray(gp45_results[9:10][0])[0]\n",
    "upper_gp45 = np.asarray(gp45_results[14:15][0])[0]\n",
    "\n",
    "lower_stp45 = np.asarray(stp45_results[4:5][0])[0]\n",
    "median_stp45 = np.asarray(stp45_results[9:10][0])[0]\n",
    "upper_stp45 = np.asarray(stp45_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration55 :\n",
    "\n",
    "slice51 = 54\n",
    "\n",
    "gp55 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp55 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp55_results = pd.DataFrame(gp55).sort_values(by=[0], ascending=False)\n",
    "stp55_results = pd.DataFrame(stp55).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp55 = np.asarray(gp55_results[4:5][0])[0]\n",
    "median_gp55 = np.asarray(gp55_results[9:10][0])[0]\n",
    "upper_gp55 = np.asarray(gp55_results[14:15][0])[0]\n",
    "\n",
    "lower_stp55 = np.asarray(stp55_results[4:5][0])[0]\n",
    "median_stp55 = np.asarray(stp55_results[9:10][0])[0]\n",
    "upper_stp55 = np.asarray(stp55_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration65 :\n",
    "\n",
    "slice61 = 64\n",
    "\n",
    "gp65 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp65 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp65_results = pd.DataFrame(gp65).sort_values(by=[0], ascending=False)\n",
    "stp65_results = pd.DataFrame(stp65).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp65 = np.asarray(gp65_results[4:5][0])[0]\n",
    "median_gp65 = np.asarray(gp65_results[9:10][0])[0]\n",
    "upper_gp65 = np.asarray(gp65_results[14:15][0])[0]\n",
    "\n",
    "lower_stp65 = np.asarray(stp65_results[4:5][0])[0]\n",
    "median_stp65 = np.asarray(stp65_results[9:10][0])[0]\n",
    "upper_stp65 = np.asarray(stp65_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration75 :\n",
    "\n",
    "slice71 = 74\n",
    "\n",
    "gp75 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp75 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp75_results = pd.DataFrame(gp75).sort_values(by=[0], ascending=False)\n",
    "stp75_results = pd.DataFrame(stp75).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp75 = np.asarray(gp75_results[4:5][0])[0]\n",
    "median_gp75 = np.asarray(gp75_results[9:10][0])[0]\n",
    "upper_gp75 = np.asarray(gp75_results[14:15][0])[0]\n",
    "\n",
    "lower_stp75 = np.asarray(stp75_results[4:5][0])[0]\n",
    "median_stp75 = np.asarray(stp75_results[9:10][0])[0]\n",
    "upper_stp75 = np.asarray(stp75_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration85 :\n",
    "\n",
    "slice81 = 84\n",
    "\n",
    "gp85 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp85 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp85_results = pd.DataFrame(gp85).sort_values(by=[0], ascending=False)\n",
    "stp85_results = pd.DataFrame(stp85).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp85 = np.asarray(gp85_results[4:5][0])[0]\n",
    "median_gp85 = np.asarray(gp85_results[9:10][0])[0]\n",
    "upper_gp85 = np.asarray(gp85_results[14:15][0])[0]\n",
    "\n",
    "lower_stp85 = np.asarray(stp85_results[4:5][0])[0]\n",
    "median_stp85 = np.asarray(stp85_results[9:10][0])[0]\n",
    "upper_stp85 = np.asarray(stp85_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration95 :\n",
    "\n",
    "slice1 = 94\n",
    "\n",
    "gp95 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp95 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp95_results = pd.DataFrame(gp95).sort_values(by=[0], ascending=False)\n",
    "stp95_results = pd.DataFrame(stp95).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp95 = np.asarray(gp95_results[4:5][0])[0]\n",
    "median_gp95 = np.asarray(gp95_results[9:10][0])[0]\n",
    "upper_gp95 = np.asarray(gp95_results[14:15][0])[0]\n",
    "\n",
    "lower_stp95 = np.asarray(stp95_results[4:5][0])[0]\n",
    "median_stp95 = np.asarray(stp95_results[9:10][0])[0]\n",
    "upper_stp95 = np.asarray(stp95_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration6 :\n",
    "\n",
    "slice1 = 5\n",
    "\n",
    "gp6 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp6 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp6_results = pd.DataFrame(gp6).sort_values(by=[0], ascending=False)\n",
    "stp6_results = pd.DataFrame(stp6).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp6 = np.asarray(gp6_results[4:5][0])[0]\n",
    "median_gp6 = np.asarray(gp6_results[9:10][0])[0]\n",
    "upper_gp6 = np.asarray(gp6_results[14:15][0])[0]\n",
    "\n",
    "lower_stp6 = np.asarray(stp6_results[4:5][0])[0]\n",
    "median_stp6 = np.asarray(stp6_results[9:10][0])[0]\n",
    "upper_stp6 = np.asarray(stp6_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration16 :\n",
    "\n",
    "slice11 = 15\n",
    "\n",
    "gp16 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp16 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp16_results = pd.DataFrame(gp16).sort_values(by=[0], ascending=False)\n",
    "stp16_results = pd.DataFrame(stp16).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp16 = np.asarray(gp16_results[4:5][0])[0]\n",
    "median_gp16 = np.asarray(gp16_results[9:10][0])[0]\n",
    "upper_gp16 = np.asarray(gp16_results[14:15][0])[0]\n",
    "\n",
    "lower_stp16 = np.asarray(stp16_results[4:5][0])[0]\n",
    "median_stp16 = np.asarray(stp16_results[9:10][0])[0]\n",
    "upper_stp16 = np.asarray(stp16_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration26 :\n",
    "\n",
    "slice21 = 25\n",
    "\n",
    "gp26 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp26 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp26_results = pd.DataFrame(gp26).sort_values(by=[0], ascending=False)\n",
    "stp26_results = pd.DataFrame(stp26).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp26 = np.asarray(gp26_results[4:5][0])[0]\n",
    "median_gp26 = np.asarray(gp26_results[9:10][0])[0]\n",
    "upper_gp26 = np.asarray(gp26_results[14:15][0])[0]\n",
    "\n",
    "lower_stp26 = np.asarray(stp26_results[4:5][0])[0]\n",
    "median_stp26 = np.asarray(stp26_results[9:10][0])[0]\n",
    "upper_stp26 = np.asarray(stp26_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration36 :\n",
    "\n",
    "slice31 = 35\n",
    "\n",
    "gp36 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp36 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp36_results = pd.DataFrame(gp36).sort_values(by=[0], ascending=False)\n",
    "stp36_results = pd.DataFrame(stp36).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp36 = np.asarray(gp36_results[4:5][0])[0]\n",
    "median_gp36 = np.asarray(gp36_results[9:10][0])[0]\n",
    "upper_gp36 = np.asarray(gp36_results[14:15][0])[0]\n",
    "\n",
    "lower_stp36 = np.asarray(stp36_results[4:5][0])[0]\n",
    "median_stp36 = np.asarray(stp36_results[9:10][0])[0]\n",
    "upper_stp36 = np.asarray(stp36_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration46 :\n",
    "\n",
    "slice41 = 45\n",
    "\n",
    "gp46 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp46 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp46_results = pd.DataFrame(gp46).sort_values(by=[0], ascending=False)\n",
    "stp46_results = pd.DataFrame(stp46).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp46 = np.asarray(gp46_results[4:5][0])[0]\n",
    "median_gp46 = np.asarray(gp46_results[9:10][0])[0]\n",
    "upper_gp46 = np.asarray(gp46_results[14:15][0])[0]\n",
    "\n",
    "lower_stp46 = np.asarray(stp46_results[4:5][0])[0]\n",
    "median_stp46 = np.asarray(stp46_results[9:10][0])[0]\n",
    "upper_stp46 = np.asarray(stp46_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration56 :\n",
    "\n",
    "slice51 = 55\n",
    "\n",
    "gp56 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp56 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp56_results = pd.DataFrame(gp56).sort_values(by=[0], ascending=False)\n",
    "stp56_results = pd.DataFrame(stp56).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp56 = np.asarray(gp56_results[4:5][0])[0]\n",
    "median_gp56 = np.asarray(gp56_results[9:10][0])[0]\n",
    "upper_gp56 = np.asarray(gp56_results[14:15][0])[0]\n",
    "\n",
    "lower_stp56 = np.asarray(stp56_results[4:5][0])[0]\n",
    "median_stp56 = np.asarray(stp56_results[9:10][0])[0]\n",
    "upper_stp56 = np.asarray(stp56_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration66 :\n",
    "\n",
    "slice61 = 65\n",
    "\n",
    "gp66 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp66 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp66_results = pd.DataFrame(gp66).sort_values(by=[0], ascending=False)\n",
    "stp66_results = pd.DataFrame(stp66).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp66 = np.asarray(gp66_results[4:5][0])[0]\n",
    "median_gp66 = np.asarray(gp66_results[9:10][0])[0]\n",
    "upper_gp66 = np.asarray(gp66_results[14:15][0])[0]\n",
    "\n",
    "lower_stp66 = np.asarray(stp66_results[4:5][0])[0]\n",
    "median_stp66 = np.asarray(stp66_results[9:10][0])[0]\n",
    "upper_stp66 = np.asarray(stp66_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration76 :\n",
    "\n",
    "slice71 = 75\n",
    "\n",
    "gp76 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp76 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp76_results = pd.DataFrame(gp76).sort_values(by=[0], ascending=False)\n",
    "stp76_results = pd.DataFrame(stp76).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp76 = np.asarray(gp76_results[4:5][0])[0]\n",
    "median_gp76 = np.asarray(gp76_results[9:10][0])[0]\n",
    "upper_gp76 = np.asarray(gp76_results[14:15][0])[0]\n",
    "\n",
    "lower_stp76 = np.asarray(stp76_results[4:5][0])[0]\n",
    "median_stp76 = np.asarray(stp76_results[9:10][0])[0]\n",
    "upper_stp76 = np.asarray(stp76_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration86 :\n",
    "\n",
    "slice81 = 85\n",
    "\n",
    "gp86 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp86 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp86_results = pd.DataFrame(gp86).sort_values(by=[0], ascending=False)\n",
    "stp86_results = pd.DataFrame(stp86).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp86 = np.asarray(gp86_results[4:5][0])[0]\n",
    "median_gp86 = np.asarray(gp86_results[9:10][0])[0]\n",
    "upper_gp86 = np.asarray(gp86_results[14:15][0])[0]\n",
    "\n",
    "lower_stp86 = np.asarray(stp86_results[4:5][0])[0]\n",
    "median_stp86 = np.asarray(stp86_results[9:10][0])[0]\n",
    "upper_stp86 = np.asarray(stp86_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration96 :\n",
    "\n",
    "slice1 = 95\n",
    "\n",
    "gp96 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp96 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp96_results = pd.DataFrame(gp96).sort_values(by=[0], ascending=False)\n",
    "stp96_results = pd.DataFrame(stp96).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp96 = np.asarray(gp96_results[4:5][0])[0]\n",
    "median_gp96 = np.asarray(gp96_results[9:10][0])[0]\n",
    "upper_gp96 = np.asarray(gp96_results[14:15][0])[0]\n",
    "\n",
    "lower_stp96 = np.asarray(stp96_results[4:5][0])[0]\n",
    "median_stp96 = np.asarray(stp96_results[9:10][0])[0]\n",
    "upper_stp96 = np.asarray(stp96_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration7 :\n",
    "\n",
    "slice1 = 6\n",
    "\n",
    "gp7 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp7 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp7_results = pd.DataFrame(gp7).sort_values(by=[0], ascending=False)\n",
    "stp7_results = pd.DataFrame(stp7).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp7 = np.asarray(gp7_results[4:5][0])[0]\n",
    "median_gp7 = np.asarray(gp7_results[9:10][0])[0]\n",
    "upper_gp7 = np.asarray(gp7_results[14:15][0])[0]\n",
    "\n",
    "lower_stp7 = np.asarray(stp7_results[4:5][0])[0]\n",
    "median_stp7 = np.asarray(stp7_results[9:10][0])[0]\n",
    "upper_stp7 = np.asarray(stp7_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration17 :\n",
    "\n",
    "slice11 = 16\n",
    "\n",
    "gp17 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp17 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp17_results = pd.DataFrame(gp17).sort_values(by=[0], ascending=False)\n",
    "stp17_results = pd.DataFrame(stp17).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp17 = np.asarray(gp17_results[4:5][0])[0]\n",
    "median_gp17 = np.asarray(gp17_results[9:10][0])[0]\n",
    "upper_gp17 = np.asarray(gp17_results[14:15][0])[0]\n",
    "\n",
    "lower_stp17 = np.asarray(stp17_results[4:5][0])[0]\n",
    "median_stp17 = np.asarray(stp17_results[9:10][0])[0]\n",
    "upper_stp17 = np.asarray(stp17_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration27 :\n",
    "\n",
    "slice21 = 26\n",
    "\n",
    "gp27 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp27 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp27_results = pd.DataFrame(gp27).sort_values(by=[0], ascending=False)\n",
    "stp27_results = pd.DataFrame(stp27).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp27 = np.asarray(gp27_results[4:5][0])[0]\n",
    "median_gp27 = np.asarray(gp27_results[9:10][0])[0]\n",
    "upper_gp27 = np.asarray(gp27_results[14:15][0])[0]\n",
    "\n",
    "lower_stp27 = np.asarray(stp27_results[4:5][0])[0]\n",
    "median_stp27 = np.asarray(stp27_results[9:10][0])[0]\n",
    "upper_stp27 = np.asarray(stp27_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration37 :\n",
    "\n",
    "slice31 = 36\n",
    "\n",
    "gp37 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp37 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp37_results = pd.DataFrame(gp37).sort_values(by=[0], ascending=False)\n",
    "stp37_results = pd.DataFrame(stp37).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp37 = np.asarray(gp37_results[4:5][0])[0]\n",
    "median_gp37 = np.asarray(gp37_results[9:10][0])[0]\n",
    "upper_gp37 = np.asarray(gp37_results[14:15][0])[0]\n",
    "\n",
    "lower_stp37 = np.asarray(stp37_results[4:5][0])[0]\n",
    "median_stp37 = np.asarray(stp37_results[9:10][0])[0]\n",
    "upper_stp37 = np.asarray(stp37_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration47 :\n",
    "\n",
    "slice41 = 46\n",
    "\n",
    "gp47 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp47 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp47_results = pd.DataFrame(gp47).sort_values(by=[0], ascending=False)\n",
    "stp47_results = pd.DataFrame(stp47).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp47 = np.asarray(gp47_results[4:5][0])[0]\n",
    "median_gp47 = np.asarray(gp47_results[9:10][0])[0]\n",
    "upper_gp47 = np.asarray(gp47_results[14:15][0])[0]\n",
    "\n",
    "lower_stp47 = np.asarray(stp47_results[4:5][0])[0]\n",
    "median_stp47 = np.asarray(stp47_results[9:10][0])[0]\n",
    "upper_stp47 = np.asarray(stp47_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration57 :\n",
    "\n",
    "slice51 = 56\n",
    "\n",
    "gp57 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp57 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp57_results = pd.DataFrame(gp57).sort_values(by=[0], ascending=False)\n",
    "stp57_results = pd.DataFrame(stp57).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp57 = np.asarray(gp57_results[4:5][0])[0]\n",
    "median_gp57 = np.asarray(gp57_results[9:10][0])[0]\n",
    "upper_gp57 = np.asarray(gp57_results[14:15][0])[0]\n",
    "\n",
    "lower_stp57 = np.asarray(stp57_results[4:5][0])[0]\n",
    "median_stp57 = np.asarray(stp57_results[9:10][0])[0]\n",
    "upper_stp57 = np.asarray(stp57_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration67 :\n",
    "\n",
    "slice61 = 66\n",
    "\n",
    "gp67 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp67 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp67_results = pd.DataFrame(gp67).sort_values(by=[0], ascending=False)\n",
    "stp67_results = pd.DataFrame(stp67).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp67 = np.asarray(gp67_results[4:5][0])[0]\n",
    "median_gp67 = np.asarray(gp67_results[9:10][0])[0]\n",
    "upper_gp67 = np.asarray(gp67_results[14:15][0])[0]\n",
    "\n",
    "lower_stp67 = np.asarray(stp67_results[4:5][0])[0]\n",
    "median_stp67 = np.asarray(stp67_results[9:10][0])[0]\n",
    "upper_stp67 = np.asarray(stp67_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration77 :\n",
    "\n",
    "slice71 = 76\n",
    "\n",
    "gp77 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp77 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp77_results = pd.DataFrame(gp77).sort_values(by=[0], ascending=False)\n",
    "stp77_results = pd.DataFrame(stp77).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp77 = np.asarray(gp77_results[4:5][0])[0]\n",
    "median_gp77 = np.asarray(gp77_results[9:10][0])[0]\n",
    "upper_gp77 = np.asarray(gp77_results[14:15][0])[0]\n",
    "\n",
    "lower_stp77 = np.asarray(stp77_results[4:5][0])[0]\n",
    "median_stp77 = np.asarray(stp77_results[9:10][0])[0]\n",
    "upper_stp77 = np.asarray(stp77_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration87 :\n",
    "\n",
    "slice81 = 86\n",
    "\n",
    "gp87 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp87 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp87_results = pd.DataFrame(gp87).sort_values(by=[0], ascending=False)\n",
    "stp87_results = pd.DataFrame(stp87).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp87 = np.asarray(gp87_results[4:5][0])[0]\n",
    "median_gp87 = np.asarray(gp87_results[9:10][0])[0]\n",
    "upper_gp87 = np.asarray(gp87_results[14:15][0])[0]\n",
    "\n",
    "lower_stp87 = np.asarray(stp87_results[4:5][0])[0]\n",
    "median_stp87 = np.asarray(stp87_results[9:10][0])[0]\n",
    "upper_stp87 = np.asarray(stp87_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration97 :\n",
    "\n",
    "slice1 = 96\n",
    "\n",
    "gp97 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp97 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp97_results = pd.DataFrame(gp97).sort_values(by=[0], ascending=False)\n",
    "stp97_results = pd.DataFrame(stp97).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp97 = np.asarray(gp97_results[4:5][0])[0]\n",
    "median_gp97 = np.asarray(gp97_results[9:10][0])[0]\n",
    "upper_gp97 = np.asarray(gp97_results[14:15][0])[0]\n",
    "\n",
    "lower_stp97 = np.asarray(stp97_results[4:5][0])[0]\n",
    "median_stp97 = np.asarray(stp97_results[9:10][0])[0]\n",
    "upper_stp97 = np.asarray(stp97_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration8 :\n",
    "\n",
    "slice1 = 7\n",
    "\n",
    "gp8 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp8 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp8_results = pd.DataFrame(gp8).sort_values(by=[0], ascending=False)\n",
    "stp8_results = pd.DataFrame(stp8).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp8 = np.asarray(gp8_results[4:5][0])[0]\n",
    "median_gp8 = np.asarray(gp8_results[9:10][0])[0]\n",
    "upper_gp8 = np.asarray(gp8_results[14:15][0])[0]\n",
    "\n",
    "lower_stp8 = np.asarray(stp8_results[4:5][0])[0]\n",
    "median_stp8 = np.asarray(stp8_results[9:10][0])[0]\n",
    "upper_stp8 = np.asarray(stp8_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration18 :\n",
    "\n",
    "slice11 = 17\n",
    "\n",
    "gp18 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp18 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp18_results = pd.DataFrame(gp18).sort_values(by=[0], ascending=False)\n",
    "stp18_results = pd.DataFrame(stp18).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp18 = np.asarray(gp18_results[4:5][0])[0]\n",
    "median_gp18 = np.asarray(gp18_results[9:10][0])[0]\n",
    "upper_gp18 = np.asarray(gp18_results[14:15][0])[0]\n",
    "\n",
    "lower_stp18 = np.asarray(stp18_results[4:5][0])[0]\n",
    "median_stp18 = np.asarray(stp18_results[9:10][0])[0]\n",
    "upper_stp18 = np.asarray(stp18_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration28 :\n",
    "\n",
    "slice21 = 27\n",
    "\n",
    "gp28 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp28 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp28_results = pd.DataFrame(gp28).sort_values(by=[0], ascending=False)\n",
    "stp28_results = pd.DataFrame(stp28).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp28 = np.asarray(gp28_results[4:5][0])[0]\n",
    "median_gp28 = np.asarray(gp28_results[9:10][0])[0]\n",
    "upper_gp28 = np.asarray(gp28_results[14:15][0])[0]\n",
    "\n",
    "lower_stp28 = np.asarray(stp28_results[4:5][0])[0]\n",
    "median_stp28 = np.asarray(stp28_results[9:10][0])[0]\n",
    "upper_stp28 = np.asarray(stp28_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration38 :\n",
    "\n",
    "slice31 = 37\n",
    "\n",
    "gp38 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp38 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp38_results = pd.DataFrame(gp38).sort_values(by=[0], ascending=False)\n",
    "stp38_results = pd.DataFrame(stp38).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp38 = np.asarray(gp38_results[4:5][0])[0]\n",
    "median_gp38 = np.asarray(gp38_results[9:10][0])[0]\n",
    "upper_gp38 = np.asarray(gp38_results[14:15][0])[0]\n",
    "\n",
    "lower_stp38 = np.asarray(stp38_results[4:5][0])[0]\n",
    "median_stp38 = np.asarray(stp38_results[9:10][0])[0]\n",
    "upper_stp38 = np.asarray(stp38_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration48 :\n",
    "\n",
    "slice41 = 47\n",
    "\n",
    "gp48 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp48 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp48_results = pd.DataFrame(gp48).sort_values(by=[0], ascending=False)\n",
    "stp48_results = pd.DataFrame(stp48).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp48 = np.asarray(gp48_results[4:5][0])[0]\n",
    "median_gp48 = np.asarray(gp48_results[9:10][0])[0]\n",
    "upper_gp48 = np.asarray(gp48_results[14:15][0])[0]\n",
    "\n",
    "lower_stp48 = np.asarray(stp48_results[4:5][0])[0]\n",
    "median_stp48 = np.asarray(stp48_results[9:10][0])[0]\n",
    "upper_stp48 = np.asarray(stp48_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration58 :\n",
    "\n",
    "slice51 = 57\n",
    "\n",
    "gp58 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp58 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp58_results = pd.DataFrame(gp58).sort_values(by=[0], ascending=False)\n",
    "stp58_results = pd.DataFrame(stp58).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp58 = np.asarray(gp58_results[4:5][0])[0]\n",
    "median_gp58 = np.asarray(gp58_results[9:10][0])[0]\n",
    "upper_gp58 = np.asarray(gp58_results[14:15][0])[0]\n",
    "\n",
    "lower_stp58 = np.asarray(stp58_results[4:5][0])[0]\n",
    "median_stp58 = np.asarray(stp58_results[9:10][0])[0]\n",
    "upper_stp58 = np.asarray(stp58_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration68 :\n",
    "\n",
    "slice61 = 67\n",
    "\n",
    "gp68 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp68 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp68_results = pd.DataFrame(gp68).sort_values(by=[0], ascending=False)\n",
    "stp68_results = pd.DataFrame(stp68).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp68 = np.asarray(gp68_results[4:5][0])[0]\n",
    "median_gp68 = np.asarray(gp68_results[9:10][0])[0]\n",
    "upper_gp68 = np.asarray(gp68_results[14:15][0])[0]\n",
    "\n",
    "lower_stp68 = np.asarray(stp68_results[4:5][0])[0]\n",
    "median_stp68 = np.asarray(stp68_results[9:10][0])[0]\n",
    "upper_stp68 = np.asarray(stp68_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration78 :\n",
    "\n",
    "slice71 = 77\n",
    "\n",
    "gp78 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp78 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp78_results = pd.DataFrame(gp78).sort_values(by=[0], ascending=False)\n",
    "stp78_results = pd.DataFrame(stp78).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp78 = np.asarray(gp78_results[4:5][0])[0]\n",
    "median_gp78 = np.asarray(gp78_results[9:10][0])[0]\n",
    "upper_gp78 = np.asarray(gp78_results[14:15][0])[0]\n",
    "\n",
    "lower_stp78 = np.asarray(stp78_results[4:5][0])[0]\n",
    "median_stp78 = np.asarray(stp78_results[9:10][0])[0]\n",
    "upper_stp78 = np.asarray(stp78_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration88 :\n",
    "\n",
    "slice81 = 87\n",
    "\n",
    "gp88 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp88 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp88_results = pd.DataFrame(gp88).sort_values(by=[0], ascending=False)\n",
    "stp88_results = pd.DataFrame(stp88).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp88 = np.asarray(gp88_results[4:5][0])[0]\n",
    "median_gp88 = np.asarray(gp88_results[9:10][0])[0]\n",
    "upper_gp88 = np.asarray(gp88_results[14:15][0])[0]\n",
    "\n",
    "lower_stp88 = np.asarray(stp88_results[4:5][0])[0]\n",
    "median_stp88 = np.asarray(stp88_results[9:10][0])[0]\n",
    "upper_stp88 = np.asarray(stp88_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration98 :\n",
    "\n",
    "slice1 = 97\n",
    "\n",
    "gp98 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp98 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp98_results = pd.DataFrame(gp98).sort_values(by=[0], ascending=False)\n",
    "stp98_results = pd.DataFrame(stp98).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp98 = np.asarray(gp98_results[4:5][0])[0]\n",
    "median_gp98 = np.asarray(gp98_results[9:10][0])[0]\n",
    "upper_gp98 = np.asarray(gp98_results[14:15][0])[0]\n",
    "\n",
    "lower_stp98 = np.asarray(stp98_results[4:5][0])[0]\n",
    "median_stp98 = np.asarray(stp98_results[9:10][0])[0]\n",
    "upper_stp98 = np.asarray(stp98_results[14:15][0])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration9 :\n",
    "\n",
    "slice1 = 8\n",
    "\n",
    "gp9 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp9 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp9_results = pd.DataFrame(gp9).sort_values(by=[0], ascending=False)\n",
    "stp9_results = pd.DataFrame(stp9).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp9 = np.asarray(gp9_results[4:5][0])[0]\n",
    "median_gp9 = np.asarray(gp9_results[9:10][0])[0]\n",
    "upper_gp9 = np.asarray(gp9_results[14:15][0])[0]\n",
    "\n",
    "lower_stp9 = np.asarray(stp9_results[4:5][0])[0]\n",
    "median_stp9 = np.asarray(stp9_results[9:10][0])[0]\n",
    "upper_stp9 = np.asarray(stp9_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration19 :\n",
    "\n",
    "slice11 = 18\n",
    "\n",
    "gp19 = [train_regret_gp_1[slice11],\n",
    "       train_regret_gp_2[slice11],\n",
    "       train_regret_gp_3[slice11],\n",
    "       train_regret_gp_4[slice11],\n",
    "       train_regret_gp_5[slice11],\n",
    "       train_regret_gp_6[slice11],\n",
    "       train_regret_gp_7[slice11],\n",
    "       train_regret_gp_8[slice11],\n",
    "       train_regret_gp_9[slice11],\n",
    "       train_regret_gp_10[slice11],\n",
    "       train_regret_gp_11[slice11],\n",
    "       train_regret_gp_12[slice11],\n",
    "       train_regret_gp_13[slice11],\n",
    "       train_regret_gp_14[slice11],\n",
    "       train_regret_gp_15[slice11],\n",
    "       train_regret_gp_16[slice11],\n",
    "       train_regret_gp_17[slice11],\n",
    "       train_regret_gp_18[slice11],\n",
    "       train_regret_gp_19[slice11],\n",
    "       train_regret_gp_20[slice11]]\n",
    "\n",
    "stp19 = [train_regret_stp_df1_1[slice11],\n",
    "       train_regret_stp_df1_2[slice11],\n",
    "       train_regret_stp_df1_3[slice11],\n",
    "       train_regret_stp_df1_4[slice11],\n",
    "       train_regret_stp_df1_5[slice11],\n",
    "       train_regret_stp_df1_6[slice11],\n",
    "       train_regret_stp_df1_7[slice11],\n",
    "       train_regret_stp_df1_8[slice11],\n",
    "       train_regret_stp_df1_9[slice11],\n",
    "       train_regret_stp_df1_10[slice11],\n",
    "       train_regret_stp_df1_11[slice11],\n",
    "       train_regret_stp_df1_12[slice11],\n",
    "       train_regret_stp_df1_13[slice11],\n",
    "       train_regret_stp_df1_14[slice11],\n",
    "       train_regret_stp_df1_15[slice11],\n",
    "       train_regret_stp_df1_16[slice11],\n",
    "       train_regret_stp_df1_17[slice11],\n",
    "       train_regret_stp_df1_18[slice11],\n",
    "       train_regret_stp_df1_19[slice11],\n",
    "       train_regret_stp_df1_20[slice11]]\n",
    "\n",
    "gp19_results = pd.DataFrame(gp19).sort_values(by=[0], ascending=False)\n",
    "stp19_results = pd.DataFrame(stp19).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp19 = np.asarray(gp19_results[4:5][0])[0]\n",
    "median_gp19 = np.asarray(gp19_results[9:10][0])[0]\n",
    "upper_gp19 = np.asarray(gp19_results[14:15][0])[0]\n",
    "\n",
    "lower_stp19 = np.asarray(stp19_results[4:5][0])[0]\n",
    "median_stp19 = np.asarray(stp19_results[9:10][0])[0]\n",
    "upper_stp19 = np.asarray(stp19_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration29 :\n",
    "\n",
    "slice21 = 28\n",
    "\n",
    "gp29 = [train_regret_gp_1[slice21],\n",
    "       train_regret_gp_2[slice21],\n",
    "       train_regret_gp_3[slice21],\n",
    "       train_regret_gp_4[slice21],\n",
    "       train_regret_gp_5[slice21],\n",
    "       train_regret_gp_6[slice21],\n",
    "       train_regret_gp_7[slice21],\n",
    "       train_regret_gp_8[slice21],\n",
    "       train_regret_gp_9[slice21],\n",
    "       train_regret_gp_10[slice21],\n",
    "       train_regret_gp_11[slice21],\n",
    "       train_regret_gp_12[slice21],\n",
    "       train_regret_gp_13[slice21],\n",
    "       train_regret_gp_14[slice21],\n",
    "       train_regret_gp_15[slice21],\n",
    "       train_regret_gp_16[slice21],\n",
    "       train_regret_gp_17[slice21],\n",
    "       train_regret_gp_18[slice21],\n",
    "       train_regret_gp_19[slice21],\n",
    "       train_regret_gp_20[slice21]]\n",
    "\n",
    "stp29 = [train_regret_stp_df1_1[slice21],\n",
    "       train_regret_stp_df1_2[slice21],\n",
    "       train_regret_stp_df1_3[slice21],\n",
    "       train_regret_stp_df1_4[slice21],\n",
    "       train_regret_stp_df1_5[slice21],\n",
    "       train_regret_stp_df1_6[slice21],\n",
    "       train_regret_stp_df1_7[slice21],\n",
    "       train_regret_stp_df1_8[slice21],\n",
    "       train_regret_stp_df1_9[slice21],\n",
    "       train_regret_stp_df1_10[slice21],\n",
    "       train_regret_stp_df1_11[slice21],\n",
    "       train_regret_stp_df1_12[slice21],\n",
    "       train_regret_stp_df1_13[slice21],\n",
    "       train_regret_stp_df1_14[slice21],\n",
    "       train_regret_stp_df1_15[slice21],\n",
    "       train_regret_stp_df1_16[slice21],\n",
    "       train_regret_stp_df1_17[slice21],\n",
    "       train_regret_stp_df1_18[slice21],\n",
    "       train_regret_stp_df1_19[slice21],\n",
    "       train_regret_stp_df1_20[slice21]]\n",
    "\n",
    "gp29_results = pd.DataFrame(gp29).sort_values(by=[0], ascending=False)\n",
    "stp29_results = pd.DataFrame(stp29).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp29 = np.asarray(gp29_results[4:5][0])[0]\n",
    "median_gp29 = np.asarray(gp29_results[9:10][0])[0]\n",
    "upper_gp29 = np.asarray(gp29_results[14:15][0])[0]\n",
    "\n",
    "lower_stp29 = np.asarray(stp29_results[4:5][0])[0]\n",
    "median_stp29 = np.asarray(stp29_results[9:10][0])[0]\n",
    "upper_stp29 = np.asarray(stp29_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration39 :\n",
    "\n",
    "slice31 = 38\n",
    "\n",
    "gp39 = [train_regret_gp_1[slice31],\n",
    "       train_regret_gp_2[slice31],\n",
    "       train_regret_gp_3[slice31],\n",
    "       train_regret_gp_4[slice31],\n",
    "       train_regret_gp_5[slice31],\n",
    "       train_regret_gp_6[slice31],\n",
    "       train_regret_gp_7[slice31],\n",
    "       train_regret_gp_8[slice31],\n",
    "       train_regret_gp_9[slice31],\n",
    "       train_regret_gp_10[slice31],\n",
    "       train_regret_gp_11[slice31],\n",
    "       train_regret_gp_12[slice31],\n",
    "       train_regret_gp_13[slice31],\n",
    "       train_regret_gp_14[slice31],\n",
    "       train_regret_gp_15[slice31],\n",
    "       train_regret_gp_16[slice31],\n",
    "       train_regret_gp_17[slice31],\n",
    "       train_regret_gp_18[slice31],\n",
    "       train_regret_gp_19[slice31],\n",
    "       train_regret_gp_20[slice31]]\n",
    "\n",
    "stp39 = [train_regret_stp_df1_1[slice31],\n",
    "       train_regret_stp_df1_2[slice31],\n",
    "       train_regret_stp_df1_3[slice31],\n",
    "       train_regret_stp_df1_4[slice31],\n",
    "       train_regret_stp_df1_5[slice31],\n",
    "       train_regret_stp_df1_6[slice31],\n",
    "       train_regret_stp_df1_7[slice31],\n",
    "       train_regret_stp_df1_8[slice31],\n",
    "       train_regret_stp_df1_9[slice31],\n",
    "       train_regret_stp_df1_10[slice31],\n",
    "       train_regret_stp_df1_11[slice31],\n",
    "       train_regret_stp_df1_12[slice31],\n",
    "       train_regret_stp_df1_13[slice31],\n",
    "       train_regret_stp_df1_14[slice31],\n",
    "       train_regret_stp_df1_15[slice31],\n",
    "       train_regret_stp_df1_16[slice31],\n",
    "       train_regret_stp_df1_17[slice31],\n",
    "       train_regret_stp_df1_18[slice31],\n",
    "       train_regret_stp_df1_19[slice31],\n",
    "       train_regret_stp_df1_20[slice31]]\n",
    "\n",
    "gp39_results = pd.DataFrame(gp39).sort_values(by=[0], ascending=False)\n",
    "stp39_results = pd.DataFrame(stp39).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp39 = np.asarray(gp39_results[4:5][0])[0]\n",
    "median_gp39 = np.asarray(gp39_results[9:10][0])[0]\n",
    "upper_gp39 = np.asarray(gp39_results[14:15][0])[0]\n",
    "\n",
    "lower_stp39 = np.asarray(stp39_results[4:5][0])[0]\n",
    "median_stp39 = np.asarray(stp39_results[9:10][0])[0]\n",
    "upper_stp39 = np.asarray(stp39_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration49 :\n",
    "\n",
    "slice41 = 48\n",
    "\n",
    "gp49 = [train_regret_gp_1[slice41],\n",
    "       train_regret_gp_2[slice41],\n",
    "       train_regret_gp_3[slice41],\n",
    "       train_regret_gp_4[slice41],\n",
    "       train_regret_gp_5[slice41],\n",
    "       train_regret_gp_6[slice41],\n",
    "       train_regret_gp_7[slice41],\n",
    "       train_regret_gp_8[slice41],\n",
    "       train_regret_gp_9[slice41],\n",
    "       train_regret_gp_10[slice41],\n",
    "       train_regret_gp_11[slice41],\n",
    "       train_regret_gp_12[slice41],\n",
    "       train_regret_gp_13[slice41],\n",
    "       train_regret_gp_14[slice41],\n",
    "       train_regret_gp_15[slice41],\n",
    "       train_regret_gp_16[slice41],\n",
    "       train_regret_gp_17[slice41],\n",
    "       train_regret_gp_18[slice41],\n",
    "       train_regret_gp_19[slice41],\n",
    "       train_regret_gp_20[slice41]]\n",
    "\n",
    "stp49 = [train_regret_stp_df1_1[slice41],\n",
    "       train_regret_stp_df1_2[slice41],\n",
    "       train_regret_stp_df1_3[slice41],\n",
    "       train_regret_stp_df1_4[slice41],\n",
    "       train_regret_stp_df1_5[slice41],\n",
    "       train_regret_stp_df1_6[slice41],\n",
    "       train_regret_stp_df1_7[slice41],\n",
    "       train_regret_stp_df1_8[slice41],\n",
    "       train_regret_stp_df1_9[slice41],\n",
    "       train_regret_stp_df1_10[slice41],\n",
    "       train_regret_stp_df1_11[slice41],\n",
    "       train_regret_stp_df1_12[slice41],\n",
    "       train_regret_stp_df1_13[slice41],\n",
    "       train_regret_stp_df1_14[slice41],\n",
    "       train_regret_stp_df1_15[slice41],\n",
    "       train_regret_stp_df1_16[slice41],\n",
    "       train_regret_stp_df1_17[slice41],\n",
    "       train_regret_stp_df1_18[slice41],\n",
    "       train_regret_stp_df1_19[slice41],\n",
    "       train_regret_stp_df1_20[slice41]]\n",
    "\n",
    "gp49_results = pd.DataFrame(gp49).sort_values(by=[0], ascending=False)\n",
    "stp49_results = pd.DataFrame(stp49).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp49 = np.asarray(gp49_results[4:5][0])[0]\n",
    "median_gp49 = np.asarray(gp49_results[9:10][0])[0]\n",
    "upper_gp49 = np.asarray(gp49_results[14:15][0])[0]\n",
    "\n",
    "lower_stp49 = np.asarray(stp49_results[4:5][0])[0]\n",
    "median_stp49 = np.asarray(stp49_results[9:10][0])[0]\n",
    "upper_stp49 = np.asarray(stp49_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration59 :\n",
    "\n",
    "slice51 = 58\n",
    "\n",
    "gp59 = [train_regret_gp_1[slice51],\n",
    "       train_regret_gp_2[slice51],\n",
    "       train_regret_gp_3[slice51],\n",
    "       train_regret_gp_4[slice51],\n",
    "       train_regret_gp_5[slice51],\n",
    "       train_regret_gp_6[slice51],\n",
    "       train_regret_gp_7[slice51],\n",
    "       train_regret_gp_8[slice51],\n",
    "       train_regret_gp_9[slice51],\n",
    "       train_regret_gp_10[slice51],\n",
    "       train_regret_gp_11[slice51],\n",
    "       train_regret_gp_12[slice51],\n",
    "       train_regret_gp_13[slice51],\n",
    "       train_regret_gp_14[slice51],\n",
    "       train_regret_gp_15[slice51],\n",
    "       train_regret_gp_16[slice51],\n",
    "       train_regret_gp_17[slice51],\n",
    "       train_regret_gp_18[slice51],\n",
    "       train_regret_gp_19[slice51],\n",
    "       train_regret_gp_20[slice51]]\n",
    "\n",
    "stp59 = [train_regret_stp_df1_1[slice51],\n",
    "       train_regret_stp_df1_2[slice51],\n",
    "       train_regret_stp_df1_3[slice51],\n",
    "       train_regret_stp_df1_4[slice51],\n",
    "       train_regret_stp_df1_5[slice51],\n",
    "       train_regret_stp_df1_6[slice51],\n",
    "       train_regret_stp_df1_7[slice51],\n",
    "       train_regret_stp_df1_8[slice51],\n",
    "       train_regret_stp_df1_9[slice51],\n",
    "       train_regret_stp_df1_10[slice51],\n",
    "       train_regret_stp_df1_11[slice51],\n",
    "       train_regret_stp_df1_12[slice51],\n",
    "       train_regret_stp_df1_13[slice51],\n",
    "       train_regret_stp_df1_14[slice51],\n",
    "       train_regret_stp_df1_15[slice51],\n",
    "       train_regret_stp_df1_16[slice51],\n",
    "       train_regret_stp_df1_17[slice51],\n",
    "       train_regret_stp_df1_18[slice51],\n",
    "       train_regret_stp_df1_19[slice51],\n",
    "       train_regret_stp_df1_20[slice51]]\n",
    "\n",
    "gp59_results = pd.DataFrame(gp59).sort_values(by=[0], ascending=False)\n",
    "stp59_results = pd.DataFrame(stp59).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp59 = np.asarray(gp59_results[4:5][0])[0]\n",
    "median_gp59 = np.asarray(gp59_results[9:10][0])[0]\n",
    "upper_gp59 = np.asarray(gp59_results[14:15][0])[0]\n",
    "\n",
    "lower_stp59 = np.asarray(stp59_results[4:5][0])[0]\n",
    "median_stp59 = np.asarray(stp59_results[9:10][0])[0]\n",
    "upper_stp59 = np.asarray(stp59_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration69 :\n",
    "\n",
    "slice61 = 68\n",
    "\n",
    "gp69 = [train_regret_gp_1[slice61],\n",
    "       train_regret_gp_2[slice61],\n",
    "       train_regret_gp_3[slice61],\n",
    "       train_regret_gp_4[slice61],\n",
    "       train_regret_gp_5[slice61],\n",
    "       train_regret_gp_6[slice61],\n",
    "       train_regret_gp_7[slice61],\n",
    "       train_regret_gp_8[slice61],\n",
    "       train_regret_gp_9[slice61],\n",
    "       train_regret_gp_10[slice61],\n",
    "       train_regret_gp_11[slice61],\n",
    "       train_regret_gp_12[slice61],\n",
    "       train_regret_gp_13[slice61],\n",
    "       train_regret_gp_14[slice61],\n",
    "       train_regret_gp_15[slice61],\n",
    "       train_regret_gp_16[slice61],\n",
    "       train_regret_gp_17[slice61],\n",
    "       train_regret_gp_18[slice61],\n",
    "       train_regret_gp_19[slice61],\n",
    "       train_regret_gp_20[slice61]]\n",
    "\n",
    "stp69 = [train_regret_stp_df1_1[slice61],\n",
    "       train_regret_stp_df1_2[slice61],\n",
    "       train_regret_stp_df1_3[slice61],\n",
    "       train_regret_stp_df1_4[slice61],\n",
    "       train_regret_stp_df1_5[slice61],\n",
    "       train_regret_stp_df1_6[slice61],\n",
    "       train_regret_stp_df1_7[slice61],\n",
    "       train_regret_stp_df1_8[slice61],\n",
    "       train_regret_stp_df1_9[slice61],\n",
    "       train_regret_stp_df1_10[slice61],\n",
    "       train_regret_stp_df1_11[slice61],\n",
    "       train_regret_stp_df1_12[slice61],\n",
    "       train_regret_stp_df1_13[slice61],\n",
    "       train_regret_stp_df1_14[slice61],\n",
    "       train_regret_stp_df1_15[slice61],\n",
    "       train_regret_stp_df1_16[slice61],\n",
    "       train_regret_stp_df1_17[slice61],\n",
    "       train_regret_stp_df1_18[slice61],\n",
    "       train_regret_stp_df1_19[slice61],\n",
    "       train_regret_stp_df1_20[slice61]]\n",
    "\n",
    "gp69_results = pd.DataFrame(gp69).sort_values(by=[0], ascending=False)\n",
    "stp69_results = pd.DataFrame(stp69).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp69 = np.asarray(gp69_results[4:5][0])[0]\n",
    "median_gp69 = np.asarray(gp69_results[9:10][0])[0]\n",
    "upper_gp69 = np.asarray(gp69_results[14:15][0])[0]\n",
    "\n",
    "lower_stp69 = np.asarray(stp69_results[4:5][0])[0]\n",
    "median_stp69 = np.asarray(stp69_results[9:10][0])[0]\n",
    "upper_stp69 = np.asarray(stp69_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration79 :\n",
    "\n",
    "slice71 = 78\n",
    "\n",
    "gp79 = [train_regret_gp_1[slice71],\n",
    "       train_regret_gp_2[slice71],\n",
    "       train_regret_gp_3[slice71],\n",
    "       train_regret_gp_4[slice71],\n",
    "       train_regret_gp_5[slice71],\n",
    "       train_regret_gp_6[slice71],\n",
    "       train_regret_gp_7[slice71],\n",
    "       train_regret_gp_8[slice71],\n",
    "       train_regret_gp_9[slice71],\n",
    "       train_regret_gp_10[slice71],\n",
    "       train_regret_gp_11[slice71],\n",
    "       train_regret_gp_12[slice71],\n",
    "       train_regret_gp_13[slice71],\n",
    "       train_regret_gp_14[slice71],\n",
    "       train_regret_gp_15[slice71],\n",
    "       train_regret_gp_16[slice71],\n",
    "       train_regret_gp_17[slice71],\n",
    "       train_regret_gp_18[slice71],\n",
    "       train_regret_gp_19[slice71],\n",
    "       train_regret_gp_20[slice71]]\n",
    "\n",
    "stp79 = [train_regret_stp_df1_1[slice71],\n",
    "       train_regret_stp_df1_2[slice71],\n",
    "       train_regret_stp_df1_3[slice71],\n",
    "       train_regret_stp_df1_4[slice71],\n",
    "       train_regret_stp_df1_5[slice71],\n",
    "       train_regret_stp_df1_6[slice71],\n",
    "       train_regret_stp_df1_7[slice71],\n",
    "       train_regret_stp_df1_8[slice71],\n",
    "       train_regret_stp_df1_9[slice71],\n",
    "       train_regret_stp_df1_10[slice71],\n",
    "       train_regret_stp_df1_11[slice71],\n",
    "       train_regret_stp_df1_12[slice71],\n",
    "       train_regret_stp_df1_13[slice71],\n",
    "       train_regret_stp_df1_14[slice71],\n",
    "       train_regret_stp_df1_15[slice71],\n",
    "       train_regret_stp_df1_16[slice71],\n",
    "       train_regret_stp_df1_17[slice71],\n",
    "       train_regret_stp_df1_18[slice71],\n",
    "       train_regret_stp_df1_19[slice71],\n",
    "       train_regret_stp_df1_20[slice71]]\n",
    "\n",
    "gp79_results = pd.DataFrame(gp79).sort_values(by=[0], ascending=False)\n",
    "stp79_results = pd.DataFrame(stp79).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp79 = np.asarray(gp79_results[4:5][0])[0]\n",
    "median_gp79 = np.asarray(gp79_results[9:10][0])[0]\n",
    "upper_gp79 = np.asarray(gp79_results[14:15][0])[0]\n",
    "\n",
    "lower_stp79 = np.asarray(stp79_results[4:5][0])[0]\n",
    "median_stp79 = np.asarray(stp79_results[9:10][0])[0]\n",
    "upper_stp79 = np.asarray(stp79_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration89 :\n",
    "\n",
    "slice81 = 88\n",
    "\n",
    "gp89 = [train_regret_gp_1[slice81],\n",
    "       train_regret_gp_2[slice81],\n",
    "       train_regret_gp_3[slice81],\n",
    "       train_regret_gp_4[slice81],\n",
    "       train_regret_gp_5[slice81],\n",
    "       train_regret_gp_6[slice81],\n",
    "       train_regret_gp_7[slice81],\n",
    "       train_regret_gp_8[slice81],\n",
    "       train_regret_gp_9[slice81],\n",
    "       train_regret_gp_10[slice81],\n",
    "       train_regret_gp_11[slice81],\n",
    "       train_regret_gp_12[slice81],\n",
    "       train_regret_gp_13[slice81],\n",
    "       train_regret_gp_14[slice81],\n",
    "       train_regret_gp_15[slice81],\n",
    "       train_regret_gp_16[slice81],\n",
    "       train_regret_gp_17[slice81],\n",
    "       train_regret_gp_18[slice81],\n",
    "       train_regret_gp_19[slice81],\n",
    "       train_regret_gp_20[slice81]]\n",
    "\n",
    "stp89 = [train_regret_stp_df1_1[slice81],\n",
    "       train_regret_stp_df1_2[slice81],\n",
    "       train_regret_stp_df1_3[slice81],\n",
    "       train_regret_stp_df1_4[slice81],\n",
    "       train_regret_stp_df1_5[slice81],\n",
    "       train_regret_stp_df1_6[slice81],\n",
    "       train_regret_stp_df1_7[slice81],\n",
    "       train_regret_stp_df1_8[slice81],\n",
    "       train_regret_stp_df1_9[slice81],\n",
    "       train_regret_stp_df1_10[slice81],\n",
    "       train_regret_stp_df1_11[slice81],\n",
    "       train_regret_stp_df1_12[slice81],\n",
    "       train_regret_stp_df1_13[slice81],\n",
    "       train_regret_stp_df1_14[slice81],\n",
    "       train_regret_stp_df1_15[slice81],\n",
    "       train_regret_stp_df1_16[slice81],\n",
    "       train_regret_stp_df1_17[slice81],\n",
    "       train_regret_stp_df1_18[slice81],\n",
    "       train_regret_stp_df1_19[slice81],\n",
    "       train_regret_stp_df1_20[slice81]]\n",
    "\n",
    "gp89_results = pd.DataFrame(gp89).sort_values(by=[0], ascending=False)\n",
    "stp89_results = pd.DataFrame(stp89).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp89 = np.asarray(gp89_results[4:5][0])[0]\n",
    "median_gp89 = np.asarray(gp89_results[9:10][0])[0]\n",
    "upper_gp89 = np.asarray(gp89_results[14:15][0])[0]\n",
    "\n",
    "lower_stp89 = np.asarray(stp89_results[4:5][0])[0]\n",
    "median_stp89 = np.asarray(stp89_results[9:10][0])[0]\n",
    "upper_stp89 = np.asarray(stp89_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.256704708026015, -6.671442029397026)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration99 :\n",
    "\n",
    "slice1 = 98\n",
    "\n",
    "gp99 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp99 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp99_results = pd.DataFrame(gp99).sort_values(by=[0], ascending=False)\n",
    "stp99_results = pd.DataFrame(stp99).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp99 = np.asarray(gp99_results[4:5][0])[0]\n",
    "median_gp99 = np.asarray(gp99_results[9:10][0])[0]\n",
    "upper_gp99 = np.asarray(gp99_results[14:15][0])[0]\n",
    "\n",
    "lower_stp99 = np.asarray(stp99_results[4:5][0])[0]\n",
    "median_stp99 = np.asarray(stp99_results[9:10][0])[0]\n",
    "upper_stp99 = np.asarray(stp99_results[14:15][0])[0]\n",
    "\n",
    "lower_gp99, lower_stp99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration10 :\n",
    "\n",
    "slice1 = 9\n",
    "\n",
    "gp10 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp10 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp10_results = pd.DataFrame(gp10).sort_values(by=[0], ascending=False)\n",
    "stp10_results = pd.DataFrame(stp10).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp10 = np.asarray(gp10_results[4:5][0])[0]\n",
    "median_gp10 = np.asarray(gp10_results[9:10][0])[0]\n",
    "upper_gp10 = np.asarray(gp10_results[14:15][0])[0]\n",
    "\n",
    "lower_stp10 = np.asarray(stp10_results[4:5][0])[0]\n",
    "median_stp10 = np.asarray(stp10_results[9:10][0])[0]\n",
    "upper_stp10 = np.asarray(stp10_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration20 :\n",
    "\n",
    "slice1 = 19\n",
    "\n",
    "gp20 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp20 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp20_results = pd.DataFrame(gp20).sort_values(by=[0], ascending=False)\n",
    "stp20_results = pd.DataFrame(stp20).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp20 = np.asarray(gp20_results[4:5][0])[0]\n",
    "median_gp20 = np.asarray(gp20_results[9:10][0])[0]\n",
    "upper_gp20 = np.asarray(gp20_results[14:15][0])[0]\n",
    "\n",
    "lower_stp20 = np.asarray(stp20_results[4:5][0])[0]\n",
    "median_stp20 = np.asarray(stp20_results[9:10][0])[0]\n",
    "upper_stp20 = np.asarray(stp20_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration30 :\n",
    "\n",
    "slice1 = 29\n",
    "\n",
    "gp30 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp30 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp30_results = pd.DataFrame(gp30).sort_values(by=[0], ascending=False)\n",
    "stp30_results = pd.DataFrame(stp30).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp30 = np.asarray(gp30_results[4:5][0])[0]\n",
    "median_gp30 = np.asarray(gp30_results[9:10][0])[0]\n",
    "upper_gp30 = np.asarray(gp30_results[14:15][0])[0]\n",
    "\n",
    "lower_stp30 = np.asarray(stp30_results[4:5][0])[0]\n",
    "median_stp30 = np.asarray(stp30_results[9:10][0])[0]\n",
    "upper_stp30 = np.asarray(stp30_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration40 :\n",
    "\n",
    "slice1 = 39\n",
    "\n",
    "gp40 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp40 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp40_results = pd.DataFrame(gp40).sort_values(by=[0], ascending=False)\n",
    "stp40_results = pd.DataFrame(stp40).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp40 = np.asarray(gp40_results[4:5][0])[0]\n",
    "median_gp40 = np.asarray(gp40_results[9:10][0])[0]\n",
    "upper_gp40 = np.asarray(gp40_results[14:15][0])[0]\n",
    "\n",
    "lower_stp40 = np.asarray(stp40_results[4:5][0])[0]\n",
    "median_stp40 = np.asarray(stp40_results[9:10][0])[0]\n",
    "upper_stp40 = np.asarray(stp40_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration50 :\n",
    "\n",
    "slice1 = 49\n",
    "\n",
    "gp50 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp50 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp50_results = pd.DataFrame(gp50).sort_values(by=[0], ascending=False)\n",
    "stp50_results = pd.DataFrame(stp50).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp50 = np.asarray(gp50_results[4:5][0])[0]\n",
    "median_gp50 = np.asarray(gp50_results[9:10][0])[0]\n",
    "upper_gp50 = np.asarray(gp50_results[14:15][0])[0]\n",
    "\n",
    "lower_stp50 = np.asarray(stp50_results[4:5][0])[0]\n",
    "median_stp50 = np.asarray(stp50_results[9:10][0])[0]\n",
    "upper_stp50 = np.asarray(stp50_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration60 :\n",
    "\n",
    "slice1 = 59\n",
    "\n",
    "gp60 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp60 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp60_results = pd.DataFrame(gp60).sort_values(by=[0], ascending=False)\n",
    "stp60_results = pd.DataFrame(stp60).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp60 = np.asarray(gp60_results[4:5][0])[0]\n",
    "median_gp60 = np.asarray(gp60_results[9:10][0])[0]\n",
    "upper_gp60 = np.asarray(gp60_results[14:15][0])[0]\n",
    "\n",
    "lower_stp60 = np.asarray(stp60_results[4:5][0])[0]\n",
    "median_stp60 = np.asarray(stp60_results[9:10][0])[0]\n",
    "upper_stp60 = np.asarray(stp60_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration70 :\n",
    "\n",
    "slice1 = 69\n",
    "\n",
    "gp70 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp70 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp70_results = pd.DataFrame(gp70).sort_values(by=[0], ascending=False)\n",
    "stp70_results = pd.DataFrame(stp70).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp70 = np.asarray(gp70_results[4:5][0])[0]\n",
    "median_gp70 = np.asarray(gp70_results[9:10][0])[0]\n",
    "upper_gp70 = np.asarray(gp70_results[14:15][0])[0]\n",
    "\n",
    "lower_stp70 = np.asarray(stp70_results[4:5][0])[0]\n",
    "median_stp70 = np.asarray(stp70_results[9:10][0])[0]\n",
    "upper_stp70 = np.asarray(stp70_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration80 :\n",
    "\n",
    "slice1 = 79\n",
    "\n",
    "gp80 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp80 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp80_results = pd.DataFrame(gp80).sort_values(by=[0], ascending=False)\n",
    "stp80_results = pd.DataFrame(stp80).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp80 = np.asarray(gp80_results[4:5][0])[0]\n",
    "median_gp80 = np.asarray(gp80_results[9:10][0])[0]\n",
    "upper_gp80 = np.asarray(gp80_results[14:15][0])[0]\n",
    "\n",
    "lower_stp80 = np.asarray(stp80_results[4:5][0])[0]\n",
    "median_stp80 = np.asarray(stp80_results[9:10][0])[0]\n",
    "upper_stp80 = np.asarray(stp80_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration90 :\n",
    "\n",
    "slice1 = 89\n",
    "\n",
    "gp90 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp90 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp90_results = pd.DataFrame(gp90).sort_values(by=[0], ascending=False)\n",
    "stp90_results = pd.DataFrame(stp90).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp90 = np.asarray(gp90_results[4:5][0])[0]\n",
    "median_gp90 = np.asarray(gp90_results[9:10][0])[0]\n",
    "upper_gp90 = np.asarray(gp90_results[14:15][0])[0]\n",
    "\n",
    "lower_stp90 = np.asarray(stp90_results[4:5][0])[0]\n",
    "median_stp90 = np.asarray(stp90_results[9:10][0])[0]\n",
    "upper_stp90 = np.asarray(stp90_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration100 :\n",
    "\n",
    "slice1 = 99\n",
    "\n",
    "gp100 = [train_regret_gp_1[slice1],\n",
    "       train_regret_gp_2[slice1],\n",
    "       train_regret_gp_3[slice1],\n",
    "       train_regret_gp_4[slice1],\n",
    "       train_regret_gp_5[slice1],\n",
    "       train_regret_gp_6[slice1],\n",
    "       train_regret_gp_7[slice1],\n",
    "       train_regret_gp_8[slice1],\n",
    "       train_regret_gp_9[slice1],\n",
    "       train_regret_gp_10[slice1],\n",
    "       train_regret_gp_11[slice1],\n",
    "       train_regret_gp_12[slice1],\n",
    "       train_regret_gp_13[slice1],\n",
    "       train_regret_gp_14[slice1],\n",
    "       train_regret_gp_15[slice1],\n",
    "       train_regret_gp_16[slice1],\n",
    "       train_regret_gp_17[slice1],\n",
    "       train_regret_gp_18[slice1],\n",
    "       train_regret_gp_19[slice1],\n",
    "       train_regret_gp_20[slice1]]\n",
    "\n",
    "stp100 = [train_regret_stp_df1_1[slice1],\n",
    "       train_regret_stp_df1_2[slice1],\n",
    "       train_regret_stp_df1_3[slice1],\n",
    "       train_regret_stp_df1_4[slice1],\n",
    "       train_regret_stp_df1_5[slice1],\n",
    "       train_regret_stp_df1_6[slice1],\n",
    "       train_regret_stp_df1_7[slice1],\n",
    "       train_regret_stp_df1_8[slice1],\n",
    "       train_regret_stp_df1_9[slice1],\n",
    "       train_regret_stp_df1_10[slice1],\n",
    "       train_regret_stp_df1_11[slice1],\n",
    "       train_regret_stp_df1_12[slice1],\n",
    "       train_regret_stp_df1_13[slice1],\n",
    "       train_regret_stp_df1_14[slice1],\n",
    "       train_regret_stp_df1_15[slice1],\n",
    "       train_regret_stp_df1_16[slice1],\n",
    "       train_regret_stp_df1_17[slice1],\n",
    "       train_regret_stp_df1_18[slice1],\n",
    "       train_regret_stp_df1_19[slice1],\n",
    "       train_regret_stp_df1_20[slice1]]\n",
    "\n",
    "gp100_results = pd.DataFrame(gp100).sort_values(by=[0], ascending=False)\n",
    "stp100_results = pd.DataFrame(stp100).sort_values(by=[0], ascending=False)\n",
    "\n",
    "### Best training regret minimization IQR - GP:\n",
    "lower_gp100 = np.asarray(gp100_results[4:5][0])[0]\n",
    "median_gp100 = np.asarray(gp100_results[9:10][0])[0]\n",
    "upper_gp100 = np.asarray(gp100_results[14:15][0])[0]\n",
    "\n",
    "lower_stp100 = np.asarray(stp100_results[4:5][0])[0]\n",
    "median_stp100 = np.asarray(stp100_results[9:10][0])[0]\n",
    "upper_stp100 = np.asarray(stp100_results[14:15][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9(a). Summarize Arrays: GPs\n",
    "\n",
    "lower_gp = [lower_gp1,\n",
    "            lower_gp2,\n",
    "            lower_gp3,\n",
    "            lower_gp4,\n",
    "            lower_gp5,\n",
    "            lower_gp6,\n",
    "            lower_gp7,\n",
    "            lower_gp8,\n",
    "            lower_gp9,\n",
    "            lower_gp10,\n",
    "            lower_gp11,\n",
    "            lower_gp12,\n",
    "            lower_gp13,\n",
    "            lower_gp14,\n",
    "            lower_gp15,\n",
    "            lower_gp16,\n",
    "            lower_gp17,\n",
    "            lower_gp18,\n",
    "            lower_gp19,\n",
    "            lower_gp20,\n",
    "            lower_gp21,\n",
    "            lower_gp22,\n",
    "            lower_gp23,\n",
    "            lower_gp24,\n",
    "            lower_gp25,\n",
    "            lower_gp26,\n",
    "            lower_gp27,\n",
    "            lower_gp28,\n",
    "            lower_gp29,\n",
    "            lower_gp30,\n",
    "            lower_gp31,\n",
    "            lower_gp32,\n",
    "            lower_gp33,\n",
    "            lower_gp34,\n",
    "            lower_gp35,\n",
    "            lower_gp36,\n",
    "            lower_gp37,\n",
    "            lower_gp38,\n",
    "            lower_gp39,\n",
    "            lower_gp40,\n",
    "            lower_gp41,\n",
    "            lower_gp42,\n",
    "            lower_gp43,\n",
    "            lower_gp44,\n",
    "            lower_gp45,\n",
    "            lower_gp46,\n",
    "            lower_gp47,\n",
    "            lower_gp48,\n",
    "            lower_gp49,\n",
    "            lower_gp50,\n",
    "            lower_gp51,\n",
    "            lower_gp52,\n",
    "            lower_gp53,\n",
    "            lower_gp54,\n",
    "            lower_gp55,\n",
    "            lower_gp56,\n",
    "            lower_gp57,\n",
    "            lower_gp58,\n",
    "            lower_gp59,\n",
    "            lower_gp60,\n",
    "            lower_gp61,\n",
    "            lower_gp62,\n",
    "            lower_gp63,\n",
    "            lower_gp64,\n",
    "            lower_gp65,\n",
    "            lower_gp66,\n",
    "            lower_gp67,\n",
    "            lower_gp68,\n",
    "            lower_gp69,\n",
    "            lower_gp70,\n",
    "            lower_gp71,\n",
    "            lower_gp72,\n",
    "            lower_gp73,\n",
    "            lower_gp74,\n",
    "            lower_gp75,\n",
    "            lower_gp76,\n",
    "            lower_gp77,\n",
    "            lower_gp78,\n",
    "            lower_gp79,\n",
    "            lower_gp80,\n",
    "            lower_gp81,\n",
    "            lower_gp82,\n",
    "            lower_gp83,\n",
    "            lower_gp84,\n",
    "            lower_gp85,\n",
    "            lower_gp86,\n",
    "            lower_gp87,\n",
    "            lower_gp88,\n",
    "            lower_gp89,\n",
    "            lower_gp90,\n",
    "            lower_gp91,\n",
    "            lower_gp92,\n",
    "            lower_gp93,\n",
    "            lower_gp94,\n",
    "            lower_gp95,\n",
    "            lower_gp96,\n",
    "            lower_gp97,\n",
    "            lower_gp98,\n",
    "            lower_gp99,\n",
    "            lower_gp100,\n",
    "            lower_gp101]\n",
    "\n",
    "median_gp = [median_gp1,\n",
    "            median_gp2,\n",
    "            median_gp3,\n",
    "            median_gp4,\n",
    "            median_gp5,\n",
    "            median_gp6,\n",
    "            median_gp7,\n",
    "            median_gp8,\n",
    "            median_gp9,\n",
    "            median_gp10,\n",
    "            median_gp11,\n",
    "            median_gp12,\n",
    "            median_gp13,\n",
    "            median_gp14,\n",
    "            median_gp15,\n",
    "            median_gp16,\n",
    "            median_gp17,\n",
    "            median_gp18,\n",
    "            median_gp19,\n",
    "            median_gp20,\n",
    "            median_gp21,\n",
    "            median_gp22,\n",
    "            median_gp23,\n",
    "            median_gp24,\n",
    "            median_gp25,\n",
    "            median_gp26,\n",
    "            median_gp27,\n",
    "            median_gp28,\n",
    "            median_gp29,\n",
    "            median_gp30,\n",
    "            median_gp31,\n",
    "            median_gp32,\n",
    "            median_gp33,\n",
    "            median_gp34,\n",
    "            median_gp35,\n",
    "            median_gp36,\n",
    "            median_gp37,\n",
    "            median_gp38,\n",
    "            median_gp39,\n",
    "            median_gp40,\n",
    "            median_gp41,\n",
    "            median_gp42,\n",
    "            median_gp43,\n",
    "            median_gp44,\n",
    "            median_gp45,\n",
    "            median_gp46,\n",
    "            median_gp47,\n",
    "            median_gp48,\n",
    "            median_gp49,\n",
    "            median_gp50,\n",
    "            median_gp51,\n",
    "            median_gp52,\n",
    "            median_gp53,\n",
    "            median_gp54,\n",
    "            median_gp55,\n",
    "            median_gp56,\n",
    "            median_gp57,\n",
    "            median_gp58,\n",
    "            median_gp59,\n",
    "            median_gp60,\n",
    "            median_gp61,\n",
    "            median_gp62,\n",
    "            median_gp63,\n",
    "            median_gp64,\n",
    "            median_gp65,\n",
    "            median_gp66,\n",
    "            median_gp67,\n",
    "            median_gp68,\n",
    "            median_gp69,\n",
    "            median_gp70,\n",
    "            median_gp71,\n",
    "            median_gp72,\n",
    "            median_gp73,\n",
    "            median_gp74,\n",
    "            median_gp75,\n",
    "            median_gp76,\n",
    "            median_gp77,\n",
    "            median_gp78,\n",
    "            median_gp79,\n",
    "            median_gp80,\n",
    "            median_gp81,\n",
    "            median_gp82,\n",
    "            median_gp83,\n",
    "            median_gp84,\n",
    "            median_gp85,\n",
    "            median_gp86,\n",
    "            median_gp87,\n",
    "            median_gp88,\n",
    "            median_gp89,\n",
    "            median_gp90,\n",
    "            median_gp91,\n",
    "            median_gp92,\n",
    "            median_gp93,\n",
    "            median_gp94,\n",
    "            median_gp95,\n",
    "            median_gp96,\n",
    "            median_gp97,\n",
    "            median_gp98,\n",
    "            median_gp99,\n",
    "            median_gp100,\n",
    "            median_gp101]\n",
    "\n",
    "upper_gp = [upper_gp1,\n",
    "            upper_gp2,\n",
    "            upper_gp3,\n",
    "            upper_gp4,\n",
    "            upper_gp5,\n",
    "            upper_gp6,\n",
    "            upper_gp7,\n",
    "            upper_gp8,\n",
    "            upper_gp9,\n",
    "            upper_gp10,\n",
    "            upper_gp11,\n",
    "            upper_gp12,\n",
    "            upper_gp13,\n",
    "            upper_gp14,\n",
    "            upper_gp15,\n",
    "            upper_gp16,\n",
    "            upper_gp17,\n",
    "            upper_gp18,\n",
    "            upper_gp19,\n",
    "            upper_gp20,\n",
    "            upper_gp21,\n",
    "            upper_gp22,\n",
    "            upper_gp23,\n",
    "            upper_gp24,\n",
    "            upper_gp25,\n",
    "            upper_gp26,\n",
    "            upper_gp27,\n",
    "            upper_gp28,\n",
    "            upper_gp29,\n",
    "            upper_gp30,\n",
    "            upper_gp31,\n",
    "            upper_gp32,\n",
    "            upper_gp33,\n",
    "            upper_gp34,\n",
    "            upper_gp35,\n",
    "            upper_gp36,\n",
    "            upper_gp37,\n",
    "            upper_gp38,\n",
    "            upper_gp39,\n",
    "            upper_gp40,\n",
    "            upper_gp41,\n",
    "            upper_gp42,\n",
    "            upper_gp43,\n",
    "            upper_gp44,\n",
    "            upper_gp45,\n",
    "            upper_gp46,\n",
    "            upper_gp47,\n",
    "            upper_gp48,\n",
    "            upper_gp49,\n",
    "            upper_gp50,\n",
    "            upper_gp51,\n",
    "            upper_gp52,\n",
    "            upper_gp53,\n",
    "            upper_gp54,\n",
    "            upper_gp55,\n",
    "            upper_gp56,\n",
    "            upper_gp57,\n",
    "            upper_gp58,\n",
    "            upper_gp59,\n",
    "            upper_gp60,\n",
    "            upper_gp61,\n",
    "            upper_gp62,\n",
    "            upper_gp63,\n",
    "            upper_gp64,\n",
    "            upper_gp65,\n",
    "            upper_gp66,\n",
    "            upper_gp67,\n",
    "            upper_gp68,\n",
    "            upper_gp69,\n",
    "            upper_gp70,\n",
    "            upper_gp71,\n",
    "            upper_gp72,\n",
    "            upper_gp73,\n",
    "            upper_gp74,\n",
    "            upper_gp75,\n",
    "            upper_gp76,\n",
    "            upper_gp77,\n",
    "            upper_gp78,\n",
    "            upper_gp79,\n",
    "            upper_gp80,\n",
    "            upper_gp81,\n",
    "            upper_gp82,\n",
    "            upper_gp83,\n",
    "            upper_gp84,\n",
    "            upper_gp85,\n",
    "            upper_gp86,\n",
    "            upper_gp87,\n",
    "            upper_gp88,\n",
    "            upper_gp89,\n",
    "            upper_gp90,\n",
    "            upper_gp91,\n",
    "            upper_gp92,\n",
    "            upper_gp93,\n",
    "            upper_gp94,\n",
    "            upper_gp95,\n",
    "            upper_gp96,\n",
    "            upper_gp97,\n",
    "            upper_gp98,\n",
    "            upper_gp99,\n",
    "            upper_gp100,\n",
    "            upper_gp101]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9(a). Summarize Arrays: STPs\n",
    "\n",
    "lower_stp = [lower_stp1,\n",
    "            lower_stp2,\n",
    "            lower_stp3,\n",
    "            lower_stp4,\n",
    "            lower_stp5,\n",
    "            lower_stp6,\n",
    "            lower_stp7,\n",
    "            lower_stp8,\n",
    "            lower_stp9,\n",
    "            lower_stp10,\n",
    "            lower_stp11,\n",
    "            lower_stp12,\n",
    "            lower_stp13,\n",
    "            lower_stp14,\n",
    "            lower_stp15,\n",
    "            lower_stp16,\n",
    "            lower_stp17,\n",
    "            lower_stp18,\n",
    "            lower_stp19,\n",
    "            lower_stp20,\n",
    "            lower_stp21,\n",
    "            lower_stp22,\n",
    "            lower_stp23,\n",
    "            lower_stp24,\n",
    "            lower_stp25,\n",
    "            lower_stp26,\n",
    "            lower_stp27,\n",
    "            lower_stp28,\n",
    "            lower_stp29,\n",
    "            lower_stp30,\n",
    "            lower_stp31,\n",
    "            lower_stp32,\n",
    "            lower_stp33,\n",
    "            lower_stp34,\n",
    "            lower_stp35,\n",
    "            lower_stp36,\n",
    "            lower_stp37,\n",
    "            lower_stp38,\n",
    "            lower_stp39,\n",
    "            lower_stp40,\n",
    "            lower_stp41,\n",
    "            lower_stp42,\n",
    "            lower_stp43,\n",
    "            lower_stp44,\n",
    "            lower_stp45,\n",
    "            lower_stp46,\n",
    "            lower_stp47,\n",
    "            lower_stp48,\n",
    "            lower_stp49,\n",
    "            lower_stp50,\n",
    "            lower_stp51,\n",
    "            lower_stp52,\n",
    "            lower_stp53,\n",
    "            lower_stp54,\n",
    "            lower_stp55,\n",
    "            lower_stp56,\n",
    "            lower_stp57,\n",
    "            lower_stp58,\n",
    "            lower_stp59,\n",
    "            lower_stp60,\n",
    "            lower_stp61,\n",
    "            lower_stp62,\n",
    "            lower_stp63,\n",
    "            lower_stp64,\n",
    "            lower_stp65,\n",
    "            lower_stp66,\n",
    "            lower_stp67,\n",
    "            lower_stp68,\n",
    "            lower_stp69,\n",
    "            lower_stp70,\n",
    "            lower_stp71,\n",
    "            lower_stp72,\n",
    "            lower_stp73,\n",
    "            lower_stp74,\n",
    "            lower_stp75,\n",
    "            lower_stp76,\n",
    "            lower_stp77,\n",
    "            lower_stp78,\n",
    "            lower_stp79,\n",
    "            lower_stp80,\n",
    "            lower_stp81,\n",
    "            lower_stp82,\n",
    "            lower_stp83,\n",
    "            lower_stp84,\n",
    "            lower_stp85,\n",
    "            lower_stp86,\n",
    "            lower_stp87,\n",
    "            lower_stp88,\n",
    "            lower_stp89,\n",
    "            lower_stp90,\n",
    "            lower_stp91,\n",
    "            lower_stp92,\n",
    "            lower_stp93,\n",
    "            lower_stp94,\n",
    "            lower_stp95,\n",
    "            lower_stp96,\n",
    "            lower_stp97,\n",
    "            lower_stp98,\n",
    "            lower_stp99,\n",
    "            lower_stp100,\n",
    "            lower_stp101]\n",
    "\n",
    "median_stp = [median_stp1,\n",
    "            median_stp2,\n",
    "            median_stp3,\n",
    "            median_stp4,\n",
    "            median_stp5,\n",
    "            median_stp6,\n",
    "            median_stp7,\n",
    "            median_stp8,\n",
    "            median_stp9,\n",
    "            median_stp10,\n",
    "            median_stp11,\n",
    "            median_stp12,\n",
    "            median_stp13,\n",
    "            median_stp14,\n",
    "            median_stp15,\n",
    "            median_stp16,\n",
    "            median_stp17,\n",
    "            median_stp18,\n",
    "            median_stp19,\n",
    "            median_stp20,\n",
    "            median_stp21,\n",
    "            median_stp22,\n",
    "            median_stp23,\n",
    "            median_stp24,\n",
    "            median_stp25,\n",
    "            median_stp26,\n",
    "            median_stp27,\n",
    "            median_stp28,\n",
    "            median_stp29,\n",
    "            median_stp30,\n",
    "            median_stp31,\n",
    "            median_stp32,\n",
    "            median_stp33,\n",
    "            median_stp34,\n",
    "            median_stp35,\n",
    "            median_stp36,\n",
    "            median_stp37,\n",
    "            median_stp38,\n",
    "            median_stp39,\n",
    "            median_stp40,\n",
    "            median_stp41,\n",
    "            median_stp42,\n",
    "            median_stp43,\n",
    "            median_stp44,\n",
    "            median_stp45,\n",
    "            median_stp46,\n",
    "            median_stp47,\n",
    "            median_stp48,\n",
    "            median_stp49,\n",
    "            median_stp50,\n",
    "            median_stp51,\n",
    "            median_stp52,\n",
    "            median_stp53,\n",
    "            median_stp54,\n",
    "            median_stp55,\n",
    "            median_stp56,\n",
    "            median_stp57,\n",
    "            median_stp58,\n",
    "            median_stp59,\n",
    "            median_stp60,\n",
    "            median_stp61,\n",
    "            median_stp62,\n",
    "            median_stp63,\n",
    "            median_stp64,\n",
    "            median_stp65,\n",
    "            median_stp66,\n",
    "            median_stp67,\n",
    "            median_stp68,\n",
    "            median_stp69,\n",
    "            median_stp70,\n",
    "            median_stp71,\n",
    "            median_stp72,\n",
    "            median_stp73,\n",
    "            median_stp74,\n",
    "            median_stp75,\n",
    "            median_stp76,\n",
    "            median_stp77,\n",
    "            median_stp78,\n",
    "            median_stp79,\n",
    "            median_stp80,\n",
    "            median_stp81,\n",
    "            median_stp82,\n",
    "            median_stp83,\n",
    "            median_stp84,\n",
    "            median_stp85,\n",
    "            median_stp86,\n",
    "            median_stp87,\n",
    "            median_stp88,\n",
    "            median_stp89,\n",
    "            median_stp90,\n",
    "            median_stp91,\n",
    "            median_stp92,\n",
    "            median_stp93,\n",
    "            median_stp94,\n",
    "            median_stp95,\n",
    "            median_stp96,\n",
    "            median_stp97,\n",
    "            median_stp98,\n",
    "            median_stp99,\n",
    "            median_stp100,\n",
    "            median_stp101]\n",
    "\n",
    "upper_stp = [upper_stp1,\n",
    "            upper_stp2,\n",
    "            upper_stp3,\n",
    "            upper_stp4,\n",
    "            upper_stp5,\n",
    "            upper_stp6,\n",
    "            upper_stp7,\n",
    "            upper_stp8,\n",
    "            upper_stp9,\n",
    "            upper_stp10,\n",
    "            upper_stp11,\n",
    "            upper_stp12,\n",
    "            upper_stp13,\n",
    "            upper_stp14,\n",
    "            upper_stp15,\n",
    "            upper_stp16,\n",
    "            upper_stp17,\n",
    "            upper_stp18,\n",
    "            upper_stp19,\n",
    "            upper_stp20,\n",
    "            upper_stp21,\n",
    "            upper_stp22,\n",
    "            upper_stp23,\n",
    "            upper_stp24,\n",
    "            upper_stp25,\n",
    "            upper_stp26,\n",
    "            upper_stp27,\n",
    "            upper_stp28,\n",
    "            upper_stp29,\n",
    "            upper_stp30,\n",
    "            upper_stp31,\n",
    "            upper_stp32,\n",
    "            upper_stp33,\n",
    "            upper_stp34,\n",
    "            upper_stp35,\n",
    "            upper_stp36,\n",
    "            upper_stp37,\n",
    "            upper_stp38,\n",
    "            upper_stp39,\n",
    "            upper_stp40,\n",
    "            upper_stp41,\n",
    "            upper_stp42,\n",
    "            upper_stp43,\n",
    "            upper_stp44,\n",
    "            upper_stp45,\n",
    "            upper_stp46,\n",
    "            upper_stp47,\n",
    "            upper_stp48,\n",
    "            upper_stp49,\n",
    "            upper_stp50,\n",
    "            upper_stp51,\n",
    "            upper_stp52,\n",
    "            upper_stp53,\n",
    "            upper_stp54,\n",
    "            upper_stp55,\n",
    "            upper_stp56,\n",
    "            upper_stp57,\n",
    "            upper_stp58,\n",
    "            upper_stp59,\n",
    "            upper_stp60,\n",
    "            upper_stp61,\n",
    "            upper_stp62,\n",
    "            upper_stp63,\n",
    "            upper_stp64,\n",
    "            upper_stp65,\n",
    "            upper_stp66,\n",
    "            upper_stp67,\n",
    "            upper_stp68,\n",
    "            upper_stp69,\n",
    "            upper_stp70,\n",
    "            upper_stp71,\n",
    "            upper_stp72,\n",
    "            upper_stp73,\n",
    "            upper_stp74,\n",
    "            upper_stp75,\n",
    "            upper_stp76,\n",
    "            upper_stp77,\n",
    "            upper_stp78,\n",
    "            upper_stp79,\n",
    "            upper_stp80,\n",
    "            upper_stp81,\n",
    "            upper_stp82,\n",
    "            upper_stp83,\n",
    "            upper_stp84,\n",
    "            upper_stp85,\n",
    "            upper_stp86,\n",
    "            upper_stp87,\n",
    "            upper_stp88,\n",
    "            upper_stp89,\n",
    "            upper_stp90,\n",
    "            upper_stp91,\n",
    "            upper_stp92,\n",
    "            upper_stp93,\n",
    "            upper_stp94,\n",
    "            upper_stp95,\n",
    "            upper_stp96,\n",
    "            upper_stp97,\n",
    "            upper_stp98,\n",
    "            upper_stp99,\n",
    "            upper_stp100,\n",
    "            upper_stp101]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 10. Visualise!\n",
    "\n",
    "title = obj_func\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(median_gp, color = 'Red')\n",
    "plt.plot(median_stp, color = 'Blue')\n",
    "\n",
    "xstar = np.arange(0, 101, step=1)\n",
    "plt.fill_between(xstar, lower_gp, upper_gp, facecolor = 'Red', alpha=0.4, label='GP ERM Regret: IQR')\n",
    "plt.fill_between(xstar, lower_stp, upper_stp, facecolor = 'Blue', alpha=0.4, label='STP ERM Regret: IQR ' r'($\\nu$' ' = {})'.format(df1))\n",
    "\n",
    "plt.title(title, weight = 'bold')\n",
    "plt.xlabel('(post-initialization) iteration $\\it{k}$', weight = 'bold') # x-axis label\n",
    "plt.ylabel('ln(Regret)', weight = 'bold') # y-axis label\n",
    "plt.legend(loc=0) # add plot legend\n",
    "\n",
    "plt.show() #visualise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
